section.name,search,action.outputtelemetry,action.outputtelemetry.param.anonymous,action.outputtelemetry.param.support,action.outputtelemetry.param.license,action.outputtelemetry.param.optinrequired,action.outputtelemetry.param.component,action.outputtelemetry.param.input,action.outputtelemetry.param.type,alert.suppress,alert.track,counttype,cron_schedule,dispatch.earliest_time,dispatch.latest_time,display.general.type,display.page.search.tab,enablesched,quantity,relation,alert.digest_mode,alert.expires,alert.suppress.period,action.email.sendresults,action.email.inline,description,dispatch.ttl,disabled,auto_summarize.dispatch.earliest_time,action.populate_lookup,action.populate_lookup.dest,run_on_startup,run_n_times,dispatchas,auto_summarize,auto_summarize.cron_schedule,display.visualizations.custom.splunk_monitoring_console.heatmap.showtooltip,display.visualizations.custom.splunk_monitoring_console.heatmap.basecolor,display.visualizations.custom.splunk_monitoring_console.heatmap.showlegend,display.visualizations.custom.splunk_monitoring_console.heatmap.showxaxis,display.visualizations.custom.splunk_monitoring_console.heatmap.showyaxis,display.visualizations.custom.splunk_monitoring_console.heatmap.legendtitle,display.visualizations.custom.splunk_monitoring_console.heatmap.xaxis,display.visualizations.custom.splunk_monitoring_console.heatmap.yaxis,displayview,action.email.usenssubject,display.events.fields,display.visualizations.show,request.ui_dispatch_app,request.ui_dispatch_view,alert.severity,alert.suppress.fields,display.page.search.mode,schedule_window,dispatch.lookups,is_visible,display.general.enablepreview,display.general.timerangepicker.show,display.visualizations.type,display.visualizations.chartheight,display.visualizations.charting.chart,display.visualizations.charting.legend.placement,display.visualizations.charting.chart.nullvaluemode,display.visualizations.charting.chart.stackmode,display.visualizations.charting.axistitley.text,display.visualizations.charting.axistitley.visibility,display.statistics.rownumbers,display.statistics.wrap,display.statistics.overlay,display.visualizations.charting.chart.style,display.visualizations.charting.legend.labelstyle.overflowmode,action.email.reportserverenabled,display.visualizations.charting.drilldown,display.statistics.drilldown
['instrumentation.lastSent'],"index=_telemetry source=telemetry sourcetype=splunk_telemetry_log status=success | fillnull value=anonymous visibility | eval anonymous_send_time = if(visibility LIKE ""%anonymous%"", _time, null) | eval license_send_time = if(visibility LIKE ""%license%"", _time, null) | eval support_send_time = if(visibility LIKE ""%support%"", _time, null) | stats latest(anonymous_send_time) as latest_anonymous_send_time latest(license_send_time) as latest_license_send_time latest(support_send_time) as latest_support_send_time",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.reportingErrorCount'],"index=_telemetry source=telemetry sourcetype=splunk_telemetry_log status=failed | fillnull value=anonymous visibility | stats count(eval(visibility LIKE ""%anonymous%"")) as anonymous_errors count(eval(visibility LIKE ""%license%"")) as license_errors count(eval(visibility LIKE ""%support%"")) as support_errors",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.anonymized.eventsByTime'],"(index=_introspection OR index=_telemetry) sourcetype=splunk_telemetry source=""http-stream"" visibility=*anonymous* | append [| savedsearch instrumentation.licenseUsage]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.support.eventsByTime'],"(index=_introspection OR index=_telemetry) sourcetype=splunk_telemetry source=""http-stream"" visibility=*support* | append [| savedsearch instrumentation.licenseUsage]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.deployment.clustering.indexer'],"| makeresults annotate=true | append [localop | rest /services/cluster/config] | sort -mode | head 1 | eval data=if(mode==""master"",""{""host"":""""+splunk_server+"""",""timezone"":""""+strftime(now(),""%z"")+"""",""multiSite"":""+multisite+"",""summaryReplication"":""+if(summary_replication=1,""true"",""false"")+"",""enabled"":true,""replicationFactor"":""+tostring(replication_factor)+"",""siteReplicationFactor"":""+coalesce(replace(replace(site_replication_factor, ""origin"", """"origin""""), ""total"", """"total""""), ""null"")+"",""siteSearchFactor"":""+coalesce(replace(replace(site_search_factor, ""origin"", """"origin""""), ""total"", """"total""""),""null"")+"",""searchFactor"":""+tostring(search_factor)+""}"",""{""host"":""""+splunk_server+"""",""timezone"":""""+strftime(now(),""%z"")+"""",""enabled"":false}"") | eval _time=now() | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.deployment.forwarders'],"index=_internal source=*metrics.log* TERM(group=tcpin_connections) (TERM(connectionType=cooked) OR TERM(connectionType=cookedSSL)) fwdType=* guid=* | rename sourceIp as forwarderHost | eval connectionType=case(fwdType==""uf"" or fwdType==""lwf"" or fwdType==""full"", fwdType, 1==1,""Splunk fwder"") | eval version=if(isnull(version),""pre 4.2"",version) | bin _time span=1d | stats sum(kb) as kb, latest(connectionType) as connectionType, latest(arch) as arch, latest(os) as os, latest(version) as version latest(forwarderHost) as forwarderHost by guid _time | stats estdc(forwarderHost) as numHosts estdc(guid) as numInstances `instrumentation_distribution_values(kb)` by connectionType arch os version _time | eval data=""{""hosts"":""+tostring(numHosts)+"",""instances"":""+tostring(numInstances)+"",""architecture"":""""+arch+"""",""os"":""""+os+"""",""splunkVersion"":""""+version+"""",""type"":""""+connectionType+"""",""bytes"":{"" + `instrumentation_distribution_strings(""kb"",1024,0)` + ""}}"" | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.deployment.app'],"| rest /services/apps/local | eval _time=now() | fields splunk_server title updated version disabled | eval data=""{""host"":""""+splunk_server+"""",""name"":""""+title+"""",""version"":""""+coalesce(version, """")+"""",""enabled"":""+if(disabled=0, ""true"", ""false"")+""}"" | eval date=strftime(_time, ""%Y-%m-%d"") | fields data _time date",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.deployment.node'],"index=_introspection sourcetype=splunk_disk_objects component::Partitions | bin _time span=1d | stats latest(data.free) as partitionFree, latest(data.capacity) as partitionCapacity by host data.fs_type data.mount_point _time | eval partitionUtilized=round(1-partitionFree/partitionCapacity,2) | eval partitions=""{""utilization"":""+`instrumentation_number_format(partitionUtilized,1,2)`+"",""capacity"":""+`instrumentation_number_format(partitionCapacity,1048576,0)`+"",""fileSystem"":""""+'data.fs_type' + """"}"" | stats delim="","" values(partitions) as partitions by host _time | rename _time as date | mvcombine partitions | rename date as _time | join type=left host _time [search index=_introspection sourcetype=splunk_resource_usage component::Hostwide | eval cpuUsage = 'data.cpu_system_pct' + 'data.cpu_user_pct' | rename data.mem_used as memUsage | bin _time span=1d | stats latest(data.cpu_count) as coreCount, latest(data.virtual_cpu_count) as virtualCoreCount, latest(data.mem) as memAvailable, latest(data.splunk_version) as splunkVersion, latest(data.cpu_arch) as cpuArch, latest(data.os_name) as osName, latest(data.os_name_ext) as osNameExt, latest(data.os_version) as osVersion, `instrumentation_distribution_values(cpuUsage)`, `instrumentation_distribution_values(memUsage)`, latest(data.instance_guid) as guid by host _time] | fillnull value=""null"" coreCount virtualCoreCount memAvailable | eval splunkVersion=coalesce(""""""+splunkVersion+"""""", ""null""), cpuArch=coalesce(""""""+cpuArch+"""""", ""null""), osName=coalesce(""""""+osName + """""", ""null""), osNameExt=coalesce(""""""+osNameExt+"""""", ""null""), osVersion=coalesce(""""""+osVersion+"""""", ""null""), guid=coalesce(""""""+guid+"""""", ""null"") | eval data = ""{""guid"":""+guid+"",""host"":""""+replace(host,"""""", ""\"""")+"""",""partitions"": "" + coalesce(""["" + partitions + ""]"", ""null"") + "",""cpu"":{""architecture"":""+cpuArch+"",""coreCount"":"" + tostring(coreCount)+ "",""virtualCoreCount"":""+tostring(virtualCoreCount)+"",""utilization"":{"" + `instrumentation_distribution_strings(""cpuUsage"",.01,2)` + ""}},""memory"":""+""{""capacity"":""+ `instrumentation_number_format(memAvailable,1048576,0)`+"",""utilization"":{"" + `instrumentation_distribution_strings(""memUsage"",1/memAvailable,2)` + ""}},""os"":""+osName+"",""osExt"":""+osNameExt + "",""osVersion"":""+osVersion+"",""splunkVersion"":""+splunkVersion+""}"" | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.deployment.index'],"| rest /services/data/indexes | join type=outer splunk_server title [| rest /services/data/indexes-extended] | append [| rest /services/data/indexes datatype=metric | join type=outer splunk_server title [| rest /services/data/indexes-extended datatype=metric]] | eval warm_bucket_size = if(isnotnull('bucket_dirs.home.warm_bucket_size'), 'bucket_dirs.home.warm_bucket_size', 'bucket_dirs.home.size') | eval cold_bucket_size_gb = tostring(round(coalesce('bucket_dirs.cold.bucket_size', 'bucket_dirs.cold.size', 0) / 1024, 2)) | eval warm_bucket_size_gb = tostring(round(coalesce(warm_bucket_size,0) / 1024, 2)) | eval hot_bucket_size = tostring(round(coalesce(total_size / 1024 - cold_bucket_size_gb - warm_bucket_size_gb, 0),2)) | eval hot_bucket_size_gb = tostring(round(coalesce(hot_bucket_size,0) / 1024, 2)) | eval thawed_bucket_size_gb = tostring(round(coalesce('bucket_dirs.thawed.bucket_size', 'bucket_dirs.thawed.size',0) / 1024, 2)) | eval warm_bucket_count = tostring(coalesce('bucket_dirs.home.warm_bucket_count', 0)) | eval hot_bucket_count = tostring(coalesce('bucket_dirs.home.hot_bucket_count',0)) | eval cold_bucket_count = tostring(coalesce('bucket_dirs.cold.bucket_count',0)) | eval thawed_bucket_count = tostring(coalesce('bucket_dirs.thawed.bucket_count',0)) | eval home_event_count = tostring(coalesce('bucket_dirs.home.event_count',0)) | eval cold_event_count = tostring(coalesce('bucket_dirs.cold.event_count',0)) | eval thawed_event_count = tostring(coalesce('bucket_dirs.thawed.event_count',0)) | eval home_bucket_capacity_gb = coalesce(if('homePath.maxDataSizeMB' == 0, """"unlimited"""", round('homePath.maxDataSizeMB' / 1024, 2)), """"unlimited"""") | eval cold_bucket_capacity_gb = coalesce(if('coldPath.maxDataSizeMB' == 0, """"unlimited"""", round('coldPath.maxDataSizeMB' / 1024, 2)), """"unlimited"""") | eval currentDBSizeGB = tostring(round(coalesce(currentDBSizeMB,0) / 1024, 2)) | eval maxTotalDataSizeGB = tostring(if(maxTotalDataSizeMB = 0, ""unlimited"", coalesce(round(maxTotalDataSizeMB / 1024, 2), ""null""))) | eval minTime = tostring(coalesce(strptime(minTime,""%Y-%m-%dT%H:%M:%S%z""),""null"")) | eval maxTime = tostring(coalesce(strptime(maxTime,""%Y-%m-%dT%H:%M:%S%z""),""null"")) | eval total_bucket_count = tostring(if(isnotnull(total_bucket_count), total_bucket_count, 0)) | eval totalEventCount = tostring(coalesce(totalEventCount, 0)) | eval total_raw_size_gb = tostring(coalesce(round(total_raw_size / 1024, 2), ""null"")) | eval index_type = coalesce(datatype ,""event"") | rename eai:acl.app as App | eval _time=now() | fields splunk_server, title,index_type, currentDBSizeGB, totalEventCount, total_bucket_count, total_raw_size_gb, minTime, maxTime, home_bucket_capacity_gb, cold_bucket_capacity_gb, hot_bucket_size_gb, warm_bucket_size_gb, cold_bucket_size_gb, thawed_bucket_size_gb, hot_bucket_count, warm_bucket_count, cold_bucket_count, thawed_bucket_count, home_event_count, cold_event_count, thawed_event_count, maxTotalDataSizeGB, maxHotBuckets, maxWarmDBCount App _time | eval data=""{""host"":""""+splunk_server+"""",""name"":""""+title+"""",""type"":""""+index_type+"""",""app"":""""+App+"""",""total"":{""currentDBSizeGB"":""+currentDBSizeGB+"",""maxDataSizeGB"":""+maxTotalDataSizeGB+"",""events"":""+totalEventCount+"",""buckets"":""+total_bucket_count+"",""rawSizeGB"":""+total_raw_size_gb+"",""minTime"":""+minTime+"",""maxTime"":""+maxTime+""},""buckets"":{""homeCapacityGB"":""+home_bucket_capacity_gb+"",""homeEventCount"":""+home_event_count+"",""coldCapacityGB"":""+cold_bucket_capacity_gb+"",""hot"":{""sizeGB"":""+hot_bucket_size_gb+"",""count"":""+hot_bucket_count+"",""max"":""+maxHotBuckets+""},""warm"":{""sizeGB"":""+warm_bucket_size_gb+"",""count"":""+warm_bucket_count+""},""cold"":{""sizeGB"":""+cold_bucket_size_gb+"",""count"":""+cold_bucket_count+"",""events"":""+cold_event_count+""},""thawed"":{""sizeGB"":""+thawed_bucket_size_gb+"",""count"":""+thawed_bucket_count+"",""events"":""+thawed_event_count+""}}}"" | eval date=strftime(_time, ""%Y-%m-%d"") | fields data _time date",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.licenseUsage'],"NOT() | append [search index=_telemetry type=RolloverSummary | eval date=strftime(_time-43200, ""%Y-%m-%d"") | eval licenseIDs=coalesce(replace(replace(replace(replace(licenseGuids,""["",""[""""),""]"",""""]""),"","","""",""""),"" "", """"),""null""), subgroup_id=coalesce(subgroupId, ""Production""), group_id=coalesce(""""""+licenseGroup+"""""", ""null""), lmGuid=coalesce(""""""+guid+"""""", ""null""), productType=coalesce(""""""+productType+"""""", ""null""), type_id=if(substr(stack,1,16)=""fixed-sourcetype"", ""fixed-sourcetype"",stack) | stats max(_time) as lastTime latest(stacksz) as stack_quota, latest(poolsz) as pool_quota, sum(b) as consumption by pool stack host lmGuid licenseIDs type_id group_id subgroup_id productType date | rename stack as stack_id | eval pool=""{""quota"":"" + pool_quota+"",""consumption"":""+consumption+""}"" | stats delim="","" values(pool) as pools, max(lastTime) as lastTime max(stack_quota) as stack_quota sum(consumption) as stack_consumption by stack_id group_id subgroup_id type_id lmGuid host licenseIDs productType date | mvcombine pools | eval _raw=""{""component"":""licensing.stack"",""data"":{""host"":""""+host+"""",""guid"":""+lmGuid+"",""name"":""""+replace(stack_id,"""""", ""\"""")+"""",""type"":"""" + type_id + """",""subgroup"":"""" + subgroup_id + """",""product"":""+productType+"",""quota"":"" + stack_quota+"",""consumption"":""+stack_consumption+"",""pools"":[""+pools+""],""licenseIDs"":""+licenseIDs+""}, ""date"":""""+date+"""",""visibility"":""anonymous,license""}"", _time=lastTime]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.licensing.stack'],"index=_telemetry source=*license_usage_summary.log* sourcetype=splunkd TERM(type=RolloverSummary) | eval date=strftime(_time, ""%m-%d-%Y""), licenseIDs=coalesce(replace(replace(replace(replace(licenseGuids,""["",""[""""),""]"",""""]""),"","","""",""""),"" "", """"),""null""), subgroup_id=coalesce(subgroupId, ""Production""), group_id=coalesce(""""""+licenseGroup+"""""", ""null""), lmGuid=coalesce(""""""+guid+"""""", ""null""), productType=coalesce(""""""+productType+"""""", ""null""), type_id=if(substr(stack,1,16)=""fixed-sourcetype"", ""fixed-sourcetype"",stack) | stats latest(stacksz) as stack_quota, latest(poolsz) as pool_quota, sum(b) as consumption by pool stack host lmGuid licenseIDs type_id group_id subgroup_id productType date | rename stack as stack_id | eval pool=""{""quota"":"" + pool_quota+"",""consumption"":""+consumption+""}"" | stats delim="","" values(pool) as pools, max(stack_quota) as stack_quota sum(consumption) as stack_consumption by stack_id group_id subgroup_id type_id lmGuid host licenseIDs productType date | mvcombine pools | eval data=""{""host"":""""+host+"""",""guid"":""+lmGuid+"",""name"":""""+replace(stack_id,"""""", ""\"""")+"""",""type"":"""" + type_id + """",""subgroup"":"""" + subgroup_id + """",""product"":""+productType+"",""quota"":"" + stack_quota+"",""consumption"":""+stack_consumption+"",""pools"":[""+pools+""],""licenseIDs"":""+licenseIDs+""}"" | eval _time=strptime(date, ""%m-%d-%Y"")-43200 | fields data _time",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.performance.indexing'],"index=_internal TERM(group=thruput) TERM(name=index_thruput) source=*metrics.log* | bin _time span=30s | stats sum(kb) as kb sum(instantaneous_kbps) as instantaneous_kbps by host _time | bin _time span=1d | stats sum(kb) as totalKB `instrumentation_distribution_values(instantaneous_kbps)` by host _time | eval data=""{""host"":""""+host+"""",""thruput"":{""total"":"" + tostring(round(totalKB*1024)) + "","" + `instrumentation_distribution_strings(""instantaneous_kbps"",1024,0)`+""}}"" | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.performance.search'],"index=_audit sourcetype=audittrail TERM(action=search) TERM(info=completed) total_run_time=* | eval search_et=if(search_et=""N/A"", 0, search_et) | eval search_lt=if(search_lt=""N/A"", exec_time, min(exec_time,search_lt)) | eval timerange=search_lt-search_et | bin _time span=1d | stats latest(searched_buckets) as searched_buckets latest(total_slices) as total_slices latest(scan_count) as scan_count latest(timerange) as timerange latest(total_run_time) as runtime by search_id _time | stats `instrumentation_distribution_values(runtime)`, `instrumentation_distribution_values(searched_buckets)`, `instrumentation_distribution_values(total_slices)`, `instrumentation_distribution_values(scan_count)`, `instrumentation_distribution_values(timerange)` count as numSearches by _time | eval data=""{""searches"":""+tostring(numSearches)+"",""latency"":{""+`instrumentation_distribution_strings(""runtime"",1,2)`+""},""buckets"":{""+`instrumentation_distribution_strings(""searched_buckets"",1,2)`+""},""slices"":{""+`instrumentation_distribution_strings(""total_slices"",1,2)`+""},""scanCount"":{""+`instrumentation_distribution_strings(""scan_count"",1,2)`+""},""dayRange"":{""+`instrumentation_distribution_strings(""timerange"",1/86400,2)`+""}}"" | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.anonymous.firstEvent'],"(index=_introspection OR index=_telemetry) sourcetype=splunk_telemetry source=""http-stream"" visibility=*anonymous* | append [savedsearch instrumentation.licenseUsage] | where date >= ""$beginDate$"" AND date <= ""$endDate$"" | head 1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.support.firstEvent'],"(index=_introspection OR index=_telemetry) sourcetype=splunk_telemetry source=""http-stream"" visibility=*support* | append [savedsearch instrumentation.licenseUsage] | where date >= ""$beginDate$"" AND date <= ""$endDate$"" | head 1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.license.firstEvent'],"| savedsearch instrumentation.licenseUsage | where date >= ""$beginDate$"" AND date <= ""$endDate$"" | head 1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.reporting'],"index=_telemetry source=telemetry sourcetype=splunk_telemetry_log | fields _raw | spath | eval time_formatted = strftime(_time, ""%Y-%m-%d %H:%M:%S"") | search (status=success OR status=failed)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.reporting.errors'],index=_telemetry source=telemetry sourcetype=splunk_telemetry_log status=failed visibility=*$visibility$*,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.app.page'],"index=_internal sourcetype=splunk_web_access uri_path=""/*/app/*/*"" NOT uri_path=""/*/static/*"" | eval uri_parts=split(uri_path, ""/""),locale=mvindex(uri_parts,1), app=mvindex(uri_parts,3), page=mvindex(uri_parts,4) | bin _time span=1d | eventstats estdc(user) as appUsers count as appOccurrences by app _time | bin _time span=1d | stats latest(locale) as locale count as occurrences estdc(user) as users by app page appUsers appOccurrences _time | sort app -occurrences | streamstats count as pageRank by app _time | where pageRank<=10 | eval data=""{""app"":""""+app+"""",""page"":""""+page+"""",""locale"":""""+locale+"""",""occurrences"":"" + tostring(occurrences) + "",""users"":"" + tostring(users) + ""}"" | eval data=if(pageRank==1,data+"";{""app"":""""+app+"""",""locale"":""""+locale+"""",""occurrences"":"" + tostring(appOccurrences) + "",""users"":"" + tostring(appUsers) + ""}"", data) | stats values(data) as data by app appOccurrences appUsers _time | sort _time -appOccurrences | streamstats count as appRank by _time | where appRank<=25 | mvexpand data | makemv delim="";"" data | mvexpand data | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.indexing.sourcetype'],"index=_internal source=*metrics.log* TERM(group=per_sourcetype_thruput) | bin _time span=1d | stats sum(ev) as events, sum(kb) as size, estdc(host) as hosts by series _time | eval data=""{""name"":""""+replace(series,"""""", ""\"""") + """",""events"":""+tostring(events)+"",""bytes"":""+tostring(round(size*1024))+"",""hosts"":""+tostring(hosts)+""}"" | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.search.concurrent'],"index=_introspection sourcetype=splunk_resource_usage component::PerProcess data.search_props.sid::* | bin _time span=10s | stats estdc(data.search_props.sid) AS concurrent_searches by _time host | bin _time span=1d | stats `instrumentation_distribution_values(concurrent_searches)` by host _time | eval data=""{""host"":""""+host+"""",""searches"":{"" + `instrumentation_distribution_strings(""concurrent_searches"",1,0)` +""}}"" | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.search.type'],"index=_introspection sourcetype=splunk_resource_usage component::PerProcess data.search_props.sid::* | rename data.search_props.type as searchType | bin _time span=1d | stats estdc(data.search_props.sid) AS search_count by searchType _time | eval data=""""""+searchType+"""":""+tostring(search_count) | stats delim="","" values(data) as data by _time | rename _time as date | mvcombine data | eval data=""{""+data+""}"" | rename date as _time | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.users.active'],"index=_audit sourcetype=audittrail TERM(action=search) user!=""splunk-system-user"" user!=""n/a"" | bin _time span=1d | stats estdc(user) as active by _time | eval data=""{""active"":""+tostring(active)+""}"" | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.topology.deployment.clustering.member'],"| localop | rest /services/cluster/master/peers | eval data=""{""master"":""""+splunk_server+"""",""member"":{""host"":""""+label+"""",""guid"":""""+title+"""",""status"":""""+status+""""},""site"":""""+site+""""}"" | where isnotnull(data) | eval _time=now() | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.topology.deployment.clustering.searchhead'],"| localop | rest /services/cluster/master/searchheads | where splunk_server!=label | eval data=""{""master"":""""+splunk_server+"""",""searchhead"":{""host"":""""+label+"""",""guid"":""""+title+"""",""status"":""""+status+""""},""site"":""""+site+""""}"" | where isnotnull(data) | eval _time=now() | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.topology.deployment.shclustering.member'],"| localop | rest /services/shcluster/captain/members | eval data=""{""site"":""""+site+"""",""captain"":""""+splunk_server+"""",""member"":{""host"":""""+label+"""",""guid"":""""+title+"""",""status"":""""+status+""""}}"" | where isnotnull(data) | eval _time=now() | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.topology.deployment.distsearch.peer'],"| localop | rest /services/search/distributed/peers | eval data=""{""host"":""""+splunk_server+"""",""peer"":{""host"":""""+peerName+"""",""guid"":""""+guid+"""",""status"":""""+status+""""}}"" | where isnotnull(data) | eval _time=now() | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.topology.deployment.licensing.slave'],"| localop | rest /services/licenser/slaves | eval data=""{""master"":""""+splunk_server+"""",""slave"":{""host"":""""+label+"""",""guid"":""""+title+"""",""pool"":""""+active_pool_ids+""""}}"" | where isnotnull(data) | eval _time=now() | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.workloadManagement.enabled'],"NOT() | append [rest splunk_server=local /services/workloads/status | eval support='general.isSupported', enabled='general.enabled', os_name='general.os_name', os_version='general.os_version'| fields support, enabled, os_name, os_version, splunk_server]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.workloadManagement.pools'],"NOT() | append [rest splunk_server=local /services/workloads/pools | where NOT title=""general"" | eval data=""""""+title+"""":{""cpu weight"":""""+cpu_weight+"""", ""memory weight"":""""+mem_weight+""""}"" | stats list(data) AS poolList, count AS poolTotal by splunk_server | eval poolCombined=mvjoin(poolList, "", ""), Ingest_pools=if(poolTotal>0,1,0), Search_pools=if(poolTotal>0,poolTotal-1,0) | fields poolTotal, poolCombined, Ingest_pools, Search_pools, splunk_server]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.workloadManagement.rules'],"NOT() | append [rest splunk_server=local /services/workloads/rules | eval data=""""""+title+"""":{""order"":""""+order+"""", ""predicate"":""""+predicate+"""", ""workload pool"":""""+workload_pool+""""}"" | stats list(data) AS ruleList, count AS ruleTotal by splunk_server | eval ruleCombined=mvjoin(ruleList, "", "") | fields ruleTotal, ruleCombined, splunk_server]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.workloadManagement.report'],"|rest splunk_server=local /services/server/info | appendcols [|rest splunk_server=local /servicesNS/nobody/splunk_instrumentation/telemetry | fields telemetrySalt]| eval telemetrySalt=if(isnull(telemetrySalt), """", telemetrySalt), hashHost=sha1(telemetrySalt+splunk_server), roleCombine=mvjoin(server_roles, "", "") | fields guid, hashHost, roleCombine, splunk_server | join type=left splunk_server [|savedsearch instrumentation.usage.workloadManagement.enabled] | join type=left splunk_server [|savedsearch instrumentation.usage.workloadManagement.pools] | join type=left splunk_server [|savedsearch instrumentation.usage.workloadManagement.rules] | fillnull value=0 | eval data=""{""host"": """"+hashHost+"""", ""guid"": """"+guid+"""", ""wlm supported"": """"+support+"""", ""os"": """"+os_name+"""", ""osVersion"": """"+os_version+"""", ""wlm enabled"": """"+enabled+"""", ""server roles"": """"+roleCombine+"""""", poolTotal=if(isnull(poolTotal),0, poolTotal), Ingest_pools=if(isnull(Ingest_pools),0, Ingest_pools), Search_pools=if(isnull(Search_pools),0, Search_pools), ruleTotal=if(isnull(ruleTotal),0, ruleTotal) | eval data=if(support==1, data+"", ""pools"":{""total count"":""""+poolTotal+"""", ""ingest pool count"":""""+Ingest_pools+"""", ""search pool count"":""""+Search_pools+""""""+if(poolTotal>0, "", ""+poolCombined, """")+""}"" + "", ""rules"":{""total count"":""""+ruleTotal+""""""+if(ruleTotal>0, "", ""+ruleCombined, """")+""}}"", data+""}""), _time=now(), date=strftime(_time, ""%Y-%m-%d"")| fields _time date data",1,1,0,0,3,usage.workloadManagement.report,data,aggregate,0,0,number of events,0 3 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1,-1w,now,statistics,statistics,1,0,greater than,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.passwordPolicy.config'],"|rest splunk_server=local /services/admin/Splunk-auth/splunk_auth| join type=left splunk_server [|rest splunk_server=local /services/server/info | fields guid, splunk_server] | appendcols [|rest splunk_server=local /servicesNS/nobody/splunk_instrumentation/telemetry | fields telemetrySalt]| eval telemetrySalt=if(isnull(telemetrySalt), """", telemetrySalt), hashHost=sha1(telemetrySalt+splunk_server)| replace ""1"" with ""true"", ""0"" with ""false"" in enablePasswordHistory,expireUserAccounts, forceWeakPasswordChange, lockoutUsers, verboseLoginFailMsg | eval data=""{""host"": """"+hashHost+"""",""guid"": """"+guid+"""", ""constant login time"":""""+constantLoginTime+"""", ""enable password history"":""""+enablePasswordHistory+"""", ""expiration alert in days"":""""+expireAlertDays+"""", ""days until password expires"":""""+expirePasswordDays+"""", ""enable password expiration"":""""+expireUserAccounts+"""", ""force existing users to change weak passwords"":""""+forceWeakPasswordChange+"""", ""failed login attempts"":""""+lockoutAttempts+"""", ""lockout duration in minutes"":""""+lockoutMins+"""", ""lockout threshold in minutes"":""""+lockoutThresholdMins+"""", ""enable lockout users"":""""+lockoutUsers+"""", ""minimum number of digits"":""""+minPasswordDigit+"""", ""minimum number of characters"":""""+minPasswordLength+"""", ""minimum number of lowercase letters"":""""+minPasswordLowercase+"""", ""minimum number of special characters"":""""+minPasswordSpecial+"""", ""minimum number of uppercase letters"":""""+minPasswordUppercase+"""", ""password history count"":""""+passwordHistoryCount+"""", ""enable verbose login fail message"":""""+verboseLoginFailMsg+""""}"",_time=now(), date=strftime(_time, ""%Y-%m-%d"") | fields data _time date",1,1,0,0,3,usage.passwordPolicy.config,data,aggregate,0,0,number of events,0 3 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1,-1w,now,statistics,statistics,1,0,greater than,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.healthMonitor.report'],"|rest splunk_server=local /services/server/health-config | eval thresh="""" | foreach indicator*red,indicator*yellow [eval thresh =if('<<FIELD>>'!="""", thresh+""""<<FIELD>>"":"" + '<<FIELD>>' + "","", thresh)] | eval thresh=rtrim(thresh, "",""), enabled=if(disabled=='' or disabled==0 or isnull(disabled), 1,0) | eval feature=""""""+title+"""":{""threshold"": {""+thresh+""}, ""enabled"": """"+enabled+""""}"", distinct=if(like(title, ""feature%""), ""feature"", ""alert"") | eval disable=coalesce('alert.disabled', disabled), action=coalesce('alert.actions','action.to','action.url', 'action.integration_url_override') | eval action=if(action=="""" or isnull(action), ""empty"", action) | eval alert=""""""+title+"""": {""disabled"": """"+disable+"""", ""action/ action.to/ action.url/ action.integration_url_override"": """"+action+""""}"" | stats list(alert) AS alertList, list(feature) AS feaList by distinct | eval alertCombined=mvjoin(alertList, "",""), feaCombined=mvjoin(feaList, "","") | eval alertCombined=""""alert"":{""+alertCombined+""}"" | eval feaCombined=if(distinct==""alert"", null, feaCombined), alertCombined=if(distinct==""feature"", null, alertCombined) | eval dataCombined=coalesce(alertCombined, feaCombined) | stats list(dataCombined) AS dataList| eval data=mvjoin(dataList, "","") | eval data=""{""+data+""}"",_time=now(), date=strftime(_time, ""%Y-%m-%d"") | fields data _time date",1,1,0,0,3,usage.healthMonitor.report,data,aggregate,0,0,number of events,0 3 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1,-1w,now,statistics,statistics,1,0,greater than,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.authMethod.config'],"|rest splunk_server=local /services/admin/auth-services| join type=left splunk_server [|rest splunk_server=local /services/server/info | fields guid, splunk_server] | appendcols [|rest splunk_server=local /servicesNS/nobody/splunk_instrumentation/telemetry | fields telemetrySalt]| eval telemetrySalt=if(isnull(telemetrySalt), """", telemetrySalt), hashHost=sha1(telemetrySalt+splunk_server)| eval data=""{""host"": """"+hashHost+"""",""guid"": """"+guid+"""", ""authentication method"": """"+active_authmodule+"""",""mfa type"": "" +"""""" + if(mfa_type=="""", ""none"", mfa_type) +""""}"", _time=now(), date=strftime(_time, ""%Y-%m-%d"") | fields data _time date",1,1,0,0,3,usage.authMethod.config,data,aggregate,0,0,number of events,0 3 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1,-1w,now,statistics,statistics,1,0,greater than,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.smartStore.global'],"|rest splunk_server=local /services/configs/conf-server | where title in (""cachemanager"",""diskUsage"", ""clustering"") | eval data=""""""+title+"""":"",hotlist_recency_secs=if(isnull(hotlist_recency_secs), ""none"", hotlist_recency_secs), hotlist_bloom_filter_recency_hours=if(isnull(hotlist_bloom_filter_recency_hours), ""none"", hotlist_bloom_filter_recency_hours) | eval data=if(title=""diskUsage"", data+""{""minFreeSpace"":""""+minFreeSpace+""""}"", data), data=if(title=""cachemanager"", data+""{""eviction_padding"":""""+eviction_padding+"""",""max_cache_size"":""""+max_cache_size+"""", ""hotlist_recency_secs"":""""+hotlist_recency_secs+"""", ""hotlist_bloom_filter_recency_hours"":""""+hotlist_bloom_filter_recency_hours+""""}"", data), data=if(title=""clustering"", data+""{""mode"":""""+mode+""""""+if(mode=""master"", "",""search_factor"":""""+search_factor+"""",""multisite"":""""+multisite+"""",""site_replication_factor"":""""+site_replication_factor+"""",""site_search_factor"":""""+site_search_factor+""""}"", ""}""), data) | stats list(data) AS dataList BY splunk_server | eval globalConfig=""""global config"":{"" + mvjoin(dataList, "","") + ""}"" | fields globalConfig, splunk_server",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.smartStore.perIndex'],"|rest splunk_server=local /services/configs/conf-indexes | appendcols [|rest splunk_server=local /servicesNS/nobody/splunk_instrumentation/telemetry | fields telemetrySalt]| eval title_dist=if(match(title, ""^([^_].*?)s*""),""external"",""internal""), s2Enabled=if(isnotnull(remotePath),""SmartStore enabled"", ""non-SmartStore enabled""),hotlist_recency_secs=if(isnull(hotlist_recency_secs), ""none"", hotlist_recency_secs), hotlist_bloom_filter_recency_hours=if(isnull(hotlist_bloom_filter_recency_hours), ""none"", hotlist_bloom_filter_recency_hours) | makejson frozenTimePeriodInSecs, hotlist_recency_secs, hotlist_bloom_filter_recency_hours, maxHotSpanSecs, maxGlobalDataSizeMB, output=""indexConfig"" | eval telemetrySalt=if(isnull(telemetrySalt), """", telemetrySalt), hashTitle=sha1(telemetrySalt+title), title_combine=title_dist+""_""+hashTitle, indexConfig=""""""+title_combine+"""":"" + indexConfig | stats list(hashTitle) AS titleList,list(indexConfig) AS indexList BY s2Enabled, splunk_server | eval indexConfig=mvjoin(indexList, "",""), titleCombined=""""""+s2Enabled+"""":"""" + mvjoin(titleList, "","") +"""""" | stats list(titleCombined) AS s2List, list(indexConfig) AS indexList BY splunk_server| eval s2Enabled=""""list of indexes"":{"" + mvjoin(s2List, "","") + ""}"", indexConfig=""""per index config"":{"" + mvjoin(indexList, "","") + ""}"" | fields s2Enabled, indexConfig, splunk_server",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.smartStore.capacity'],"|rest splunk_server=local /services/server/status/partitions-space | makejson available, capacity, free, fs_type, output=""cap"" | eval cap=""""""+title+"""": ""+cap+"""" | stats list(cap) AS capList BY splunk_server | eval capCombined=""""total storage capacity"":{"" + mvjoin(capList, "", "") + ""}"" | fields capCombined, splunk_server",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.smartStore.config'],"|savedsearch instrumentation.usage.smartStore.global | join type=left splunk_server [|savedsearch instrumentation.usage.smartStore.perIndex] | join type=left splunk_server [|savedsearch instrumentation.usage.smartStore.capacity] | eval data=""{""+globalConfig+"", ""+capCombined+"", ""+indexConfig+"", ""+s2Enabled+""}"",_time=now(), date=strftime(_time, ""%Y-%m-%d"") | fields data _time date",1,1,0,0,3,usage.smartStore.Config,data,aggregate,0,0,number of events,0 3 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1,-1w,now,statistics,statistics,1,0,greater than,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.search.report_acceleration'],"| localop | rest /servicesNS/-/-/admin/summarization | stats count as existing_report_accelerations, sum(summary.access_count) as access_count_of_existing_report_accelerations | makejson access_count_of_existing_report_accelerations(int) existing_report_accelerations(int) output=""data"" | eval _time=now(), date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.search.searchTelemetry'],"index=_introspection sourcetype=search_telemetry | rename search_commands{}.name as name | stats count by name | makejson output=commands | fields commands | mvcombine delim="","" commands | nomv commands | eval _time=now(), date=strftime(_time, ""%Y-%m-%d"") | eval data=""{ ""commands"" : ["".commands.""]}"" | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.usage.lookups.lookupDefinitions'],"|rest splunk_server=local /services/admin/transforms-lookup getsize=true | eval name = 'eai:acl.app' + ""."" + title | rename ""eai:acl.sharing"" AS sharing | eval is_temporal = if(isnull(time_field),0,1) | table name type is_temporal size sharing | join type=left name [rest splunk_server=local /services/admin/kvstore-collectionstats | table data | mvexpand data | spath input=data | table ns size | rename ns as name] | makejson output=lookups | stats list(lookups) as lookups | eval data = ""{ ""lookups"" : ["" . mvjoin(lookups,"","") . ""]}"", _time = now(), date=strftime(_time, ""%Y-%m-%d"") | fields data _time date",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['instrumentation.performance.bundleReplication'],"index=_internal source=*/metrics.log TERM(group=bundles_uploads) | bin _time span=1d | stats count as bundles_uploads_count avg(peer_count) as avg_peer_count avg(average_baseline_bundle_bytes) as avg_baseline_bundle_bytes max(average_baseline_bundle_bytes) as max_baseline_bundle_bytes avg(average_delta_bundle_bytes) as avg_delta_bundle_bytes max(average_delta_bundle_bytes) as max_delta_bundle_bytes sum(total_count) as total_count sum(delta_count) as total_delta_count sum(success_count) as total_success_count sum(baseline_count) as total_baseline_count sum(already_present_count) as total_already_present_count sum(total_msec_spent) as total_msec_spent sum(delta_msec_spent) as total_delta_msec_spent sum(total_bytes) as total_bytes sum(delta_bytes) as total_delta_bytes by host _time | makejson output=data | eval date=strftime(_time, ""%Y-%m-%d"") | fields _time date data",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Alert - Total License Usage Near Daily Quota'],"| rest splunk_server_group=dmc_group_license_master /services/licenser/pools | join type=outer stack_id splunk_server [rest splunk_server_group=dmc_group_license_master /services/licenser/groups | search is_active=1 | eval stack_id=stack_ids | fields splunk_server stack_id is_active] | search is_active=1 | fields splunk_server, stack_id, used_bytes | join type=outer stack_id splunk_server [rest splunk_server_group=dmc_group_license_master /services/licenser/stacks | eval stack_id=title | eval stack_quota=quota | fields splunk_server stack_id stack_quota] | stats sum(used_bytes) as used_bytes max(stack_quota) as stack_quota by splunk_server | eval usedGB=round(used_bytes/1024/1024/1024,3) | eval totalGB=round(stack_quota/1024/1024/1024,3) | eval percentage=round(usedGB / totalGB, 3)*100 | fields splunk_server, percentage, usedGB, totalGB | where percentage > 90 | rename splunk_server AS Instance, percentage AS ""License quota used (%)"", usedGB AS ""License quota used (GB)"", totalGB as ""Total license quota (GB)""",,,,,,,,,1,1,number of events,"3,33 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf",,,,,1,0,greater than,1,7d,4h,1,1,You have used 90% of your total daily license quota.,14400,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Alert - Missing forwarders'],"| inputlookup dmc_forwarder_assets| search status=""missing"" | rename hostname as Instance",,,,,,,,,0,1,number of events,*/15 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,,,,,1,0,greater than,,,,,,One or more forwarders are missing.,,1,-1d@h,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Alert - Expired and Soon To Expire Licenses'],"| rest splunk_server_group=dmc_group_license_master /services/licenser/licenses | join type=outer group_id splunk_server [ rest splunk_server_group=dmc_group_license_master /services/licenser/groups | where is_active = 1 | rename title AS group_id | fields is_active group_id splunk_server] | where is_active = 1 | eval days_left = floor((expiration_time - now()) / 86400) | where (status == ""EXPIRED"" OR days_left < 15) AND NOT (quota = 1048576 OR label == ""Splunk Enterprise Reset Warnings"" OR label == ""Splunk Lite Reset Warnings"") | eval expiration_status = case(days_left >= 14, days_left."" days left"", days_left < 14 AND days_left >= 0, ""Expires soon: "".days_left."" days left"", days_left < 0, ""Expired"") | eval total_gb=round(quota/1024/1024/1024,3) | fields splunk_server label license_hash type group_id total_gb expiration_time expiration_status | convert ctime(expiration_time) | rename splunk_server AS Instance label AS ""Label"" license_hash AS ""License Hash"" type AS Type group_id AS Group total_gb AS Size expiration_time AS ""Expires On"" expiration_status AS Status",,,,,,,,,0,1,number of events,3 0 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,,,,,1,0,greater than,1,7d,,1,1,You have licenses that expired or will expire within 2 weeks.,14400,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Alert - Saturated Event-Processing Queues'],"| rest splunk_server_group=dmc_group_indexer /services/server/introspection/queues | search title=tcpin_queue OR title=parsingQueue OR title=aggQueue OR title=typingQueue OR title=indexQueue | eval fifteen_min_fill_perc = round(value_cntr3_size_bytes_lookback / max_size_bytes 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 100,2) | fields title fifteen_min_fill_perc splunk_server | where fifteen_min_fill_perc > 90 | rename splunk_server as Instance, title AS ""Queue name"", fifteen_min_fill_perc AS ""Average queue fill percentage (last 15min)""",,,,,,,,,1,1,number of events,"3,13,23,33,43,53 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf",,,,,1,0,greater than,1,7d,1h,1,1,"One or more of your indexer queues is reporting a fill percentage, averaged over the last 15 minutes, of 90% or more.",14400,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Alert - Abnormal State of Indexer Processor'],"| rest splunk_server_group=dmc_group_indexer /services/server/introspection/indexer | fields splunk_server, average_KBps, status, reason | where status != ""normal"" | eval average_KBps = round(average_KBps, 0) | eval status= if(status==""normal"", status, status."" - "".reason) | fields - reason | rename splunk_server as Instance, average_KBps as ""Average KB/s (last 30s)"", status as Status",,,,,,,,,1,1,number of events,"3,8,13,18,23,28,33,38,43,48,53,58 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf",,,,,1,0,greater than,1,7d,30m,1,1,One or more of your indexers is reporting an abnormal state.,14400,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Alert - Search Peer Not Responding'],"| rest splunk_server=local /services/search/distributed/peers/ | where status!=""Up"" AND disabled=0 | fields peerName, status | rename peerName as Instance, status as Status",,,,,,,,,1,1,number of events,"3,8,13,18,23,28,33,38,43,48,53,58 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf",,,,,1,0,greater than,1,7d,30m,1,1,One or more of your search peers is currently down.,14400,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Alert - Critical System Physical Memory Usage'],"| rest splunk_server_group=dmc_group_* /services/server/status/resource-usage/hostwide | eval percentage=round(mem_used/mem,3)*100 | where percentage > 90 | fields splunk_server, percentage, mem_used, mem | rename splunk_server AS Instance, mem AS ""Physical memory installed (MB)"", percentage AS ""Memory used (%)"", mem_used AS ""Memory used (MB)""",,,,,,,,,1,1,number of events,"3,8,13,18,23,28,33,38,43,48,53,58 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf",,,,,1,0,greater than,1,7d,30m,1,1,One or more instances has exceeded 90% memory usage.,14400,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Alert - Near Critical Disk Usage'],"| rest splunk_server_group=dmc_group_* /services/server/status/partitions-space | eval free = if(isnotnull(available), available, free) | eval usage = capacity - free | eval pct_usage = floor(usage / capacity 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 100) | where pct_usage > 80 | stats first(fs_type) as fs_type first(capacity) AS capacity first(usage) AS usage first(pct_usage) AS pct_usage by splunk_server, mount_point | eval usage = round(usage / 1024, 2) | eval capacity = round(capacity / 1024, 2) | rename splunk_server AS Instance mount_point as ""Mount Point"", fs_type as ""File System Type"", usage as ""Usage (GB)"", capacity as ""Capacity (GB)"", pct_usage as ""Usage (%)""",,,,,,,,,1,1,number of events,"3,33 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf",,,,,1,0,greater than,1,7d,4h,1,1,You have used 80% of your disk capacity.,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Asset - Build Standalone Asset Table'],"| `dmc_get_local_instance_asset` | rename search_groups AS search_group | inputlookup append=true dmc_assets | stats last(*) AS 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf by peerURI, search_group | fields peerURI serverName host machine search_group",,,,,,,,,,,,*/1 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,,,,,1,,,,,,,,This search establishes an updated cache of metadata necessary for the localhost to be included in DMC dashboards. This search will be disabled when user go throught the setup process. and will be re-enabled when user resets to factory mode.,,0,,1,dmc_assets,1,1,user,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Asset - Build Standalone Computed Groups Only'],| `dmc_get_local_instance_asset` | rename search_groups AS search_group | fields peerURI serverName host machine search_group,,,,,,,,,,,,,,,,,,,,,,,,,,,0,,1,dmc_assets,,,user,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Asset - Build Full'],"| rest splunk_server=local /services/search/distributed/peers | search status=Up disabled=0 | eval os = os_name | fields guid title peerName host host_fqdn server_roles search_groups cpu_arch os numberOfCores physicalMemoryMB version | rename title AS peerURI peerName AS serverName host_fqdn AS machine numberOfCores AS cpu_count physicalMemoryMB AS mem version AS splunk_version server_roles AS inherited_server_roles | where isnotnull(mvfind(search_groups,""dmc_group_"")) | join type=outer peerURI [ | rest splunk_server=local /servicesNS/nobody/splunk_monitoring_console/configs/conf-splunk_monitoring_console_assets | fields title host host_fqdn | rename title AS peerURI host_fqdn AS machine] | mvexpand search_groups | append [ | `dmc_get_local_instance_asset_in_distributed_mode` ] | fields peerURI serverName host machine search_groups | rename search_groups AS search_group",,,,,,,,,,,,,,,,,,,,,,,,,,,0,,1,dmc_assets,,,user,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC Forwarder - Build Asset Table'],"`dmc_build_forwarder_assets(1m)` | inputlookup append=true dmc_forwarder_assets | stats values(forwarder_type) as forwarder_type, max(version) as version, values(arch) as arch, values(os) as os, max(last_connected) as last_connected, values(new_sum_kb) as sum_kb, values(new_avg_tcp_kbps_sparkline) as avg_tcp_kbps_sparkline, values(new_avg_tcp_kbps) as avg_tcp_kbps, values(new_avg_tcp_eps) as avg_tcp_eps by guid, hostname | addinfo | eval status = if(isnull(sum_kb) or (sum_kb <= 0) or (last_connected < (info_max_time - 900)), ""missing"", ""active"") | eval sum_kb = round(sum_kb, 2) | eval avg_tcp_kbps = round(avg_tcp_kbps, 2) | eval avg_tcp_eps = round(avg_tcp_eps, 2) | fields guid, hostname, forwarder_type, version, arch, os, status, last_connected, sum_kb, avg_tcp_kbps_sparkline, avg_tcp_kbps, avg_tcp_eps | outputlookup dmc_forwarder_assets",,,,,,,,,,,,"3,18,33,48 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf",-16m@m,-1m@m,,,1,,,,,,,,,,1,,,,false,,user,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['DMC License Usage Data Cube'],"index=_internal source=*license_usage.log* type=""Usage"" | eval h=if(len(h)=0 OR isnull(h),""(SQUASHED)"",h) | eval s=if(len(s)=0 OR isnull(s),""(SQUASHED)"",s) | eval idx=if(len(idx)=0 OR isnull(idx),""(UNKNOWN)"",idx) | bin _time span=1d | stats sum(b) as b by _time, host, pool, s, st, h, idx",,,,,,,,,,,,,-31d,-0d,,,,,,,,,,,,,,-1mon@d,,,,,,0,"3,13,23,33,43,53 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['default'],,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,#284774,true,true,true,Instance count,Time,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['Errors in the last 24 hours'],error OR failed OR severe OR ( sourcetype=access_* ( 404 OR 500 OR 503 ) ),,,,,,,,,,,,,-1d,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['Errors in the last hour'],error OR failed OR severe OR ( sourcetype=access_* ( 404 OR 500 OR 503 ) ),,,,,,,,,,,,,-1h,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['Messages by minute last 3 hours'],"index=_internal source=""*metrics.log"" eps ""group=per_source_thruput"" NOT filetracker | eval events=eps*kb/kbps | timechart fixedrange=t span=1m limit=5 sum(events) by series",,,,,,,,,,,,,-3h,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,report_builder_display,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['Splunk errors last 24 hours'],"index=_internal "" error "" NOT debug source=*splunkd.log*",,,,,,,,,,,,,-24h,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['Orphaned scheduled searches'],"| rest timeout=600 splunk_server=local /servicesNS/-/-/saved/searches add_orphan_field=yes count=0 | search orphan=1 disabled=0 is_scheduled=1 | eval status = if(disabled = 0, ""enabled"", ""disabled"") | fields title eai:acl.owner eai:acl.app eai:acl.sharing orphan status is_scheduled cron_schedule next_scheduled_time next_scheduled_time actions | rename title AS ""search name"" eai:acl.owner AS owner eai:acl.app AS app eai:acl.sharing AS sharing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['License Usage Data Cube'],"index=_internal source=*license_usage.log* type=""Usage"" | eval h=if(len(h)=0 OR isnull(h),""(SQUASHED)"",h) | eval s=if(len(s)=0 OR isnull(s),""(SQUASHED)"",s) | eval idx=if(len(idx)=0 OR isnull(idx),""(UNKNOWN)"",idx) | bin _time span=1d | stats sum(b) as b by _time, pool, s, st, h, idx",,,,,,,,,,,,,-31d,-0d,,,,,,,,,,,,,,-1mon@d,,,,,,0,"3,13,23,33,43,53 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['403_by_clientip'],"index=""fundamental_one"" status=403 | stats count as ""Attempts"" by clientip | sort - ""Attempts""",,,,,,,,,,0,,,0,,statistics,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,"[""host"",""source"",""sourcetype"",""method"",""action"",""file"",""process""]",0,search,search,,,,,,,,,,,,,,,,,,,,,,,,
['Splunk Web Login Attempts'],"index=""_audit"" action=""login attempt"" info=""failed"" user=""admin""",,,,,,,,,1,1,number of events,1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,rt-1m,rt-0m,,,1,0,greater than,0,,60s,,,,,,,,,,,,,,,,,,,,,,,,,,search,search,4,host,fast,,,,,,,,,,,,,,,,,,,,,
['Bucket Copy Trigger'],| archivebuckets,,,,,,,,,,,,17 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,,,,,1,,,,,,,,Triggers bucket copying,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['Generate posix_identities lookup'],"| inputlookup directory_posix_identities | eval source=""directory"" | append [|inputlookup local_posix_identities | eval source=""local""] | append[|inputlookup learnt_posix_identities | rename _key as uid | search NOT uid=4294967295 | eval source=""learnt""] | eventstats dc(user) as dc by uid | eval user=if(dc>1,uid,user) | dedup uid | table uid user | sort 0 +uid | outputlookup posix_identities",,,,,,,,,,0,,*/5 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['Update auditd_host_inventory KVStore collection'],"[|inputlookup auditd_indices] [|inputlookup auditd_sourcetypes] type=""DAEMON_START"" | dedup host | rex field=kernel ""^(?<kernel_version>[0-9-.]+).(?<distribution_release>[^.]+).?(?<architecture>.*)"" | eval architecture =if(architecture=="""",""unknown"",architecture) | table host kernel_version distribution_release architecture | rename host as _key | lookup auditd_host_inventory _key OUTPUT last_boot | outputlookup append=true auditd_host_inventory",,,,,,,,,,0,,30 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,-1h@h,@h,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15,,,,,,,,,,,,,,,,,,,,
['Update learnt_posix_identities KVStore collection'],"[|inputlookup auditd_indices] [|inputlookup auditd_sourcetypes] type=""USER_START"" acct=* NOT acct=root NOT auid=0 terminal=/dev/tty* OR NOT addr=? NOT auid=4294967295 | dedup auid | table auid acct | rename auid as _key | rename acct as user | outputlookup append=true learnt_posix_identities",,,,,,,,,,0,,30 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,-1h@h,@h,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15,,,,,,,,,,,,,,,,,,,,
['Update auditd_hosts lookup'],| tstats values(host) as host WHERE [|inputlookup auditd_indices] [|inputlookup auditd_sourcetypes] | mvexpand host limit=0 | outputlookup auditd_hosts,,,,,,,,,,0,,30 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,30,,,,,,,,,,,,,,,,,,,,
['Update auditd_indices lookup'],| tstats values(sourcetype) as sourcetype where index=* [|inputlookup auditd_sourcetypes] by index | table index | outputlookup auditd_indices,,,,,,,,,,0,,0 */4 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60,,,,,,,,,,,,,,,,,,,,
['Update last_boot in auditd_host_inventory KVStore collection'],"| pivot Auditd Auditd latest(_time) as time FILTER type in (SYSTEM_BOOT,DAEMON_START,SYSTEM_SHUTDOWN,DAEMON_END) SPLITROW host SPLITROW type | convert timeformat=""%Y-%m-%dT%H:%M:%S.%3N%z"" mktime(time) as last_boot | sort -last_boot | dedup host | eval last_boot=if(type==""SYSTEM_SHUTDOWN"",0,round(last_boot)) | table host last_boot | rename host AS _key | lookup auditd_host_inventory _key OUTPUT kernel_version distribution_release architecture | outputlookup append=true auditd_host_inventory",,,,,,,,,,0,,*/10 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,-15m,now,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3,,,,,,,,,,,,,,,,,,,,
['Cisco Security Suite - Overview - Global Security Events Map'],"eventtype=cisco-security-events dest_ip!=""255.255.255.255"" dest_ip!=""0.0.0.0"" src_ip=""*"" | eval isLocalIP=`local-ip-list(src_ip)` | where isLocalIP!=1 AND isnotnull(threat_reason) AND threat_reason!=""-"" | stats count by src_ip | iplocation src_ip | geostats latfield=lat longfield=lon count by Country",,,,,,,,,,,,,-60m,now,,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,,,,,,,,
['Cisco Security Suite - Overview - Security Event Stats by Host'],"eventtype=cisco-security-events | chart count,sparkline(count) as ""Trend"" by host | sort -count",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,,,,,,,,
['Cisco Security Suite - Overview - Security Event Stats by Sourcetype'],"eventtype=cisco-security-events | chart count,sparkline(count) as ""Trend"" by sourcetype | sort -count",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,,,,,,,,
['Cisco Security Suite - Overview - Top Destinations'],"eventtype=cisco-security-events dest_ip=""*"" dest_ip!=""255.255.255.255"" dest_ip!=""0.0.0.0"" | top dest_ip",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco Security Suite - Overview - Top Services'],"eventtype=cisco-security-events dest_ip!=""255.255.255.255"" dest_ip!=""0.0.0.0"" | eval port=coalesce(dest_port,src_port) | where isnotnull(port) | lookup networkservice ""Port Number"" as port OUTPUT ""Service Name"" AS service | eval service=if(isnull(service),""Port:""+tostring(port),service) | top service",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco Security Suite - Overview - Top Sources'],"eventtype=cisco-security-events dest_ip!=""255.255.255.255"" dest_ip!=""0.0.0.0"" src_ip=""*"" | top src_ip",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco Security Suite - Overview - Top Threats'],"eventtype=cisco-security-events dest_ip!=""255.255.255.255"" dest_ip!=""0.0.0.0"" | where isnotnull(threat_reason) AND threat_reason!=""-"" | eval product=if(isnull(product),""Cisco"",product) | eval threat_reason=if(http_action=""TCP_DENIED/407"",""authfail"",threat_reason) | eval threat_reason=""[""+product+""]:""+threat_reason | top limit=10 threat_reason",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco ASA - Overview - Drop Reason'],eventtype=cisco-firewall action=block* | top cause,,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,right,zero,,,,,,,,,,,
['Cisco ASA - Overview - Firewall Events'],"eventtype=cisco-firewall action=""*"" | timechart count by action",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,right,zero,stacked,"""# Events""",visible,,,,,,,,
['Cisco ASA - Overview - Top Destinations'],eventtype=cisco-firewall | top dest_ip,,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco ASA - Overview - Top Protocols'],"eventtype=cisco-firewall service=""*"" | top service",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco ASA - Overview - Top Sources'],eventtype=cisco-firewall | top src_ip,,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco ESA - Overview - Incoming Mail Over Time'],"eventtype=cisco-esa | transaction keepevicted=true icid mid | search policy_direction=""inbound"" | timechart count by threat_reason",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,right,zero,stacked,,,,,,,,,,
['Cisco ESA - Overview - Messages Processed'],"eventtype=cisco-esa | timechart dc(internal_message_id) as ""Messages"" by host",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,right,zero,,,,,,,,,,,
['Cisco ESA - Overview - Outgoing Mail Over Time'],"eventtype=cisco-esa | transaction keepevicted=true icid mid | search policy_direction=""outbound"" | timechart count by threat_reason",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,right,zero,stacked,,,,,,,,,,
['Cisco ESA - Overview - Top Recipients'],"eventtype=cisco-esa recipient=""*"" | top recipient",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco ESA - Overview - Top Senders'],"eventtype=cisco-esa sender=""*"" | top sender",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco ESA - Performance - Deliveries'],"eventtype=cisco-esa | timechart dc(dcid) as ""Delivery Connections"" by host",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,right,zero,,,,,,,,,,,
['Cisco ESA - Performance - Injections'],"eventtype=cisco-esa | timechart dc(icid) as ""Incoming Connections"" by host",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,right,zero,,,,,,,,,,,
['Cisco ESA - Performance - Message Size'],"eventtype=cisco-esa message_size=""*"" | timechart avg(message_size) as avg_size | eval avg_size = round((avg_size/(1024*1024)),2) | rename avg_size AS ""Avg. Size""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,right,zero,stacked,,,,,,,,,,
['Cisco ESA - Performance - Message Size Distribution'],"eventtype=cisco-esa message_size=""*"" | eval msg_size=case(message_size <= 4096, ""<4K"", message_size > 4096 AND message_size <= 32768, ""4K-32K"", message_size > 32768 AND message_size <= 131072, ""32K-128K"", message_size > 131072 AND message_size <= 524288, ""128K-512K"", message_size > 524288 AND message_size <= 1048576, ""512K-1M"", message_size > 1048576 AND message_size <= 2097152, ""1M-2M"", message_size > 2097152 AND message_size <= 4194304, ""2M-4M"", message_size > 4194304 AND message_size <= 8388608, ""4M-8M"", message_size > 8388608, "">8M"") | chart count by msg_size | sort - msg_size | rename msg_size AS ""Message Size"" count AS Count",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,right,,,,,,,,,,,,
['Cisco ESA - Performance - Messages'],"eventtype=cisco-esa | timechart dc(mid) as ""Messages"" by host",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,right,zero,,,,,,,,,,,
['Cisco IPS - GC - Top Attackers'],eventtype=cisco_ips | top limit=10 attacker,,,,,,,,,,,,,-60m,now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - GC - Top Attacking Countries'],eventtype=cisco_ips | iplocation src_ip | top limit=10 Country,,,,,,,,,,,,,-60m,now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - GC - Top HostID'],eventtype=cisco_ips | top limit=10 hostId,,,,,,,,,,,,,-60m,now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - GC - Top Signatures'],eventtype=cisco_ips | top limit=10 description | rename description as Signature,,,,,,,,,,,,,-60m,now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - GC - Top Targets'],eventtype=cisco_ips | top limit=10 target,,,,,,,,,,,,,-60m,now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - GC - Global Threat Score Over Time'],eventtype=cisco_ips | timechart count by gc_score,,,,,,,,,,,,,-60m,now,,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - Overview - Average Risk Rating'],"eventtype=cisco_ips | stats avg(risk_rating) as average | eval average=round(average, 1)",,,,,,,,,,,,,-24h@h,now,,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - Overview - Average Threat Rating'],"eventtype=cisco_ips | stats avg(threat_rating) as average | eval average=round(average, 1)",,,,,,,,,,,,,-24h@h,now,,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - Overview - IPS Events By Severity'],"eventtype=cisco_ips | transaction maxevents=2 maxspan=5m eventid | eval attack_count=if(isnotnull(summary_count),summary_count,1) | timechart sum(attack_count) by severity",,,,,,,,,,,,,-24h@h,now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - Overview - IPS Severity Distribution'],eventtype=cisco_ips | stats count by severity | sort - count,,,,,,,,,,,,,-24h@h,now,,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - Overview - Top Attackers'],"eventtype=cisco_ips | transaction maxevents=2 maxspan=5m eventid | eval attack_count=if(isnotnull(summary_count),summary_count,1) | stats sum(attack_count) as count,sparkline by attacker | sort - count",,,,,,,,,,,,,-24h@h,now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - Overview - Top Signatures'],"eventtype=cisco_ips | transaction maxevents=2 maxspan=5m eventid | eval attack_count=if(isnotnull(summary_count),summary_count,1) | stats sum(attack_count) as count,sparkline by severity,sig_type,description | sort - count | rename sig_type as Type",,,,,,,,,,,,,-24h@h,now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Cisco IPS - Overview - Top Targets'],"eventtype=cisco_ips | transaction maxevents=2 maxspan=5m eventid | eval attack_count=if(isnotnull(summary_count),summary_count,1) | stats sum(attack_count) as count,sparkline by target | sort - count",,,,,,,,,,,,,-24h@h,now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,,,,,,,,,,,,,,,,,,
['Lookup - Locations'],"eventtype=""css-ise"" Location=""*"" | stats count by Location | inputlookup append=T ISE_Locations.csv | stats count by Location | table Location | outputlookup ISE_Locations.csv",,,,,,,,,0,0,,0 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,-24h@h,now,,,1,,,,,,,1,Updates the ISE_Locations.csv lookup file,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['_lookup_create_interface_list'],"sourcetype=cisco:esa* src_interface=* OR dest_interface=* | eval interface=trim(coalesce(src_interface,"""") . "","" . coalesce(dest_interface,""""), "","") | makemv delim="","" interface | stats count by interface | where len(interface)>0 | fields interface | rename interface as dest_interface | outputlookup interface_list",,,,,,,,,,,,0 0 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf,,now,,,1,,,,,,,,,,,-1d@h,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Business vs. Other'],"eventtype=css-wsa-squid | eval usage = if(usage=""Business"",""Business Use"",""Other"") | timechart count by usage",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,none,zero,,"""# Transactions""",visible,,,,,,,,
['Cisco WSA - Acceptable Use - Legal vs. Other'],"eventtype=css-wsa-squid | eval usage = if(usage=""Violation"",""Legal Liability"",""Other"") | timechart count by usage",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,none,zero,,"""# Transactions""",visible,,,,,,,,
['Cisco WSA - Acceptable Use - Personal vs. Other'],"eventtype=css-wsa-squid | eval usage = if(usage=""Personal"",""Personal Use"",""Other"") | timechart count by usage",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,none,zero,,"""# Transactions""",visible,,,,,,,,
['Cisco WSA - Acceptable Use - Top Business Categories'],"eventtype=css-wsa-squid x_webcat_code_full=""*"" usage=""Business"" | top x_webcat_code_full | rename x_webcat_code_full as ""Category""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Top Business Clients'],"eventtype=css-wsa-squid src_ip=""*"" usage=""Business"" | top src_ip | rename src_ip as ""Source IP""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Top Business Users'],"eventtype=css-wsa-squid cs_username=""*"" usage=""Business"" | top cs_username | rename cs_username as Username",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Top Business Websites'],"eventtype=css-wsa-squid cs_url_host=""*"" usage=""Business"" | top cs_url_host | rename cs_url_host as ""Website""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Top Legal Categories'],"eventtype=css-wsa-squid x_webcat_code_full=""*"" usage=""Violation"" | top x_webcat_code_full | rename x_webcat_code_full as ""Category""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Top Legal Clients'],"eventtype=css-wsa-squid src_ip=""*"" usage=""Violation"" | top src_ip | rename src_ip as ""Source IP""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Top Legal Users'],"eventtype=css-wsa-squid cs_username=""*"" usage=""Violation"" | top cs_username | rename cs_username as Username",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Top Legal Websites'],"eventtype=css-wsa-squid cs_url_host=""*"" usage=""Violation"" | top cs_url_host | rename cs_url_host as ""Website""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Top Personal Categories'],"eventtype=css-wsa-squid x_webcat_code_full=""*"" usage=""Personal"" | top x_webcat_code_full | rename x_webcat_code_full as ""Category""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Top Personal Clients'],"eventtype=css-wsa-squid src_ip=""*"" usage=""Personal"" | top src_ip | rename src_ip as ""Source IP""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Top Personal Users'],"eventtype=css-wsa-squid cs_username=""*"" usage=""Personal"" | top cs_username | rename cs_username as Username",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Acceptable Use - Top Personal Websites'],"eventtype=css-wsa-squid cs_url_host=""*"" usage=""Personal"" | top cs_url_host | rename cs_url_host as ""Website""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,bar,none,,,,,,,,,,,,
['Cisco WSA - Destinations - By City'],"eventtype=css-wsa-squid action=allow | iplocation dest_ip | eval City=if(isnotnull(City),City+"",""+Country,Country) | top City",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Destinations - By Country'],eventtype=css-wsa-squid action=allow | iplocation dest_ip | top Country,,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Destinations - Top Blocked Domains'],eventtype=css-wsa-squid action=block* | top dest_domain,,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Destinations - Top Destination Domains'],eventtype=css-wsa-squid action=allow* | top dest_domain,,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Destinations - Top Protocols'],"eventtype=css-wsa-squid action=allow* | eval num=lower(dest_port) | eval protocol=""tcp"" | lookup networkservice ""Transport Protocol"" as protocol, ""Port Number"" as dest_port OUTPUT ""Service Name"" as service | eval method=if(cs_url_scheme=""tunnel"", service+"" [tunnel]"", cs_url_scheme+"" [direct]"") | top method",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Network Resources - Bandwidth Utilization'],"eventtype=css-wsa-squid action=allow* | eval bytes = ((bytes_in + bytes_out) 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 10) / (1024 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1024) | timechart per_second(mb) as ""Bandwidth (MBps)""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Network Resources - By Usage'],"eventtype=css-wsa-squid action=allow* | eval mb = ((bytes_in + bytes_out) 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 10) / (1024 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1024) | where isnotnull(usage) | timechart per_second(mb) as ""Bandwidth (MBps)"" by usage",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Network Resources - Top Categories'],"eventtype=css-wsa-squid action=allow* | eval bw = (bytes_in + bytes_out) / (1024 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1024) | stats sum(bw) as x by x_webcat_code_full | sort -x | head 10 | rename x as ""Transfer Size (MB)"", x_webcat_code_full as ""Category""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Network Resources - Top Sites'],"eventtype=css-wsa-squid action=allow* | eval bytes = (bytes_in + bytes_out) / (1024 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1024) | stats sum(bytes) as x by dest_domain | sort -x | head 10 | rename x as ""Transfer Size (MB)"", dest_domain as ""Destination""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Overview - Requests by Application'],"eventtype=css-wsa-squid x_avc_app=""*"" x_avc_app!=""-"" x_avc_app!=""Unknown"" | top x_avc_app",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco WSA - Overview - Requests by Category'],"eventtype=css-wsa-squid | eval Category=if(match(x_webcat_code_abbr,""C_.*""),""[CUSTOM] ""+x_webcat_code_full,x_webcat_code_full) | top Category",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco WSA - Overview - Top Destination Domains'],"eventtype=css-wsa-squid | eval bytes=bytes_in+bytes_out | stats sum(bytes) as bytecount,count by dest_domain | sort -bytecount | `resize-bytes(""bytecount"", bytecount)` | rename count as ""# Requests"", bytecount as ""Transfer Size"", dest_domain as ""Destination""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,heatmap,,,,,
['Cisco WSA - Overview - Top Users'],"eventtype=css-wsa-squid | eval action=if(http_result=""TCP_DENIED/407"",""block"",action) | where action!=""error"" | eval cs_username=if(isnull(cs_username) OR cs_username=""-"",""[""+c_ip+""]"",cs_username) | chart count by cs_username,action | eval count=block+allow | eval f_username=if(match(cs_username,""^[""),""*"",cs_username) | eval f_ip=if(match(cs_username,""^[""),replace(cs_username,""[[]]"",""""),""*"") | sort - count | table cs_username,f_username,f_ip,count,allow,block | rename cs_username as ""Username"",count as ""# Requests"", block as ""Blocked"", allow as ""Allowed""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Overview - Web Security Events'],"eventtype=css-wsa-squid | eval action=if(http_result=""TCP_DENIED/407"", ""Auth Failed"", action) | timechart usenull=f count by action",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,right,zero,stacked,"""# Transactions""",visible,,,,,,,,
['Cisco WSA - Overview - Web Security Threats'],"eventtype=css-wsa-squid threat_reason=""*"" threat_reason!=""-"" | eval threat_reason=if(http_result=""TCP_DENIED/407"",""Auth Failure"",threat_reason) | top threat_reason",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,pie,right,,,,,,,,,,,,
['Cisco WSA - Proxy Performance - Bandwidth'],"eventtype=css-wsa-squid | eval mbytes_in = bytes_in/(1024*1024) | eval mbytes_out = bytes_out/(1024*1024) | timechart sum(mbytes_in) as ""Inbound (MB)"", sum(mbytes_Out) as ""Outbound (MB)""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Proxy Performance - By Access Policy'],eventtype=css-wsa-squid | stats count by access_policy | sort -count,,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Proxy Performance - Cache Performance'],"eventtype=css-wsa-squid cache!=""-"" | timechart count by cache | rename hit as ""Cache Hit"", miss as ""Cache Miss""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Proxy Performance - Request Duration'],"eventtype=css-wsa-squid | timechart avg(duration) as ""Avg Duration (ms)"", max(duration) as ""Peak Duration (ms)""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Proxy Performance - Requests'],"eventtype=css-wsa-squid | eval count=1 | timechart per_second(count) AS ""Requests/sec"" by host",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Proxy Performance - SSL Traffic Load'],"eventtype=css-wsa-squid | eval num=lower(dest_port) | eval protocol=""tcp"" | lookup networkservice ""Transport Protocol"" as protocol, ""Port Number"" as dest_port OUTPUT ""Service Name"" as service | eval aa = "" ["" + action + ""]"" | eval method=if(cs_url_scheme=""tunnel"",service+aa,cs_url_scheme+aa) | stats count by method | sort -count",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Search Analytics - Search Providers'],"eventtype=css-wsa-squid action=""allow"" cs_url_stem=""*search*"" | rex field=cs_url ""[?&#](?<qarg>(video|query|search|q|search_query|p))(=|/)(?<qstr>[^?&]+)"" max_match=0 | rex field=qstr ""(?<search_term>w+)"" max_match=0 | mvexpand search_term | stats dc(cs_username) as usercount,dc(search_term) as stcount by dest_domain | sort -usercount | rename usercount as ""# Unique Users"", stcount as ""# Search Terms"",dest_domain as ""Search Provider""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,,pie,,,,,,,,,,,,,
['Cisco WSA - Search Analytics - Search Terms'],"eventtype=css-wsa-squid action=""allow"" cs_url_stem=""*search*"" | rex field=cs_url ""[?&#](?<qarg>(video|query|search|q|search_query|p))(=|/)(?<qstr>[^?&]+)"" max_match=0 | rex field=qstr ""(?<search_term>w+)"" max_match=0 | top useother=f search_term | rename count as ""# Searches"",search_term as ""Search Term""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,,pie,,,,,,,,,,,,,
['Cisco WSA - Search Analytics - Search Users'],"eventtype=css-wsa-squid action=""allow"" cs_url_stem=""*search*"" | rex field=cs_url ""[?&#](?<qarg>(video|query|search|q|search_query|p))(=|/)(?<qstr>[^?&]+)"" max_match=0 | rex field=qstr ""(?<search_term>w+)"" max_match=0 | top cs_username | rename count as ""# Searches"",cs_username as ""Username""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,,pie,,,,,,,,,,,,,
['Cisco WSA - Security - Top Suspicious Categories'],"eventtype=css-wsa-squid http_result!=""TCP_DENIED/407"" x_wbrs_score!=""-"" x_wbrs_score<=6.0 | eval Category=if(match(x_webcat_code_abbr,""C_.*""),""[CUSTOM] ""+x_webcat_code_full,x_webcat_code_full) | top Category",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Security - Top Client IPs'],"eventtype=css-wsa-squid http_result!=""TCP_DENIED/407"" x_wbrs_score!=""-"" x_wbrs_score<=6.0 | top limit=10 src_ip | eval c_ip=src_ip | rename src_ip AS ""Client IP""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Security - Top Suspicious Domains'],"eventtype=css-wsa-squid http_result!=""TCP_DENIED/407"" x_wbrs_score!=""-"" x_wbrs_score<=6.0 | top limit=10 dest_domain | rename dest_domain as ""Destination""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Security - Top Web Threat Clients'],"eventtype=css-wsa-squid http_result!=""TCP_DENIED/407"" X-ScanVerdict=1 | top limit=10 src_ip | eval c_ip=src_ip | rename src_ip as ""Client IP""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Security - Top Web Threat Domains'],"eventtype=css-wsa-squid http_result!=""TCP_DENIED/407"" X-ScanVerdict=1 | top limit=10 dest_domain | rename dest_domain as ""Destination""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Security - Top Web Threats'],"eventtype=css-wsa-squid http_result!=""TCP_DENIED/407"" X-ScanVerdict=1 | top limit=10 X-ThreatName | rename X-ThreatName AS ""Threat Name""",,,,,,,,,,,,,-60m,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,false,true,true,,,,,,,,,true,true,none,,,,,
['Cisco WSA - Security - Traffic Severity Timechart'],"eventtype=css-wsa-squid http_result!=""TCP_DENIED/407"" | eval severity=`cisco-wsa-score(x_wbrs_score)` | eval severity=if(X-ScanVerdict=1,""red"",severity) | timechart count by severity | table _time,red,orange,yellow,blue,green",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,area,right,zero,stacked,"""# Requests""",visible,,,,shiny,ellipsisEnd,,,
['Cisco WSA - Security - Web Requests by Reputation'],"eventtype=css-wsa-squid | eval x_wbrs_score=case(x_wbrs_score=""ns"",""unknown"",x_wbrs_score=""-"",""unknown"",1=1,x_wbrs_score) | eval score=if(x_wbrs_score=""unknown"",""unknown"",floor(x_wbrs_score)) | stats count by score | sort score",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,600px,column,none,gaps,,"""# Transactions""",visible,,,,,,,,
['Cisco WSA - Web Request Metrics - Average Request Size'],"eventtype=css-wsa-squid action=""allow"" | eval bytes=bytes_in + bytes_out | timechart min(bytes) as min, avg(bytes) as avg, max(bytes) as max",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,,pie,,,,,,,,,,,,,
['Cisco WSA - Web Request Metrics - Cache Efficiency'],"eventtype=css-wsa-squid action=""allow"" | stats count by cache",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,,pie,,,,,,,,,,,,,
['Cisco WSA - Web Request Metrics - Unique Users'],"eventtype=css-wsa-squid cs_username!=""-"" | timechart dc(cs_username) as ""# Unique Users""",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,,pie,,,,,,,,,,,,,
['Cisco WSA - Web Request Metrics - Users with Multiple IPs'],"eventtype=css-wsa-squid cs_username!=""-"" | stats dc(src_ip) as ipcount by cs_username | stats count by ipcount",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,,pie,,,,,,,,,,,,,
['Cisco WSA - Web Request Metrics - Users with Multiple UAs'],"eventtype=css-wsa-squid cs_username!=""-"" | stats dc(cs_user_agent) as uacount by cs_username | stats count by uacount",,,,,,,,,,,,,-60m,now,visualizations,,,,,,,,,,,,,-1d@h,,,,,,1,,,,,,,,,,,,,true,,,,,,,1,false,true,true,charting,,pie,,,,,,,,,,,,,
['CIM - Vendor Product Tracker - Lookup Gen'],"| tstats prestats=true summariesonly=true min(_time),max(_time) from datamodel=Malware.Malware_Attacks by Malware_Attacks.vendor_product | `drop_dm_object_name(""Malware_Attacks"")` | eval model=""Malware"" | tstats prestats=true summariesonly=true append=true min(_time),max(_time) from datamodel=Network_Traffic.All_Traffic by All_Traffic.vendor_product | `drop_dm_object_name(""All_Traffic"")` | eval model=if(isnull(model),""Network_Traffic"",model) | tstats prestats=true summariesonly=true append=true min(_time),max(_time) from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.vendor_product | `drop_dm_object_name(""IDS_Attacks"")` | eval model=if(isnull(model),""Intrusion_Detection"",model) | tstats prestats=true summariesonly=true append=true min(_time),max(_time) from datamodel=Vulnerabilities.Vulnerabilities by Vulnerabilities.vendor_product | `drop_dm_object_name(""Vulnerabilities"")` | eval model=if(isnull(model),""Vulnerabilities"",model) | stats min(_time) as firstTime,max(_time) as lastTime by vendor_product,model | inputlookup append=true cim_vendor_product_tracker | stats min(firstTime) as firstTime,max(lastTime) as lastTime by vendor_product,model | outputlookup cim_vendor_product_tracker | stats count",,,,,,,,,,,,"5,20,35,50 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf 1-create-csv-with-header.py 2-write-section-to-csv.py billyLocalsavedsearches.conf contents.txt master.conf master-preclean.conf master-section-collection processed-single-section.conf result.csv searchLocalsavedsearches.conf single-section.conf splunk-conf-extraction splunk-conf-extraction20190906.py splunk-conf-extraction.py splunk-csv-extract Data Validation.xlsx splunkEnterpriseSecuritySuiteDefaultsavedsearches.conf",-30m@m,+0s,,,0,,,,,,0,,Maintains a list of vendor_product values and the first and list time they have been seen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,
['CIM - Top Data Model Accelerations'],"| `datamodel(""Splunk_Audit"", ""Datamodel_Acceleration"")` | `drop_dm_object_name(""Datamodel_Acceleration"")` | join type=outer last_sid [| rest splunk_server=local count=0 /services/search/jobs reportSearch=summarize* | rename sid as last_sid | fields last_sid,runDuration] | eval ""size(MB)""=round(size/1048576,1), ""retention(days)""=if(retention==0,""unlimited"",round(retention/86400,1)), ""complete(%)""=round(complete*100,1), ""runDuration(s)""=round(runDuration,1)",,,,,,,,,,,,,,now,,,,,,,,,,,Maintains a data cube of DMA statistics for use in Datamodel Audit view,,,,,,,,user,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,
['CIM - Top Data Model Accelerations By Size'],"| `datamodel(""Splunk_Audit"", ""Datamodel_Acceleration"")` | `drop_dm_object_name(""Datamodel_Acceleration"")` | eval size(MB)=size/1048576 | sort 100 - size | table datamodel,size(MB)",,,,,,,,,,0,,,,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,1,false,,350,bar,,,,,,0,0,,,,0,all,
['CIM - Top Data Model Accelerations By Run Duration'],"| `datamodel(""Splunk_Audit"", ""Datamodel_Acceleration"")` | `drop_dm_object_name(""Datamodel_Acceleration"")` | join type=outer last_sid [| rest splunk_server=local count=0 /services/search/jobs reportSearch=summarize* | rename sid as last_sid | fields last_sid,runDuration] | sort 100 - runDuration | table datamodel,runDuration",,,,,,,,,,0,,,,now,visualizations,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,1,false,,350,bar,,,,,,0,0,,,,0,all,
['CIM - Data Model Acceleration Details'],"| `datamodel(""Splunk_Audit"", ""Datamodel_Acceleration"")` | `drop_dm_object_name(""Datamodel_Acceleration"")` | eval size(MB)=round(size/1048576,1) | eval retention(days)=retention/86400 | eval complete(%)=round(complete*100,1) | sort 100 + datamodel | fieldformat earliest=strftime(earliest, ""%m/%d/%Y %H:%M:%S"") | fieldformat latest=strftime(latest, ""%m/%d/%Y %H:%M:%S"") | fields datamodel,app,cron,retention(days),earliest,latest,is_inprogress,complete(%),size(MB),last_error",,,,,,,,,,0,,,,now,statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,,,,,,,,,1,false,,,,,,,,,0,0,,,,0,,row

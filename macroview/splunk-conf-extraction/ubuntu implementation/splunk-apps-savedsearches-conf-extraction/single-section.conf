
#####################
## Authentication
#####################

###### Correlation Searches ######
## SOLNESS-6481 Implement correlation search for detecting concurrent access attempts
[Access - Concurrent App Accesses - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Concurrent Login Attempts Detected
action.email.sendresults              = 0
action.notable.param.security_domain  = access
action.notable.param.severity         = medium
action.notable.param.rule_title       = Concurrent Access Event Detected For $user$
action.notable.param.rule_description = Concurrent access attempts to $app$ by $user$ from two different sources( $previous_src$, $src$ ) have been detected.
action.notable.param.nes_fields       = user
action.notable.param.drilldown_name   = View access attemps by $user$
action.notable.param.drilldown_search = | from datamodel:"Authentication"."Authentication" | search user="$user$"
action.notable.param.default_owner    =
action.notable.param.default_status   =
action.risk                           = 1
action.risk.param._risk_object        = user
action.risk.param._risk_object_type   = user
action.risk.param._risk_score         = 20
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = app,user
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 10 * * * *
description                           = Alerts on concurrent access attempts to an app from different hosts. These are good indicators of shared passwords and potential misuse.
disabled                              = True
dispatch.earliest_time                = -70m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | tstats `summariesonly` count from datamodel=Authentication.Authentication by _time,Authentication.app,Authentication.src,Authentication.user span=1s | `drop_dm_object_name("Authentication")` | eventstats dc(src) as src_count by app,user | search src_count>1 | sort 0 + _time | streamstats current=t window=2 earliest(_time) as previous_time,earliest(src) as previous_src by app,user | where (src!=previous_src) | eval time_diff=abs(_time-previous_time) | where time_diff<300

[Access - High or Critical Priority Individual Logging into Infected Machine - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = High or Critical Priority Individual Logging into Infected Machine
## commenting guided mode for now, because multiple search parts not implemented in gui
#action.customsearchbuilder           = 0
#action.customsearchbuilder.enabled   = 1
#action.customsearchbuilder.routine   = make_correlation_search:makeCorrelationSearch
#action.customsearchbuilder.spec      = {\
#    "version":  "1.0",\
#    "searches": [\
#        {"key":          "dest",\
#         "datamodel":    "Authentication",\
#         "object":       "Successful_Authentication",\
#         "earliest":     "-70m@m",\
#         "latest":       "+0s",\
#         "eventFilter":  "('Authentication.user_priority'=\"high\" OR 'Authentication.user_priority'=\"critical\")",\
#         "aggregates":   [{"function": "values", "attribute": "Authentication.user", "alias": "user"}],\
#         "splitby":      [{"attribute": "Authentication.dest", "alias": "dest"}]\
#        },\
#        {"key":          "dest",\
#         "datamodel":    "Malware",\
#         "object":       "Allowed_Malware",\
#         "earliest":     "-1450m@m",\
#         "latest":       "+0s",\
#         "aggregates":   [{"function": "values", "attribute": "Malware_Attacks.signature", "alias": "signature"}],\
#         "splitby":      [{"attribute": "Malware_Attacks.dest", "alias": "dest"}]\
#        }\
#    ],\
#    "alert.suppress":         "1",\
#    "alert.suppress.fields":  ["dest"]\
#}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = access
action.notable.param.severity         = critical
action.notable.param.rule_title       = High or Critical Priority User Accessed Machine Infected with Malware
action.notable.param.rule_description = $user$ accessed $dest$ which is infected with $signature$
action.notable.param.nes_fields       = dest
action.notable.param.drilldown_name   = View successful authentication attempts on infected system $dest$
action.notable.param.drilldown_search = | from datamodel:"Authentication"."Successful_Authentication" | where ('user_priority'="high" OR 'user_priority'="critical") AND 'dest'="$dest$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 100
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 10 * * * *
description                           = Detects users with a high or critical priority logging into a malware infected machine
disabled                              = True
dispatch.earliest_time                = -1450m@m
dispatch.latest_time                  = +0s
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | tstats `summariesonly` values(Authentication.user) as "user" from datamodel=Authentication.Authentication where earliest=-70m@m latest=+0s nodename=Authentication.Successful_Authentication ("Authentication.user_priority"="high" OR "Authentication.user_priority"="critical") by "Authentication.dest" | rename "Authentication.dest" as "dest" | eval cs_key='dest' | join type=inner cs_key [| tstats summariesonly=false allow_old_summaries=true values(Malware_Attacks.signature) as "signature" from datamodel=Malware.Malware_Attacks where earliest=-1450m@m latest=+0s nodename=Malware_Attacks.Allowed_Malware  by "Malware_Attacks.dest" | rename "Malware_Attacks.dest" as "dest" | eval cs_key='dest']

## SOLNESS-6455 Implement correlation search for impossible travel detection. 
## This should run every hour, and scan events for the past 18 hours to detect login attempts from a given login 
## from two geographically distant locations.
[Access - Geographically Improbable Access Detected - Rule]
action.correlationsearch                       = 0
action.correlationsearch.enabled               = 1
action.correlationsearch.label                 = Geographically Improbable Access Detected
action.correlationsearch.related_searches      = ["Access - Geographically Improbable Access - Summary Gen"]
action.email.sendresults                       = 0
action.notable                                 = 1
action.notable.param.security_domain           = access
action.notable.param.severity                  = high
action.notable.param.rule_title                = Geographically Improbable Access Detected For $user$
action.notable.param.rule_description          = Login attempts for $user$ from geographically distant locations ( $src_city$, $dest_city$ ) have been detected.  This is an indication of potentially malicious or unauthorized access attempts.
action.notable.param.nes_fields                = user
action.notable.param.drilldown_name            = View login attemps by $user$
action.notable.param.drilldown_search          = | from datamodel:"Authentication"."Authentication" | search user="$user$" (src="$src$" OR src="$dest$")
action.notable.param.drilldown_earliest_offset = 86400
action.notable.param.drilldown_latest_offset   = 0
action.notable.param.default_owner             =
action.notable.param.default_status            =
action.risk                                    = 1
action.risk.param._risk_object                 = user
action.risk.param._risk_object_type            = user
action.risk.param._risk_score                  = 80
## action.summary_index._name present for migration purposes
action.summary_index._name                     = notable
alert.digest_mode                              = 1
alert.suppress                                 = 1
alert.suppress.fields                          = user
alert.suppress.period                          = 86300s
alert.track                                    = false
counttype                                      = number of events
relation                                       = greater than
quantity                                       = 0
cron_schedule                                  = 5 * * * *
description                                    = Alerts on access attempts that are improbable based on time and geography.
disabled                                       = True
dispatch.earliest_time                         = -65m@m
dispatch.latest_time                           = +0s
enableSched                                    = 1
is_visible                                     = false
request.ui_dispatch_app                        = SplunkEnterpriseSecuritySuite
schedule_window                                = 5
search                                         = index=gia_summary source="Access - Geographically Improbable Access - Summary Gen" | fields user,src_time,src_app,src,src_lat,src_long,src_city,src_country,dest_time,dest_app,dest,dest_lat,dest_long,dest_city,dest_country,distance,speed
      
[Access - Short-lived Account Detected - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Short-lived Account Detected
action.email.sendresults              = 0
action.risk                           = 1
action.risk.param._risk_object        = user
action.risk.param._risk_object_type   = user
action.risk.param._risk_score         = 80
action.notable                        = 1
action.notable.param.security_domain  = access
action.notable.param.severity         = high
action.notable.param.rule_title       = Short-lived Account Detected ($user$)
action.notable.param.rule_description = Account $user$ on $dest$ created and deleted within $timestr$
action.notable.param.nes_fields       = user
action.notable.param.drilldown_name   = View account change events of $user$
action.notable.param.drilldown_search = | from datamodel:"Change"."Account_Management" | search user="$user$" (action="created" OR action="deleted")
action.notable.param.default_owner    = 
action.notable.param.default_status   = 
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = user
alert.suppress.period                 = 14400s
alert.track                           = 0
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */15 * * * *
description                           = Detects when a account or credential is created and then removed a short time later. This may be an indication of malicious activities.
disabled                              = True
dispatch.earliest_time                = -250m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
search                                = | tstats `summariesonly` count from datamodel=Change.All_Changes where nodename="All_Changes.Account_Management" (All_Changes.action="created" OR All_Changes.action="deleted") by _time,All_Changes.dest,All_Changes.user span=1s | `drop_dm_object_name("All_Changes")` | streamstats range(_time) as delta,sum(count) as count by user,dest window=2 global=f | where count>1 AND delta<`useraccount_minimal_lifetime` | `uptime2string(delta,timestr)` | table user, dest, delta, timestr

###### Key Indicator Searches ######
[Access - Number Of Default Accounts In Use]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Default Accounts
action.keyindicator.subtitle                  = Distinct Accounts
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(Authentication.user) as count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s Authentication.user_category=default by Authentication.user
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(Authentication.user)%20as%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Authentication.user_category%3Ddefault%20by%20Authentication.user
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Default Accounts
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Authentication.user) as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s Authentication.user_category=default | appendcols [| tstats `summariesonly` estdc(Authentication.user) as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h Authentication.user_category=default] | `get_delta`

[Access - Distinct Apps]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Auth. Apps
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(Authentication.app) as count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s by Authentication.app
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(Authentication.app)%20as%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Authentication.app
action.keyindicator.group.0.name              = access_center
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Apps
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Authentication.app) as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Authentication.app) as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h] | `get_delta`

[Access - Distinct Destinations]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Auth. Dest's
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(Authentication.dest) as count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s by Authentication.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(Authentication.app)%20as%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Authentication.user_category%3Ddefault%20by%20Authentication.app
action.keyindicator.group.0.name              = access_center
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Destinations
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Authentication.dest) as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Authentication.dest) as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h] | `get_delta`

[Access - Distinct Sources]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Auth. Sources
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(Authentication.src) as count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s by Authentication.src
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(Authentication.src)%20as%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Authentication.src
action.keyindicator.group.0.name              = access_center
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Sources
display.visualizations.show                   = 2
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Authentication.src) as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Authentication.src) as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h] | `get_delta`

[Access - Distinct Users]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Auth. Users
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(Authentication.user) as count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s by Authentication.user
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(Authentication.user)%20as%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Authentication.user
action.keyindicator.group.0.name              = access_center
action.keyindicator.group.0.order             = 4
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Users
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Authentication.user) as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Authentication.user) as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h] | `get_delta`

[Access - Total Access Attempts]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Auth. Attempts
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s
action.keyindicator.group.0.name              = access_center
action.keyindicator.group.0.order             = 5
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Total Access Attempts
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h] | `get_ksi_fields(current_count,historical_count)` | xsFindBestConcept current_count from count_1d in authentication as current_count_qual | xsfindbestconcept delta from percentile in default as delta_qual

###### Report Searches ######
[Access - Access Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication by _time span=10m | timechart minspan=10m count

[Access - Access Over Time By Action]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication by _time,Authentication.action span=10m | timechart minspan=10m useother=`useother` count by Authentication.action | `drop_dm_object_name("Authentication")`

[Access - Access Over Time By App]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication by _time,Authentication.app span=10m | timechart minspan=10m useother=`useother` count by Authentication.app

[Access - Account Usage For Expired Identities]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -7d@d
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` max(_time) as _time,values(Authentication.dest) as dest from datamodel=Authentication.Authentication by Authentication.user | `drop_dm_object_name("Authentication")` | `get_identity4events(user)` | where isnotnull(user_endDate) | where _time>user_endDate | `uitime(user_endDate,"%m/%d/%Y %H:%M:%S")` | fields _time,user,user_first,user_last,user_endDate,dest

[Access - Default Account Usage Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -7d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication where nodename=Authentication.Default_Authentication Authentication.action=success by _time span=1h | timechart minspan=1h count

[Access - Default Account Usage Over Time By App]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -7d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication where nodename=Authentication.Default_Authentication Authentication.action=success by _time,Authentication.app span=1h | timechart minspan=1h count by Authentication.app | `drop_dm_object_name("Authentication")`

[Access - Default Accounts In Use]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` max(_time) as _time,values(Authentication.user_category) as user_category,dc(Authentication.dest) as dc(dest) from datamodel=Authentication.Authentication where Authentication.user_category=default by Authentication.user | `drop_dm_object_name("Authentication")` | sort 100 - _time | fields _time,user,user_category,dc(dest)

[Access - Default Local Accounts]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `useraccounts_tracker` | search user_category=default | stats max(lastTime) as _time,values(user_category) as user_category,dc(dest) as dc(dest) by user | sort 100 - _time | fields _time,user,user_category,dc(dest)

[Access - First Time Account Access]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | from inputlookup:access_tracker | stats min(firstTime) as firstTime,values(dest) as dest by user | sort 100 - firstTime | `uitime(firstTime)` | fields dest user firstTime

[Access - First Time Account Access Over Time]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -30d@d
dispatch.latest_time                      = now
dispatchAs                                = user
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = column
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | inputlookup append=T access_tracker where `tracker_trp(firstTime_user,firstTime_user)` | rename firstTime as _time | timechart count

[Access - Inactive Accounts]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `inactive_accounts(90)` | sort 100 + lastTime | `uitime(lastTime)` | fields user lastTime inactiveDays

[Access - Inactive Account Usage]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `inactive_account_usage(90,24)` | sort 100 - lastTime | `uitime(second2lastTime)` | `uitime(lastTime)` | fields user second2lastTime lastTime inactiveDays

[Access - Notable Access Events]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = `notable` | search security_domain=access | stats sum(count) as count by rule_name

[Access - Privileged Account Usage Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -7d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = connect
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication where nodename=Authentication.Privileged_Authentication by _time span=1h | timechart span=1h count

[Access - Privileged Accounts In Use]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` values(Authentication.user_category) as user_category,dc(Authentication.dest) as dest_count,max(_time) as lastTime from datamodel=Authentication.Authentication where Authentication.user_category=privileged by Authentication.user | `drop_dm_object_name("Authentication")` | sort 100 - lastTime | `uitime(lastTime)`

[Access - Top Access By Source]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` count from datamodel=Authentication.Authentication by _time,Authentication.src span=1h | `drop_dm_object_name("Authentication")` | stats sparkline(sum(count),1h) as sparkline,sum(count) as count by src | sort - count

[Access - Top Access By Destination]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` count from datamodel=Authentication.Authentication by _time,Authentication.dest span=1h | `drop_dm_object_name("Authentication")` | stats sparkline(sum(count),1h) as sparkline,sum(count) as count by dest | sort - count

[Access - Unique Access By App Count]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` values(Authentication.app) as app,count from datamodel=Authentication.Authentication by _time,Authentication.src span=1h | `drop_dm_object_name("Authentication")` | stats sparkline(sum(count),1h) as sparkline,dc(app) as app_count by src | sort - app_count

[Access - Unique Access By Destination Count]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` values(Authentication.dest) as dest,count from datamodel=Authentication.Authentication by _time,Authentication.src span=1h | `drop_dm_object_name("Authentication")` | stats sparkline(sum(count),1h) as sparkline,dc(dest) as dest_count by src | sort - dest_count

[Access - Unique Access By User Count]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` values(Authentication.user) as user,count from datamodel=Authentication.Authentication by _time,Authentication.src span=1h | `drop_dm_object_name("Authentication")` | stats sparkline(sum(count),1h) as sparkline,dc(user) as user_count by src | sort - user_count

###### Swim Lane Searches ######
[Access - All Authentication By Asset - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = All Authentication
action.swimlane.color                             = blue
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = Authentication.src,Authentication.dest,src,dest
action.swimlane.drilldown_search                  = | from datamodel:"Authentication"."Authentication" | search $constraints$
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 0
is_visible                                        = false
request.ui_dispatch_app                           = SplunkEnterpriseSecuritySuite
search                                            = | tstats `summariesonly` values(Authentication.action) as action,values(Authentication.app) as app,values(Authentication.src) as src,values(Authentication.dest) as dest,values(Authentication.user) as user,count from datamodel=Authentication.Authentication where $constraints$ by _time span=$span$

[Access - All Authentication By Identity - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = All Authentication
action.swimlane.color                                = blue
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = Authentication.src_user,Authentication.user,src_user,user
action.swimlane.drilldown_search                     = | from datamodel:"Authentication"."Authentication" | search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 0
is_visible                                           = false
request.ui_dispatch_app                              = SplunkEnterpriseSecuritySuite
search                                               = | tstats `summariesonly` values(Authentication.action) as action,values(Authentication.app) as app,values(Authentication.src) as src,values(Authentication.dest) as dest,values(Authentication.user) as user,count from datamodel=Authentication.Authentication where $constraints$ by _time span=$span$

###### Summary Generating Searches ######

## Access - Geographically Improbable Access - Summary Gen Breakdown
## 1  - Get src/user combinations using prestats
## 2  - Alias fields
## 3  - Perform distributed asset lookup by str
## 4  - Perform distributed asset lookup by cidr
## 5  - Get iplocation on src
## 6  - Filter items with proper location
## 7  - Consolidate location information
## 8  - Persist the needed fields
## 9  - Consolidate prestats via stats
## 10 - Eval for key
## 11 - Use eventstats to copy src values to dest
## 12 - Filter single-src instances
## 13 - Expand key (this produces all combinations of srcs)
## 14 - Extract dest values
## 15 - Filter instances where src==dest (itself)
## 16 - Create key for src/dest combo
## 17 - Dedup key
## 18 - Compute globedistance
## 19 - Compute speed
## 20 - Filter speed
## 21 - Persist fields
## 22 - Index events with current time
[Access - Geographically Improbable Access - Summary Gen]
action.email.sendresults   = 0
action.summary_index       = 1
action.summary_index._name = gia_summary
cron_schedule              = 50 * * * *
disabled                   = True
dispatch.earliest_time     = -1090m@m
dispatch.latest_time       = +0s
enableSched                = 1
is_visible                 = false
request.ui_dispatch_app    = SplunkEnterpriseSecuritySuite
schedule_window            = 5
search                     = | `tstats` min(_time),earliest(Authentication.app) from datamodel=Authentication.Authentication where Authentication.action="success" by Authentication.src,Authentication.user | eval psrsvd_ct_src_app='psrsvd_ct_Authentication.app',psrsvd_et_src_app='psrsvd_et_Authentication.app',psrsvd_ct_src_time='psrsvd_ct__time',psrsvd_nc_src_time='psrsvd_nc__time',psrsvd_nn_src_time='psrsvd_nn__time',psrsvd_vt_src_time='psrsvd_vt__time',src_time='_time',src_app='Authentication.app',user='Authentication.user',src='Authentication.src' | lookup asset_lookup_by_str key as "src" OUTPUTNEW lat as "src_lat",long as "src_long",city as "src_city",country as "src_country" | lookup asset_lookup_by_cidr key as "src" OUTPUTNEW lat as "src_lat",long as "src_long",city as "src_city",country as "src_country" | iplocation src | search (src_lat=* src_long=*) OR (lat=* lon=*) | eval src_lat=if(isnotnull(src_lat),src_lat,lat),src_long=if(isnotnull(src_long),src_long,lon),src_city=case(isnotnull(src_city),src_city,isnotnull(City),City,1=1,"unknown"),src_country=case(isnotnull(src_country),src_country,isnotnull(Country),Country,1=1,"unknown") | fields psrsvd*src_*,psrsvd_v,src*,user | stats earliest(src_app) as src_app,min(src_time) as src_time by src,src_lat,src_long,src_city,src_country,user | eval key=src."@@".src_time."@@".src_app."@@".src_lat."@@".src_long."@@".src_city."@@".src_country | eventstats dc(key) as key_count,values(key) as key by user | search key_count>1 | stats first(src_app) as src_app,first(src_time) as src_time,first(src_lat) as src_lat,first(src_long) as src_long,first(src_city) as src_city,first(src_country) as src_country by src,key,user | rex field=key "^(?<dest>.+?)@@(?<dest_time>.+?)@@(?<dest_app>.+)@@(?<dest_lat>.+)@@(?<dest_long>.+)@@(?<dest_city>.+)@@(?<dest_country>.+)" | where src!=dest | eval key=mvsort(mvappend(src."->".dest, NULL, dest."->".src)),units="m" | dedup key, user | `globedistance(src_lat,src_long,dest_lat,dest_long,units)` | eval speed=distance/(abs(src_time-dest_time+1)/3600) | where speed>=500 | fields user,src_time,src_app,src,src_lat,src_long,src_city,src_country,dest_time,dest_app,dest,dest_lat,dest_long,dest_city,dest_country,distance,speed | eval _time=now()


#####################
## Account Management
#####################

###### Correlation Searches ######

###### Key Indicator Searches ######
[Change - Number Of Account Lockouts]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
counttype                                     = number of events
relation                                      = greater than
quantity                                      = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Account Lockouts
action.keyindicator.subtitle                  = Distinct Accounts
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(All_Changes.user) as count from datamodel=Change.All_Changes where earliest=-24h@h latest=+0s nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.user
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(All_Changes.user)%20as%20count%20from%20datamodel%3DChange.All_Changes%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20nodename%3DAll_Changes.Account_Management%20All_Changes.result%3D%22lockout%22%20by%20All_Changes.user
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Account Lockouts
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(All_Changes.user) as current_count from datamodel=Change.All_Changes where earliest=-24h@h latest=+0s nodename=All_Changes.Account_Management All_Changes.result="lockout" | appendcols [| tstats `summariesonly` estdc(All_Changes.user) as historical_count from datamodel=Change.All_Changes where earliest=-48h@h latest=-24h@h nodename=All_Changes.Account_Management All_Changes.result="lockout"] | `get_delta`

###### Report Searches ######
[Change - Account Lockouts]
action.email.reportServerEnabled = 0
alert.track                      = 0
counttype                        = number of events
relation                         = greater than
quantity                         = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` count from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.src,All_Changes.Account_Management.src_nt_domain,All_Changes.user | sort 100 - count | `drop_dm_object_name("All_Changes")` |  `drop_dm_object_name("Account_Management")`

[Change - Account Management By Source User]
action.email.reportServerEnabled          = 0
alert.track                               = 0
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
dispatch.earliest_time                    = -24h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` count from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management by All_Changes.Account_Management.src_user| `drop_dm_object_name("All_Changes")` | `drop_dm_object_name("Account_Management")` | sort 10 - count

[Change - Account Management Over Time By Action]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
counttype                                           = number of events
relation                                            = greater than
quantity                                            = 0
dispatch.earliest_time                              = -24h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management by _time,All_Changes.action span=10m | timechart minspan=10m useother=`useother` count by All_Changes.action | `drop_dm_object_name("All_Changes")`

[Change - Recent Account Management]
action.email.reportServerEnabled = 0
alert.track                      = 0
counttype                        = number of events
relation                         = greater than
quantity                         = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.events.fields            = ["action", "src", "src_nt_domain", "src_user", "dest", "dest_nt_domain", "user"]
display.events.list.wrap         = true
display.events.rowNumbers        = false
display.events.type              = list
display.general.enablePreview    = true
display.general.type             = events
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | from datamodel:"Change"."Account_Management" | head 1000

[Change - Top Account Management Events]
action.email.reportServerEnabled = 0
alert.track                      = 0
counttype                        = number of events
relation                         = greater than
quantity                         = 0
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` count from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management by _time,All_Changes.action span=1h | `drop_dm_object_name("All_Changes")` | stats sparkline(sum(count),1h) as sparkline,sum(count) as count by action | sort 10 - count###### Incident Review Saved Search ######
#
# Note: this saved search is intended to mirror the `notable` macro, but with slots for filtering. Any changes in the notable macro
# must be reflected here in order to view them on incident review.
#
[Incident Review - Main]
search         = $time_filter$ (`get_notable_index` OR `get_sequenced_index`) $source_filter$ | eval `get_event_id_meval`,rule_id=event_id | search $event_id_filter$ | fields - host_* | tags outputfield=tag | `mvappend_field(tag,orig_tag)` | dedup rule_id | `notable_xref_lookup` | `get_correlations` | search $security_domain_filter$ | `get_current_status` | search $status_filter$ | `get_owner` | search $owner_filter$ | `get_urgency` | search $urgency_filter$ | typer | tags outputfield=tag | `mvappend_field(tag,orig_tag)` | search $tag_filter$ | `suppression_extract` | search NOT suppression=* | `risk_correlation`
is_visible     = false

###### Administrative Searches ######
[Threats - Disable Suppressions - Administrative]
cron_schedule          = 0 3 * * *
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
search                 = | rest splunk_server=local count=0 /services/alerts/suppressions/-/_autodisable
run_on_startup         = true

[Threat - Refresh Governance - Administrative]
cron_schedule          = 0 * * * *
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
search                 = | rest splunk_server=local count=0 /services/alerts/governance/_reload
run_on_startup         = true

[Threat - Refresh Reviewstatuses - Administrative]
cron_schedule          = 0 * * * *
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
search                 = | rest splunk_server=local count=0 /services/alerts/reviewstatuses/_reload
run_on_startup         = true

###### Context Generators ######
[Risk - Median Object Risk Per Day - Context Gen]
action.email.sendresults   = 0
cron_schedule              = 0 0 * * *
disabled                   = False
dispatch.earliest_time     = -30d@d
dispatch.latest_time       = @d
enableSched                = 1
is_visible                 = false    
schedule_window            = 20
search                     = | tstats `summariesonly` sum(All_Risk.risk_score) as object_risk from datamodel=Risk.All_Risk by _time,All_Risk.risk_object,All_Risk.risk_object_type span=1d | `drop_dm_object_name("All_Risk")` | `context_stats(object_risk, risk_object_type)` | eval min=0 | eval max=median*2 | xsUpdateDDContext app=SA-ThreatIntelligence name=median_object_risk_by_object_type_1d container=risk class=risk_object_type type=domain scope=app | stats count

[Risk - Total Risk By Risk Object Type Per Day - Context Gen]
action.email.sendresults   = 0
cron_schedule              = 0 1 * * *
disabled                   = False
dispatch.earliest_time     = -30d@d
dispatch.latest_time       = @d
enableSched                = 1
is_visible                 = false 
schedule_window            = 20
search                     = | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk by _time,All_Risk.risk_object_type span=1d | `drop_dm_object_name("All_Risk")` | `context_stats(accum_risk, risk_object_type)` | eval min=0 | eval max=median*2 | xsUpdateDDContext app=SA-ThreatIntelligence name=total_risk_by_object_type_1d container=risk class=risk_object_type type=domain scope=app | stats count

###### Correlation Searches ######
## SOLNESS-7123: Introducing correlation search entry for manually created notable events
## This will permit users to define a default set of suppression fields if they so choose
[Manual Notable Event - Rule]
action.notable.param.nes_fields =
disabled                        = False
is_visible                      = false
search                          = | noop

## SOLNESS-6161: Notable Event Audit Notifications
## Use Case: Please alert me (the SOC team manager) when any NEs are created that remain unassigned (i.e. in "New" status) for longer than 4 hours
## The key here is the dispatch times.  latest_time=-4h@h ensures that everything is at least 4 hours old
## From there we filter for status_group="New" OR owner="unassigned"
## Prepend result fields with orig_ in case the notable event action is enabled for this correlation
## No alert actions enabled by default
[Audit - Untriaged Notable Events - Rule]
action.correlationsearch         = 0
action.correlationsearch.enabled = 1
action.correlationsearch.label   = Untriaged Notable Events
action.email.sendresults         = 0
action.notable.param.rule_title  = Untriaged Notable Events
alert.digest_mode                = 1
alert.suppress                   = 1
alert.suppress.fields            = orig_rule_id
alert.suppress.period            = 86300s
alert.track                      = false
counttype                        = number of events
relation                         = greater than
quantity                         = 0
cron_schedule                    = 35 * * * *
description                      = Alerts when notable events have not been triaged
disabled                         = True
dispatch.earliest_time           = -48h@h
dispatch.latest_time             = -4h@h
enableSched                      = 1
is_visible                       = false
schedule_window                  = 5
search                           = `notable` | search (status_group="New" OR owner="unassigned") | table _time,rule_id,rule_name,status_label,owner | rename * as orig_*

[Threat - Same Error On Many Systems - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Same Error On Many Servers Detected
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = threat
action.notable.param.severity         = medium
action.notable.param.rule_title       = Same Error On Many Servers Detected
action.notable.param.rule_description = $orig_sourcetype$ errors were discovered on $system_count$ different systems.  Errors are determined to be "like" based on the Splunk punctuation field (punct).
action.notable.param.nes_fields       = orig_sourcetype
action.notable.param.drilldown_name   = View all $orig_sourcetype$ errors
action.notable.param.drilldown_search = tag=error NOT tag=authentication sourcetype="$orig_sourcetype$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = sourcetype
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 40 * * * *
description                           = Alerts when multiple systems are exhibiting the same errors
disabled                              = True
dispatch.earliest_time                = -65m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
schedule_window                       = 5
search                                = tag=error NOT tag=authentication | stats first(_raw) as orig_raw,dc(host) as system_count by sourcetype,punct | where 'system_count'>100

[Threat - Watchlisted Events - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Watchlisted Event Observed
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = threat
action.notable.param.severity         = high
action.notable.param.rule_title       = Watchlisted Event Observed
action.notable.param.rule_description = A watchlisted $orig_sourcetype$ event was observed from $orig_host$. This event may have a high priority and ought to be investigated.
action.notable.param.nes_fields       = orig_host,orig_sourcetype
action.notable.param.drilldown_name   = 
action.notable.param.drilldown_search = 
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = host
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = suppression_value
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Alerts when an event is discovered including text has been identified as important. This rule triggers whenever an event is discovered with the tag of "watchlist".
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = tag=watchlist NOT sourcetype=stash | eval risk_object=case(isnotnull(user),user,isnotnull(src_user),src_user,isnotnull(dest),dest,isnotnull(src),src,1=1,host) | eval risk_object_type=case(isnotnull(user),"user",isnotnull(src_user),"user",isnotnull(dest),"system",isnotnull(src),"system",1=1,"system") | eval risk_score=if(eventtype="website_watchlist",50,null()) | eval suppression_value=sourcetype."|".risk_object  | `get_event_id` | table _raw,event_id,host,source,sourcetype,src,dest,dvc,src_user,user

###### Key Indicator Searches ######
[Risk - Distinct Risk Object Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Distinct Risk Objects
action.keyindicator.subtitle                  = Object Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc("All_Risk.risk_object") as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(%22All_Risk.risk_object%22)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Risk Object Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` estdc("All_Risk.risk_object") as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s | appendcols [|tstats `summariesonly` estdc("All_Risk.risk_object") as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h] | `get_delta` | fields current_count,*

[Risk - Distinct Risk Object Count By System]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Distinct Risk System Objects
action.keyindicator.subtitle                  = System Object Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count(All_Risk.risk_object) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=system by "All_Risk.risk_object"
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count(All_Risk.risk_object)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3Dsystem%20by%20%22All_Risk.risk_object%22
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct System Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` estdc(All_Risk.risk_object) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=system by "All_Risk.risk_object_type" | appendcols [| tstats `summariesonly` estdc(All_Risk.risk_object) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type=system by "All_Risk.risk_object_type"] | `get_delta` | fields current_count,*

[Risk - Distinct Risk Object Count By User]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Distinct Risk User Objects
action.keyindicator.subtitle                  = User Object Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count(All_Risk.risk_object) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=user by All_Risk.risk_object 
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count(All_Risk.risk_object)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3Duser%20by%20All_Risk.risk_object%20
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct User Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` estdc(All_Risk.risk_object) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=user by All_Risk.risk_object_type | appendcols [| tstats `summariesonly` estdc(All_Risk.risk_object) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type=user by All_Risk.risk_object_type] | `get_delta` | fields current_count,*

[Risk - Distinct Risk Object Count By Other]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Distinct Risk Other Objects
action.keyindicator.subtitle                  = Other Object Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count(All_Risk.risk_object) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=other by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count(All_Risk.risk_object)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3Dother%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Other Object Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` estdc(All_Risk.risk_object) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=other by All_Risk.risk_object_type | appendcols [| tstats `summariesonly` estdc(All_Risk.risk_object) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type=other by All_Risk.risk_object_type] | `get_delta` | fields current_count,*

[Risk - Median Risk Score]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Median Risk Score
action.keyindicator.subtitle                  = Overall Median Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(All_Risk.risk_object)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3Dother%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Median Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s by All_Risk.risk_object | stats median(accum_risk) as current_count | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h by All_Risk.risk_object | stats median(accum_risk) as historical_count] | `get_ksi_fields(current_count, historical_count)` | xsfindbestconcept current_count FROM median_object_risk_by_object_type_1d IN risk as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Median Risk Score By System]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Median System Risk
action.keyindicator.subtitle                  = System Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
#  | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="system" by All_Risk.risk_object, All_Risk.risk_object_type
action.keyindicator.drilldown_uri             = search?q=%20%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20accum_risk%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22system%22%20by%20All_Risk.risk_object%2C%20All_Risk.risk_object_type
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Median Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="system" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as current_count | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="system" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as historical_count] | eval risk_object_type="system" | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM median_object_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Median Risk Score By User]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Median User Risk
action.keyindicator.subtitle                  = User Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="user" by All_Risk.risk_object, All_Risk.risk_object_type 
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20accum_risk%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22user%22%20by%20All_Risk.risk_object%2C%20All_Risk.risk_object_type%20
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Median Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="user" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as current_count | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="user" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as historical_count] | eval risk_object_type="user" | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM median_object_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Median Risk Score By Other]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Median Other Risk
action.keyindicator.subtitle                  = Other Object Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="other" by All_Risk.risk_object, All_Risk.risk_object_type
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20accum_risk%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22other%22%20by%20All_Risk.risk_object%2C%20All_Risk.risk_object_type
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Median Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="other" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as current_count | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="other" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as historical_count] | eval risk_object_type="other" | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM median_object_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Aggregated Risk]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Aggregated Risk
action.keyindicator.subtitle                  = Total Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
#  | tstats `summariesonly` sum(All_Risk.risk_score) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%20%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Aggregated Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h] | `get_ksi_fields(current_count, historical_count)` | xsfindbestconcept current_count FROM total_risk_by_object_type_1d IN risk as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Aggregated System Risk]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Aggregated System Risk
action.keyindicator.subtitle                  = Total System Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="system" by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20current_count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22system%22%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Aggregated Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="system" by All_Risk.risk_object_type | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="system" by All_Risk.risk_object_type] | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM total_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Aggregated User Risk]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Aggregated User Risk
action.keyindicator.subtitle                  = Total User Risk
action.keyindicator.value                     = current_count
action.keyindicator.drilldown_uri             = user_activity
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="user" by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22user%22%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 4
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Aggregated Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="user" by All_Risk.risk_object_type | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="user" by All_Risk.risk_object_type] | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM total_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Aggregated Other Risk]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Aggregated Other Risk
action.keyindicator.subtitle                  = Total Other Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as score from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="other" by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20score%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22other%22%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 5
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Aggregated Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="other" by All_Risk.risk_object_type | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="other" by All_Risk.risk_object_type] | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM total_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Distinct Modifier Sources]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Distinct Modifier Sources
action.keyindicator.subtitle                  = Source Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count(source) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s by source
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count(source)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20source
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Modifier Sources
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` estdc(source) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s | appendcols[| tstats `summariesonly` estdc(source) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h] | `get_delta`

###### Lookup Generating Searches ######
## Threat - Correlation Searches - Lookup Gen Breakdown
## 1  - Get saved/searches with listDefaultActionArgs=1
## 2  - Whitelist correlation, notable or risk action searches
## 3  - Set rule_name based on correlationsearch label
## 4  - Renames
## 5  - Append configs/conf-correlationsearches
## 6  - Eval empty strings to null()
## 7  - Use appendpipe to add versions of _key with quotes replaces as underscores (per SOLNESS-12049)
## 7a - Filter _key values with "
## 7b - Replace " with _
## 8  - Use stats to take the first values we come to
## 9  - Upsert to correlationsearches_lookup
## 10 - Consolidating stats
[Threat - Correlation Searches - Lookup Gen]
cron_schedule          = * * * * *
disabled               = False
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = true
search                 = | rest splunk_server=local count=0 "/servicesNS/-/-/saved/searches?listDefaultActionArgs=1" | where match('action.correlationsearch.enabled', "1|[Tt]|[Tt][Rr][Uu][Ee]") OR match('action.notable', "1|[Tt]|[Tt][Rr][Uu][Ee]") OR match('action.risk', "1|[Tt]|[Tt][Rr][Uu][Ee]") | eval rule_name=if(isnotnull('action.correlationsearch.label'),'action.correlationsearch.label',title) | rename title as _key,action.notable.param.* as * | append [| rest splunk_server=local count=0 /servicesNS/-/-/configs/conf-correlationsearches | rename title as _key] | eval security_domain=if(security_domain="",null(),security_domain),severity=if(severity="",null(),severity),rule_name=if(rule_name="",null(),rule_name),description=if(description="",null(),description),rule_title=if(rule_title="",null(),rule_title),rule_description=if(rule_description="",null(),rule_description),drilldown_name=if(drilldown_name="",null(),drilldown_name),drilldown_search=if(drilldown_search="",null(),drilldown_search),drilldown_earliest_offset=if(drilldown_earliest_offset="",null(),drilldown_earliest_offset),drilldown_latest_offset=if(drilldown_latest_offset="",null(),drilldown_latest_offset),default_status=if(default_status="",null(),default_status),default_owner=if(default_owner="",null(),default_owner),next_steps=if(next_steps="",null(),next_steps),investigation_profiles=if(investigation_profiles="",null(),investigation_profiles),extract_assets=if(extract_assets="",null(),extract_assets),extract_identities=if(extract_identities="",null(),extract_identities),recommended_actions=if(recommended_actions="",null(),recommended_actions) | appendpipe [ where _key LIKE "%\"%" | eval _key=replace(_key, "\"", "_") ] | stats first(security_domain) as security_domain,first(severity) as severity,first(rule_name) as rule_name,first(description) as description,first(rule_title) as rule_title,first(rule_description) as rule_description,first(drilldown_name) as drilldown_name,first(drilldown_search) as drilldown_search,first(drilldown_earliest_offset) as drilldown_earliest_offset,first(drilldown_latest_offset) as drilldown_latest_offset,first(default_status) as default_status,first(default_owner) as default_owner,first(next_steps) as next_steps,first(investigation_profiles) as investigation_profiles,first(extract_assets) as extract_assets,first(extract_identities) as extract_identities,first(recommended_actions) as recommended_actions by _key | outputlookup correlationsearches_lookup append=T key_field=_key | stats count

[Threat - Notable Owners - Lookup Gen]
cron_schedule          = */10 * * * *
disabled               = False
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = true
search                 = | rest splunk_server=local count=0 /services/authentication/users | search capabilities="can_own_notable_events" | rename title as owner | append [| makeresults | eval owner="unassigned" ] | eval _key=owner | eval realname=if(isnull(realname) or realname="", null(), realname) | table _key owner realname | outputlookup notable_owners_lookup | stats count

[Threat - Risk Correlation By System - Lookup Gen]
cron_schedule          = */30 * * * *
disabled               = False
dispatch.earliest_time = -7d@h
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = false
search                 = | tstats summariesonly=false allow_old_summaries=true sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk where All_Risk.risk_object_type="system" by All_Risk.risk_object | eval dest=lower('All_Risk.risk_object') | `get_asset(dest)` | eval dest=if(isnotnull(dest_asset_id),mvappend(dest,NULL,lower(dest_mac)),dest),dest=if(isnotnull(dest_asset_id),mvappend(dest,NULL,lower(dest_nt_host)),dest),dest=if(isnotnull(dest_asset_id),mvappend(dest,NULL,lower(dest_dns)),dest) | stats sum(risk_score) as risk_score by dest | rename dest as risk_object | outputlookup risk_correlation_by_system_lookup | stats count

[Threat - Risk Correlation By User - Lookup Gen]
cron_schedule          = */30 * * * *
disabled               = False
dispatch.earliest_time = -7d@h
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = false
search                 = | tstats summariesonly=false allow_old_summaries=true sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk where All_Risk.risk_object_type="user" by All_Risk.risk_object | eval user=lower('All_Risk.risk_object') | `get_identity4events(user)` | eval risk_object=if(isnotnull(user_identity),lower(user_identity),user) | stats sum(risk_score) as risk_score by risk_object | outputlookup risk_correlation_by_user_lookup | stats count

[Threat - Risk Correlation By Other - Lookup Gen]
cron_schedule          = */30 * * * *
disabled               = True
dispatch.earliest_time = -7d@h
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = false
search                 = | tstats summariesonly=false allow_old_summaries=true sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk where (All_Risk.risk_object_type!="user" AND All_Risk.risk_object_type!="system") by All_Risk.risk_object,All_Risk.risk_object_type | `drop_dm_object_name("All_Risk")` | eval risk_object=lower('risk_object'),risk_object_type=lower('risk_object_type') | stats sum(risk_score) as risk_score by risk_object,risk_object_type | outputlookup risk_correlation_by_other_lookup | stats count

[Threat - Alexa Top Sites - Lookup Gen]
cron_schedule          = 1 5 * * *
disabled               = 1
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence `top_1m_sites` | outputlookup alexa_lookup_by_str | stats count

[Threat - ASN String Matches - Lookup Gen]
cron_schedule          = 1 15 * * *
disabled               = 1
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence maxmind_geoip_asn_ipv4 | expandiprange ip | eval ip=mvfilter(!match(ip, `ipv4_cidr_regex`)) | where isnotnull(ip) | mvexpand ip| outputlookup output_format=splunk_mv_csv asn_lookup_by_str | stats count

[Threat - ASN CIDR Matches - Lookup Gen]
cron_schedule          = 1 15 * * *
disabled               = 1
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence maxmind_geoip_asn_ipv4 | expandiprange ip | eval ip=mvfilter(match(ip, `ipv4_cidr_regex`)) | where isnotnull(ip) | mvexpand ip | outputlookup output_format=splunk_mv_csv asn_lookup_by_cidr | stats count

[Threat - ASN IPv6 CIDR Matches - Lookup Gen]
cron_schedule          = 1 15 * * *
disabled               = 1
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence maxmind_geoip_asn_ipv6 | outputlookup asn_lookup_by_cidr_ipv6 | stats count

[Threat - ICANN Top Level Domain - Lookup Gen]
cron_schedule          = 1 15 * * *
disabled               = 0
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence icann_top_level_domain_list | eval tld=lower(domain) | fields tld | outputlookup cim_http_tld_lookup | stats count

[Threat - Mozilla Public Suffix - Lookup Gen]
cron_schedule          = 1 20 * * *
disabled               = 0
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence mozilla_public_suffix_list | eval segments=mvcount(split(domain, ".")), length=case(rule=="*", segments+2, rule=="!", segments, 1==1, segments+1) | fields length,domain,segments | outputlookup mozilla_public_suffix_lookup | stats count

###### Report Searches ######
[Incident Review - Activity By Reviewer Over Time] 
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
dispatchAs                                = user
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = column
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
search                                    = | `incident_review` | timechart useother=`useother` count by reviewer_realname

[Incident Review - Notable Events By Status]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
search                                    = `notable` | search NOT `suppression` | stats count by status_label | rename status_label as status | sort 10 - count

[Incident Review - Notable Events By Owner]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
search                                    = `notable` | search NOT `suppression` | chart count over owner by urgency | `sort_chart`

[Incident Review - Mean Time To Closure]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -60d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats `summariesonly` earliest(_time) as _time from datamodel=Incident_Management.Notable_Events_Meta by source,Notable_Events_Meta.rule_id | `drop_dm_object_name("Notable_Events_Meta")` | `get_correlations` | `get_current_status` | search status_label="Closed" | eval ttc=mvindex(review_time, 0) | eval ttc=ttc-_time | stats count avg(ttc) as avg_ttc,max(ttc) as max_ttc by rule_name | sort - avg_ttc | `uptime2string(avg_ttc, avg_ttc)` | `uptime2string(max_ttc, max_ttc)` | rename *_ttc* as *(time_to_closure)* | fields - *_dec

[Incident Review - Mean Time To Triage]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -14d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats `summariesonly` earliest(_time) as _time from datamodel=Incident_Management.Notable_Events_Meta by source,Notable_Events_Meta.rule_id | `drop_dm_object_name("Notable_Events_Meta")` | `get_correlations` | join rule_id [| from inputlookup:incident_review_lookup | eval _time=time | stats earliest(_time) as review_time by rule_id] | eval ttt=review_time-_time | stats count,avg(ttt) as avg_ttt,max(ttt) as max_ttt by rule_name | sort - avg_ttt | `uptime2string(avg_ttt, avg_ttt)` | `uptime2string(max_ttt, max_ttt)` | rename *_ttt* as *(time_to_triage)* | fields - *_dec

[Incident Review - Top Reviewers]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `incident_review` | stats sparkline,count,min(_time) as firstTime,max(_time) as lastTime by reviewer_realname | `uitime(firstTime)` | `uitime(lastTime)` | sort 100 - count

[Incident Review - Recent Review Activity]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `incident_review` | rename status_label as status | sort 100 - _time | table _time,rule_id,status,rule_name,owner_realname,comment,reviewer_realname

[Risk - Risk Modifiers Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = column
display.visualizations.charting.axisY2.enabled      = 1
display.visualizations.charting.chart.overlayFields = count
display.visualizations.charting.legend.placement    = bottom
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = | tstats prestats=true summariesonly=false allow_old_summaries=`allow_old_summaries_bool` sum(All_Risk.risk_score),count from datamodel=Risk.All_Risk by _time span=10m | timechart minspan=10m sum(All_Risk.risk_score) as risk_score,count

[Risk - Risk Score By Business Unit]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats summariesonly=false allow_old_summaries=`allow_old_summaries_bool` sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk by All_Risk.risk_object,All_Risk.risk_object_type | `drop_dm_object_name("All_Risk")` | eval dest=if(risk_object_type=="system",risk_object,null()) | eval user=if(risk_object_type=="user",risk_object,null()) | `get_asset(dest)` | `get_identity4events(user)` | `mvappend_field(dest_bunit,user_bunit)` | stats sum(risk_score) as risk_score,dc(risk_object) by dest_bunit | eval avg_score=floor('risk_score'/'dc(risk_object)') | rename dest_bunit as bunit

[Risk - Risk Score By Object]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats summariesonly=false allow_old_summaries=`allow_old_summaries_bool` sum(All_Risk.risk_score) as risk_score,dc(source) as source_count,count from datamodel=Risk.All_Risk by All_Risk.risk_object,All_Risk.risk_object_type | `drop_dm_object_name("All_Risk")` | sort 1000 - risk_score

[Risk - Most Active Sources]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats summariesonly=false allow_old_summaries=`allow_old_summaries_bool` sum(All_Risk.risk_score) as risk_score,dc(All_Risk.risk_object) as risk_objects,count from datamodel=Risk.All_Risk by source | sort 1000 - count,risk_score

[Risk - Recent Risk Modifiers]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | from datamodel:"Risk"."All_Risk" | head 1000 | table _time risk_object risk_object_type source description risk_score

[Suppressions - Currently Suppressed Events Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = `suppressed_notables` | timechart minspan=10m count by rule_name

[Suppressions - Suppression History Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -30d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = index=notable_summary source="Threat - Suppressed Notables - Summary Gen" | timechart minspan=1d sum(count) as count by rule_name

[Suppressions - Suppression Management Activity]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -7d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = `suppression_audit` | table _time suppression action status user

[Suppressions - Expired Suppressions]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -7d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = `suppression_audit-expired` | eval raw=_raw | table _time suppression raw

###### Summary Generating Searches ######
[Threat - Suppressed Notables - Summary Gen]
action.email.sendresults   = 0
action.summary_index       = 1
action.summary_index._name = notable_summary
cron_schedule              = 55 0,6,12,18 * * *
dispatch.earliest_time     = -365m@m
dispatch.latest_time       = -5m@m
enableSched                = 1
is_visible                 = false
schedule_window            = 10
search                     = `suppressed_notables` | stats count by security_domain, rule_name, urgency, suppression

###### Swim Lane Searches ######
[Threat - All Notable Events By Asset - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = Notable Events
action.swimlane.color                             = yellow
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = orig_host,dvc,src,dest
action.swimlane.drilldown_search                  = $constraints$ `notable`
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 5
is_visible                                        = false
search                                            = $constraints$ `notable` | bucket _time span=$span$ | stats values(rule_name) as rule_name,values(urgency) as urgency,values(src) as src,values(dest) as dest,count by _time

[Threat - All Notable Events By Identity - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = Notable Events
action.swimlane.color                                = yellow
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = src_user,user
action.swimlane.drilldown_search                     = $constraints$ `notable`
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 5
is_visible                                           = false
search                                               = $constraints$ `notable` | bucket _time span=$span$ | stats values(rule_name) as rule_name,values(urgency) as urgency,values(src) as src,values(dest) as dest,count by _time

[Threat - All Risk Modifiers By Asset - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = Risk Modifiers
action.swimlane.color                             = blue
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = All_Risk.risk_object
action.swimlane.drilldown_search                  = | tstats summariesonly=false allow_old_summaries=true sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk where $constraints$ by source | sort - risk_score
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 6
is_visible                                        = false
search                                            = | tstats summariesonly=false allow_old_summaries=true values(source) as source,values(All_Risk.risk_object) as risk_object,sum(All_Risk.risk_score) as count from datamodel=Risk.All_Risk where $constraints$ by _time span=$span$ | eval risk_score=count

[Threat - All Risk Modifiers By Identity - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = Risk Modifiers
action.swimlane.color                             = blue
action.swimlane.constraint_method                 = reverse_identity_lookup
action.swimlane.constraint_fields                 = All_Risk.risk_object
action.swimlane.drilldown_search                  = | tstats summariesonly=false allow_old_summaries=true sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk where $constraints$ by source | sort - risk_score
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 6
is_visible                                        = false
search                                            = | tstats summariesonly=false allow_old_summaries=true values(source) as source,values(All_Risk.risk_object) as risk_object,sum(All_Risk.risk_score) as count from datamodel=Risk.All_Risk where $constraints$ by _time span=$span$ | eval risk_score=count
[Qualys Integration Framework Basic - Vulnarable Services Lookup]
action.email.useNSSubject = 1
action.sendmn = 1
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 0 0 * * *
dispatch.earliest_time = -1d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeQualysIntegrationFrameworkBasic
request.ui_dispatch_view = search
search = | inputlookup vulnerable_services.csv | search NOT [|  inputlookup vulnerable_services.csv | stats count by HostIP | table HostIP |   append  [ search index=*  eventtype=qualys_vm_detection_event VULN_TYPE=Vulnerability PORT=*  STATUS!=FIXED |rename  IP as HostIP| stats count by HostIP |table HostIP  ] | stats count by HostIP | where count=2 | table HostIP ] | append [search index=*  eventtype=qualys_vm_detection_event VULN_TYPE=Vulnerability PORT=*  STATUS!=FIXED |  rename  IP as HostIP DNS as Hostname QID as VulnQID PORT as VulnPort PROTOCOL as VulnProtocol vuln_category as VulnServiceName SEVERITY as VulnSeverity | table _time  HostIP Hostname VulnQID VulnPort VulnProtocol VulnServiceName VulnSeverity] | outputlookup vulnerable_services.csv

[Connection to Vulnerable Service]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to Vulnerable Service" dest_ip=$result.dest_ip$ dest_port=$result.dest_port$ src_ip=$result.src_ip$
action.logevent.param.index = qifb
action.logevent.param.source = qifb
action.logevent.param.sourcetype = qifb
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeQualysIntegrationFrameworkBasic
request.ui_dispatch_view = search
search = index=* (tag::eventtype="communicate" OR tag::eventtype="network")  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | join dest_ip dest_port [| inputlookup vulnerable_services.csv | rename HostIP as dest_ip VulnPort as dest_port]  | table _time dest_ip dest_port src_ip

[Gateway Avoidance by Vulnerable Host]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Gateway Avoidance by Vulnerable Host" dest_ip=$result.dest_ip$ dest_port=$result.dest_port$ src_ip=$result.src_ip$
action.logevent.param.index = qifb
action.logevent.param.source = qifb
action.logevent.param.sourcetype = qifb
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeQualysIntegrationFrameworkBasic
request.ui_dispatch_view = search
search = index=* (tag::eventtype="communicate" OR tag::eventtype="network")  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | lookup ipdomain clientip as src_ip  OUTPUT class | where class="internal" | join src_ip [| inputlookup vulnerable_services.csv | dedup HostIP | rename HostIP as src_ip | table src_ip ] | lookup ipdomain clientip as dest_ip  OUTPUT class as class1 | search NOT   [|inputlookup ipdomain | rename class as class1| table class1] | table _time src_ip dest_port dest_ip
[Connection to Industroyer C&C]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to Industroyer C&C" Severity="6" src_ip="$result.src_ip$" dest_ip=$result.IPAddress$ dest_port=$result.dest_port$
action.logevent.param.index = industroyer
action.logevent.param.source = industroyer
action.logevent.param.sourcetype = industroyer
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCIndustroyerMalwareDetector
request.ui_dispatch_view = search
search = index=* (tag::eventtype="web" OR tag::eventtype="proxy" OR tag::eventtype="communicate" OR tag::eventtype="network") NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rex field=dest "(?<IP_add>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(?<dest_port>\d+)" | rename dest_ip as clientip  | lookup ipdomain clientip  OUTPUT class | search NOT class=*  | rename clientip as IPAddress | search (IPAddress=195.16.88.6 OR IPAddress=46.28.200.132 OR IPAddress=188.42.253.43 OR IPAddress=5.39.218.152 OR IPAddress=93.115.27.57) | table  _time ,src_ip, IPAddress, dest_port

[Scan from IP which tried to connect to C&C]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="SScan from IP which tried to connect to C&C" Severity="8" src_ip="$result.src_ip$" HostsScanned=$result.HostsScanned$
action.logevent.param.index = industroyer
action.logevent.param.source = industroyer
action.logevent.param.sourcetype = industroyer
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCIndustroyerMalwareDetector
request.ui_dispatch_view = search
search = index=*  ( tag::eventtype="communicate" OR tag::eventtype="network") dest_port=102  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_ip) AS HostsScanned by src_ip, _time |  where HostsScanned >= 50 | dedup src_ip, HostsScanned | table src_ip, HostsScanned, _time | join type=inner [ search index="industroyer" earliest=-30d  latest=now  Name="Connection to Industroyer C&C" | dedup src_ip | fields src_ip ]

[Industroyer hash detected]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Process runnning with Industroyer hash detected" Severity="6" src_ip="$result.src_ip$" ProcessName=$result.Image$ Hash=$result.Hashes$
action.logevent.param.index = industroyer
action.logevent.param.source = industroyer
action.logevent.param.sourcetype = industroyer
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCIndustroyerMalwareDetector
request.ui_dispatch_view = search
search = index=*  source="WinEventLog:Microsoft-Windows-Sysmon/Operational"  (EventDescription="Process Create" OR EventDescription="File Create" ) | rex field=Hashes mode=sed "s/SHA256=//g" | rex field=Hashes mode=sed "s/SHA1=//g" | rex field=Hashes mode=sed "s/MD5=//g" | search (Hashes=F6C21F8189CED6AE150F9EF2E82A3A57843B587D OR Hashes=CCCCE62996D578B984984426A024D9B250237533 OR Hashes=8E39ECA1E48240C01EE570631AE8F0C9A9637187 OR Hashes=2CB8230281B86FA944D3043AE906016C8B5984D9 OR Hashes=79CA89711CDAEDB16B0CCCCFDCFBD6AA7E57120A OR Hashes=94488F214B165512D2FC0438A581F5C9E3BD4D4C OR Hashes=5A5FAFBC3FEC8D36FD57B075EBF34119BA3BFF04 OR Hashes=B92149F046F00BB69DE329B8457D32C24726EE00 OR Hashes=B335163E6EB854DF5E08E85026B2C3518891EDA8)| rename Computer as host | lookup dnsLookup host  OUTPUT ip | rename ip as src_ip host as Hostname | table _time src_ip Image Hashes

[Scan 102 port, 50 hosts per 1 min]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Scan 102 port, 50 hosts per 1 min" Severity="6" src_ip="$result.src_ip$" HostsScanned=$result.HostsScanned$
action.logevent.param.index = industroyer
action.logevent.param.source = industroyer
action.logevent.param.sourcetype = industroyer
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCIndustroyerMalwareDetector
request.ui_dispatch_view = search
search = index=* ( tag::eventtype="communicate" OR tag::eventtype="network") dest_port=102  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_ip) AS HostsScanned by src_ip, _time |  where HostsScanned >= 50 | dedup src_ip, HostsScanned | table src_ip, HostsScanned, _time
[EternalRocks Worm Detector - Network Scan on 445 Port (by EternalRocks)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Network Scan on 445 Port" Severity="8" src_ip="$result.src_ip$" HostsScanned=$result.HostsScanned$
action.logevent.param.index = eternalrocks
action.logevent.param.source = eternalrocks
action.logevent.param.sourcetype = eternalrocks
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCEternalRocksWormDetector
request.ui_dispatch_view = search
search = index=* ( tag::eventtype="communicate" OR tag::eventtype="network") dest_port=445  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_ip) AS HostsScanned by src_ip, _time |  where HostsScanned >= 30 | dedup src_ip, HostsScanned | table src_ip, HostsScanned, _time

[EternalRocks Worm Detector - Activity on Windows Hosts by File Names (Sysmon)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by File Names" Severity="8"\
src_ip="$result.ip$" FileName=$result.FileName$
action.logevent.param.index = eternalrocks
action.logevent.param.source = eternalrocks
action.logevent.param.sourcetype = eternalrocks
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCEternalRocksWormDetector
request.ui_dispatch_view = search
search = index=*  sourcetype="xmlwineventlog:microsoft-windows-sysmon/operational"  (EventDescription="Process Create" OR EventDescription="File Create" ) |rename process as FileName |  join FileName [| inputlookup eternalrocks_files.csv | table FileName ]  |  rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip FileName

[EternalRocks Worm Detector - Activity on Windows Hosts by File Hashes (Sysmon)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by File Hashes" Severity="8"\
src_ip="$result.ip$" Hashes=$result.Hashes$
action.logevent.param.index = eternalrocks
action.logevent.param.source = eternalrocks
action.logevent.param.sourcetype = eternalrocks
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCEternalRocksWormDetector
request.ui_dispatch_view = search
search = index=*  sourcetype="xmlwineventlog:microsoft-windows-sysmon/operational"  (EventDescription="Process Create" OR EventDescription="File Create" ) | rex field=Hashes mode=sed "s/SHA256=//g" | rex field=Hashes mode=sed "s/SHA1=//g" | rex field=Hashes mode=sed "s/MD5=//g"| join Hashes [| inputlookup eternalrocks_hashes.csv | table Hash | rename Hash as Hashes] | rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip Hashes

[EternalRocks Worm Detector - Activity on Windows Hosts by Process (Sysmon)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by Process" Severity="8"\
src_ip="$result.ip$" CommandLine="$result.CommandLine$"
action.logevent.param.index = eternalrocks
action.logevent.param.source = eternalrocks
action.logevent.param.sourcetype = eternalrocks
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCEternalRocksWormDetector
request.ui_dispatch_view = search
search = index=*  sourcetype="xmlwineventlog:microsoft-windows-sysmon/operational"  (EventDescription="Process Create" OR EventDescription="File Create" )   shadowbrokers.zip OR SharpZLib.zip OR installed.fgh OR ICSharpCode.SharpZipLib.dll OR Microsoft.Win32.TaskScheduler.dll OR tor.zip OR required.glo OR taskhost.exe OR TaskScheduler.zip OR torunzip.exe OR (C:\Program Files\Microsoft Updates\SharpZLib.zip) OR (C:\Program Files\Microsoft Updates\svchost.exe) OR (C:\Program Files\Microsoft Updates\installed.fgh)  OR (C:\Program Files\Microsoft Updates\ICSharpCode.SharpZipLib.dll) OR (C:\Program Files\Microsoft Updates\Microsoft.Win32.TaskScheduler.dll) OR (C:\Program Files\Microsoft Updates\SharpZLib) OR (C:\Program Files\Microsoft Updates\temp\tor.zip) OR (C:\Program Files\Microsoft Updates\temp\Tor) OR (C:\Program Files\Microsoft Updates\required.glo) OR (C:\Program Files\Microsoft Updates\taskhost.exe) OR (C:\Program Files\Microsoft Updates\TaskScheduler.zip) OR (C:\Program Files\Microsoft Updates\TaskScheduler) OR (C:\Program Files\Microsoft Updates\torunzip.exe) | rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip CommandLine 

[EternalRocks Worm Detector - Connection to TORPROJECT.ORG,onion]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to TORPROJECT.ORG,onion" Severity="7" src_ip="$result.src_ip$"  domain=$result.domain$
action.logevent.param.index = eternalrocks
action.logevent.param.source = eternalrocks
action.logevent.param.sourcetype = eternalrocks
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCEternalRocksWormDetector
request.ui_dispatch_view = search
search = index=* tag=proxy ( url=*torproject.org* OR url=*.onion* OR url=*api.nuget.org/packages/taskscheduler.2.5.23.nupkg* OR url=*api.nuget.org/packages/sharpziplib.0.86.0.nupkg* )  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rex field=url "((?:http(?:s)?:\/\/)?(?<domain>[\w\-\.]+)(?:\:|\/)?(?: \d+)?[^$]*)" | table _time src_ip domain

# See savedsearches.conf.spec in this app that defines these two keys.  
# In Splunk if you extend the conf key space like that,  you also need to 
# put these empty keys here in default, in the same app as the conf.spec
# file.  If you do not have these empty keys defined here, (or keys in default 
# specifying some value),  then when later your app tries to create or edit a 
# savedsearch and it submits values for these keys, splunk will throw the values away.
#
# TL;DR If you take these away then extended keys defined in 
# savedsearches.conf.spec, do not work properly in the REST API. 
[default]
request.ui_context = 
request.ui_edit_view = 

#SAVED REPORTS 

[911_calls]
search = `cdr_events` `911_numbers` | eval boundary=relative_time(now(),"-5min") | where _time>boundary OR _indextime>boundary | `customizable_sites_extractions` | `get_sites` | table `911_fields` 
dispatch.earliest_time = -1h
dispatch.latest_time = now
displayview = search
enableSched = 0
counttype = number of events
relation = greater than
quantity = 0
cron_schedule = */5 * * * *
alert.digest_mode = True
alert.suppress = 0
alert.track = 1
action.email = 1
action.email.message.alert = 911 call detected.
#action.email.to
action.email.useNSSubject = 1


[example concurrent calls alert]
search = `cdr_events` duration>0 ( eventtype="incoming_call" OR eventtype="outgoing_call" )\
| search ( gateway="*" )\
| `get_call_concurrency(gateway)`\
| where _time>relative_time(now(),"-1h")\
| stats max(concurrency) as maxConcurrency by gateway\
| where maxConcurrency>40\
| sort - concurrency
dispatch.earliest_time = -4h
dispatch.latest_time = now
displayview = search
enableSched = 0
counttype = number of events
relation = greater than
quantity = 0
cron_schedule = 0 * * * *
alert.digest_mode = True
alert.suppress = 0
alert.track = 1
action.email = 1
action.email.message.alert = 1 or more gateways have exceeded the concurrency threshold.
#action.email.to
action.email.useNSSubject = 1

[example get devices from axl]
disabled = 1
action.email.useNSSubject = 1
alert.track = 0
description = Retrieves devices with either device-level assignment or line-level assignment from AXL (relies on sa_cisco_cdr_axl TA).  Should be scheduled.
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
search = | ciscoaxlquery "\
select 'devices' AS src,\
eu.userid, eu.lastname, eu.firstname, eu.middlename, eu.manager, eu.department, eu.telephonenumber, eu.mailid, eu.mobile, eu.homephone, eu.title, eu.nickname,\
d.name AS name, d.description AS description, n.dnorpattern as DN, n.description as numplandescription, rp.name as partition, css.name as callingsearchspacename,\
dp.name as devicepool, sp.name as securityprofilename, tdp.name as protocol, tp.name as productname\
from device as d\
inner join devicenumplanmap as dnpm on dnpm.fkdevice = d.pkid\
left join enduserdevicemap as eudm on eudm.fkdevice=d.pkid\
left join enduser as eu on eudm.fkenduser=eu.pkid\
inner join numplan as n on dnpm.fknumplan = n.pkid and d.tkclass = 1\
left join routepartition as rp on rp.pkid = n.fkroutepartition\
left join callingsearchspace css on css.pkid = d.fkcallingsearchspace\
left join devicepool dp on d.fkdevicepool = dp.pkid\
left join securityprofile sp on sp.pkid = d.fksecurityprofile\
left join typedeviceprotocol tdp on tdp.enum = d.tkdeviceprotocol\
left join typeproduct tp on tp.enum = d.tkproduct\
UNION\
select 'lines' as src,\
' ' as userid, ' ' as lastname, ' ' as firstname, ' ' as middlename, ' ' as manager, ' ' as department, ' ' as telephonenumber, ' ' as mailid, ' ' as mobile, ' ' as homephone, ' ' as title, ' ' as nickname,\
d.name AS name, d.description AS description, n.dnorpattern as DN, n.description as numplandescription, rp.name as partition, css.name as callingsearchspacename,\
dp.name as devicepool, sp.name as securityprofilename, tdp.name as protocol, tp.name as productname\
from device as d\
inner join devicenumplanmap as dnpm on dnpm.fkdevice = d.pkid\
AND dnpm.pkid NOT IN (select dnpeum.fkdevicenumplanmap from devicenumplanmapendusermap as dnpeum)\
inner join numplan as n on dnpm.fknumplan = n.pkid and d.tkclass = 1 left join routepartition as rp on rp.pkid = n.fkroutepartition\
left join callingsearchspace css on css.pkid = d.fkcallingsearchspace\
left join devicepool dp on d.fkdevicepool = dp.pkid\
left join securityprofile sp on sp.pkid = d.fksecurityprofile\
left join typedeviceprotocol tdp on tdp.enum = d.tkdeviceprotocol\
left join typeproduct tp on tp.enum = d.tkproduct\
"\
| eval userFullName = lastname . ", " . firstname\
| rename devicepool AS devicePool, productname as productName, mailid AS mailId, userid AS userId, callingsearchspacename AS callingSearchSpaceName, securityprofilename AS securityProfileName\
| fillnull value=""\
| stats first(productName) as productName, first(department) AS department, first(mailId) AS mailId, first(userFullName) AS userFullName, first(userId) AS userId count BY name,description,devicePool,callingSearchSpaceName,protocol,securityProfileName\
| table name,productName,department,description,devicePool,mailId,userFullName,userId,callingSearchSpaceName,protocol,securityProfileName\

[User list - Successful login past 30d]
action.email.useNSSubject = 1
action.sendmn = 1
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 0 * * * *
dispatch.earliest_time = -30d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCPasswordSecurityBasic
request.ui_dispatch_view = search
search = index=* source="WinEventLog:security" (EventCode=528 OR EventCode=540 OR EventCode=4624) (Logon_Type=2 OR Logon_Type=3 OR Logon_Type=7 OR Logon_Type=10) | eval User=if(mvcount(Account_Name)>1, mvindex(Account_Name,1), mvindex(Account_Name, 0)) |search NOT  (User=*$ OR User="ANONYMOUS LOGON" OR User="LOCAL SERVICE" OR User=SYSTEM) | stats count by User | fields User| outputlookup users.csv

[Successful login IP-User list past 30d]
action.email.useNSSubject = 1
action.sendmn = 1
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 0 * * * *
dispatch.earliest_time = -30d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCPasswordSecurityBasic
request.ui_dispatch_view = search
search = index=* source="WinEventLog:security" (EventCode=528 OR EventCode=540 OR EventCode=4624) (Logon_Type=2 OR Logon_Type=3 OR Logon_Type=7 OR Logon_Type=10) | eval User=if(mvcount(Account_Name)>1, mvindex(Account_Name,1), mvindex(Account_Name, 0)) | search NOT(User=*$ OR User="ANONYMOUS LOGON" OR User="LOCAL SERVICE" OR User=SYSTEM)  (Source_Network_Address=*  AND Source_Network_Address!="-")| lookup dnsLookup ip as Source_Network_Address OUTPUT host as Source_Host | dedup Source_Network_Address User|rename _time as Time |table Time Source_Host Source_Network_Address User | outputlookup successful_logins.csv
[Successful login IP-User list past 30d]
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
action.nbtstat.param.verbose = 0
action.notable.param.verbose = 0
action.nslookup.param.verbose = 0
action.ping.param.verbose = 0
action.risk.param.verbose = 0
action.send2uba.param.verbose = 0

#####################
## Global
#####################

###### Correlation Searches ######
[Network - Policy Or Configuration Change - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Network Change Detected
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Change",\
         "object":        "Network_Changes",\
         "earliest":      "rt-5m@m",\
         "latest":        "rt+5m@m",\
         "aggregates":    [{"function": "max", "attribute": "_time", "alias": "lastTime"},\
                           {"function": "latest", "attribute": "_raw", "alias": "orig_raw"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "All_Changes.dvc", "alias": "dvc"},\
                           {"attribute": "All_Changes.action", "alias": "action"},\
                           {"attribute": "All_Changes.command", "alias": "command"}\
                          ],\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dvc","command"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = medium
action.notable.param.rule_title       = Network Change Detected On $dvc$
action.notable.param.rule_description = A configuration or policy change has been made to $dvc$.  Please verify that this is an authorized change.
action.notable.param.nes_fields       = dvc
action.notable.param.drilldown_name   = View configuration or policy changes on device $dvc$
action.notable.param.drilldown_search = | from datamodel:"Change"."Network_Changes" | search dvc="$dvc$" command="$command$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dvc
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dvc,command
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects changes to policies of the network protection devices (such as firewall policy changes).
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Change"."Network_Changes" | stats max(_time) as "lastTime",latest(_raw) as "orig_raw",count by "dvc","action","command"

###### Lookup Generating Searches ######

#####################
## Certificates
#####################
[Network - Certificate Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 50 * * * *
disabled                 = True
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=false allow_old_summaries=true min(_time) as firstTime,max(_time) as lastTime from datamodel=Certificates.All_Certificates where nodename=All_Certificates.SSL by All_Certificates.SSL.ssl_serial,All_Certificates.SSL.ssl_hash,All_Certificates.SSL.ssl_subject,All_Certificates.SSL.ssl_issuer | rename All_Certificates.SSL.ssl* as certificate* | inputlookup append=T certificate_tracker | stats min(firstTime),max(lastTime) by certificate_serial,certificate_hash,certificate_subject,certificate_issuer | rename certificate* as ssl* | extract cim_ssl_issuer_common_name,cim_ssl_issuer_email,cim_ssl_issuer_unit,cim_ssl_subject_common_name,cim_ssl_subject_email,cim_ssl_subject_unit | rename ssl* as certificate* | outputlookup override_if_empty=false certificate_tracker | stats count


#####################
## Firewall
#####################

##### Context-updating searches #####
[Network - Port Activity By Destination Port - Context Gen]
# To recreate from scratch use: | makeresults | eval size=250 | eval count=0 | eval median=1000 | xscreateddcontext name=count_by_dest_port_1d container=network_traffic type=median_centered terms="minimal,low,medium,high,extreme" width=3 scope=app app=SA-NetworkProtection
action.email.sendresults = 0
cron_schedule            = 0 3 * * *
disabled                 = true
dispatch.earliest_time   = -30d@d
dispatch.latest_time     = -1d@d
enableSched              = 1
is_visible               = false
schedule_window          = 10
search                   = | tstats `summariesonly` count as dest_port_traffic_count from datamodel=Network_Traffic.All_Traffic by All_Traffic.dest_port,_time span=1d | `drop_dm_object_name("All_Traffic")` | `context_stats(dest_port_traffic_count, dest_port)` | search size>0 | xscreateddcontext name=count_by_dest_port_1d class=dest_port container=network_traffic type=median_centered terms="minimal,low,medium,high,extreme" width=3 scope=app app=SA-NetworkProtection | stats count

# Replaces traffic_volume_tracker
[Network - Traffic Source Count Per 30m - Context Gen]
action.email.sendresults = 0
cron_schedule            = 35 * * * *
disabled                 = true
dispatch.earliest_time   = -90m@m
dispatch.latest_time     = -30m@m
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` dc(All_Traffic.src) as src_count from datamodel=Network_Traffic.All_Traffic by _time span=30m | stats count, median(src_count) as median, stdev(src_count) as size | search size>0 | xsupdateddcontext name=src_count_30m container=network_traffic terms="minimal,low,medium,high,extreme" type=median_centered width=3 app=SA-NetworkProtection scope=app | stats count

# Replaces traffic_volume_tracker
[Network - Traffic Volume Per 30m - Context Gen]
action.email.sendresults = 0
cron_schedule            = 45 * * * *
disabled                 = true
dispatch.earliest_time   = -90m@m
dispatch.latest_time     = -30m@m
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` count as total_count from datamodel=Network_Traffic.All_Traffic by _time span=30m | stats count, median(total_count) as median, stdev(total_count) as size | search size>0 | xsupdateddcontext name=count_30m container=network_traffic terms="minimal,low,medium,high,extreme" type=median_centered width=3 app=SA-NetworkProtection scope=app | stats count

[Web - Web Event Count By Src By HTTP Method Per 1d - Context Gen]
action.email.sendresults   = 0
cron_schedule              = 0 0 * * *
disabled                   = False
dispatch.earliest_time     = -31d@d
dispatch.latest_time       = -1d@d
enableSched                = 1
is_visible                 = false    
schedule_window            = 20
search                     = | tstats `summariesonly` count as web_event_count from datamodel=Web.Web by Web.src, Web.http_method, _time span=24h | `drop_dm_object_name("Web")` | where match(http_method, "^[A-Za-z]+$") | `context_stats(web_event_count, http_method)` | eval min=0 | eval max=median*2 | xscreateddcontext name=count_by_http_method_by_src_1d container=web class=http_method app="SA-NetworkProtection" scope=app type=domain terms=`xs_default_magnitude_concepts` | stats count


###### Lookup Generating Searches ######

## Network - Communication Rule Tracker - Lookup Gen Breakdown
##  1-2 - get count by _time,dvc,rule,vendor_product from datamodel=Network_Traffic
##    3 - field renaming
##  4-5 - get month and year
##    6 - consolidate by month/year
##    7 - input communication_rule_tracker lookup
##    8 - consolidate results and existing lookup data
## 9-10 - recreate _time from month/year
##   11 - filter last 396 days of data
##   12 - remove unneeded fields
##   13 - write lookup
##   14 - purge results
[Network - Communication Rule Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 45 * * * *
description              = Maintains a list of Traffic rule values by device and vendor and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic where All_Traffic.rule!=unknown by _time,All_Traffic.dvc,All_Traffic.rule,All_Traffic.vendor_product span=1d | `drop_dm_object_name("All_Traffic")` | convert timeformat="%m" ctime(_time) as month | convert timeformat="%Y" ctime(_time) as year | stats sum(count) as count by month,year,dvc,rule,vendor_product | inputlookup append=T communication_rule_tracker | stats sum(count) as count by month,year,dvc,rule,vendor_product | eval date=month."-01-".year | convert timeformat="%m-%d-%Y" mktime(date) as _time | `daysago(396)` | fields - _time,date,dayDiff | outputlookup override_if_empty=false communication_rule_tracker | stats count

## Network - Port And Protocol Tracker - Lookup Gen Breakdown
## 1-2 - get earliest/latest allowed traffic by transport,dest_port
##   3 - field renaming
##   4 - input port_protocol tracker
##   5 - consolidate results
##   6 - write lookup
##   7 - purge results
[Network - Port And Protocol Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Network_Traffic",\
	    "object":        "All_Traffic",\
        "earliest":      "-70m@m",\
        "latest":        "+0s",\
        "eventFilter":   "'All_Traffic.action'!=\"allowed\"",\
		"aggregates":    [{"function": "min", "attribute": "_time", "alias": "firstTime"},\
	                      {"function": "max", "attribute": "_time", "alias": "lastTime"}\
	                     ],\
	    "splitby":       [\
	                      {"attribute": "All_Traffic.transport", "alias": "transport"},\
	                      {"attribute": "All_Traffic.dest_port", "alias": "dest_port"}\
	                     ],\
        "summariesonly": "1",\
        "outputlookup":  "port_protocol_tracker",\
        "retention":     {\
            "earliestTime":  "-5y",\
            "timeField":     "lastTime",\
            "timeFormat":    "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 50 * * * *
description              = Maintains a list of allowed Traffic by unique transport protocol and destination port combination and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Network_Traffic"."All_Traffic" where    "All_Traffic.action"!="allowed" by "All_Traffic.transport","All_Traffic.dest_port"  | rename "All_Traffic.transport" as "transport","All_Traffic.dest_port" as "dest_port" | inputlookup append=T "port_protocol_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "transport","dest_port" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "port_protocol_tracker" | stats count


#####################
## IDS
#####################

##### Context-updating searches #####
[Network - Event Count By Signature Per Hour - Context Gen]
action.email.sendresults = 0
cron_schedule            = 0 3 * * *
disabled                 = true
dispatch.earliest_time   = -61d@d
dispatch.latest_time     = -1d@d
enableSched              = 1
is_visible               = false
schedule_window          = 10
search                   = | tstats `summariesonly` count as count_by_signature_1h from datamodel=Intrusion_Detection.IDS_Attacks by _time,IDS_Attacks.signature span=1h | `drop_dm_object_name("IDS_Attacks")` | `context_stats(count_by_signature_1h, signature)` | search size>0 | xsCreateDDContext name=count_by_signature_1h class=signature container=ids_attacks type=median_centered terms="minimal,low,medium,high,extreme" scope=app app=SA-NetworkProtection | stats count

###### Correlation Searches ######
[Network - Substantial Increase in an Event - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Substantial Increase In Intrusion Events
action.correlationsearch.related_searches = ["Network - Event Count By Signature Per Hour - Context Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = network
action.notable.param.severity             = high
action.notable.param.rule_title           = Substantial Increase In $signature$ Events
action.notable.param.rule_description     = A statistically significant increase in the volume of $signature$ events was noted. Today's value is $count$.
action.notable.param.nes_fields           = signature
action.notable.param.drilldown_name       = View all $signature$ events
action.notable.param.drilldown_search     = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | search signature="$signature$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = signature
action.risk.param._risk_object_type       = other
action.risk.param._risk_score             = 80
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = signature
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 15 * * * *
description                               = Alerts when a statistically significant increase in a particular intrusion event is observed.
disabled                                  = True
dispatch.earliest_time                    = -70m@m
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
schedule_window                           = 5
search                                    = | tstats `summariesonly` count,values(IDS_Attacks.tag) as tag from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.signature | `drop_dm_object_name("IDS_Attacks")` | xswhere count from count_by_signature_1h in ids_attacks by signature is above medium

###### Lookup Generating Searches ######

## Network - IDS Attack Tracker - Lookup Gen Breakdown
## 1-2 - get the most recent ids_type,signature,vendor_product pairings from datamodel=Intrusion_Detection
##   3 - field renaming
##   4 - inputlookup existing data
##   5 - consolidate event and tracker data
##   6 - write lookup
##   7 - purge results
[Network - IDS Attack Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Intrusion_Detection",\
	    "object":        "IDS_Attacks",\
        "earliest":      "-70m@m",\
        "latest":        "+0s",\
        "eventFilter":   "",\
		"aggregates":    [{"function": "min", "attribute": "_time", "alias": "firstTime"},\
	                      {"function": "max", "attribute": "_time", "alias": "lastTime"}\
	                     ],\
	    "splitby":       [\
	                      {"attribute": "IDS_Attacks.ids_type", "alias": "ids_type"},\
	                      {"attribute": "IDS_Attacks.signature", "alias": "signature"},\
	                      {"attribute": "IDS_Attacks.vendor_product", "alias": "vendor_product"}\
	                     ],\
        "summariesonly": "1",\
        "outputlookup":  "ids_attack_tracker",\
        "retention":     {\
            "earliestTime":  "-5y",\
            "timeField":     "lastTime",\
            "timeFormat":    "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 25 * * * *
description              = Maintains a list of IDS attacks by vendor and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Intrusion_Detection"."IDS_Attacks"  by "IDS_Attacks.ids_type","IDS_Attacks.signature","IDS_Attacks.vendor_product"  | rename "IDS_Attacks.ids_type" as "ids_type","IDS_Attacks.signature" as "signature","IDS_Attacks.vendor_product" as "vendor_product" | inputlookup append=T "ids_attack_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "ids_type","signature","vendor_product" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "ids_attack_tracker" | stats count

## Network -  IDS Category Tracker - Lookup Gen Breakdown
## 1-2 - get the most recent category info from datamodel=Intrusion_Detection
##   3 - field renaming
##   4 - inputlookup existing data
##   5 - consolidate event and tracker data
##   6 - write lookup
##   7 - purge results
[Network - IDS Category Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Intrusion_Detection",\
	    "object":        "IDS_Attacks",\
        "earliest":      "-30m@m",\
        "latest":        "+0s",\
        "eventFilter":   "'IDS_Attacks.category'!=\"unknown\"",\
		"aggregates":    [{"function": "min", "attribute": "_time", "alias": "firstTime"},\
	                      {"function": "max", "attribute": "_time", "alias": "lastTime"}\
	                     ],\
	    "splitby":       [\
	                      {"attribute": "IDS_Attacks.category", "alias": "category"},\
	                      {"attribute": "IDS_Attacks.vendor_product", "alias": "vendor_product"}\
	                     ],\
        "summariesonly": "1",\
        "outputlookup":  "ids_category_tracker",\
        "retention":     {\
            "earliestTime": "-5y",\
            "timeField":    "lastTime",\
            "timeFormat":   "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 10,25,40,55 * * * *
description              = Maintains a list of IDS attack categories by vendor and the first and last time they were seen
dispatch.earliest_time   = -30m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
search                   = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Intrusion_Detection"."IDS_Attacks" where    "IDS_Attacks.category"!="unknown" by "IDS_Attacks.category","IDS_Attacks.vendor_product"  | rename "IDS_Attacks.category" as "category","IDS_Attacks.vendor_product" as "vendor_product" | inputlookup append=T "ids_category_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "category","vendor_product" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "ids_category_tracker" | stats count


###################
## Network Changes
###################

###### Correlation Searches ######
[Network - Network Device Rebooted - Rule]
action.correlationsearch            = 0
action.correlationsearch.enabled    = 1
action.correlationsearch.label      = Network Device Rebooted
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec     = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Change",\
         "object":        "Device_Restarts",\
         "earliest":      "-70m@m",\
         "latest":        "+0s",\
         "aggregates":    [{"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "All_Changes.dvc", "alias": "dvc"},\
                           {"attribute": "_time", "span": "1s"}\
                          ],\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dvc", "orig_time"]\
}
action.email.sendresults            = 0
action.notable.param.rule_title     = Network Device Rebooted
action.risk                         = 1
action.risk.param._risk_object      = dvc
action.risk.param._risk_object_type = system
action.risk.param._risk_score       = 20
alert.digest_mode                   = 1
alert.suppress                      = 1
alert.suppress.fields               = dvc, orig_time
alert.suppress.period               = 86300s
alert.track                         = 0
counttype                           = number of events
relation                            = greater than
quantity                            = 0
cron_schedule                       = 20 * * * *
description                         = Increases the risk score of network devices that have been rebooted.
disabled                            = 1
dispatch.earliest_time              = -70m@m
dispatch.latest_time                = +0s
enableSched                         = 1
is_visible                          = false
schedule_window                     = 5
search                              = | tstats summariesonly=true allow_old_summaries=true count from datamodel="Change"."All_Changes" where   nodename="All_Changes.Network_Changes.Device_Restarts"  by "All_Changes.dvc","_time" span="1s" | rename "All_Changes.dvc" as "dvc"

[Network - Substantial Increase in Port Activity (By Destination) - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Substantial Increase In Port Activity
action.correlationsearch.related_searches = ["Network - Port Activity By Destination Port - Context Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = network
action.notable.param.severity             = high
action.notable.param.rule_title           = Substantial Increase In Port Activity ($dest_port$)
action.notable.param.rule_description     = A statistically significant increase in the volume of activity on port $dest_port$ was noted. Today's value is $count$.
action.notable.param.nes_fields           = dest_port
action.notable.param.drilldown_name       = View all port activity for $dest_port$
action.notable.param.drilldown_search     = | from datamodel:"Network_Traffic"."All_Traffic" | search dest_port=$dest_port$
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = dest_port
action.risk.param._risk_object_type       = other
action.risk.param._risk_score             = 80
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = dest_port
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 15 * * * *
description                               = Alerts when a statistically significant increase in events on a given port is observed.
disabled                                  = True
dispatch.earliest_time                    = -1450m@m
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
schedule_window                           = 5
search                                    = | tstats `summariesonly` count,values(All_Traffic.tag) as tag from datamodel=Network_Traffic.All_Traffic by All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | xswhere count from count_by_dest_port_1d in network_traffic by dest_port is extreme

#####################
## Proxy
#####################

#####################
## Vulnerabilities
#####################

###### Correlation Searches ######
[Network - Vulnerability Scanner Detection (by event) - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Vulnerability Scanner Detected (by events)
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Intrusion_Detection",\
         "object":        "IDS_Attacks",\
         "earliest":      "rt-65m@m",\
         "latest":        "rt-5m@m",\
         "aggregates":    [{"function": "values", "attribute": "IDS_Attacks.tag", "alias": "tag"},\
                           {"function": "dc", "attribute": "IDS_Attacks.signature", "alias": "count"}\
                          ],\
         "splitby":       [{"attribute": "IDS_Attacks.src", "alias": "src"}],\
         "resultFilter":  {"field": "count", "comparator": ">", "value": "25"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["src"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = high
action.notable.param.rule_title       = Vulnerability Scanner Detected ($src$)
action.notable.param.rule_description = A potential vulnerability scanner was detected. $src$ has generated $count$ events in the last hour. This may be indicative of a vulnerability scanner since vulnerability scanners generally trigger a large volume of unique events.
action.notable.param.nes_fields       = src
action.notable.param.drilldown_name   = View all attack events from device $src$
action.notable.param.drilldown_search = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | search src="$src$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = src
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = src
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects a potential vulnerability scanner by detecting devices that have triggered a large number of unique events. Vulnerability scanners generally trigger a high number unique events when scanning a host since each vulnerability check tends to trigger a unique event.
disabled                              = True
dispatch.earliest_time                = rt-65m@m
dispatch.latest_time                  = rt-5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | stats values(tag) as "tag",dc(signature) as "count" by "src" | where 'count'>25

[Network - Vulnerability Scanner Detection (by targets) - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Vulnerability Scanner Detected (by targets)
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Intrusion_Detection",\
         "object":        "IDS_Attacks",\
         "earliest":      "rt-65m@m",\
         "latest":        "rt-5m@m",\
         "aggregates":    [{"function": "values", "attribute": "IDS_Attacks.tag", "alias": "tag"},\
                           {"function": "dc", "attribute": "IDS_Attacks.dest", "alias": "count"}\
                          ],\
         "splitby":       [{"attribute": "IDS_Attacks.src", "alias": "src"}],\
         "resultFilter":  {"field": "count", "comparator": ">", "value": "25"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["src"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = high
action.notable.param.rule_title       = Vulnerability Scanner Detected ($src$)
action.notable.param.rule_description = A potential vulnerability scanner was detected. $src$ has generated events against $count$ targets in the last hour. This may be indicative of a vulnerability scanner since vulnerability scanners generally trigger events against a high number of unique targets.
action.notable.param.nes_fields       = src
action.notable.param.drilldown_name   = View all attack events from device $src$
action.notable.param.drilldown_search = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | search src="$src$"
action.notable.param.default_status   =
action.notable.param.default_owner    =
action.risk                           = 1
action.risk.param._risk_object        = src
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = src
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects a potential vulnerability scanner by detecting devices that have triggered events against a large number of unique targets. Vulnerability scanners generally trigger events against a high number of unique hosts when they are scanning a network for vulnerable hosts.
disabled                              = True
dispatch.earliest_time                = rt-65m@m
dispatch.latest_time                  = rt-5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | stats values(tag) as "tag",dc(dest) as "count" by "src" | where 'count'>25

###### Lookup Generating Searches ######

## Network - Vulnerability Signature Reference - Lookup Gen Breakdown
##   1-2 - get cve,bugtraq,cert,msft,mskb,xref values per signature,vendor_product
##     3 - field renaming
##     4 - read lookup
##  5-10 - make input data multi value
##    11 - consolidate results
## 12-17 - make cve,bugtraq,cert,msft,mskb,xref single value
##    18 - write lookup
##    19 - purge results
[Network - Vulnerability Signature Reference - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 20 * * * *
description              = Maintains a list of vulnerability signatures by vendor (including external reference information such as cve) and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` min(_time) as firstTime,max(_time) as lastTime,values(Vulnerabilities.bugtraq) as bugtraq,values(Vulnerabilities.cert) as cert,values(Vulnerabilities.cve) as cve,values(Vulnerabilities.msft) as msft,values(Vulnerabilities.mskb) as mskb,values(Vulnerabilities.xref) as xref from datamodel=Vulnerabilities.Vulnerabilities by Vulnerabilities.signature,Vulnerabilities.vendor_product | `drop_dm_object_name("Vulnerabilities")` | inputlookup append=T vuln_signature_reference | `makemv(bugtraq)` | `makemv(cert)` | `makemv(cve)` | `makemv(msft)` | `makemv(mskb)` | `makemv(xref)` | stats min(firstTime) as firstTime,max(lastTime) as lastTime,values(cve) as cve,values(bugtraq) as bugtraq,values(cert) as cert,values(msft) as msft,values(mskb) as mskb,values(xref) as xref by signature,vendor_product | `makesv(bugtraq)` | `makesv(cert)` | `makesv(cve)` | `makesv(msft)` | `makesv(mskb)` | `makesv(xref)` | outputlookup override_if_empty=false vuln_signature_reference | stats count
[ActiveDirectory: Create Computer Lookup]
disabled = 0
search =  `admon-computer-lookup-update`
run_on_startup = true
dispatch.earliest_time = 0
dispatch.latest_time = now

[ActiveDirectory: Update Computer Lookup]
disabled = 0
search =  `admon-computer-lookup-update`
enableSched = 1
cron_schedule = */15 * * * *
run_on_startup = true
dispatch.earliest_time = -30m
dispatch.latest_time = now

[ActiveDirectory: Create GPO Lookup]
disabled = 0
search =  `admon-gpo-lookup-update`
run_on_startup = true
dispatch.earliest_time = 0
dispatch.latest_time = now

[ActiveDirectory: Update GPO Lookup]
disabled = 0
search =  `admon-gpo-lookup-update`
enableSched = 1
cron_schedule = */15 * * * *
run_on_startup = true
dispatch.earliest_time = -30m
dispatch.latest_time = now

[ActiveDirectory: Create Group Lookup]
disabled = 0
search =  `admon-group-lookup-update`
run_on_startup = true
dispatch.earliest_time = 0
dispatch.latest_time = now

[ActiveDirectory: Update Group Lookup]
disabled = 0
search =  `admon-group-lookup-update`
enableSched = 1
cron_schedule = */15 * * * *
run_on_startup = true
dispatch.earliest_time = -30m
dispatch.latest_time = now

[ActiveDirectory: Create User Lookup]
disabled = 0
search =  `admon-user-lookup-update`
run_on_startup = true
dispatch.earliest_time = 0
dispatch.latest_time = now

[ActiveDirectory: Update User Lookup]
disabled = 0
search =  `admon-user-lookup-update`
enableSched = 1
cron_schedule = */15 * * * *
run_on_startup = true
dispatch.earliest_time = -30m
dispatch.latest_time = now

[DNS: Failing Domains]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Snd" response!="NOERROR"|top questiontype,questionname,response|`fix-dnsname(questionname)`
enableSched = 0


[DNS: Top Failing Domains]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Rcv" response!="NOERROR"|top questiontype,questionname|`fix-dnsname(questionname)`
enableSched = 0


[DNS: Top Hosts sending failing queries]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Rcv" response!="NOERROR"|top src_ip
enableSched = 0


[DNS: Top Non-Authoritative Responses]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Snd" response!="NOERROR" flags!="A*"|top questiontype,questionname|`fix-dnsname(questionname)`
enableSched = 0


[DNS: Top Querying Hosts]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Rcv"|top src_ip
enableSched = 0


[DNS: Top Recursive Failure Domains]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Rcv" flags="*DR" response!="NOERROR"|top questiontype,questionname|`fix-dnsname(questionname)`
enableSched = 0


[DNS: Top Requested Queries]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Rcv"|top questiontype,questionname|`fix-dnsname(questionname)`
enableSched = 0


[DomainSelector_Lookup]
disabled = 0
search =  `domain-selector-search` \
| eval _key = host \
| outputlookup DomainSelector append=true
enableSched = 1
cron_schedule = */15 * * * *
realtime_schedule = 1
dispatch.earliest_time = -1h
dispatch.latest_time = now

[DomainSelector_Lookup_Migrate]
disabled = 0
search = | outputlookup DomainSelector \
| inputlookup append=true DomainSelector.csv \
| eval _key = host \
| outputlookup DomainSelector
enableSched = 0
[HostToDomain_Lookup_Update]
disabled = 0
search =  `domain-list` \
| sort host \
| eval _key = host \
| outputlookup HostToDomain append=true
enableSched = 1
cron_schedule = 30 2 * * *
realtime_schedule = 1
dispatch.earliest_time = -24h@h
dispatch.latest_time = now

[HostToDomain_Lookup_Migrate]
disabled = 0
search = | outputlookup HostToDomain \
| inputlookup append=true DomainList.csv \
| eval _key = host \
| outputlookup HostToDomain
enableSched = 0
[tHostInfo_Lookup_Update]
disabled = 0
search =  `thostinfo`|inputlookup append=T tHostInfo|where _time > relative_time(now(), "-30d@d")|sort 0 src_ip,src_hostdomain,_time|dedup consecutive=T src_ip,src_hostdomain|sort 0 -_time|outputlookup tHostInfo
enableSched = 1
cron_schedule = */5 * * * *
realtime_schedule = 1
dispatch.earliest_time = -5m
dispatch.latest_time = now

[tHostInfo_Lookup_Migrate]
disabled = 0
search = | inputlookup tHostInfo.csv | outputlookup tHostInfo
enableSched = 0

# This saved search runs per 10 min and get last 15 min data and append it to the lookup tSessions
[tSessions_Lookup_Update]
disabled = 0
search = `tsessions`|eval _key = session_id |sort 0 _time|outputlookup tSessions  append=true 
enableSched = 1
cron_schedule = */10 * * * *
realtime_schedule = 1
dispatch.earliest_time = -15m
dispatch.latest_time = now

# This saved search runs per sunday at 00:00 and maintain last 30days data in tSessions lookup so it remove data which is older than last 30days
[tSessions_Lookup_Update_Per_Day]
disabled = 0
search = | inputlookup tSessions | where _time > relative_time(now(), "-30d@d") | outputlookup tSessions
enableSched = 1
cron_schedule = 0 0 * * 0
realtime_schedule = 1

# This saves search runs per sunday at 01:02:00 and 02:02:00 and append data from 00:00 to a current time.
# This save search is used for retrieve missing data because of tSessions_Lookup_Update_Per_Day saved search.
# tSessions_Lookup_Update_Per_Day saved search takes long time so in between tSessions_Lookup_Update also runs so incase of any data missing, that will retrieved by this saved search.
[tSessions_Lookup_Update_For_Lost_Data]
disabled = 0
search = `tsessions`|eval _key = session_id |sort 0 _time|outputlookup tSessions  append=true 
enableSched = 1
cron_schedule = 2 1,2 * * 0
realtime_schedule = 1
dispatch.earliest_time = -0d@d
dispatch.latest_time = now

# This saved search will runs on the end of guided setup and fill last 30 days data into it.
# This will runs by javascript so it doesn't schedule here.
[tSessions_Lookup_Update_One_Time]
alert.track = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
search = `wineventlog-index` eventtype=wineventlog_security session_id="*x*" session_id!="0x3e7" earliest=-30d@d latest=now() \
| eval login_username = if(eventtype=="msad-successful-user-logons",user,NULL) \
    | eval login_domain=if(eventtype=="msad-successful-user-logons",dest_nt_domain,NULL) \
    | stats earliest(_time) as _time values(eventtype) as eventtype count as eventcount values(src_ip) as src_ip values(user) as user values(host) as host values(login_username) as login_username values(login_domain) as login_domain by session_id \
    | where eventtype=="msad-successful-user-logons" AND eventcount>=1 AND isnotnull(src_ip) AND isnotnull(user) \
    | eval login_host=if(src_ip=="127.0.0.1" OR src_ip=="::1" OR src_ip=="-",upper(host),src_ip) \
    | table _time,session_id,login_username,login_domain,login_host |eval _key = session_id |sort 0 _time|outputlookup tSessions  append=true

[tSessions_Lookup_Migrate]
disabled = 0
search = | inputlookup tSessions.csv | outputlookup tSessions
enableSched = 0

[SiteInfo_Lookup_Update]
disabled = 0
search =  eventtype=msad-dc-health \
| table host,Site \
| dedup host, Site \
| eval _key = host \
| outputlookup SiteInfo append=true
enableSched = 1
cron_schedule = 30 * * * *
realtime_schedule = 1
dispatch.earliest_time = -60m
dispatch.latest_time = now

[SiteInfo_Lookup_Migrate]
disabled = 0
search = | outputlookup SiteInfo \
| inputlookup append=true SiteInfo.csv \
| eval _key = host \
| outputlookup SiteInfo
enableSched = 0

#########################################################################################
######				Windows Application Infrastructure Searches					#########
#########################################################################################

##########################################
###### Lookup Tables Lists searches ######
##########################################

[WinApp_Lookup_Event - Event Details]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_details\
| table LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription\
| sort  LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription

[WinApp_Lookup_Event - Host]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_system\
| dedup Host\
| table Host\
| sort Host

###### Specific Fields Lists ######
[WinApp_Lookup_Event - EventCode Description]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_details\
| dedup EventCode\
| eval Event=EventCode.":".EventCodeDescription\
| table EventCode, EventCodeDescription, Event\
| sort EventCode

[WinApp_Lookup_Event - EventCode]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_details\
| dedup EventCode\
| table EventCode\
| sort EventCode

[WinApp_Lookup_Event - LogName]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_details\
| dedup LogName\
| table LogName\
| sort LogName

[WinApp_Lookup_Event - TaskCategory]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_details\
| dedup TaskCategory\
| table TaskCategory\
| sort TaskCategory

[WinApp_Lookup_Perfmon - Combined]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_perfmon_details | dedup instance | table object, counter , instance | sort object, counter, instance

[WinApp_Lookup_Perfmon - Object]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_perfmon_details\
| dedup object\
| table object\
| sort object

[WinApp_Lookup_Perfmon - Collections, Object, and counters]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_perfmon_details\
| stats values(counter) as Perfmon_counters by object\
| sort object

[WinApp_Lookup_Perfmon - counters and instances]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_perfmon_details\
| eval Perfmon_counters=object.": ".counter\
| stats values(instance) as Perfmon_instances by Perfmon_counters\
| sort Perfmon_counters

[WinApp_Lookup_Perfmon - Host]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_perfmon_system\
| dedup Host\
| table Host\
| sort Host


######################################################
###### Lookup Tables -  UPDATE Lookups searches ######
######################################################

[WinApp_Lookup_Build_Perfmon - Update - Server]
disabled = 0
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="perfmon_windows" object=* \
| eval Host=if(isNull(Host),host,Host) \
| stats count by Host \
| eval _key = Host \
| outputlookup windows_perfmon_system append=true	

[WinApp_Lookup_Build_Perfmon - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 1 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="perfmon_windows" object=* \
| eval instance = if(isnull(instance), "NA", instance) \
| stats count by collection, object, counter, instance \
| sort collection, object, counter, instance \
| eval _key = collection . "___" . object . "___" . counter . "___" . instance \
| outputlookup windows_perfmon_details append=true

[WinApp_Lookup_Build_Event - Update - Server]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 2 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="wineventlog_common" \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| stats count by Host \
| eval _key = Host \
| outputlookup windows_event_system append=true

[WinApp_Lookup_Build_Event - Update - Detail]
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
cron_schedule = 3 * * * *
displayview = search
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
request.ui_dispatch_view = search
search =  eventtype="wineventlog_common" \
| dedup EventCode, LogName \
| fields + LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription, Message \
| eval EventCodeDescription=if(isnull(EventCodeDescription) OR len(trim(EventCodeDescription))==0 OR EventCode=="No Description Available-Update windows_eventcode_definitions", mvindex(split(Message, "."), 0), EventCodeDescription) \
| table LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription \
| eval _key = LogName . "___" . EventCode . "___" . SourceName . "___" . TaskCategory . "___" . Type . "___" . EventCodeDescription \
| outputlookup windows_event_details append=true

[WinApp_Lookup_Build_Hostmon - Update - Server]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 4 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="hostmon_windows" \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| stats count by Host \
| eval _key = Host \
| outputlookup windows_hostmon_system append=true

[WinApp_Lookup_Build_Hostmon_Machine - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 5 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="hostmon_windows" Type=OperatingSystem \
| join host [search eventtype=hostmon_windows Type=Computer earliest=-80m] \
| stats count by OS, Domain, Architecture, Manufacturer \
| eval _key = OS . "___" . Domain . "___" . Architecture . "___" . Manufacturer \
| outputlookup windows_hostmon_machine_details append=true

[WinApp_Lookup_Build_Hostmon_FS - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 6 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype=hostmon_windows Type=Disk \
| eval FreeSpacePct=round(FreeSpaceKB/TotalSpaceKB*100) \
| eval TotalSpaceGB=round(TotalSpaceKB/1024/1024) \
| stats count by FileSystem, DriveType, FreeSpacePct, TotalSpaceGB \
| eval _key = FileSystem . "___" . DriveType . "___" . FreeSpacePct . "___" . TotalSpaceGB \
| outputlookup windows_hostmon_fs_details append=true

[WinApp_Lookup_Build_Hostmon_Process - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 7 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype=hostmon_windows Type=Process \
| stats count by Name \
| eval _key = Name \
| outputlookup windows_hostmon_process_details append=true

[WinApp_Lookup_Build_Hostmon_Services - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 8 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype=hostmon_windows Type=Service \
| stats count by Name, StartMode, State \
| eval _key = Name . "___" . StartMode . "___" . State \
| outputlookup windows_hostmon_services_details append=true

[WinApp_Lookup_Build_Netmon - Update - Server]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 9 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="netmon_windows" \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| stats count by Host \
| eval _key = Host \
| outputlookup windows_netmon_system append=true

[WinApp_Lookup_Build_Netmon - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 10 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="netmon_windows" \
| stats count by Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| sort Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| eval _key = Direction . "___" . Protocol . "___" . PacketType . "___" . RemoteHostName . "___" . RemotePort . "___" . LocalPort . "___" . ProcessName . "___" . UserName \
| outputlookup windows_netmon_details append=true

[WinApp_Lookup_Build_Printmon - Update]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 11 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  sourcetype=WinPrintMon \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| stats count by Host printer operation user \
| sort Host printer operation user \
| eval _key = Host . "___" . printer . "___" . operation . "___" . user \
| outputlookup windows_printmon append=true


######################################################
###### Lookup Tables -  CREATE Lookups searches ######
######################################################

[WinApp_Lookup_Build_Perfmon - CreateNew - Server]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="perfmon_windows" object=* earliest=-60m \
| eval Host=if(isNull(Host),host,Host) \
| stats count by Host \
| outputlookup windows_perfmon_system

[WinApp_Lookup_Build_Netmon - CreateNew - Server]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype="netmon_windows" \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| stats count by Host \
| outputlookup windows_netmon_system

[WinApp_Lookup_Build_Netmon - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype="netmon_windows" \
| fields Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| dedup Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| table Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| sort Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| outputlookup windows_netmon_details

[WinApp_Lookup_Build_Printmon - CreateNew]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = sourcetype=WinPrintMon \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| fields Host printer operation user \
| dedup Host printer operation user \
| table Host printer operation user \
| sort Host printer operation user \
| outputlookup windows_printmon

[WinApp_Lookup_Build_Perfmon - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="perfmon_windows" object=* \
| fillnull value=NA instance \
| dedup collection, object, counter, instance \
| table collection, object, counter, instance \
| outputlookup windows_perfmon_details

[WinApp_Lookup_Build_Event - CreateNew - Server]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| fields Host \
| dedup Host \
| table Host \
| sort Host \
| outputlookup windows_event_system

[WinApp_Lookup_Build_Event - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" \
| dedup EventCode \
| fields + LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription \
| dedup EventCode, Type \
| table LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription \
| sort  LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription \
| outputlookup windows_event_details

[WinApp_Lookup_Build_Hostmon - CreateNew - Server]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype="hostmon_windows"\
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| fields Host \
| dedup Host \
| table Host \
| sort Host \
| outputlookup windows_hostmon_system

[WinApp_Lookup_Build_Hostmon_Machine - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype="hostmon_windows" Type=OperatingSystem \
| join host [search eventtype=hostmon_windows Type=Computer] \
| dedup OS, Domain, Architecture, Manufacturer \
| table OS, Domain, Architecture, Manufacturer \
| outputlookup windows_hostmon_machine_details

[WinApp_Lookup_Build_Hostmon_FS - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype=hostmon_windows Type=Disk \
| eval FreeSpacePct=round(FreeSpaceKB/TotalSpaceKB*100) \
| eval TotalSpaceGB=round(TotalSpaceKB/1024/1024) \
| dedup FileSystem, DriveType, FreeSpacePct, TotalSpaceGB \
| table FileSystem, DriveType, FreeSpacePct, TotalSpaceGB \
| outputlookup windows_hostmon_fs_details

[WinApp_Lookup_Build_Hostmon_Process - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype=hostmon_windows Type=Process \
| dedup Name \
| table Name \
| outputlookup windows_hostmon_process_details

[WinApp_Lookup_Build_Hostmon_Services - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype=hostmon_windows Type=Service \
| dedup Name, StartMode, State \
| table Name, StartMode, State \
| outputlookup windows_hostmon_services_details


####################################
###### Windows Event Searches ######
####################################

[Generic event counts]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -60m@m
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
description= Event search try
search = eventtype="wineventlog_common" \
| stats count by LogName, EventCode, Keywords, TaskCategory, Type

[Event categories and counts by host for the last 30 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" \
| fields host, TaskCategory \
| stats count as EvtCounts by host, TaskCategory \
| sort -EvtCounts \
| eval EvtCatCnt = TaskCategory." (".EvtCounts.")" \
| stats sum(EvtCounts) as Total_Events, values(EvtCatCnt) as Event_Category_Count by host \
| sort -Total_Events \
| eval Host_Count = host." (".Total_Events.")" \
| table Host_Count, Event_Category_Count

[Event severity counts by host for the last 30 days]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" (EventType=2 OR EventType=3 OR EventType=1) \
| eval EventSeverity=case(EventType == 2, "Error", EventType == 3,"Warning", EventType == 1, "Critical") \
| eval host=upper(host) \
| stats count by host EventSeverity \
| xyseries host EventSeverity count \
| eval t=1 \
| addcoltotals \
| sort t desc \
| eval host = if(t>1,"Totals",host) \
| fields - t \
| table host *

[Event severity counts by host for the last 7 days]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" (EventType=2 OR EventType=3 OR EventType=1) \
| eval EventSeverity=case(EventType == 2, "Error", EventType == 3,"Warning", EventType == 1, "Critical") \
| eval host=upper(host) \
| stats count by host EventSeverity \
| xyseries host EventSeverity count \
| eval t=1 \
| addcoltotals \
| sort t desc \
| eval host = if(t>1,"Totals",host) \
| fields - t \
| table host *

[Event severity counts by host for the last 24 hours]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = @d
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" (EventType=2 OR EventType=3 OR EventType=1) \
| eval EventSeverity=case(EventType == 2, "Error", EventType == 3,"Warning", EventType == 1, "Critical") \
| eval host=upper(host) \
| stats count by host EventSeverity \
| xyseries host EventSeverity count \
| eval t=1 \
| addcoltotals \
| sort t desc \
| eval host = if(t>1,"Totals",host) \
| fields - t \
| table host *


######################################
###### Windows Perfmon Searches ######
######################################

[Performance counter categories and counts by host for the last 7 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="perfmon_windows" \
| stats values(object) as Perfmon_counter_Category, dc(counter) as Perfmon_counter_Count by Host \
| table Host, Perfmon_counter_Category, Perfmon_counter_Count \
| sort Host

[Number of hosts with Average CPU utilization > 80% in the last 24 hours]
dispatch.earliest_time = -24h
dispatch.latest_time = now
dispatch.ttl = 2p
relation = None
search = eventtype=perfmon_windows Host=* object="processor" counter="% processor time"|stats avg(Value) as Threshold by Host \
| eval range=case(Threshold<10, "OK (<50%)", Threshold<50, "Warn (80%-94%)", Threshold>50, "Critical (95%+)") \
| chart values(Host), count by range

[Average Memory utilization per process, host in the last 24 hours]
action.email.sendresults = 0
dispatch.earliest_time = -24h
dispatch.latest_time = now
dispatch.ttl = 2p
relation = None
search = eventtype=perfmon_windows object=Process  counter="Private Bytes" \
| eval MB=Value/(1024*1024) \
| stats avg(MB) as "Avg. Memory Utilization in MB" by instance, host

[Average CPU utilization per process, host in the last 24 hours]
action.email.sendresults = 0
dispatch.earliest_time = -24h
dispatch.latest_time = now
dispatch.ttl = 2p
relation = None
search = eventtype=perfmon_windows object=Process counter="% Processor Time" \
| stats avg(Value) as "Avg. CPU utilization" by instance, Host


#############################################
###### Windows OS App Crashes Searches ######
#############################################

[Application crash count in the last 24 hours]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
search = eventtype="wineventlog_common" EventCode="1001" Event_Name="*" \
| eval application=P1." (version: ".P2.")" \
| timechart count by application

[Application crash count in the last 7 days]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -7d@d
dispatch.latest_time = now
search = eventtype="wineventlog_common" EventCode="1001" Event_Name="*" \
| eval application=P1." (version: ".P2.")" \
| timechart count by application

[Application crash count in the last 30 days]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
search = eventtype="wineventlog_common" EventCode="1001" Event_Name="*" \
| eval application=P1." (version: ".P2.")" \
| timechart count by application

##############################################
###### Windows OS App Installs Searches ######
##############################################

[Count of total installs per user for the last 7 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" SourceName=MsiInstaller EventCode=11707 \
| stats count by User \
| sort -count

[Count of total installs per user each day for the last 7 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" SourceName=MsiInstaller EventCode=11707 \
| timechart count by User

[System_App Installs - By Host - Timechart - 7days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" SourceName=MsiInstaller EventCode=11707 \
| dedup _raw \
| rex field=Message "(?s)Product: (?<product_name>.*) --" \
| timechart span=1d count by host

[Count of total installs per Application each day for the last 7 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" SourceName=MsiInstaller EventCode=11707 \
| rex field=Message "(?s)Product: (?<product_name>.*) --" \
| timechart span=1d count by product_name

[List of Applications, Time of install, User and Host for the last 7 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" SourceName=MsiInstaller EventCode=11707 \
| rex field=Message "(?s)Product: (?<product_name>.*) --" \
| table _time host User product_name


#####################################
###### Windows Update searches ######
#####################################

[List of Failed KB installs in the last 7 days]
action.email.inline = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -7d
dispatch.latest_time = now
search = NOT [ search eventtype="Update_Successful" | dedup package, host | fields + host, package ] \
eventtype="Update_Failed" package=* \
| dedup host package \
| stats count, max(_time) as latest_failure_time by host,package \
| sort - latest_failure_time | convert ctime(latest_failure_time) \
| eval kb_details="KB".package." (Total Fails=".tostring(count).") (Last Failure at:".latest_failure_time.")" \
| stats sum(count) as total_fails, values(kb_details) as latest_fail_details by host

[List of KB successful and failed KB installation for the last 30 days]
action.email.inline = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = tag=Windows_Update package=* \
| dedup package, host \
| eval status=if(eventtype=="Update_Successful", "Success", if(eventtype=="Update_Failed", "Failed", "NA")) \
| search NOT status="NA"  \
| stats latest(_time) as ltime, count by status, host, package \
| convert ctime(ltime) \
| eval lsuccess="Succesful at (".ltime.")" \
| eval lfail="Failed at (".ltime.")" \
| eval lstatus=if(status=="Success",lsuccess,lfail) \
| stats values(lstatus) as Status_History by host, package \
| sort host,package \
| eval scount=mvcount(Status_History) \
| eval Last_Status=if(scount>1,"Success",if(match(Status_History, "Success*"),"Success","Failed")) \
| table host, package, Last_Status, Status_History \
| sort host,package

[List of Successful installations (non-KB) for the last 7 days]
action.email.inline = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -7d
dispatch.latest_time = now
search = eventtype="Update_Successful" NOT package=* \
| dedup package, host \
| chart count,max(_time) as latest_install_time by package \
| sort - latest_install_time \
| convert ctime(latest_install_time)

[List of shutdowns for last 30 days]
action.email.sendresults = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
relation = None
search = source=wineventlog:system "EventCode=1076" OR "EventCode=6008" \
| rex field=Message "(?m)(?<cause>.*)$" \
| fields + _time,host,cause

[List of unexpected service terminations for the last 30 days]
action.email.sendresults = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
relation = None
search = source=wineventlog:system terminated ("EventCode=7034" OR "EventCode=7031") \
| rex field=Message "(?i)^The (?<Service_Name>.*) service terminated unexpectedly.\s+It has done this (?<num_failures>\d+)" \
| fields + _time,host,Service_Name

[List of failed service starts for the last 30 days]
action.email.sendresults = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
relation = None
search = source=wineventlog:system SourceName="Microsoft-Windows-Service Control Manager" "service failed to start" \
| rex field=Message "^The (?<Service_Name>.*) service failed" \
| fields + _time,host,Service_Name

[WinMgmt_Security_Logon_Success Overall by Host]
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common"("EventCode=4776" AND Keywords="Audit Success") OR ("EventCode=680" AND "Success Audit") NOT (Logon_Account="*$" OR Logon_account="*$") \
| eval "User_Account" = coalesce(Logon_Account,Logon_account) \
| transaction "User_Account",Source_Workstation maxpause=5s \
| stats count by host \
| sort 10 -count

[WinMgmt_Security_Logon_Success Overtime]
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" ("EventCode=4776" AND Keywords="Audit Success") OR ("EventCode=680" AND "Success Audit") NOT (Logon_Account="*$" OR Logon_account="*$") \
| eval "User_Account" = coalesce(Logon_Account,Logon_account) \
| transaction "User_Account",Source_Workstation maxpause=5s \
| timechart bins=1000 count

[WinMgmt_Security_Logon_Unsuccessful]
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" ("EventCode=4776" AND Keywords="Audit Success") OR ("EventCode=680" AND "Success Audit") NOT (Logon_Account="*$" OR Logon_account="*$") \
| eval "User_Account" = coalesce(Logon_Account,Logon_account) \
| transaction "User_Account",Source_Workstation maxpause=5s  \
| stats latest(_time) as ltime, count by User_Account, Source_Workstation, dest_nt_host, field_match_sum, duration \
| convert ctime(ltime)

[WinMgmt_System_Reboot Overtime]
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" EventCode=1074 SourceName="USER32" \
| rex field=_raw "Comment:.(?<comment>.*)" \
| rex field=Message "The process.(?<process>[^ ]+)" \
| transaction host maxspan=5m \
| eval user_count=mvcount(User) \
| eval final_user=case(user_count == 1, User, user_count > 1, mvindex(User, user_count-1))\
| eval process_count=mvcount(process) \
| eval final_process=case(process_count == 1, process, process_count > 1, mvindex(process, process_count-1)) \
| search host="*" final_user="*" \
| table _time host final_user final_process comment \
| rename _time AS Time \
| convert ctime(Time) \
| rename final_user AS Username \
| rename final_process AS "Process name" \
| rename comment AS "Comment"

##########################################
###### Lookup Migration Searches #########
##########################################

[WinApp_Lookup_Build_Event - Migrate - Detail]
disabled = 0
search = | outputlookup windows_event_details \
| inputlookup append=true windows_event_details.csv \
| eval _key = LogName . "___" . EventCode . "___" . SourceName . "___" . TaskCategory . "___" . Type . "___" . EventCodeDescription \
| outputlookup windows_event_details
enableSched = 0

[WinApp_Lookup_Build_Event - Migrate - Server]
disabled = 0
search = | outputlookup windows_event_system \
| inputlookup append=true windows_event_system.csv \
| eval _key = Host \
| outputlookup windows_event_system
enableSched = 0

[WinApp_Lookup_Build_Hostmon - Migrate - Server]
disabled = 0
search = | outputlookup windows_hostmon_system \
| inputlookup append=true windows_hostmon_system.csv \
| eval _key = Host \
| outputlookup windows_hostmon_system key_field=Host
enableSched = 0

[WinApp_Lookup_Build_Hostmon_FS - Migrate - Detail]
disabled = 0
search = | outputlookup windows_hostmon_fs_details \
| inputlookup append=true windows_hostmon_fs_details.csv \
| eval _key = FileSystem . "___" . DriveType . "___" . FreeSpacePct . "___" . TotalSpaceGB \
| outputlookup windows_hostmon_fs_details
enableSched = 0

[WinApp_Lookup_Build_Hostmon_Machine - Migrate - Detail]
disabled = 0
search = | outputlookup windows_hostmon_machine_details \
| inputlookup append=true windows_hostmon_machine_details.csv \
| eval _key = OS . "___" . Domain . "___" . Architecture . "___" . Manufacturer \
| outputlookup windows_hostmon_machine_details
enableSched = 0

[WinApp_Lookup_Build_Hostmon_Process - Migrate - Detail]
disabled = 0
search = | outputlookup windows_hostmon_process_details \
| inputlookup append=true windows_hostmon_process_details.csv \
| eval _key = Name \
| outputlookup windows_hostmon_process_details
enableSched = 0

[WinApp_Lookup_Build_Hostmon_Services - Migrate - Detail]
disabled = 0
search = | outputlookup windows_hostmon_services_details \
| inputlookup append=true windows_hostmon_services_details.csv \
| eval _key = Name . "___" . StartMode . "___" . State \
| outputlookup windows_hostmon_services_details
enableSched = 0

[WinApp_Lookup_Build_Netmon - Migrate - Detail]
disabled = 0
search = | outputlookup windows_netmon_details \
| inputlookup append=true windows_netmon_details.csv \
| eval _key = Direction . "___" . Protocol . "___" . PacketType . "___" . RemoteHostName . "___" . RemotePort . "___" . LocalPort . "___" . ProcessName . "___" . UserName \
| outputlookup windows_netmon_details
enableSched = 0

[WinApp_Lookup_Build_Netmon - Migrate - Server]
disabled = 0
search = | outputlookup windows_netmon_system \
| inputlookup append=true windows_netmon_system.csv \
| eval _key = Host \
| outputlookup windows_netmon_system key_field=Host
enableSched = 0

[WinApp_Lookup_Build_Perfmon - Migrate - Detail]
disabled = 0
search = | outputlookup windows_perfmon_details \
| inputlookup append=true windows_perfmon_details.csv \
| eval _key = collection . "___" . object . "___" . counter . "___" . instance \
| outputlookup windows_perfmon_details
enableSched = 0

[WinApp_Lookup_Build_Perfmon - Migrate - Server]
disabled = 0
search = | outputlookup windows_perfmon_system \
| inputlookup append=true windows_perfmon_system.csv \
| eval _key = Host \
| outputlookup windows_perfmon_system key_field=Host
enableSched = 0

[WinApp_Lookup_Build_Printmon - Migrate]
disabled = 0
search = | outputlookup windows_printmon \
| inputlookup append=true windows_printmon.csv \
| eval _key = Host . "___" . printer . "___" . operation . "___" . user \
| outputlookup windows_printmon
enableSched = 0

#####################
## Endpoint Changes
#####################

###### Context Generators ######
[Change - Total Change Count By User By Change Type Per Day - Context Gen]
action.email.sendresults   = 0
cron_schedule              = 0 0 * * *
disabled                   = False
dispatch.earliest_time     = -31d@d
dispatch.latest_time       = -1d@d
enableSched                = 1
is_visible                 = false    
schedule_window            = 20
search                     = | `tstats` count from datamodel=Endpoint.Filesystem where Filesystem.tag="change" by _time,Filesystem.user span=24h | eval change_type="filesystem",user='Filesystem.user' | `tstats` append=T count from datamodel=Endpoint.Registry where Registry.tag="change" by _time,Registry.user span=24h | eval change_type=if(isnull(change_type),"registry",change_type),user=if(isnull(user),'Registry.user',user) | `tstats` append=T count from datamodel=Change.All_Changes by _time,All_Changes.change_type,All_Changes.user span=24h | eval change_type=if(isnull(change_type),'All_Changes.change_type',change_type),user=if(isnull(user),'All_Changes.user',user) | stats count as change_count by _time,change_type,user | `context_stats(change_count, change_type)` | eval min=0 | eval max=median*2 | xsupdateddcontext name=change_count_by_user_by_change_type_1d container=change_analysis class=change_type type=domain app="SA-EndpointProtection" scope=app terms=`xs_default_magnitude_concepts` | stats count


#####################
## Endpoint
#####################

###### Correlation Searches ######
[Endpoint - Anomalous New Processes - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Anomalous New Process
action.correlationsearch.related_searches = ["Endpoint - Local Processes Tracker - Lookup Gen"]
action.customsearchbuilder                = 0
action.customsearchbuilder.enabled        = 1
action.customsearchbuilder.routine        = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec           = {\
    "version":  "1.0",\
    "searches": [\
        {"inputlookup":  {"lookupName": "localprocesses_tracker", "timeField":  "firstTime"},\
         "earliest":     "-24h@h",\
         "latest":       "+0s",\
         "aggregates":   [{"function": "dc", "attribute": "dest", "alias": "dest_count"},\
                          {"function": "values", "attribute": "dest", "alias": "dest"}\
                         ],\
         "splitby":      [{"attribute": "process"}],\
         "resultFilter": {"field": "dest_count", "comparator": ">", "value": "9"}\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["process"]\
}
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = endpoint
action.notable.param.severity             = medium
action.notable.param.rule_title           = Anomalous New Process ($process$)
action.notable.param.rule_description     = An suspicious number of new processes were identified. $dest_count$ hosts were discovered with new instances of $process$ in the last 24 hours.
action.notable.param.nes_fields           = process
action.notable.param.drilldown_name       = View all instances of $process$
action.notable.param.drilldown_search     = | from datamodel:"Endpoint"."Processes" | search process_name="$process|s$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = process
action.risk.param._risk_object_type       = other
action.risk.param._risk_score             = 60
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = process
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 25 * * * *
description                               = Alerts when an anomalous number hosts are detected with a new process.
disabled                                  = True
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
## This remains implemented using the localprocesses_tracker which will maintain true firstTime for us
schedule_window                           = 5
search                                    = | from inputlookup:"localprocesses_tracker" | eval earliestQual=case(match("-24h@h", "^\d"), tostring("-24h@h"),  match("-24h@h", "^([@\+-]){1}"), relative_time(time(), "-24h@h"),  true(), time()) | eval latestQual=case(match("+0s", "^\d"), tostring("+0s"),  match("+0s", "^([@\+-]){1}"), relative_time(time(), "+0s"),  true(), time()) | where ('firstTime'>=earliestQual AND 'firstTime'<=latestQual) | fields - earliestQual, latestQual | stats dc(dest) as "dest_count",values(dest) as "dest" by "process" | where 'dest_count'>9

[Endpoint - Anomalous New Services - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Anomalous New Service
action.correlationsearch.related_searches = ["Endpoint - Services Tracker - Lookup Gen"]
action.customsearchbuilder                = 0
action.customsearchbuilder.enabled        = 1
action.customsearchbuilder.routine        = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec           = {\
    "version":  "1.0",\
    "searches": [\
        {"inputlookup":  {"lookupName": "services_tracker", "timeField":  "firstTime"},\
         "earliest":     "-24h@h",\
         "latest":       "+0s",\
         "aggregates":   [{"function": "dc", "attribute": "dest", "alias": "dest_count"},\
                          {"function": "values", "attribute": "dest", "alias": "dest"}\
                         ],\
         "splitby":      [{"attribute": "service"}],\
         "resultFilter": {"field": "dest_count", "comparator": ">", "value": "9"}\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["service"]\
}
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = endpoint
action.notable.param.severity             = medium
action.notable.param.rule_title           = Anomalous New Service ($service$)
action.notable.param.rule_description     = An suspicious number of new services were identified. $dest_count$ hosts were discovered with new instances of the $service$ service in the last 24 hours.
action.notable.param.nes_fields           = service
action.notable.param.drilldown_name       = View all instances of $service$
action.notable.param.drilldown_search     = | from datamodel:"Endpoint"."Services" | search service="$service$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = service
action.risk.param._risk_object_type       = other
action.risk.param._risk_score             = 60
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = service
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 25 * * * *
description                               = Alerts when an anomalous number hosts are detected with a new service.
disabled                                  = True
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
schedule_window                           = 5
## This remains implemented using the listeningports_tracker which will maintain true firstTime for us
search                                    = | from inputlookup:"services_tracker" | eval earliestQual=case(match("-24h@h", "^\d"), tostring("-24h@h"),  match("-24h@h", "^([@\+-]){1}"), relative_time(time(), "-24h@h"),  true(), time()) | eval latestQual=case(match("+0s", "^\d"), tostring("+0s"),  match("+0s", "^([@\+-]){1}"), relative_time(time(), "+0s"),  true(), time()) | where ('firstTime'>=earliestQual AND 'firstTime'<=latestQual) | fields - earliestQual, latestQual | stats dc(dest) as "dest_count",values(dest) as "dest" by "service" | where 'dest_count'>9

###### Lookup Generating Searches ######
[Endpoint - Listening Ports Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Endpoint",\
	    "object":        "Ports",\
        "earliest":      "-70m@m",\
        "latest":        "+0s",\
        "eventFilter":   "",\
		"aggregates":    [{"function": "min", "attribute": "_time", "alias": "firstTime"},\
	                      {"function": "max", "attribute": "_time", "alias": "lastTime"}\
	                     ],\
	    "splitby":       [\
	                      {"attribute": "Ports.dest", "alias": "dest"},\
	                      {"attribute": "Ports.transport", "alias": "transport"},\
	                      {"attribute": "Ports.dest_port", "alias": "dest_port"}\
	                     ],\
        "summariesonly": "1",\
        "outputlookup":  "listeningports_tracker",\
        "retention":     {\
            "earliestTime":  "-5y",\
            "timeField":     "lastTime",\
            "timeFormat":    "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 35 * * * *
description              = Maintains a list of all port and protocol combinations listening on each system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Endpoint"."Ports"  by "Ports.dest","Ports.transport","Ports.dest_port"  | rename "Ports.dest" as "dest","Ports.transport" as "transport","Ports.dest_port" as "dest_port" | inputlookup append=T "listeningports_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "dest","transport","dest_port" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "listeningports_tracker" | stats count

[Endpoint - Local Processes Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 40 * * * *
description              = Maintains a list of all processes on each system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` min(_time) as firstTime,max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest,Processes.process | `drop_dm_object_name("Processes")` | inputlookup append=T localprocesses_tracker | rex field=process "^\s*(?<process>[^\s]+)" | stats min(firstTime) as firstTime,max(lastTime) as lastTime by dest,process | outputlookup override_if_empty=false localprocesses_tracker | stats count

[Endpoint - Services Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 40 * * * *
description              = Maintains a list of all services (and the most recent startmode) for each system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` min(_time) as firstTime,max(_time) as lastTime,latest(Services.start_mode) as start_mode from datamodel=Endpoint.Services by Services.dest,Services.service | `drop_dm_object_name("Services")` | inputlookup append=T services_tracker | sort 0 - lastTime | stats min(firstTime) as firstTime,max(lastTime) as lastTime,first(start_mode) as start_mode by dest,service | outputlookup override_if_empty=false services_tracker | stats count


#####################
## Compute Inventory
#####################

###### Lookup Generating Searches ######
[Endpoint - System Version Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Compute_Inventory",\
	    "object":        "OS",\
        "earliest":      "-70m@m",\
        "latest":        "+0s",\
        "eventFilter":   "",\
		"aggregates":    [{"function": "max", "attribute": "_time", "alias": "_time"}],\
	    "splitby":       [\
	                      {"attribute": "All_Inventory.dest", "alias": "dest"},\
	                      {"attribute": "All_Inventory.OS.os", "alias": "os"}\
	                     ],\
        "summariesonly": "0",\
        "outputlookup":  "system_version_tracker",\
        "retention":     {\
            "earliestTime":  "-5y",\
            "timeField":     "_time",\
            "timeFormat":    "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 20 * * * *
description              = Maintains a list of the most recent operating system version for each system and the time we got this information
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=false allow_old_summaries=true max(_time) as "_time" from datamodel="Compute_Inventory"."All_Inventory" where   nodename="All_Inventory.OS"  by "All_Inventory.dest","All_Inventory.OS.os"  | rename "All_Inventory.dest" as "dest","All_Inventory.OS.os" as "os" | inputlookup append=T "system_version_tracker" | stats max(_time) as "_time" by "dest","os" | where strptime('_time', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "system_version_tracker" | stats count

[Endpoint - User Account Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 10 * * * *
description              = Maintains a list of all local user accounts on each system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | from datamodel:"Compute_Inventory"."User" | stats min(_time) as firstTime,max(_time) as lastTime,latest(interactive) as interactive by dest,user | inputlookup append=T useraccounts_tracker | eval _time=lastTime | stats min(firstTime) as firstTime,max(lastTime) as lastTime,latest(interactive) as interactive by dest,user | fields firstTime,lastTime,dest,user,interactive | outputlookup override_if_empty=false useraccounts_tracker | stats count


#####################
## Email
#####################

##### Context-updating searches #####
[Endpoint - Emails By Source - Context Gen]
action.email.sendresults = 0
cron_schedule            = 0 3 * * *
disabled                 = true
dispatch.earliest_time   = -25h@h
dispatch.latest_time     = -1h@h
enableSched              = 1
is_visible               = false
schedule_window          = 20
search                   = | tstats summariesonly=false allow_old_summaries=true sum(All_Email.recipient_count) as recipient_count from datamodel=Email.All_Email where NOT All_Email.src_category="email_servers" by "All_Email.src",_time span=1h | stats avg(recipient_count) as avg, count | eval min=0 | eval max=avg * 2 | xsUpdateDDContext app=SA-EndpointProtection name=recipients_by_src_1h container=email type=domain scope=app | stats count

[Endpoint - Emails By Destination Count - Context Gen]
action.email.sendresults = 0
cron_schedule            = 0 4 * * *
disabled                 = true
dispatch.earliest_time   = -25h@h
dispatch.latest_time     = -1h@h
enableSched              = 1
is_visible               = false
schedule_window          = 20
search                   = | tstats summariesonly=false allow_old_summaries=true dc(All_Email.dest) as dest_count from datamodel=Email.All_Email where NOT All_Email.src_category="email_servers" by "All_Email.src",_time span=1h | stats avg(dest_count) as avg, count | eval min=0 | eval max=avg * 2 | xsUpdateDDContext app=SA-EndpointProtection name=destinations_by_src_1h container=email type=domain scope=app | stats count


#####################
## Malware
#####################

##### Context-updating searches #####
[Endpoint - Malware Daily Count - Context Gen]
action.email.sendresults = 0
cron_schedule            = 0 3 * * *
dispatch.earliest_time   = -31d@d
dispatch.latest_time     = -1d@d
enableSched              = 1
is_visible               = false
schedule_window          = 20
search                   = | tstats `summariesonly` dc(Malware_Attacks.signature) as infection_count from datamodel=Malware.Malware_Attacks where earliest=-31d@d latest=-1d@d Malware_Attacks.action=allowed by Malware_Attacks.dest,_time span=1d | stats sum(infection_count) as total_infection_count by _time | stats count,median(total_infection_count) as median by _time | eval min=0 | eval max=median*2 | xsCreateDDContext name=count_1d container=malware type=domain terms="minimal,small,medium,large,extreme" scope=app app=SA-NetworkProtection | stats count

###### Correlation Searches ######
[Endpoint - Outbreak Observed - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Outbreak Detected
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Malware",\
         "object":        "Malware_Attacks",\
         "earliest":      "-1450m@m",\
         "latest":        "+0s",\
         "aggregates":    [{"function": "dc", "attribute": "Malware_Attacks.dest", "alias": "system_count"},\
                           {"function": "values", "attribute": "Malware_Attacks.tag", "alias": "tag"}\
                          ],\
         "splitby":       [{"attribute": "Malware_Attacks.signature", "alias": "signature"}],\
         "resultFilter":  {"field": "system_count", "comparator": ">", "value": "10"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["signature"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = high
action.notable.param.rule_title       = Outbreak Detected Of $signature$
action.notable.param.rule_description = A potential outbreak was noted. $system_count$ hosts have been detected as newly infected by $signature$ within the past 24 hours.
action.notable.param.nes_fields       = signature
action.notable.param.drilldown_name   = View events associated with potential outbreak of $signature$
action.notable.param.drilldown_search = | from datamodel:"Malware"."Malware_Attacks" | search signature="$signature$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = signature
action.risk.param._risk_object_type   = other
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = signature
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */15 * * * *
description                           = Alerts when a potential outbreak is observed based on newly infected systems all exhibiting the same infection
disabled                              = True
dispatch.earliest_time                = -1450m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
search                                = | tstats summariesonly=true allow_old_summaries=true dc(Malware_Attacks.dest) as "system_count",values(Malware_Attacks.tag) as "tag" from datamodel="Malware"."Malware_Attacks"   by "Malware_Attacks.signature"  | rename "Malware_Attacks.signature" as "signature" | where 'system_count'>10

[Endpoint - Recurring Malware Infection - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Host With A Recurring Malware Infection
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Malware",\
         "object":        "Malware_Attacks",\
         "earliest":      "-10090m@m",\
         "latest":        "+0s",\
         "aggregates":    [{"function": "dc", "attribute": "Malware_Attacks.date", "alias": "day_count"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "Malware_Attacks.dest", "alias": "dest"},\
                           {"attribute": "Malware_Attacks.signature", "alias": "signature"}\
                          ],\
         "resultFilter":  {"field": "day_count", "comparator": ">", "value": "3"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest","signature"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = high
action.notable.param.rule_title       = Host With A Recurring Malware Infection ($signature$ On $dest$)
action.notable.param.rule_description = The device $dest$ was detected with malware '$signature$' that has been detected as active for $day_count$ days in a row. AV has successfully removed the infection each time but the system is continually reinfected; this may indicate the presence of another form of malware is on the system that is prompting the download of '$signature$'.
action.notable.param.nes_fields       = dest,signature
action.notable.param.drilldown_name   = View related '$signature$' events for $dest$
action.notable.param.drilldown_search = | from datamodel:"Malware"."Malware_Attacks" | search dest="$dest$" signature="$signature$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest,signature
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 45 * * * *
description                           = Alerts when a host has an infection that has been re-infected remove multiple times over multiple days.
disabled                              = True
dispatch.earliest_time                = -10090m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
schedule_window                       = 5
search                                = | tstats summariesonly=true allow_old_summaries=true dc(Malware_Attacks.date) as "day_count",count from datamodel="Malware"."Malware_Attacks"   by "Malware_Attacks.dest","Malware_Attacks.signature" | rename "Malware_Attacks.dest" as "dest","Malware_Attacks.signature" as "signature" | where 'day_count'>3


###### Lookup Generating Searches ######

## Endpoint - Malware Tracker - Lookup Gen Breakdown
##   1 - get the most recent signature + dest pairings from datamodel=Malware
##   2 - field renaming
##   3 - input existing signature + det pairings
##   4 - consolidate event and tracker data
##   5 - write lookup
##   6 - purge results
[Endpoint - Malware Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Malware",\
	    "object":        "Malware_Attacks",\
        "earliest":      "-70m@m",\
        "latest":        "+0s",\
        "eventFilter":   "",\
		"aggregates":    [{"function": "min", "attribute": "_time", "alias": "firstTime"},\
	                      {"function": "max", "attribute": "_time", "alias": "lastTime"}\
	                     ],\
	    "splitby":       [\
	                      {"attribute": "Malware_Attacks.dest", "alias": "dest"},\
	                      {"attribute": "Malware_Attacks.signature", "alias": "signature"}\
	                     ],\
        "summariesonly": "1",\
        "outputlookup": "malware_tracker",\
        "retention":    {\
            "earliestTime":  "-5y",\
            "timeField":     "lastTime",\
            "timeFormat":    "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 10 * * * *
description              = Maintains a list of all detections (regardless of status) for each system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Malware"."Malware_Attacks"  by "Malware_Attacks.dest","Malware_Attacks.signature"  | rename "Malware_Attacks.dest" as "dest","Malware_Attacks.signature" as "signature" | inputlookup append=T "malware_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "dest","signature" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "malware_tracker" | stats count

## Endpoint - Malware Operations Tracker - Lookup Gen Breakdown
##     1 - get the most recent malware operations data
##     2 - field renaming
##     3 - filter events that have a product or signature version
##     4 - create time_product_version==_time if product_version exists
##     5 - create time_signature_version==_time if signature_version exists
##     6 - consolidate events into _time,dest,dest_nt_domain,time_product_version,product_version,time_signature_version,signature_version,vendor_product
##    6a - this supports events the have either a product_version, a signature_version, or both
##     7 - perform a "| lookup" on the tracker to bring in "old" values for product_version and signature_version
##  8-11 - decide whether to keep old product and signature version values or new
##    8a - case1: if product_version_old isnull, take product_version
##    8b - case2: if product_version_old isnotnull (implied) and (product_version isnull OR product_version is older than product_version_old), keep product_version_old
##    8c - case3: if product_version_old isnotnull (implied) and (product_version isnotnull (implied) and product_version is newer than product_version_old (implied)) and product_version equal product_version_old, keep product_version_old
##    8d - case4: if product_version_old isnotnull (implied) and (product_version isnotnull (implied) and product_version is newer than product_version_old (implied)) and product_version not equal product_version_old (implied but specified anyway), take product_version
##  8-11 - repeat for time_product_version,signature_version, and time_signature_version respectively
##    12 - remove *_old fields
##    13 - inputlookup malware_operations_tracker data
##    14 - get latest _time,latest dest_nt_domain,latest vendor_product
##    15 - deduplicate based on dest
##    16 - write lookup
##    17 - purge results
[Endpoint - Malware Operations Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 15 0,4,8,12,16,20 * * *
dispatch.earliest_time   = -250m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 10
search                   = | from datamodel:"Malware"."Malware_Operations" | search (product_version=* OR signature_version=*) | eval time_product_version=if(isnotnull(product_version),_time,null()) | eval time_signature_version=if(isnotnull(signature_version),_time,null()) | stats latest(_time) as _time,latest(dest_nt_domain) as dest_nt_domain,latest(time_product_version) as time_product_version,latest(product_version) as product_version,latest(time_signature_version) as time_signature_version,latest(signature_version) as signature_version,latest(vendor_product) as vendor_product by dest | lookup malware_operations_tracker dest OUTPUT time_product_version as time_product_version_old,product_version as product_version_old,time_signature_version as time_signature_version_old,signature_version as signature_version_old | eval product_version=case(isnull(product_version_old),product_version,isnull(product_version) OR time_product_version<time_product_version_old,product_version_old,product_version==product_version_old,product_version_old,product_version!=product_version_old,product_version) | eval time_product_version=case(isnull(product_version_old),time_product_version,isnull(product_version) OR time_product_version<time_product_version_old,time_product_version_old,product_version==product_version_old,time_product_version_old,product_version!=product_version_old,time_product_version) | eval signature_version=case(isnull(signature_version_old),signature_version,isnull(signature_version) OR time_signature_version<time_signature_version_old,signature_version_old,signature_version==signature_version_old,signature_version_old,signature_version!=signature_version_old,signature_version) | eval time_signature_version=case(isnull(signature_version_old),time_signature_version,isnull(signature_version) OR time_signature_version<time_signature_version_old,time_signature_version_old,signature_version==signature_version_old,time_signature_version_old,signature_version!=signature_version_old,time_signature_version) | fields - *old | inputlookup append=T malware_operations_tracker | eventstats latest(_time) as _time by dest | eventstats latest(dest_nt_domain) as dest_nt_domain by dest | eventstats latest(vendor_product) as vendor_product by dest | dedup dest | outputlookup override_if_empty=false malware_operations_tracker | stats count

###### Summary Generating Searches ######
[Endpoint - Average Infection Length - Summary Gen]
action.email.sendresults   = 0
action.summary_index       = 1
action.summary_index._name = endpoint_summary
cron_schedule              = 50 * * * *
dispatch.earliest_time     = 0
dispatch.latest_time       = +0s
enableSched                = 1
is_visible                 = false
schedule_window            = 5
search                     = | from inputlookup:malware_tracker | eval dayDiff=(lastTime-firstTime)/86400 | stats avg(dayDiff) as avg_dayDiff by dest


#####################
## Performance
#####################

###### Correlation Searches ######

## Endpoint - Should Timesync Host Not Syncing - Rule Breakdown
## 1  - Get successful timesync data from Performance datamodel
## 2  - Drop All_Performance lineage from dest
## 3  - Get asset on dest
## 4  - Drop dest_ from the beginning of all fields
## 5  - Append entire asset list
## 6  - Filter on things that should timesync
## 7  - Consolidate entire asset list with data returned from Performance datamodel
## 8  - Filter on things without a lastTime
## 9  - addinfo
## 10 - Compute hourdiff
## 11 - Persist fields of interest
[Endpoint - Should Timesync Host Not Syncing - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Should Timesync Host Not Syncing
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = medium
action.notable.param.rule_title       = Should Timesync Host Not Syncing ($dest$)
action.notable.param.rule_description = The device $dest$ is expected to be synchronizing its clock and has not in the last $hourDiff$ hours.
action.notable.param.nes_fields       = dest
action.notable.param.drilldown_name   = View time-sync events for device $dest$
action.notable.param.drilldown_search = | from datamodel:"Performance"."Timesync" | search dest=$dest$
action.notable.param.default_status   =
action.notable.param.default_owner    =
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 30 8 * * *
description                           = Detects when hosts that are required to synchronize their clocks have failed to do so. Time synchronization is important because it ensures that the event logs are stamped with the proper time. Additionally, this is required by some regulatory compliance standards (such as PCI).
disabled                              = True
dispatch.earliest_time                = -1450m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
schedule_window                       = auto
search                                = | tstats `summariesonly` max(_time) as lastTime from datamodel=Performance.All_Performance where nodename=All_Performance.OS.Timesync All_Performance.OS.Timesync.action=success by All_Performance.dest | rename All_Performance.dest as dest | `get_asset(dest)` | rename dest_* as * | `assets` | search should_timesync=true | stats max(lastTime) as lastTime,first(should_timesync) as should_timesync,values(key) as dest by asset_id | where isnull(lastTime) | addinfo | eval hourDiff=floor((info_max_time-info_min_time)/3600) | fields dest,should_timesync,hourDiff


###############################
##  Primary Functions
###############################
[Endpoint - Multiple Primary Functions Detected - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Multiple Primary Functions Detected
action.correlationsearch.related_searches = [\
    "Endpoint - Local Processes Tracker - Lookup Gen",\
    "Endpoint - Services Tracker - Lookup Gen",\
    "Endpoint - Listening Ports Tracker - Lookup Gen"\
]
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = medium
action.notable.param.rule_title       = Multiple Primary Functions Detected
action.notable.param.rule_description = System $dest$ has multiple ($function_count$) primary functions ($function$) enabled
action.notable.param.nes_fields       = dest,signature
action.notable.param.drilldown_name   = View primary functions on $dest$
action.notable.param.drilldown_search = | `primary_functions_tracker`| search dest=$dest$ | table dest, dest_port, transport, function
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest 
alert.suppress.period                 = 86300s
alert.track                           = 0
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 25 * * * * 
description                           = Multiple Primary Functions Detected
disabled                              = True
dispatch.earliest_time                = 0
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
schedule_window                       = 5
search                                = | `primary_functions_tracker` | eval _time=lastTime | `hoursago(24)` | search is_primary=true | stats values(function) as function,dc(function) as function_count by dest | search function_count>1


#####################
## Processes
#####################
[Endpoint - Prohibited Process Detection - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Prohibited Process Detected
action.correlationsearch.related_searches = ["Endpoint - Local Processes Tracker - Lookup Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = endpoint
action.notable.param.severity             = medium
action.notable.param.rule_title           = Prohibited Process Detected ($process$)
action.notable.param.rule_description     = A prohibited process ($process$) was detected.
action.notable.param.nes_fields           = dest,app
action.notable.param.drilldown_name       = View instances of $process$
action.notable.param.drilldown_search     = | from datamodel:"Endpoint"."Processes" | search process=$process|s$
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = dest
action.risk.param._risk_object_type       = system
action.risk.param._risk_score             = 60
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = dest,process
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = */5 * * * *
description                               = Alerts when a service in the prohibited process list is detected.
disabled                                  = True
dispatch.earliest_time                    = rt-5m@m
dispatch.latest_time                      = rt+5m@m
dispatch.rt_backfill                      = 1
enableSched                               = 1
is_visible                                = false
search                                    = | from datamodel:"Endpoint"."Processes" | `get_interesting_processes` | search is_prohibited=true | `get_event_id` | fields + event_id,_raw,dest,process,note 

#####################
## Services
#####################
[Endpoint - Prohibited Service Detection - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Prohibited Service Detected
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = medium
action.notable.param.rule_title       = Prohibited Service Detected ($service$)
action.notable.param.rule_description = A prohibited service ($service$) was detected.
action.notable.param.nes_fields       = dest,app
action.notable.param.drilldown_name   = View instances of service $service$
action.notable.param.drilldown_search = | from datamodel:"Endpoint"."Services" | search service="$service$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest,service
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Alerts when a service in the prohibited service list is detected.
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = NOT sourcetype=stash `service` | `get_interesting_services` | search is_prohibited=true | `get_event_id` | fields + event_id,_raw,dest,service,note 


#####################
## Registry
#####################

## Endpoint - Registry Tracker - Lookup Gen Breakdown
## 1 - get registry events
## 2 - fill registry_value_name as empty (this is because it's used in splitby)
## 3 - stats
## 4 - input existing data
## 5 - stats
## 6 - filter any empty registry_value_name values
## 7 - write lookup
## 8 - purge results
[Endpoint - Registry Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 55 * * * *
disabled                 = True
description              = Maintains a list of registry paths, keys, and value information by system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = sourcetype=WinRegistry | fillnull value="" registry_value_name | stats min(_time) as firstTime,max(_time) as lastTime,values(registry_value_data) as registry_value_data by registry_path,registry_key_name,registry_value_name,dest | inputlookup append=T registry_tracker | stats min(firstTime) as firstTime,max(lastTime) as lastTime,values(registry_value_data) as registry_value_data by registry_path,registry_key_name,registry_value_name,dest | eval registry_value_name=mvfilter(registry_value_name!="") | outputlookup override_if_empty=false registry_tracker | stats count


#####################
## Time
#####################

## Endpoint - Index Time Delta 2 - Summary Gen Breakdown
## 1  - Perform non-datamodel tstats w/ prestats
## 1a - Filter in all non-underscore indexes
## 1b - Filter out sourcetype=stash
## 1c - Use subsearch to generate index time constraints (-1d@d -> @d) 
## 2  - Compute timeDiff
## 3  - Remove preserved (sistats) fields
## 4  - Filter anything with less than 300s diff
## 5  - Perform consolidating stats
## 6  - Set _time to now()
[Endpoint - Index Time Delta 2 - Summary Gen]
action.email.sendresults   = 0
action.summary_index       = 1
action.summary_index._name = endpoint_summary
## Every Wednesday at Midnight
cron_schedule              = 0 0 * * 3
disabled                   = False
dispatch.earliest_time     = -72h@h
dispatch.latest_time       = +72h@h
enableSched                = 1
is_visible                 = false
schedule_window            = 20
search                     = | tstats prestats=true count where index=* NOT sourcetype=stash [| makeresults | `make_ts_value("-1d@d",start)` | `make_ts_value("+0s",end)` | eval search="(_indextime>=".start." AND _indextime<=".end.")"] by _time,_indextime,host,sourcetype span=1s | eval timeDiff=_time-_indextime | fields - psrsvd* | where timeDiff>300 | stats min(timeDiff) as min_timeDiff,max(timeDiff) as max_timeDiff,sum(timeDiff) as sum_timeDiff,count by host,sourcetype | eval _time=now()


#####################
## Updates
#####################

###### Lookup Generating Searches ######

## Endpoint - Update Signature Reference - Lookup Gen Breakdown
##  1 - Get update events
##  2 - field renaming
##  3 - zip signature and signature_id into a single MV field
##  4 - mvexpand events based on signature_zipo
##  5 - extract SV signature and signature_id fields
##  6 - stats
##  7 - input existing data
##  8 - consolidate event and tracker data
##  9 - write lookup
## 10 - purge results
[Endpoint - Update Signature Reference - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 0 * * * *
description              = Maintains a list of all updates by vendor and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
schedule_window          = 5
search                   = | from datamodel:"Updates"."Updates" | eval signature_zip=mvzip(signature,signature_id) | mvexpand signature_zip | rex field=signature_zip "(?<signature>.*)\,(?<signature_id>.*)" | stats min(_time) as firstTime,max(_time) as lastTime,latest(signature) as signature by signature_id,vendor_product | inputlookup append=T update_signature_reference_lookup | eval _time=lastTime | stats min(firstTime) as firstTime,max(lastTime) as lastTime,latest(signature) as signature by signature_id,vendor_product | outputlookup override_if_empty=false update_signature_reference_lookup | stats count
[Endpoint - Recurring Malware Infection - Rule]
disabled = 0

###### Correlation Searches ######
[Asset - Asset Ownership Unspecified - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Asset Ownership Unspecified
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":	 "Identity_Management",\
         "object":		 "All_Assets",\
         "earliest":     "0",\
         "latest":       "+0s",\
         "eventFilter":  "isnotnull('All_Assets.priority') AND len('All_Assets.priority')>0 AND isnotnull('All_Assets.category') AND len('All_Assets.category')>0 AND (isnull('All_Assets.owner') OR len('All_Assets.owner')==0) AND (isnull('All_Assets.ip') OR len('All_Assets.ip')==0 OR mvcount('All_Assets.ip')==1)",\
         "aggregates":   [{"function": "count"}],\
         "resultFilter": {"field": "count", "comparator": ">", "value": "0"}\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["const_dedup_id"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = identity
action.notable.param.severity         = low
action.notable.param.rule_title       = Identified $count$ Asset(s) without Ownership
action.notable.param.rule_description = $count$ asset(s) were identified as having a defined priority and category without an assigned owner. This may indicate a potential responsibility gap.
action.notable.param.drilldown_name   = View Affected Asset(s)
action.notable.param.drilldown_search = | from datamodel:"Identity_Management"."All_Assets" | where isnotnull('priority') AND len('priority')>0 AND isnotnull('category') AND len('category')>0 AND (isnull('owner') OR len('owner')==0) AND (isnull('ip') OR len('ip')==0 OR mvcount('ip')==1)
action.notable.param.default_status   = 
action.notable.param.default_owner    = 
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = const_dedup_id
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
description                           = Alerts when there are assets that define a specific priority and category but do not have an assigned owner. 
disabled                              = 1
dispatch.earliest_time                = 0
dispatch.latest_time                  = +0s
enableSched                           = 1
cron_schedule                         = 0 */12 * * *
is_visible                            = false
schedule_window                       = 20
search                                = | from datamodel:"Identity_Management"."All_Assets" | where isnotnull('priority') AND len('priority')>0 AND isnotnull('category') AND len('category')>0 AND (isnull('owner') OR len('owner')==0) AND (isnull('ip') OR len('ip')==0 OR mvcount('ip')==1) | stats count | where 'count'>0 | eval const_dedup_id="const_dedup_id"


#####################
## Authentication
#####################

###### Correlation Searches ######
## SOLNESS-6481 Implement correlation search for detecting concurrent access attempts
[Access - Concurrent App Accesses - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Concurrent Login Attempts Detected
action.email.sendresults              = 0
action.notable.param.security_domain  = access
action.notable.param.severity         = medium
action.notable.param.rule_title       = Concurrent Access Event Detected For $user$
action.notable.param.rule_description = Concurrent access attempts to $app$ by $user$ from two different sources( $previous_src$, $src$ ) have been detected.
action.notable.param.nes_fields       = user
action.notable.param.drilldown_name   = View access attemps by $user$
action.notable.param.drilldown_search = | from datamodel:"Authentication"."Authentication" | search user="$user$"
action.notable.param.default_owner    =
action.notable.param.default_status   =
action.risk                           = 1
action.risk.param._risk_object        = user
action.risk.param._risk_object_type   = user
action.risk.param._risk_score         = 20
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = app,user
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 10 * * * *
description                           = Alerts on concurrent access attempts to an app from different hosts. These are good indicators of shared passwords and potential misuse.
disabled                              = True
dispatch.earliest_time                = -70m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | tstats `summariesonly` count from datamodel=Authentication.Authentication by _time,Authentication.app,Authentication.src,Authentication.user span=1s | `drop_dm_object_name("Authentication")` | eventstats dc(src) as src_count by app,user | search src_count>1 | sort 0 + _time | streamstats current=t window=2 earliest(_time) as previous_time,earliest(src) as previous_src by app,user | where (src!=previous_src) | eval time_diff=abs(_time-previous_time) | where time_diff<300

[Access - High or Critical Priority Individual Logging into Infected Machine - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = High or Critical Priority Individual Logging into Infected Machine
## commenting guided mode for now, because multiple search parts not implemented in gui
#action.customsearchbuilder           = 0
#action.customsearchbuilder.enabled   = 1
#action.customsearchbuilder.routine   = make_correlation_search:makeCorrelationSearch
#action.customsearchbuilder.spec      = {\
#    "version":  "1.0",\
#    "searches": [\
#        {"key":          "dest",\
#         "datamodel":    "Authentication",\
#         "object":       "Successful_Authentication",\
#         "earliest":     "-70m@m",\
#         "latest":       "+0s",\
#         "eventFilter":  "('Authentication.user_priority'=\"high\" OR 'Authentication.user_priority'=\"critical\")",\
#         "aggregates":   [{"function": "values", "attribute": "Authentication.user", "alias": "user"}],\
#         "splitby":      [{"attribute": "Authentication.dest", "alias": "dest"}]\
#        },\
#        {"key":          "dest",\
#         "datamodel":    "Malware",\
#         "object":       "Allowed_Malware",\
#         "earliest":     "-1450m@m",\
#         "latest":       "+0s",\
#         "aggregates":   [{"function": "values", "attribute": "Malware_Attacks.signature", "alias": "signature"}],\
#         "splitby":      [{"attribute": "Malware_Attacks.dest", "alias": "dest"}]\
#        }\
#    ],\
#    "alert.suppress":         "1",\
#    "alert.suppress.fields":  ["dest"]\
#}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = access
action.notable.param.severity         = critical
action.notable.param.rule_title       = High or Critical Priority User Accessed Machine Infected with Malware
action.notable.param.rule_description = $user$ accessed $dest$ which is infected with $signature$
action.notable.param.nes_fields       = dest
action.notable.param.drilldown_name   = View successful authentication attempts on infected system $dest$
action.notable.param.drilldown_search = | from datamodel:"Authentication"."Successful_Authentication" | where ('user_priority'="high" OR 'user_priority'="critical") AND 'dest'="$dest$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 100
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 10 * * * *
description                           = Detects users with a high or critical priority logging into a malware infected machine
disabled                              = True
dispatch.earliest_time                = -1450m@m
dispatch.latest_time                  = +0s
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | tstats `summariesonly` values(Authentication.user) as "user" from datamodel=Authentication.Authentication where earliest=-70m@m latest=+0s nodename=Authentication.Successful_Authentication ("Authentication.user_priority"="high" OR "Authentication.user_priority"="critical") by "Authentication.dest" | rename "Authentication.dest" as "dest" | eval cs_key='dest' | join type=inner cs_key [| tstats summariesonly=false allow_old_summaries=true values(Malware_Attacks.signature) as "signature" from datamodel=Malware.Malware_Attacks where earliest=-1450m@m latest=+0s nodename=Malware_Attacks.Allowed_Malware  by "Malware_Attacks.dest" | rename "Malware_Attacks.dest" as "dest" | eval cs_key='dest']

## SOLNESS-6455 Implement correlation search for impossible travel detection. 
## This should run every hour, and scan events for the past 18 hours to detect login attempts from a given login 
## from two geographically distant locations.
[Access - Geographically Improbable Access Detected - Rule]
action.correlationsearch                       = 0
action.correlationsearch.enabled               = 1
action.correlationsearch.label                 = Geographically Improbable Access Detected
action.correlationsearch.related_searches      = ["Access - Geographically Improbable Access - Summary Gen"]
action.email.sendresults                       = 0
action.notable                                 = 1
action.notable.param.security_domain           = access
action.notable.param.severity                  = high
action.notable.param.rule_title                = Geographically Improbable Access Detected For $user$
action.notable.param.rule_description          = Login attempts for $user$ from geographically distant locations ( $src_city$, $dest_city$ ) have been detected.  This is an indication of potentially malicious or unauthorized access attempts.
action.notable.param.nes_fields                = user
action.notable.param.drilldown_name            = View login attemps by $user$
action.notable.param.drilldown_search          = | from datamodel:"Authentication"."Authentication" | search user="$user$" (src="$src$" OR src="$dest$")
action.notable.param.drilldown_earliest_offset = 86400
action.notable.param.drilldown_latest_offset   = 0
action.notable.param.default_owner             =
action.notable.param.default_status            =
action.risk                                    = 1
action.risk.param._risk_object                 = user
action.risk.param._risk_object_type            = user
action.risk.param._risk_score                  = 80
## action.summary_index._name present for migration purposes
action.summary_index._name                     = notable
alert.digest_mode                              = 1
alert.suppress                                 = 1
alert.suppress.fields                          = user
alert.suppress.period                          = 86300s
alert.track                                    = false
counttype                                      = number of events
relation                                       = greater than
quantity                                       = 0
cron_schedule                                  = 5 * * * *
description                                    = Alerts on access attempts that are improbable based on time and geography.
disabled                                       = True
dispatch.earliest_time                         = -65m@m
dispatch.latest_time                           = +0s
enableSched                                    = 1
is_visible                                     = false
request.ui_dispatch_app                        = SplunkEnterpriseSecuritySuite
schedule_window                                = 5
search                                         = index=gia_summary source="Access - Geographically Improbable Access - Summary Gen" | fields user,src_time,src_app,src,src_lat,src_long,src_city,src_country,dest_time,dest_app,dest,dest_lat,dest_long,dest_city,dest_country,distance,speed
      
[Access - Short-lived Account Detected - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Short-lived Account Detected
action.email.sendresults              = 0
action.risk                           = 1
action.risk.param._risk_object        = user
action.risk.param._risk_object_type   = user
action.risk.param._risk_score         = 80
action.notable                        = 1
action.notable.param.security_domain  = access
action.notable.param.severity         = high
action.notable.param.rule_title       = Short-lived Account Detected ($user$)
action.notable.param.rule_description = Account $user$ on $dest$ created and deleted within $timestr$
action.notable.param.nes_fields       = user
action.notable.param.drilldown_name   = View account change events of $user$
action.notable.param.drilldown_search = | from datamodel:"Change"."Account_Management" | search user="$user$" (action="created" OR action="deleted")
action.notable.param.default_owner    = 
action.notable.param.default_status   = 
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = user
alert.suppress.period                 = 14400s
alert.track                           = 0
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */15 * * * *
description                           = Detects when a account or credential is created and then removed a short time later. This may be an indication of malicious activities.
disabled                              = True
dispatch.earliest_time                = -250m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
search                                = | tstats `summariesonly` count from datamodel=Change.All_Changes where nodename="All_Changes.Account_Management" (All_Changes.action="created" OR All_Changes.action="deleted") by _time,All_Changes.dest,All_Changes.user span=1s | `drop_dm_object_name("All_Changes")` | streamstats range(_time) as delta,sum(count) as count by user,dest window=2 global=f | where count>1 AND delta<`useraccount_minimal_lifetime` | `uptime2string(delta,timestr)` | table user, dest, delta, timestr

###### Key Indicator Searches ######
[Access - Number Of Default Accounts In Use]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Default Accounts
action.keyindicator.subtitle                  = Distinct Accounts
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(Authentication.user) as count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s Authentication.user_category=default by Authentication.user
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(Authentication.user)%20as%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Authentication.user_category%3Ddefault%20by%20Authentication.user
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Default Accounts
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Authentication.user) as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s Authentication.user_category=default | appendcols [| tstats `summariesonly` estdc(Authentication.user) as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h Authentication.user_category=default] | `get_delta`

[Access - Distinct Apps]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Auth. Apps
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(Authentication.app) as count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s by Authentication.app
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(Authentication.app)%20as%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Authentication.app
action.keyindicator.group.0.name              = access_center
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Apps
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Authentication.app) as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Authentication.app) as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h] | `get_delta`

[Access - Distinct Destinations]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Auth. Dest's
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(Authentication.dest) as count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s by Authentication.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(Authentication.app)%20as%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Authentication.user_category%3Ddefault%20by%20Authentication.app
action.keyindicator.group.0.name              = access_center
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Destinations
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Authentication.dest) as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Authentication.dest) as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h] | `get_delta`

[Access - Distinct Sources]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Auth. Sources
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(Authentication.src) as count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s by Authentication.src
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(Authentication.src)%20as%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Authentication.src
action.keyindicator.group.0.name              = access_center
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Sources
display.visualizations.show                   = 2
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Authentication.src) as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Authentication.src) as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h] | `get_delta`

[Access - Distinct Users]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Auth. Users
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(Authentication.user) as count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s by Authentication.user
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(Authentication.user)%20as%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Authentication.user
action.keyindicator.group.0.name              = access_center
action.keyindicator.group.0.order             = 4
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Users
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Authentication.user) as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Authentication.user) as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h] | `get_delta`

[Access - Total Access Attempts]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Auth. Attempts
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DAuthentication.Authentication%20where%20earliest%3D-24h%40h%20latest%3D%2B0s
action.keyindicator.group.0.name              = access_center
action.keyindicator.group.0.order             = 5
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Total Access Attempts
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count as current_count from datamodel=Authentication.Authentication where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Authentication.Authentication where earliest=-48h@h latest=-24h@h] | `get_ksi_fields(current_count,historical_count)` | xsFindBestConcept current_count from count_1d in authentication as current_count_qual | xsfindbestconcept delta from percentile in default as delta_qual

###### Report Searches ######
[Access - Access Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication by _time span=10m | timechart minspan=10m count

[Access - Access Over Time By Action]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication by _time,Authentication.action span=10m | timechart minspan=10m useother=`useother` count by Authentication.action | `drop_dm_object_name("Authentication")`

[Access - Access Over Time By App]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication by _time,Authentication.app span=10m | timechart minspan=10m useother=`useother` count by Authentication.app

[Access - Account Usage For Expired Identities]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -7d@d
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` max(_time) as _time,values(Authentication.dest) as dest from datamodel=Authentication.Authentication by Authentication.user | `drop_dm_object_name("Authentication")` | `get_identity4events(user)` | where isnotnull(user_endDate) | where _time>user_endDate | `uitime(user_endDate,"%m/%d/%Y %H:%M:%S")` | fields _time,user,user_first,user_last,user_endDate,dest

[Access - Default Account Usage Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -7d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication where nodename=Authentication.Default_Authentication Authentication.action=success by _time span=1h | timechart minspan=1h count

[Access - Default Account Usage Over Time By App]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -7d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication where nodename=Authentication.Default_Authentication Authentication.action=success by _time,Authentication.app span=1h | timechart minspan=1h count by Authentication.app | `drop_dm_object_name("Authentication")`

[Access - Default Accounts In Use]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` max(_time) as _time,values(Authentication.user_category) as user_category,dc(Authentication.dest) as dc(dest) from datamodel=Authentication.Authentication where Authentication.user_category=default by Authentication.user | `drop_dm_object_name("Authentication")` | sort 100 - _time | fields _time,user,user_category,dc(dest)

[Access - Default Local Accounts]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `useraccounts_tracker` | search user_category=default | stats max(lastTime) as _time,values(user_category) as user_category,dc(dest) as dc(dest) by user | sort 100 - _time | fields _time,user,user_category,dc(dest)

[Access - First Time Account Access]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | from inputlookup:access_tracker | stats min(firstTime) as firstTime,values(dest) as dest by user | sort 100 - firstTime | `uitime(firstTime)` | fields dest user firstTime

[Access - First Time Account Access Over Time]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -30d@d
dispatch.latest_time                      = now
dispatchAs                                = user
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = column
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | inputlookup append=T access_tracker where `tracker_trp(firstTime_user,firstTime_user)` | rename firstTime as _time | timechart count

[Access - Inactive Accounts]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `inactive_accounts(90)` | sort 100 + lastTime | `uitime(lastTime)` | fields user lastTime inactiveDays

[Access - Inactive Account Usage]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `inactive_account_usage(90,24)` | sort 100 - lastTime | `uitime(second2lastTime)` | `uitime(lastTime)` | fields user second2lastTime lastTime inactiveDays

[Access - Notable Access Events]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = `notable` | search security_domain=access | stats sum(count) as count by rule_name

[Access - Privileged Account Usage Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -7d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = connect
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Authentication.Authentication where nodename=Authentication.Privileged_Authentication by _time span=1h | timechart span=1h count

[Access - Privileged Accounts In Use]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` values(Authentication.user_category) as user_category,dc(Authentication.dest) as dest_count,max(_time) as lastTime from datamodel=Authentication.Authentication where Authentication.user_category=privileged by Authentication.user | `drop_dm_object_name("Authentication")` | sort 100 - lastTime | `uitime(lastTime)`

[Access - Top Access By Source]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` count from datamodel=Authentication.Authentication by _time,Authentication.src span=1h | `drop_dm_object_name("Authentication")` | stats sparkline(sum(count),1h) as sparkline,sum(count) as count by src | sort - count

[Access - Top Access By Destination]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` count from datamodel=Authentication.Authentication by _time,Authentication.dest span=1h | `drop_dm_object_name("Authentication")` | stats sparkline(sum(count),1h) as sparkline,sum(count) as count by dest | sort - count

[Access - Unique Access By App Count]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` values(Authentication.app) as app,count from datamodel=Authentication.Authentication by _time,Authentication.src span=1h | `drop_dm_object_name("Authentication")` | stats sparkline(sum(count),1h) as sparkline,dc(app) as app_count by src | sort - app_count

[Access - Unique Access By Destination Count]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` values(Authentication.dest) as dest,count from datamodel=Authentication.Authentication by _time,Authentication.src span=1h | `drop_dm_object_name("Authentication")` | stats sparkline(sum(count),1h) as sparkline,dc(dest) as dest_count by src | sort - dest_count

[Access - Unique Access By User Count]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` values(Authentication.user) as user,count from datamodel=Authentication.Authentication by _time,Authentication.src span=1h | `drop_dm_object_name("Authentication")` | stats sparkline(sum(count),1h) as sparkline,dc(user) as user_count by src | sort - user_count

###### Swim Lane Searches ######
[Access - All Authentication By Asset - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = All Authentication
action.swimlane.color                             = blue
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = Authentication.src,Authentication.dest,src,dest
action.swimlane.drilldown_search                  = | from datamodel:"Authentication"."Authentication" | search $constraints$
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 0
is_visible                                        = false
request.ui_dispatch_app                           = SplunkEnterpriseSecuritySuite
search                                            = | tstats `summariesonly` values(Authentication.action) as action,values(Authentication.app) as app,values(Authentication.src) as src,values(Authentication.dest) as dest,values(Authentication.user) as user,count from datamodel=Authentication.Authentication where $constraints$ by _time span=$span$

[Access - All Authentication By Identity - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = All Authentication
action.swimlane.color                                = blue
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = Authentication.src_user,Authentication.user,src_user,user
action.swimlane.drilldown_search                     = | from datamodel:"Authentication"."Authentication" | search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 0
is_visible                                           = false
request.ui_dispatch_app                              = SplunkEnterpriseSecuritySuite
search                                               = | tstats `summariesonly` values(Authentication.action) as action,values(Authentication.app) as app,values(Authentication.src) as src,values(Authentication.dest) as dest,values(Authentication.user) as user,count from datamodel=Authentication.Authentication where $constraints$ by _time span=$span$

###### Summary Generating Searches ######

## Access - Geographically Improbable Access - Summary Gen Breakdown
## 1  - Get src/user combinations using prestats
## 2  - Alias fields
## 3  - Perform distributed asset lookup by str
## 4  - Perform distributed asset lookup by cidr
## 5  - Get iplocation on src
## 6  - Filter items with proper location
## 7  - Consolidate location information
## 8  - Persist the needed fields
## 9  - Consolidate prestats via stats
## 10 - Eval for key
## 11 - Use eventstats to copy src values to dest
## 12 - Filter single-src instances
## 13 - Expand key (this produces all combinations of srcs)
## 14 - Extract dest values
## 15 - Filter instances where src==dest (itself)
## 16 - Create key for src/dest combo
## 17 - Dedup key
## 18 - Compute globedistance
## 19 - Compute speed
## 20 - Filter speed
## 21 - Persist fields
## 22 - Index events with current time
[Access - Geographically Improbable Access - Summary Gen]
action.email.sendresults   = 0
action.summary_index       = 1
action.summary_index._name = gia_summary
cron_schedule              = 50 * * * *
disabled                   = True
dispatch.earliest_time     = -1090m@m
dispatch.latest_time       = +0s
enableSched                = 1
is_visible                 = false
request.ui_dispatch_app    = SplunkEnterpriseSecuritySuite
schedule_window            = 5
search                     = | `tstats` min(_time),earliest(Authentication.app) from datamodel=Authentication.Authentication where Authentication.action="success" by Authentication.src,Authentication.user | eval psrsvd_ct_src_app='psrsvd_ct_Authentication.app',psrsvd_et_src_app='psrsvd_et_Authentication.app',psrsvd_ct_src_time='psrsvd_ct__time',psrsvd_nc_src_time='psrsvd_nc__time',psrsvd_nn_src_time='psrsvd_nn__time',psrsvd_vt_src_time='psrsvd_vt__time',src_time='_time',src_app='Authentication.app',user='Authentication.user',src='Authentication.src' | lookup asset_lookup_by_str key as "src" OUTPUTNEW lat as "src_lat",long as "src_long",city as "src_city",country as "src_country" | lookup asset_lookup_by_cidr key as "src" OUTPUTNEW lat as "src_lat",long as "src_long",city as "src_city",country as "src_country" | iplocation src | search (src_lat=* src_long=*) OR (lat=* lon=*) | eval src_lat=if(isnotnull(src_lat),src_lat,lat),src_long=if(isnotnull(src_long),src_long,lon),src_city=case(isnotnull(src_city),src_city,isnotnull(City),City,1=1,"unknown"),src_country=case(isnotnull(src_country),src_country,isnotnull(Country),Country,1=1,"unknown") | fields psrsvd*src_*,psrsvd_v,src*,user | stats earliest(src_app) as src_app,min(src_time) as src_time by src,src_lat,src_long,src_city,src_country,user | eval key=src."@@".src_time."@@".src_app."@@".src_lat."@@".src_long."@@".src_city."@@".src_country | eventstats dc(key) as key_count,values(key) as key by user | search key_count>1 | stats first(src_app) as src_app,first(src_time) as src_time,first(src_lat) as src_lat,first(src_long) as src_long,first(src_city) as src_city,first(src_country) as src_country by src,key,user | rex field=key "^(?<dest>.+?)@@(?<dest_time>.+?)@@(?<dest_app>.+)@@(?<dest_lat>.+)@@(?<dest_long>.+)@@(?<dest_city>.+)@@(?<dest_country>.+)" | where src!=dest | eval key=mvsort(mvappend(src."->".dest, NULL, dest."->".src)),units="m" | dedup key, user | `globedistance(src_lat,src_long,dest_lat,dest_long,units)` | eval speed=distance/(abs(src_time-dest_time+1)/3600) | where speed>=500 | fields user,src_time,src_app,src,src_lat,src_long,src_city,src_country,dest_time,dest_app,dest,dest_lat,dest_long,dest_city,dest_country,distance,speed | eval _time=now()


#####################
## Account Management
#####################

###### Correlation Searches ######

###### Key Indicator Searches ######
[Change - Number Of Account Lockouts]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
counttype                                     = number of events
relation                                      = greater than
quantity                                      = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Account Lockouts
action.keyindicator.subtitle                  = Distinct Accounts
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc(All_Changes.user) as count from datamodel=Change.All_Changes where earliest=-24h@h latest=+0s nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.user
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(All_Changes.user)%20as%20count%20from%20datamodel%3DChange.All_Changes%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20nodename%3DAll_Changes.Account_Management%20All_Changes.result%3D%22lockout%22%20by%20All_Changes.user
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Account Lockouts
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(All_Changes.user) as current_count from datamodel=Change.All_Changes where earliest=-24h@h latest=+0s nodename=All_Changes.Account_Management All_Changes.result="lockout" | appendcols [| tstats `summariesonly` estdc(All_Changes.user) as historical_count from datamodel=Change.All_Changes where earliest=-48h@h latest=-24h@h nodename=All_Changes.Account_Management All_Changes.result="lockout"] | `get_delta`

###### Report Searches ######
[Change - Account Lockouts]
action.email.reportServerEnabled = 0
alert.track                      = 0
counttype                        = number of events
relation                         = greater than
quantity                         = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` count from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.src,All_Changes.Account_Management.src_nt_domain,All_Changes.user | sort 100 - count | `drop_dm_object_name("All_Changes")` |  `drop_dm_object_name("Account_Management")`

[Change - Account Management By Source User]
action.email.reportServerEnabled          = 0
alert.track                               = 0
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
dispatch.earliest_time                    = -24h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` count from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management by All_Changes.Account_Management.src_user| `drop_dm_object_name("All_Changes")` | `drop_dm_object_name("Account_Management")` | sort 10 - count

[Change - Account Management Over Time By Action]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
counttype                                           = number of events
relation                                            = greater than
quantity                                            = 0
dispatch.earliest_time                              = -24h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management by _time,All_Changes.action span=10m | timechart minspan=10m useother=`useother` count by All_Changes.action | `drop_dm_object_name("All_Changes")`

[Change - Recent Account Management]
action.email.reportServerEnabled = 0
alert.track                      = 0
counttype                        = number of events
relation                         = greater than
quantity                         = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.events.fields            = ["action", "src", "src_nt_domain", "src_user", "dest", "dest_nt_domain", "user"]
display.events.list.wrap         = true
display.events.rowNumbers        = false
display.events.type              = list
display.general.enablePreview    = true
display.general.type             = events
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | from datamodel:"Change"."Account_Management" | head 1000

[Change - Top Account Management Events]
action.email.reportServerEnabled = 0
alert.track                      = 0
counttype                        = number of events
relation                         = greater than
quantity                         = 0
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` count from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management by _time,All_Changes.action span=1h | `drop_dm_object_name("All_Changes")` | stats sparkline(sum(count),1h) as sparkline,sum(count) as count by action | sort 10 - count###### Incident Review Saved Search ######
#
# Note: this saved search is intended to mirror the `notable` macro, but with slots for filtering. Any changes in the notable macro
# must be reflected here in order to view them on incident review.
#
[Incident Review - Main]
search         = $time_filter$ (`get_notable_index` OR `get_sequenced_index`) $source_filter$ | eval `get_event_id_meval`,rule_id=event_id | search $event_id_filter$ | fields - host_* | tags outputfield=tag | `mvappend_field(tag,orig_tag)` | dedup rule_id | `notable_xref_lookup` | `get_correlations` | search $security_domain_filter$ | `get_current_status` | search $status_filter$ | `get_owner` | search $owner_filter$ | `get_urgency` | search $urgency_filter$ | typer | tags outputfield=tag | `mvappend_field(tag,orig_tag)` | search $tag_filter$ | `suppression_extract` | search NOT suppression=* | `risk_correlation`
is_visible     = false

###### Administrative Searches ######
[Threats - Disable Suppressions - Administrative]
cron_schedule          = 0 3 * * *
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
search                 = | rest splunk_server=local count=0 /services/alerts/suppressions/-/_autodisable
run_on_startup         = true

[Threat - Refresh Governance - Administrative]
cron_schedule          = 0 * * * *
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
search                 = | rest splunk_server=local count=0 /services/alerts/governance/_reload
run_on_startup         = true

[Threat - Refresh Reviewstatuses - Administrative]
cron_schedule          = 0 * * * *
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
search                 = | rest splunk_server=local count=0 /services/alerts/reviewstatuses/_reload
run_on_startup         = true

###### Context Generators ######
[Risk - Median Object Risk Per Day - Context Gen]
action.email.sendresults   = 0
cron_schedule              = 0 0 * * *
disabled                   = False
dispatch.earliest_time     = -30d@d
dispatch.latest_time       = @d
enableSched                = 1
is_visible                 = false    
schedule_window            = 20
search                     = | tstats `summariesonly` sum(All_Risk.risk_score) as object_risk from datamodel=Risk.All_Risk by _time,All_Risk.risk_object,All_Risk.risk_object_type span=1d | `drop_dm_object_name("All_Risk")` | `context_stats(object_risk, risk_object_type)` | eval min=0 | eval max=median*2 | xsUpdateDDContext app=SA-ThreatIntelligence name=median_object_risk_by_object_type_1d container=risk class=risk_object_type type=domain scope=app | stats count

[Risk - Total Risk By Risk Object Type Per Day - Context Gen]
action.email.sendresults   = 0
cron_schedule              = 0 1 * * *
disabled                   = False
dispatch.earliest_time     = -30d@d
dispatch.latest_time       = @d
enableSched                = 1
is_visible                 = false 
schedule_window            = 20
search                     = | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk by _time,All_Risk.risk_object_type span=1d | `drop_dm_object_name("All_Risk")` | `context_stats(accum_risk, risk_object_type)` | eval min=0 | eval max=median*2 | xsUpdateDDContext app=SA-ThreatIntelligence name=total_risk_by_object_type_1d container=risk class=risk_object_type type=domain scope=app | stats count

###### Correlation Searches ######
## SOLNESS-7123: Introducing correlation search entry for manually created notable events
## This will permit users to define a default set of suppression fields if they so choose
[Manual Notable Event - Rule]
action.notable.param.nes_fields =
disabled                        = False
is_visible                      = false
search                          = | noop

## SOLNESS-6161: Notable Event Audit Notifications
## Use Case: Please alert me (the SOC team manager) when any NEs are created that remain unassigned (i.e. in "New" status) for longer than 4 hours
## The key here is the dispatch times.  latest_time=-4h@h ensures that everything is at least 4 hours old
## From there we filter for status_group="New" OR owner="unassigned"
## Prepend result fields with orig_ in case the notable event action is enabled for this correlation
## No alert actions enabled by default
[Audit - Untriaged Notable Events - Rule]
action.correlationsearch         = 0
action.correlationsearch.enabled = 1
action.correlationsearch.label   = Untriaged Notable Events
action.email.sendresults         = 0
action.notable.param.rule_title  = Untriaged Notable Events
alert.digest_mode                = 1
alert.suppress                   = 1
alert.suppress.fields            = orig_rule_id
alert.suppress.period            = 86300s
alert.track                      = false
counttype                        = number of events
relation                         = greater than
quantity                         = 0
cron_schedule                    = 35 * * * *
description                      = Alerts when notable events have not been triaged
disabled                         = True
dispatch.earliest_time           = -48h@h
dispatch.latest_time             = -4h@h
enableSched                      = 1
is_visible                       = false
schedule_window                  = 5
search                           = `notable` | search (status_group="New" OR owner="unassigned") | table _time,rule_id,rule_name,status_label,owner | rename * as orig_*

[Threat - Same Error On Many Systems - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Same Error On Many Servers Detected
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = threat
action.notable.param.severity         = medium
action.notable.param.rule_title       = Same Error On Many Servers Detected
action.notable.param.rule_description = $orig_sourcetype$ errors were discovered on $system_count$ different systems.  Errors are determined to be "like" based on the Splunk punctuation field (punct).
action.notable.param.nes_fields       = orig_sourcetype
action.notable.param.drilldown_name   = View all $orig_sourcetype$ errors
action.notable.param.drilldown_search = tag=error NOT tag=authentication sourcetype="$orig_sourcetype$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = sourcetype
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 40 * * * *
description                           = Alerts when multiple systems are exhibiting the same errors
disabled                              = True
dispatch.earliest_time                = -65m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
schedule_window                       = 5
search                                = tag=error NOT tag=authentication | stats first(_raw) as orig_raw,dc(host) as system_count by sourcetype,punct | where 'system_count'>100

[Threat - Watchlisted Events - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Watchlisted Event Observed
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = threat
action.notable.param.severity         = high
action.notable.param.rule_title       = Watchlisted Event Observed
action.notable.param.rule_description = A watchlisted $orig_sourcetype$ event was observed from $orig_host$. This event may have a high priority and ought to be investigated.
action.notable.param.nes_fields       = orig_host,orig_sourcetype
action.notable.param.drilldown_name   = 
action.notable.param.drilldown_search = 
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = host
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = suppression_value
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Alerts when an event is discovered including text has been identified as important. This rule triggers whenever an event is discovered with the tag of "watchlist".
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = tag=watchlist NOT sourcetype=stash | eval risk_object=case(isnotnull(user),user,isnotnull(src_user),src_user,isnotnull(dest),dest,isnotnull(src),src,1=1,host) | eval risk_object_type=case(isnotnull(user),"user",isnotnull(src_user),"user",isnotnull(dest),"system",isnotnull(src),"system",1=1,"system") | eval risk_score=if(eventtype="website_watchlist",50,null()) | eval suppression_value=sourcetype."|".risk_object  | `get_event_id` | table _raw,event_id,host,source,sourcetype,src,dest,dvc,src_user,user

###### Key Indicator Searches ######
[Risk - Distinct Risk Object Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Distinct Risk Objects
action.keyindicator.subtitle                  = Object Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` estdc("All_Risk.risk_object") as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(%22All_Risk.risk_object%22)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Risk Object Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` estdc("All_Risk.risk_object") as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s | appendcols [|tstats `summariesonly` estdc("All_Risk.risk_object") as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h] | `get_delta` | fields current_count,*

[Risk - Distinct Risk Object Count By System]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Distinct Risk System Objects
action.keyindicator.subtitle                  = System Object Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count(All_Risk.risk_object) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=system by "All_Risk.risk_object"
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count(All_Risk.risk_object)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3Dsystem%20by%20%22All_Risk.risk_object%22
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct System Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` estdc(All_Risk.risk_object) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=system by "All_Risk.risk_object_type" | appendcols [| tstats `summariesonly` estdc(All_Risk.risk_object) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type=system by "All_Risk.risk_object_type"] | `get_delta` | fields current_count,*

[Risk - Distinct Risk Object Count By User]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Distinct Risk User Objects
action.keyindicator.subtitle                  = User Object Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count(All_Risk.risk_object) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=user by All_Risk.risk_object 
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count(All_Risk.risk_object)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3Duser%20by%20All_Risk.risk_object%20
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct User Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` estdc(All_Risk.risk_object) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=user by All_Risk.risk_object_type | appendcols [| tstats `summariesonly` estdc(All_Risk.risk_object) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type=user by All_Risk.risk_object_type] | `get_delta` | fields current_count,*

[Risk - Distinct Risk Object Count By Other]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Distinct Risk Other Objects
action.keyindicator.subtitle                  = Other Object Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count(All_Risk.risk_object) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=other by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count(All_Risk.risk_object)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3Dother%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Other Object Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` estdc(All_Risk.risk_object) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type=other by All_Risk.risk_object_type | appendcols [| tstats `summariesonly` estdc(All_Risk.risk_object) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type=other by All_Risk.risk_object_type] | `get_delta` | fields current_count,*

[Risk - Median Risk Score]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Median Risk Score
action.keyindicator.subtitle                  = Overall Median Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20estdc(All_Risk.risk_object)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3Dother%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Median Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s by All_Risk.risk_object | stats median(accum_risk) as current_count | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h by All_Risk.risk_object | stats median(accum_risk) as historical_count] | `get_ksi_fields(current_count, historical_count)` | xsfindbestconcept current_count FROM median_object_risk_by_object_type_1d IN risk as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Median Risk Score By System]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Median System Risk
action.keyindicator.subtitle                  = System Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
#  | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="system" by All_Risk.risk_object, All_Risk.risk_object_type
action.keyindicator.drilldown_uri             = search?q=%20%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20accum_risk%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22system%22%20by%20All_Risk.risk_object%2C%20All_Risk.risk_object_type
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Median Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="system" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as current_count | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="system" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as historical_count] | eval risk_object_type="system" | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM median_object_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Median Risk Score By User]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Median User Risk
action.keyindicator.subtitle                  = User Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="user" by All_Risk.risk_object, All_Risk.risk_object_type 
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20accum_risk%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22user%22%20by%20All_Risk.risk_object%2C%20All_Risk.risk_object_type%20
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Median Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="user" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as current_count | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="user" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as historical_count] | eval risk_object_type="user" | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM median_object_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Median Risk Score By Other]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Median Other Risk
action.keyindicator.subtitle                  = Other Object Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="other" by All_Risk.risk_object, All_Risk.risk_object_type
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20accum_risk%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22other%22%20by%20All_Risk.risk_object%2C%20All_Risk.risk_object_type
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Median Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="other" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as current_count | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as accum_risk from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="other" by All_Risk.risk_object, All_Risk.risk_object_type | stats median(accum_risk) as historical_count] | eval risk_object_type="other" | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM median_object_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Aggregated Risk]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Aggregated Risk
action.keyindicator.subtitle                  = Total Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
#  | tstats `summariesonly` sum(All_Risk.risk_score) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%20%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             =
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Aggregated Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h] | `get_ksi_fields(current_count, historical_count)` | xsfindbestconcept current_count FROM total_risk_by_object_type_1d IN risk as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Aggregated System Risk]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Aggregated System Risk
action.keyindicator.subtitle                  = Total System Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="system" by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20current_count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22system%22%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Aggregated Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="system" by All_Risk.risk_object_type | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="system" by All_Risk.risk_object_type] | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM total_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Aggregated User Risk]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Aggregated User Risk
action.keyindicator.subtitle                  = Total User Risk
action.keyindicator.value                     = current_count
action.keyindicator.drilldown_uri             = user_activity
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="user" by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22user%22%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 4
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Aggregated Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="user" by All_Risk.risk_object_type | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="user" by All_Risk.risk_object_type] | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM total_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Aggregated Other Risk]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Aggregated Other Risk
action.keyindicator.subtitle                  = Total Other Risk
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Risk.risk_score) as score from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="other" by All_Risk.risk_object
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Risk.risk_score)%20as%20score%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Risk.risk_object_type%3D%22other%22%20by%20All_Risk.risk_object
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 5
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Aggregated Risk
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` sum(All_Risk.risk_score) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s All_Risk.risk_object_type="other" by All_Risk.risk_object_type | appendcols [| tstats `summariesonly` sum(All_Risk.risk_score) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h All_Risk.risk_object_type="other" by All_Risk.risk_object_type] | `get_ksi_fields(current_count, historical_count)` | `drop_dm_object_name("All_Risk")` | xsfindbestconcept current_count FROM total_risk_by_object_type_1d IN risk BY risk_object_type as current_count_qual | xsfindbestconcept delta FROM percentile in default as delta_qual

[Risk - Distinct Modifier Sources]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Distinct Modifier Sources
action.keyindicator.subtitle                  = Source Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count(source) as count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s by source
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count(source)%20as%20count%20from%20datamodel%3DRisk.All_Risk%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20source
action.keyindicator.group.0.name              = risk_analysis
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Modifier Sources
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` estdc(source) as current_count from datamodel=Risk.All_Risk where earliest=-24h@h latest=+0s | appendcols[| tstats `summariesonly` estdc(source) as historical_count from datamodel=Risk.All_Risk where earliest=-48h@h latest=-24h@h] | `get_delta`

###### Lookup Generating Searches ######
## Threat - Correlation Searches - Lookup Gen Breakdown
## 1  - Get saved/searches with listDefaultActionArgs=1
## 2  - Whitelist correlation, notable or risk action searches
## 3  - Set rule_name based on correlationsearch label
## 4  - Renames
## 5  - Append configs/conf-correlationsearches
## 6  - Eval empty strings to null()
## 7  - Use appendpipe to add versions of _key with quotes replaces as underscores (per SOLNESS-12049)
## 7a - Filter _key values with "
## 7b - Replace " with _
## 8  - Use stats to take the first values we come to
## 9  - Upsert to correlationsearches_lookup
## 10 - Consolidating stats
[Threat - Correlation Searches - Lookup Gen]
cron_schedule          = * * * * *
disabled               = False
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = true
search                 = | rest splunk_server=local count=0 "/servicesNS/-/-/saved/searches?listDefaultActionArgs=1" | where match('action.correlationsearch.enabled', "1|[Tt]|[Tt][Rr][Uu][Ee]") OR match('action.notable', "1|[Tt]|[Tt][Rr][Uu][Ee]") OR match('action.risk', "1|[Tt]|[Tt][Rr][Uu][Ee]") | eval rule_name=if(isnotnull('action.correlationsearch.label'),'action.correlationsearch.label',title) | rename title as _key,action.notable.param.* as * | append [| rest splunk_server=local count=0 /servicesNS/-/-/configs/conf-correlationsearches | rename title as _key] | eval security_domain=if(security_domain="",null(),security_domain),severity=if(severity="",null(),severity),rule_name=if(rule_name="",null(),rule_name),description=if(description="",null(),description),rule_title=if(rule_title="",null(),rule_title),rule_description=if(rule_description="",null(),rule_description),drilldown_name=if(drilldown_name="",null(),drilldown_name),drilldown_search=if(drilldown_search="",null(),drilldown_search),drilldown_earliest_offset=if(drilldown_earliest_offset="",null(),drilldown_earliest_offset),drilldown_latest_offset=if(drilldown_latest_offset="",null(),drilldown_latest_offset),default_status=if(default_status="",null(),default_status),default_owner=if(default_owner="",null(),default_owner),next_steps=if(next_steps="",null(),next_steps),investigation_profiles=if(investigation_profiles="",null(),investigation_profiles),extract_assets=if(extract_assets="",null(),extract_assets),extract_identities=if(extract_identities="",null(),extract_identities),recommended_actions=if(recommended_actions="",null(),recommended_actions) | appendpipe [ where _key LIKE "%\"%" | eval _key=replace(_key, "\"", "_") ] | stats first(security_domain) as security_domain,first(severity) as severity,first(rule_name) as rule_name,first(description) as description,first(rule_title) as rule_title,first(rule_description) as rule_description,first(drilldown_name) as drilldown_name,first(drilldown_search) as drilldown_search,first(drilldown_earliest_offset) as drilldown_earliest_offset,first(drilldown_latest_offset) as drilldown_latest_offset,first(default_status) as default_status,first(default_owner) as default_owner,first(next_steps) as next_steps,first(investigation_profiles) as investigation_profiles,first(extract_assets) as extract_assets,first(extract_identities) as extract_identities,first(recommended_actions) as recommended_actions by _key | outputlookup correlationsearches_lookup append=T key_field=_key | stats count

[Threat - Notable Owners - Lookup Gen]
cron_schedule          = */10 * * * *
disabled               = False
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = true
search                 = | rest splunk_server=local count=0 /services/authentication/users | search capabilities="can_own_notable_events" | rename title as owner | append [| makeresults | eval owner="unassigned" ] | eval _key=owner | eval realname=if(isnull(realname) or realname="", null(), realname) | table _key owner realname | outputlookup notable_owners_lookup | stats count

[Threat - Risk Correlation By System - Lookup Gen]
cron_schedule          = */30 * * * *
disabled               = False
dispatch.earliest_time = -7d@h
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = false
search                 = | tstats summariesonly=false allow_old_summaries=true sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk where All_Risk.risk_object_type="system" by All_Risk.risk_object | eval dest=lower('All_Risk.risk_object') | `get_asset(dest)` | eval dest=if(isnotnull(dest_asset_id),mvappend(dest,NULL,lower(dest_mac)),dest),dest=if(isnotnull(dest_asset_id),mvappend(dest,NULL,lower(dest_nt_host)),dest),dest=if(isnotnull(dest_asset_id),mvappend(dest,NULL,lower(dest_dns)),dest) | stats sum(risk_score) as risk_score by dest | rename dest as risk_object | outputlookup risk_correlation_by_system_lookup | stats count

[Threat - Risk Correlation By User - Lookup Gen]
cron_schedule          = */30 * * * *
disabled               = False
dispatch.earliest_time = -7d@h
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = false
search                 = | tstats summariesonly=false allow_old_summaries=true sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk where All_Risk.risk_object_type="user" by All_Risk.risk_object | eval user=lower('All_Risk.risk_object') | `get_identity4events(user)` | eval risk_object=if(isnotnull(user_identity),lower(user_identity),user) | stats sum(risk_score) as risk_score by risk_object | outputlookup risk_correlation_by_user_lookup | stats count

[Threat - Risk Correlation By Other - Lookup Gen]
cron_schedule          = */30 * * * *
disabled               = True
dispatch.earliest_time = -7d@h
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = false
search                 = | tstats summariesonly=false allow_old_summaries=true sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk where (All_Risk.risk_object_type!="user" AND All_Risk.risk_object_type!="system") by All_Risk.risk_object,All_Risk.risk_object_type | `drop_dm_object_name("All_Risk")` | eval risk_object=lower('risk_object'),risk_object_type=lower('risk_object_type') | stats sum(risk_score) as risk_score by risk_object,risk_object_type | outputlookup risk_correlation_by_other_lookup | stats count

[Threat - Alexa Top Sites - Lookup Gen]
cron_schedule          = 1 5 * * *
disabled               = 1
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence `top_1m_sites` | outputlookup alexa_lookup_by_str | stats count

[Threat - ASN String Matches - Lookup Gen]
cron_schedule          = 1 15 * * *
disabled               = 1
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence maxmind_geoip_asn_ipv4 | expandiprange ip | eval ip=mvfilter(!match(ip, `ipv4_cidr_regex`)) | where isnotnull(ip) | mvexpand ip| outputlookup output_format=splunk_mv_csv asn_lookup_by_str | stats count

[Threat - ASN CIDR Matches - Lookup Gen]
cron_schedule          = 1 15 * * *
disabled               = 1
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence maxmind_geoip_asn_ipv4 | expandiprange ip | eval ip=mvfilter(match(ip, `ipv4_cidr_regex`)) | where isnotnull(ip) | mvexpand ip | outputlookup output_format=splunk_mv_csv asn_lookup_by_cidr | stats count

[Threat - ASN IPv6 CIDR Matches - Lookup Gen]
cron_schedule          = 1 15 * * *
disabled               = 1
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence maxmind_geoip_asn_ipv6 | outputlookup asn_lookup_by_cidr_ipv6 | stats count

[Threat - ICANN Top Level Domain - Lookup Gen]
cron_schedule          = 1 15 * * *
disabled               = 0
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence icann_top_level_domain_list | eval tld=lower(domain) | fields tld | outputlookup cim_http_tld_lookup | stats count

[Threat - Mozilla Public Suffix - Lookup Gen]
cron_schedule          = 1 20 * * *
disabled               = 0
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = 0
search                 = | inputintelligence mozilla_public_suffix_list | eval segments=mvcount(split(domain, ".")), length=case(rule=="*", segments+2, rule=="!", segments, 1==1, segments+1) | fields length,domain,segments | outputlookup mozilla_public_suffix_lookup | stats count

###### Report Searches ######
[Incident Review - Activity By Reviewer Over Time] 
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
dispatchAs                                = user
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = column
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
search                                    = | `incident_review` | timechart useother=`useother` count by reviewer_realname

[Incident Review - Notable Events By Status]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
search                                    = `notable` | search NOT `suppression` | stats count by status_label | rename status_label as status | sort 10 - count

[Incident Review - Notable Events By Owner]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
search                                    = `notable` | search NOT `suppression` | chart count over owner by urgency | `sort_chart`

[Incident Review - Mean Time To Closure]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -60d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats `summariesonly` earliest(_time) as _time from datamodel=Incident_Management.Notable_Events_Meta by source,Notable_Events_Meta.rule_id | `drop_dm_object_name("Notable_Events_Meta")` | `get_correlations` | `get_current_status` | search status_label="Closed" | eval ttc=mvindex(review_time, 0) | eval ttc=ttc-_time | stats count avg(ttc) as avg_ttc,max(ttc) as max_ttc by rule_name | sort - avg_ttc | `uptime2string(avg_ttc, avg_ttc)` | `uptime2string(max_ttc, max_ttc)` | rename *_ttc* as *(time_to_closure)* | fields - *_dec

[Incident Review - Mean Time To Triage]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -14d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats `summariesonly` earliest(_time) as _time from datamodel=Incident_Management.Notable_Events_Meta by source,Notable_Events_Meta.rule_id | `drop_dm_object_name("Notable_Events_Meta")` | `get_correlations` | join rule_id [| from inputlookup:incident_review_lookup | eval _time=time | stats earliest(_time) as review_time by rule_id] | eval ttt=review_time-_time | stats count,avg(ttt) as avg_ttt,max(ttt) as max_ttt by rule_name | sort - avg_ttt | `uptime2string(avg_ttt, avg_ttt)` | `uptime2string(max_ttt, max_ttt)` | rename *_ttt* as *(time_to_triage)* | fields - *_dec

[Incident Review - Top Reviewers]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `incident_review` | stats sparkline,count,min(_time) as firstTime,max(_time) as lastTime by reviewer_realname | `uitime(firstTime)` | `uitime(lastTime)` | sort 100 - count

[Incident Review - Recent Review Activity]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `incident_review` | rename status_label as status | sort 100 - _time | table _time,rule_id,status,rule_name,owner_realname,comment,reviewer_realname

[Risk - Risk Modifiers Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = column
display.visualizations.charting.axisY2.enabled      = 1
display.visualizations.charting.chart.overlayFields = count
display.visualizations.charting.legend.placement    = bottom
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = | tstats prestats=true summariesonly=false allow_old_summaries=`allow_old_summaries_bool` sum(All_Risk.risk_score),count from datamodel=Risk.All_Risk by _time span=10m | timechart minspan=10m sum(All_Risk.risk_score) as risk_score,count

[Risk - Risk Score By Business Unit]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats summariesonly=false allow_old_summaries=`allow_old_summaries_bool` sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk by All_Risk.risk_object,All_Risk.risk_object_type | `drop_dm_object_name("All_Risk")` | eval dest=if(risk_object_type=="system",risk_object,null()) | eval user=if(risk_object_type=="user",risk_object,null()) | `get_asset(dest)` | `get_identity4events(user)` | `mvappend_field(dest_bunit,user_bunit)` | stats sum(risk_score) as risk_score,dc(risk_object) by dest_bunit | eval avg_score=floor('risk_score'/'dc(risk_object)') | rename dest_bunit as bunit

[Risk - Risk Score By Object]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats summariesonly=false allow_old_summaries=`allow_old_summaries_bool` sum(All_Risk.risk_score) as risk_score,dc(source) as source_count,count from datamodel=Risk.All_Risk by All_Risk.risk_object,All_Risk.risk_object_type | `drop_dm_object_name("All_Risk")` | sort 1000 - risk_score

[Risk - Most Active Sources]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats summariesonly=false allow_old_summaries=`allow_old_summaries_bool` sum(All_Risk.risk_score) as risk_score,dc(All_Risk.risk_object) as risk_objects,count from datamodel=Risk.All_Risk by source | sort 1000 - count,risk_score

[Risk - Recent Risk Modifiers]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | from datamodel:"Risk"."All_Risk" | head 1000 | table _time risk_object risk_object_type source description risk_score

[Suppressions - Currently Suppressed Events Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = `suppressed_notables` | timechart minspan=10m count by rule_name

[Suppressions - Suppression History Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -30d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = index=notable_summary source="Threat - Suppressed Notables - Summary Gen" | timechart minspan=1d sum(count) as count by rule_name

[Suppressions - Suppression Management Activity]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -7d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = `suppression_audit` | table _time suppression action status user

[Suppressions - Expired Suppressions]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -7d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = `suppression_audit-expired` | eval raw=_raw | table _time suppression raw

###### Summary Generating Searches ######
[Threat - Suppressed Notables - Summary Gen]
action.email.sendresults   = 0
action.summary_index       = 1
action.summary_index._name = notable_summary
cron_schedule              = 55 0,6,12,18 * * *
dispatch.earliest_time     = -365m@m
dispatch.latest_time       = -5m@m
enableSched                = 1
is_visible                 = false
schedule_window            = 10
search                     = `suppressed_notables` | stats count by security_domain, rule_name, urgency, suppression

###### Swim Lane Searches ######
[Threat - All Notable Events By Asset - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = Notable Events
action.swimlane.color                             = yellow
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = orig_host,dvc,src,dest
action.swimlane.drilldown_search                  = $constraints$ `notable`
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 5
is_visible                                        = false
search                                            = $constraints$ `notable` | bucket _time span=$span$ | stats values(rule_name) as rule_name,values(urgency) as urgency,values(src) as src,values(dest) as dest,count by _time

[Threat - All Notable Events By Identity - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = Notable Events
action.swimlane.color                                = yellow
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = src_user,user
action.swimlane.drilldown_search                     = $constraints$ `notable`
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 5
is_visible                                           = false
search                                               = $constraints$ `notable` | bucket _time span=$span$ | stats values(rule_name) as rule_name,values(urgency) as urgency,values(src) as src,values(dest) as dest,count by _time

[Threat - All Risk Modifiers By Asset - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = Risk Modifiers
action.swimlane.color                             = blue
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = All_Risk.risk_object
action.swimlane.drilldown_search                  = | tstats summariesonly=false allow_old_summaries=true sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk where $constraints$ by source | sort - risk_score
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 6
is_visible                                        = false
search                                            = | tstats summariesonly=false allow_old_summaries=true values(source) as source,values(All_Risk.risk_object) as risk_object,sum(All_Risk.risk_score) as count from datamodel=Risk.All_Risk where $constraints$ by _time span=$span$ | eval risk_score=count

[Threat - All Risk Modifiers By Identity - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = Risk Modifiers
action.swimlane.color                             = blue
action.swimlane.constraint_method                 = reverse_identity_lookup
action.swimlane.constraint_fields                 = All_Risk.risk_object
action.swimlane.drilldown_search                  = | tstats summariesonly=false allow_old_summaries=true sum(All_Risk.risk_score) as risk_score from datamodel=Risk.All_Risk where $constraints$ by source | sort - risk_score
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 6
is_visible                                        = false
search                                            = | tstats summariesonly=false allow_old_summaries=true values(source) as source,values(All_Risk.risk_object) as risk_object,sum(All_Risk.risk_score) as count from datamodel=Risk.All_Risk where $constraints$ by _time span=$span$ | eval risk_score=count
[Qualys Integration Framework Basic - Vulnarable Services Lookup]
action.email.useNSSubject = 1
action.sendmn = 1
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 0 0 * * *
dispatch.earliest_time = -1d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeQualysIntegrationFrameworkBasic
request.ui_dispatch_view = search
search = | inputlookup vulnerable_services.csv | search NOT [|  inputlookup vulnerable_services.csv | stats count by HostIP | table HostIP |   append  [ search index=*  eventtype=qualys_vm_detection_event VULN_TYPE=Vulnerability PORT=*  STATUS!=FIXED |rename  IP as HostIP| stats count by HostIP |table HostIP  ] | stats count by HostIP | where count=2 | table HostIP ] | append [search index=*  eventtype=qualys_vm_detection_event VULN_TYPE=Vulnerability PORT=*  STATUS!=FIXED |  rename  IP as HostIP DNS as Hostname QID as VulnQID PORT as VulnPort PROTOCOL as VulnProtocol vuln_category as VulnServiceName SEVERITY as VulnSeverity | table _time  HostIP Hostname VulnQID VulnPort VulnProtocol VulnServiceName VulnSeverity] | outputlookup vulnerable_services.csv

[Connection to Vulnerable Service]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to Vulnerable Service" dest_ip=$result.dest_ip$ dest_port=$result.dest_port$ src_ip=$result.src_ip$
action.logevent.param.index = qifb
action.logevent.param.source = qifb
action.logevent.param.sourcetype = qifb
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeQualysIntegrationFrameworkBasic
request.ui_dispatch_view = search
search = index=* (tag::eventtype="communicate" OR tag::eventtype="network")  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | join dest_ip dest_port [| inputlookup vulnerable_services.csv | rename HostIP as dest_ip VulnPort as dest_port]  | table _time dest_ip dest_port src_ip

[Gateway Avoidance by Vulnerable Host]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Gateway Avoidance by Vulnerable Host" dest_ip=$result.dest_ip$ dest_port=$result.dest_port$ src_ip=$result.src_ip$
action.logevent.param.index = qifb
action.logevent.param.source = qifb
action.logevent.param.sourcetype = qifb
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeQualysIntegrationFrameworkBasic
request.ui_dispatch_view = search
search = index=* (tag::eventtype="communicate" OR tag::eventtype="network")  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | lookup ipdomain clientip as src_ip  OUTPUT class | where class="internal" | join src_ip [| inputlookup vulnerable_services.csv | dedup HostIP | rename HostIP as src_ip | table src_ip ] | lookup ipdomain clientip as dest_ip  OUTPUT class as class1 | search NOT   [|inputlookup ipdomain | rename class as class1| table class1] | table _time src_ip dest_port dest_ip
[Connection to Industroyer C&C]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to Industroyer C&C" Severity="6" src_ip="$result.src_ip$" dest_ip=$result.IPAddress$ dest_port=$result.dest_port$
action.logevent.param.index = industroyer
action.logevent.param.source = industroyer
action.logevent.param.sourcetype = industroyer
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCIndustroyerMalwareDetector
request.ui_dispatch_view = search
search = index=* (tag::eventtype="web" OR tag::eventtype="proxy" OR tag::eventtype="communicate" OR tag::eventtype="network") NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rex field=dest "(?<IP_add>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(?<dest_port>\d+)" | rename dest_ip as clientip  | lookup ipdomain clientip  OUTPUT class | search NOT class=*  | rename clientip as IPAddress | search (IPAddress=195.16.88.6 OR IPAddress=46.28.200.132 OR IPAddress=188.42.253.43 OR IPAddress=5.39.218.152 OR IPAddress=93.115.27.57) | table  _time ,src_ip, IPAddress, dest_port

[Scan from IP which tried to connect to C&C]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="SScan from IP which tried to connect to C&C" Severity="8" src_ip="$result.src_ip$" HostsScanned=$result.HostsScanned$
action.logevent.param.index = industroyer
action.logevent.param.source = industroyer
action.logevent.param.sourcetype = industroyer
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCIndustroyerMalwareDetector
request.ui_dispatch_view = search
search = index=*  ( tag::eventtype="communicate" OR tag::eventtype="network") dest_port=102  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_ip) AS HostsScanned by src_ip, _time |  where HostsScanned >= 50 | dedup src_ip, HostsScanned | table src_ip, HostsScanned, _time | join type=inner [ search index="industroyer" earliest=-30d  latest=now  Name="Connection to Industroyer C&C" | dedup src_ip | fields src_ip ]

[Industroyer hash detected]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Process runnning with Industroyer hash detected" Severity="6" src_ip="$result.src_ip$" ProcessName=$result.Image$ Hash=$result.Hashes$
action.logevent.param.index = industroyer
action.logevent.param.source = industroyer
action.logevent.param.sourcetype = industroyer
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCIndustroyerMalwareDetector
request.ui_dispatch_view = search
search = index=*  source="WinEventLog:Microsoft-Windows-Sysmon/Operational"  (EventDescription="Process Create" OR EventDescription="File Create" ) | rex field=Hashes mode=sed "s/SHA256=//g" | rex field=Hashes mode=sed "s/SHA1=//g" | rex field=Hashes mode=sed "s/MD5=//g" | search (Hashes=F6C21F8189CED6AE150F9EF2E82A3A57843B587D OR Hashes=CCCCE62996D578B984984426A024D9B250237533 OR Hashes=8E39ECA1E48240C01EE570631AE8F0C9A9637187 OR Hashes=2CB8230281B86FA944D3043AE906016C8B5984D9 OR Hashes=79CA89711CDAEDB16B0CCCCFDCFBD6AA7E57120A OR Hashes=94488F214B165512D2FC0438A581F5C9E3BD4D4C OR Hashes=5A5FAFBC3FEC8D36FD57B075EBF34119BA3BFF04 OR Hashes=B92149F046F00BB69DE329B8457D32C24726EE00 OR Hashes=B335163E6EB854DF5E08E85026B2C3518891EDA8)| rename Computer as host | lookup dnsLookup host  OUTPUT ip | rename ip as src_ip host as Hostname | table _time src_ip Image Hashes

[Scan 102 port, 50 hosts per 1 min]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Scan 102 port, 50 hosts per 1 min" Severity="6" src_ip="$result.src_ip$" HostsScanned=$result.HostsScanned$
action.logevent.param.index = industroyer
action.logevent.param.source = industroyer
action.logevent.param.sourcetype = industroyer
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCIndustroyerMalwareDetector
request.ui_dispatch_view = search
search = index=* ( tag::eventtype="communicate" OR tag::eventtype="network") dest_port=102  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_ip) AS HostsScanned by src_ip, _time |  where HostsScanned >= 50 | dedup src_ip, HostsScanned | table src_ip, HostsScanned, _time
[EternalRocks Worm Detector - Network Scan on 445 Port (by EternalRocks)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Network Scan on 445 Port" Severity="8" src_ip="$result.src_ip$" HostsScanned=$result.HostsScanned$
action.logevent.param.index = eternalrocks
action.logevent.param.source = eternalrocks
action.logevent.param.sourcetype = eternalrocks
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCEternalRocksWormDetector
request.ui_dispatch_view = search
search = index=* ( tag::eventtype="communicate" OR tag::eventtype="network") dest_port=445  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_ip) AS HostsScanned by src_ip, _time |  where HostsScanned >= 30 | dedup src_ip, HostsScanned | table src_ip, HostsScanned, _time

[EternalRocks Worm Detector - Activity on Windows Hosts by File Names (Sysmon)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by File Names" Severity="8"\
src_ip="$result.ip$" FileName=$result.FileName$
action.logevent.param.index = eternalrocks
action.logevent.param.source = eternalrocks
action.logevent.param.sourcetype = eternalrocks
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCEternalRocksWormDetector
request.ui_dispatch_view = search
search = index=*  sourcetype="xmlwineventlog:microsoft-windows-sysmon/operational"  (EventDescription="Process Create" OR EventDescription="File Create" ) |rename process as FileName |  join FileName [| inputlookup eternalrocks_files.csv | table FileName ]  |  rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip FileName

[EternalRocks Worm Detector - Activity on Windows Hosts by File Hashes (Sysmon)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by File Hashes" Severity="8"\
src_ip="$result.ip$" Hashes=$result.Hashes$
action.logevent.param.index = eternalrocks
action.logevent.param.source = eternalrocks
action.logevent.param.sourcetype = eternalrocks
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCEternalRocksWormDetector
request.ui_dispatch_view = search
search = index=*  sourcetype="xmlwineventlog:microsoft-windows-sysmon/operational"  (EventDescription="Process Create" OR EventDescription="File Create" ) | rex field=Hashes mode=sed "s/SHA256=//g" | rex field=Hashes mode=sed "s/SHA1=//g" | rex field=Hashes mode=sed "s/MD5=//g"| join Hashes [| inputlookup eternalrocks_hashes.csv | table Hash | rename Hash as Hashes] | rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip Hashes

[EternalRocks Worm Detector - Activity on Windows Hosts by Process (Sysmon)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by Process" Severity="8"\
src_ip="$result.ip$" CommandLine="$result.CommandLine$"
action.logevent.param.index = eternalrocks
action.logevent.param.source = eternalrocks
action.logevent.param.sourcetype = eternalrocks
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCEternalRocksWormDetector
request.ui_dispatch_view = search
search = index=*  sourcetype="xmlwineventlog:microsoft-windows-sysmon/operational"  (EventDescription="Process Create" OR EventDescription="File Create" )   shadowbrokers.zip OR SharpZLib.zip OR installed.fgh OR ICSharpCode.SharpZipLib.dll OR Microsoft.Win32.TaskScheduler.dll OR tor.zip OR required.glo OR taskhost.exe OR TaskScheduler.zip OR torunzip.exe OR (C:\Program Files\Microsoft Updates\SharpZLib.zip) OR (C:\Program Files\Microsoft Updates\svchost.exe) OR (C:\Program Files\Microsoft Updates\installed.fgh)  OR (C:\Program Files\Microsoft Updates\ICSharpCode.SharpZipLib.dll) OR (C:\Program Files\Microsoft Updates\Microsoft.Win32.TaskScheduler.dll) OR (C:\Program Files\Microsoft Updates\SharpZLib) OR (C:\Program Files\Microsoft Updates\temp\tor.zip) OR (C:\Program Files\Microsoft Updates\temp\Tor) OR (C:\Program Files\Microsoft Updates\required.glo) OR (C:\Program Files\Microsoft Updates\taskhost.exe) OR (C:\Program Files\Microsoft Updates\TaskScheduler.zip) OR (C:\Program Files\Microsoft Updates\TaskScheduler) OR (C:\Program Files\Microsoft Updates\torunzip.exe) | rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip CommandLine 

[EternalRocks Worm Detector - Connection to TORPROJECT.ORG,onion]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to TORPROJECT.ORG,onion" Severity="7" src_ip="$result.src_ip$"  domain=$result.domain$
action.logevent.param.index = eternalrocks
action.logevent.param.source = eternalrocks
action.logevent.param.sourcetype = eternalrocks
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCEternalRocksWormDetector
request.ui_dispatch_view = search
search = index=* tag=proxy ( url=*torproject.org* OR url=*.onion* OR url=*api.nuget.org/packages/taskscheduler.2.5.23.nupkg* OR url=*api.nuget.org/packages/sharpziplib.0.86.0.nupkg* )  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rex field=url "((?:http(?:s)?:\/\/)?(?<domain>[\w\-\.]+)(?:\:|\/)?(?: \d+)?[^$]*)" | table _time src_ip domain

# See savedsearches.conf.spec in this app that defines these two keys.  
# In Splunk if you extend the conf key space like that,  you also need to 
# put these empty keys here in default, in the same app as the conf.spec
# file.  If you do not have these empty keys defined here, (or keys in default 
# specifying some value),  then when later your app tries to create or edit a 
# savedsearch and it submits values for these keys, splunk will throw the values away.
#
# TL;DR If you take these away then extended keys defined in 
# savedsearches.conf.spec, do not work properly in the REST API. 
[default]
request.ui_context = 
request.ui_edit_view = 

#SAVED REPORTS 

[911_calls]
search = `cdr_events` `911_numbers` | eval boundary=relative_time(now(),"-5min") | where _time>boundary OR _indextime>boundary | `customizable_sites_extractions` | `get_sites` | table `911_fields` 
dispatch.earliest_time = -1h
dispatch.latest_time = now
displayview = search
enableSched = 0
counttype = number of events
relation = greater than
quantity = 0
cron_schedule = */5 * * * *
alert.digest_mode = True
alert.suppress = 0
alert.track = 1
action.email = 1
action.email.message.alert = 911 call detected.
#action.email.to
action.email.useNSSubject = 1


[example concurrent calls alert]
search = `cdr_events` duration>0 ( eventtype="incoming_call" OR eventtype="outgoing_call" )\
| search ( gateway="*" )\
| `get_call_concurrency(gateway)`\
| where _time>relative_time(now(),"-1h")\
| stats max(concurrency) as maxConcurrency by gateway\
| where maxConcurrency>40\
| sort - concurrency
dispatch.earliest_time = -4h
dispatch.latest_time = now
displayview = search
enableSched = 0
counttype = number of events
relation = greater than
quantity = 0
cron_schedule = 0 * * * *
alert.digest_mode = True
alert.suppress = 0
alert.track = 1
action.email = 1
action.email.message.alert = 1 or more gateways have exceeded the concurrency threshold.
#action.email.to
action.email.useNSSubject = 1

[example get devices from axl]
disabled = 1
action.email.useNSSubject = 1
alert.track = 0
description = Retrieves devices with either device-level assignment or line-level assignment from AXL (relies on sa_cisco_cdr_axl TA).  Should be scheduled.
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
search = | ciscoaxlquery "\
select 'devices' AS src,\
eu.userid, eu.lastname, eu.firstname, eu.middlename, eu.manager, eu.department, eu.telephonenumber, eu.mailid, eu.mobile, eu.homephone, eu.title, eu.nickname,\
d.name AS name, d.description AS description, n.dnorpattern as DN, n.description as numplandescription, rp.name as partition, css.name as callingsearchspacename,\
dp.name as devicepool, sp.name as securityprofilename, tdp.name as protocol, tp.name as productname\
from device as d\
inner join devicenumplanmap as dnpm on dnpm.fkdevice = d.pkid\
left join enduserdevicemap as eudm on eudm.fkdevice=d.pkid\
left join enduser as eu on eudm.fkenduser=eu.pkid\
inner join numplan as n on dnpm.fknumplan = n.pkid and d.tkclass = 1\
left join routepartition as rp on rp.pkid = n.fkroutepartition\
left join callingsearchspace css on css.pkid = d.fkcallingsearchspace\
left join devicepool dp on d.fkdevicepool = dp.pkid\
left join securityprofile sp on sp.pkid = d.fksecurityprofile\
left join typedeviceprotocol tdp on tdp.enum = d.tkdeviceprotocol\
left join typeproduct tp on tp.enum = d.tkproduct\
UNION\
select 'lines' as src,\
' ' as userid, ' ' as lastname, ' ' as firstname, ' ' as middlename, ' ' as manager, ' ' as department, ' ' as telephonenumber, ' ' as mailid, ' ' as mobile, ' ' as homephone, ' ' as title, ' ' as nickname,\
d.name AS name, d.description AS description, n.dnorpattern as DN, n.description as numplandescription, rp.name as partition, css.name as callingsearchspacename,\
dp.name as devicepool, sp.name as securityprofilename, tdp.name as protocol, tp.name as productname\
from device as d\
inner join devicenumplanmap as dnpm on dnpm.fkdevice = d.pkid\
AND dnpm.pkid NOT IN (select dnpeum.fkdevicenumplanmap from devicenumplanmapendusermap as dnpeum)\
inner join numplan as n on dnpm.fknumplan = n.pkid and d.tkclass = 1\
left join routepartition as rp on rp.pkid = n.fkroutepartition\
left join callingsearchspace css on css.pkid = d.fkcallingsearchspace\
left join devicepool dp on d.fkdevicepool = dp.pkid\
left join securityprofile sp on sp.pkid = d.fksecurityprofile\
left join typedeviceprotocol tdp on tdp.enum = d.tkdeviceprotocol\
left join typeproduct tp on tp.enum = d.tkproduct\
"\
| eval userFullName = lastname . ", " . firstname\
| rename devicepool AS devicePool, productname as productName, mailid AS mailId, userid AS userId, callingsearchspacename AS callingSearchSpaceName, securityprofilename AS securityProfileName\
| fillnull value=""\
| stats first(productName) as productName, first(department) AS department, first(mailId) AS mailId, first(userFullName) AS userFullName, first(userId) AS userId count BY name,description,devicePool,callingSearchSpaceName,protocol,securityProfileName\
| table name,productName,department,description,devicePool,mailId,userFullName,userId,callingSearchSpaceName,protocol,securityProfileName\

[User list - Successful login past 30d]
action.email.useNSSubject = 1
action.sendmn = 1
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 0 * * * *
dispatch.earliest_time = -30d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCPasswordSecurityBasic
request.ui_dispatch_view = search
search = index=* source="WinEventLog:security" (EventCode=528 OR EventCode=540 OR EventCode=4624) (Logon_Type=2 OR Logon_Type=3 OR Logon_Type=7 OR Logon_Type=10) | eval User=if(mvcount(Account_Name)>1, mvindex(Account_Name,1), mvindex(Account_Name, 0)) |search NOT  (User=*$ OR User="ANONYMOUS LOGON" OR User="LOCAL SERVICE" OR User=SYSTEM) | stats count by User | fields User| outputlookup users.csv

[Successful login IP-User list past 30d]
action.email.useNSSubject = 1
action.sendmn = 1
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 0 * * * *
dispatch.earliest_time = -30d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCPasswordSecurityBasic
request.ui_dispatch_view = search
search = index=* source="WinEventLog:security" (EventCode=528 OR EventCode=540 OR EventCode=4624) (Logon_Type=2 OR Logon_Type=3 OR Logon_Type=7 OR Logon_Type=10) | eval User=if(mvcount(Account_Name)>1, mvindex(Account_Name,1), mvindex(Account_Name, 0)) | search NOT(User=*$ OR User="ANONYMOUS LOGON" OR User="LOCAL SERVICE" OR User=SYSTEM)  (Source_Network_Address=*  AND Source_Network_Address!="-")| lookup dnsLookup ip as Source_Network_Address OUTPUT host as Source_Host | dedup Source_Network_Address User|rename _time as Time |table Time Source_Host Source_Network_Address User | outputlookup successful_logins.csv
[Successful login IP-User list past 30d]
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
action.nbtstat.param.verbose = 0
action.notable.param.verbose = 0
action.nslookup.param.verbose = 0
action.ping.param.verbose = 0
action.risk.param.verbose = 0
action.send2uba.param.verbose = 0

#####################
## Global
#####################

###### Correlation Searches ######
[Network - Policy Or Configuration Change - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Network Change Detected
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Change",\
         "object":        "Network_Changes",\
         "earliest":      "rt-5m@m",\
         "latest":        "rt+5m@m",\
         "aggregates":    [{"function": "max", "attribute": "_time", "alias": "lastTime"},\
                           {"function": "latest", "attribute": "_raw", "alias": "orig_raw"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "All_Changes.dvc", "alias": "dvc"},\
                           {"attribute": "All_Changes.action", "alias": "action"},\
                           {"attribute": "All_Changes.command", "alias": "command"}\
                          ],\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dvc","command"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = medium
action.notable.param.rule_title       = Network Change Detected On $dvc$
action.notable.param.rule_description = A configuration or policy change has been made to $dvc$.  Please verify that this is an authorized change.
action.notable.param.nes_fields       = dvc
action.notable.param.drilldown_name   = View configuration or policy changes on device $dvc$
action.notable.param.drilldown_search = | from datamodel:"Change"."Network_Changes" | search dvc="$dvc$" command="$command$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dvc
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dvc,command
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects changes to policies of the network protection devices (such as firewall policy changes).
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Change"."Network_Changes" | stats max(_time) as "lastTime",latest(_raw) as "orig_raw",count by "dvc","action","command"

###### Lookup Generating Searches ######

#####################
## Certificates
#####################
[Network - Certificate Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 50 * * * *
disabled                 = True
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=false allow_old_summaries=true min(_time) as firstTime,max(_time) as lastTime from datamodel=Certificates.All_Certificates where nodename=All_Certificates.SSL by All_Certificates.SSL.ssl_serial,All_Certificates.SSL.ssl_hash,All_Certificates.SSL.ssl_subject,All_Certificates.SSL.ssl_issuer | rename All_Certificates.SSL.ssl* as certificate* | inputlookup append=T certificate_tracker | stats min(firstTime),max(lastTime) by certificate_serial,certificate_hash,certificate_subject,certificate_issuer | rename certificate* as ssl* | extract cim_ssl_issuer_common_name,cim_ssl_issuer_email,cim_ssl_issuer_unit,cim_ssl_subject_common_name,cim_ssl_subject_email,cim_ssl_subject_unit | rename ssl* as certificate* | outputlookup override_if_empty=false certificate_tracker | stats count


#####################
## Firewall
#####################

##### Context-updating searches #####
[Network - Port Activity By Destination Port - Context Gen]
# To recreate from scratch use: | makeresults | eval size=250 | eval count=0 | eval median=1000 | xscreateddcontext name=count_by_dest_port_1d container=network_traffic type=median_centered terms="minimal,low,medium,high,extreme" width=3 scope=app app=SA-NetworkProtection
action.email.sendresults = 0
cron_schedule            = 0 3 * * *
disabled                 = true
dispatch.earliest_time   = -30d@d
dispatch.latest_time     = -1d@d
enableSched              = 1
is_visible               = false
schedule_window          = 10
search                   = | tstats `summariesonly` count as dest_port_traffic_count from datamodel=Network_Traffic.All_Traffic by All_Traffic.dest_port,_time span=1d | `drop_dm_object_name("All_Traffic")` | `context_stats(dest_port_traffic_count, dest_port)` | search size>0 | xscreateddcontext name=count_by_dest_port_1d class=dest_port container=network_traffic type=median_centered terms="minimal,low,medium,high,extreme" width=3 scope=app app=SA-NetworkProtection | stats count

# Replaces traffic_volume_tracker
[Network - Traffic Source Count Per 30m - Context Gen]
action.email.sendresults = 0
cron_schedule            = 35 * * * *
disabled                 = true
dispatch.earliest_time   = -90m@m
dispatch.latest_time     = -30m@m
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` dc(All_Traffic.src) as src_count from datamodel=Network_Traffic.All_Traffic by _time span=30m | stats count, median(src_count) as median, stdev(src_count) as size | search size>0 | xsupdateddcontext name=src_count_30m container=network_traffic terms="minimal,low,medium,high,extreme" type=median_centered width=3 app=SA-NetworkProtection scope=app | stats count

# Replaces traffic_volume_tracker
[Network - Traffic Volume Per 30m - Context Gen]
action.email.sendresults = 0
cron_schedule            = 45 * * * *
disabled                 = true
dispatch.earliest_time   = -90m@m
dispatch.latest_time     = -30m@m
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` count as total_count from datamodel=Network_Traffic.All_Traffic by _time span=30m | stats count, median(total_count) as median, stdev(total_count) as size | search size>0 | xsupdateddcontext name=count_30m container=network_traffic terms="minimal,low,medium,high,extreme" type=median_centered width=3 app=SA-NetworkProtection scope=app | stats count

[Web - Web Event Count By Src By HTTP Method Per 1d - Context Gen]
action.email.sendresults   = 0
cron_schedule              = 0 0 * * *
disabled                   = False
dispatch.earliest_time     = -31d@d
dispatch.latest_time       = -1d@d
enableSched                = 1
is_visible                 = false    
schedule_window            = 20
search                     = | tstats `summariesonly` count as web_event_count from datamodel=Web.Web by Web.src, Web.http_method, _time span=24h | `drop_dm_object_name("Web")` | where match(http_method, "^[A-Za-z]+$") | `context_stats(web_event_count, http_method)` | eval min=0 | eval max=median*2 | xscreateddcontext name=count_by_http_method_by_src_1d container=web class=http_method app="SA-NetworkProtection" scope=app type=domain terms=`xs_default_magnitude_concepts` | stats count


###### Lookup Generating Searches ######

## Network - Communication Rule Tracker - Lookup Gen Breakdown
##  1-2 - get count by _time,dvc,rule,vendor_product from datamodel=Network_Traffic
##    3 - field renaming
##  4-5 - get month and year
##    6 - consolidate by month/year
##    7 - input communication_rule_tracker lookup
##    8 - consolidate results and existing lookup data
## 9-10 - recreate _time from month/year
##   11 - filter last 396 days of data
##   12 - remove unneeded fields
##   13 - write lookup
##   14 - purge results
[Network - Communication Rule Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 45 * * * *
description              = Maintains a list of Traffic rule values by device and vendor and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic where All_Traffic.rule!=unknown by _time,All_Traffic.dvc,All_Traffic.rule,All_Traffic.vendor_product span=1d | `drop_dm_object_name("All_Traffic")` | convert timeformat="%m" ctime(_time) as month | convert timeformat="%Y" ctime(_time) as year | stats sum(count) as count by month,year,dvc,rule,vendor_product | inputlookup append=T communication_rule_tracker | stats sum(count) as count by month,year,dvc,rule,vendor_product | eval date=month."-01-".year | convert timeformat="%m-%d-%Y" mktime(date) as _time | `daysago(396)` | fields - _time,date,dayDiff | outputlookup override_if_empty=false communication_rule_tracker | stats count

## Network - Port And Protocol Tracker - Lookup Gen Breakdown
## 1-2 - get earliest/latest allowed traffic by transport,dest_port
##   3 - field renaming
##   4 - input port_protocol tracker
##   5 - consolidate results
##   6 - write lookup
##   7 - purge results
[Network - Port And Protocol Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Network_Traffic",\
	    "object":        "All_Traffic",\
        "earliest":      "-70m@m",\
        "latest":        "+0s",\
        "eventFilter":   "'All_Traffic.action'!=\"allowed\"",\
		"aggregates":    [{"function": "min", "attribute": "_time", "alias": "firstTime"},\
	                      {"function": "max", "attribute": "_time", "alias": "lastTime"}\
	                     ],\
	    "splitby":       [\
	                      {"attribute": "All_Traffic.transport", "alias": "transport"},\
	                      {"attribute": "All_Traffic.dest_port", "alias": "dest_port"}\
	                     ],\
        "summariesonly": "1",\
        "outputlookup":  "port_protocol_tracker",\
        "retention":     {\
            "earliestTime":  "-5y",\
            "timeField":     "lastTime",\
            "timeFormat":    "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 50 * * * *
description              = Maintains a list of allowed Traffic by unique transport protocol and destination port combination and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Network_Traffic"."All_Traffic" where    "All_Traffic.action"!="allowed" by "All_Traffic.transport","All_Traffic.dest_port"  | rename "All_Traffic.transport" as "transport","All_Traffic.dest_port" as "dest_port" | inputlookup append=T "port_protocol_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "transport","dest_port" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "port_protocol_tracker" | stats count


#####################
## IDS
#####################

##### Context-updating searches #####
[Network - Event Count By Signature Per Hour - Context Gen]
action.email.sendresults = 0
cron_schedule            = 0 3 * * *
disabled                 = true
dispatch.earliest_time   = -61d@d
dispatch.latest_time     = -1d@d
enableSched              = 1
is_visible               = false
schedule_window          = 10
search                   = | tstats `summariesonly` count as count_by_signature_1h from datamodel=Intrusion_Detection.IDS_Attacks by _time,IDS_Attacks.signature span=1h | `drop_dm_object_name("IDS_Attacks")` | `context_stats(count_by_signature_1h, signature)` | search size>0 | xsCreateDDContext name=count_by_signature_1h class=signature container=ids_attacks type=median_centered terms="minimal,low,medium,high,extreme" scope=app app=SA-NetworkProtection | stats count

###### Correlation Searches ######
[Network - Substantial Increase in an Event - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Substantial Increase In Intrusion Events
action.correlationsearch.related_searches = ["Network - Event Count By Signature Per Hour - Context Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = network
action.notable.param.severity             = high
action.notable.param.rule_title           = Substantial Increase In $signature$ Events
action.notable.param.rule_description     = A statistically significant increase in the volume of $signature$ events was noted. Today's value is $count$.
action.notable.param.nes_fields           = signature
action.notable.param.drilldown_name       = View all $signature$ events
action.notable.param.drilldown_search     = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | search signature="$signature$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = signature
action.risk.param._risk_object_type       = other
action.risk.param._risk_score             = 80
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = signature
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 15 * * * *
description                               = Alerts when a statistically significant increase in a particular intrusion event is observed.
disabled                                  = True
dispatch.earliest_time                    = -70m@m
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
schedule_window                           = 5
search                                    = | tstats `summariesonly` count,values(IDS_Attacks.tag) as tag from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.signature | `drop_dm_object_name("IDS_Attacks")` | xswhere count from count_by_signature_1h in ids_attacks by signature is above medium

###### Lookup Generating Searches ######

## Network - IDS Attack Tracker - Lookup Gen Breakdown
## 1-2 - get the most recent ids_type,signature,vendor_product pairings from datamodel=Intrusion_Detection
##   3 - field renaming
##   4 - inputlookup existing data
##   5 - consolidate event and tracker data
##   6 - write lookup
##   7 - purge results
[Network - IDS Attack Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Intrusion_Detection",\
	    "object":        "IDS_Attacks",\
        "earliest":      "-70m@m",\
        "latest":        "+0s",\
        "eventFilter":   "",\
		"aggregates":    [{"function": "min", "attribute": "_time", "alias": "firstTime"},\
	                      {"function": "max", "attribute": "_time", "alias": "lastTime"}\
	                     ],\
	    "splitby":       [\
	                      {"attribute": "IDS_Attacks.ids_type", "alias": "ids_type"},\
	                      {"attribute": "IDS_Attacks.signature", "alias": "signature"},\
	                      {"attribute": "IDS_Attacks.vendor_product", "alias": "vendor_product"}\
	                     ],\
        "summariesonly": "1",\
        "outputlookup":  "ids_attack_tracker",\
        "retention":     {\
            "earliestTime":  "-5y",\
            "timeField":     "lastTime",\
            "timeFormat":    "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 25 * * * *
description              = Maintains a list of IDS attacks by vendor and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Intrusion_Detection"."IDS_Attacks"  by "IDS_Attacks.ids_type","IDS_Attacks.signature","IDS_Attacks.vendor_product"  | rename "IDS_Attacks.ids_type" as "ids_type","IDS_Attacks.signature" as "signature","IDS_Attacks.vendor_product" as "vendor_product" | inputlookup append=T "ids_attack_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "ids_type","signature","vendor_product" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "ids_attack_tracker" | stats count

## Network -  IDS Category Tracker - Lookup Gen Breakdown
## 1-2 - get the most recent category info from datamodel=Intrusion_Detection
##   3 - field renaming
##   4 - inputlookup existing data
##   5 - consolidate event and tracker data
##   6 - write lookup
##   7 - purge results
[Network - IDS Category Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Intrusion_Detection",\
	    "object":        "IDS_Attacks",\
        "earliest":      "-30m@m",\
        "latest":        "+0s",\
        "eventFilter":   "'IDS_Attacks.category'!=\"unknown\"",\
		"aggregates":    [{"function": "min", "attribute": "_time", "alias": "firstTime"},\
	                      {"function": "max", "attribute": "_time", "alias": "lastTime"}\
	                     ],\
	    "splitby":       [\
	                      {"attribute": "IDS_Attacks.category", "alias": "category"},\
	                      {"attribute": "IDS_Attacks.vendor_product", "alias": "vendor_product"}\
	                     ],\
        "summariesonly": "1",\
        "outputlookup":  "ids_category_tracker",\
        "retention":     {\
            "earliestTime": "-5y",\
            "timeField":    "lastTime",\
            "timeFormat":   "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 10,25,40,55 * * * *
description              = Maintains a list of IDS attack categories by vendor and the first and last time they were seen
dispatch.earliest_time   = -30m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
search                   = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Intrusion_Detection"."IDS_Attacks" where    "IDS_Attacks.category"!="unknown" by "IDS_Attacks.category","IDS_Attacks.vendor_product"  | rename "IDS_Attacks.category" as "category","IDS_Attacks.vendor_product" as "vendor_product" | inputlookup append=T "ids_category_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "category","vendor_product" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "ids_category_tracker" | stats count


###################
## Network Changes
###################

###### Correlation Searches ######
[Network - Network Device Rebooted - Rule]
action.correlationsearch            = 0
action.correlationsearch.enabled    = 1
action.correlationsearch.label      = Network Device Rebooted
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec     = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Change",\
         "object":        "Device_Restarts",\
         "earliest":      "-70m@m",\
         "latest":        "+0s",\
         "aggregates":    [{"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "All_Changes.dvc", "alias": "dvc"},\
                           {"attribute": "_time", "span": "1s"}\
                          ],\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dvc", "orig_time"]\
}
action.email.sendresults            = 0
action.notable.param.rule_title     = Network Device Rebooted
action.risk                         = 1
action.risk.param._risk_object      = dvc
action.risk.param._risk_object_type = system
action.risk.param._risk_score       = 20
alert.digest_mode                   = 1
alert.suppress                      = 1
alert.suppress.fields               = dvc, orig_time
alert.suppress.period               = 86300s
alert.track                         = 0
counttype                           = number of events
relation                            = greater than
quantity                            = 0
cron_schedule                       = 20 * * * *
description                         = Increases the risk score of network devices that have been rebooted.
disabled                            = 1
dispatch.earliest_time              = -70m@m
dispatch.latest_time                = +0s
enableSched                         = 1
is_visible                          = false
schedule_window                     = 5
search                              = | tstats summariesonly=true allow_old_summaries=true count from datamodel="Change"."All_Changes" where   nodename="All_Changes.Network_Changes.Device_Restarts"  by "All_Changes.dvc","_time" span="1s" | rename "All_Changes.dvc" as "dvc"

[Network - Substantial Increase in Port Activity (By Destination) - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Substantial Increase In Port Activity
action.correlationsearch.related_searches = ["Network - Port Activity By Destination Port - Context Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = network
action.notable.param.severity             = high
action.notable.param.rule_title           = Substantial Increase In Port Activity ($dest_port$)
action.notable.param.rule_description     = A statistically significant increase in the volume of activity on port $dest_port$ was noted. Today's value is $count$.
action.notable.param.nes_fields           = dest_port
action.notable.param.drilldown_name       = View all port activity for $dest_port$
action.notable.param.drilldown_search     = | from datamodel:"Network_Traffic"."All_Traffic" | search dest_port=$dest_port$
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = dest_port
action.risk.param._risk_object_type       = other
action.risk.param._risk_score             = 80
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = dest_port
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 15 * * * *
description                               = Alerts when a statistically significant increase in events on a given port is observed.
disabled                                  = True
dispatch.earliest_time                    = -1450m@m
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
schedule_window                           = 5
search                                    = | tstats `summariesonly` count,values(All_Traffic.tag) as tag from datamodel=Network_Traffic.All_Traffic by All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | xswhere count from count_by_dest_port_1d in network_traffic by dest_port is extreme

#####################
## Proxy
#####################

#####################
## Vulnerabilities
#####################

###### Correlation Searches ######
[Network - Vulnerability Scanner Detection (by event) - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Vulnerability Scanner Detected (by events)
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Intrusion_Detection",\
         "object":        "IDS_Attacks",\
         "earliest":      "rt-65m@m",\
         "latest":        "rt-5m@m",\
         "aggregates":    [{"function": "values", "attribute": "IDS_Attacks.tag", "alias": "tag"},\
                           {"function": "dc", "attribute": "IDS_Attacks.signature", "alias": "count"}\
                          ],\
         "splitby":       [{"attribute": "IDS_Attacks.src", "alias": "src"}],\
         "resultFilter":  {"field": "count", "comparator": ">", "value": "25"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["src"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = high
action.notable.param.rule_title       = Vulnerability Scanner Detected ($src$)
action.notable.param.rule_description = A potential vulnerability scanner was detected. $src$ has generated $count$ events in the last hour. This may be indicative of a vulnerability scanner since vulnerability scanners generally trigger a large volume of unique events.
action.notable.param.nes_fields       = src
action.notable.param.drilldown_name   = View all attack events from device $src$
action.notable.param.drilldown_search = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | search src="$src$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = src
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = src
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects a potential vulnerability scanner by detecting devices that have triggered a large number of unique events. Vulnerability scanners generally trigger a high number unique events when scanning a host since each vulnerability check tends to trigger a unique event.
disabled                              = True
dispatch.earliest_time                = rt-65m@m
dispatch.latest_time                  = rt-5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | stats values(tag) as "tag",dc(signature) as "count" by "src" | where 'count'>25

[Network - Vulnerability Scanner Detection (by targets) - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Vulnerability Scanner Detected (by targets)
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Intrusion_Detection",\
         "object":        "IDS_Attacks",\
         "earliest":      "rt-65m@m",\
         "latest":        "rt-5m@m",\
         "aggregates":    [{"function": "values", "attribute": "IDS_Attacks.tag", "alias": "tag"},\
                           {"function": "dc", "attribute": "IDS_Attacks.dest", "alias": "count"}\
                          ],\
         "splitby":       [{"attribute": "IDS_Attacks.src", "alias": "src"}],\
         "resultFilter":  {"field": "count", "comparator": ">", "value": "25"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["src"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = high
action.notable.param.rule_title       = Vulnerability Scanner Detected ($src$)
action.notable.param.rule_description = A potential vulnerability scanner was detected. $src$ has generated events against $count$ targets in the last hour. This may be indicative of a vulnerability scanner since vulnerability scanners generally trigger events against a high number of unique targets.
action.notable.param.nes_fields       = src
action.notable.param.drilldown_name   = View all attack events from device $src$
action.notable.param.drilldown_search = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | search src="$src$"
action.notable.param.default_status   =
action.notable.param.default_owner    =
action.risk                           = 1
action.risk.param._risk_object        = src
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = src
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects a potential vulnerability scanner by detecting devices that have triggered events against a large number of unique targets. Vulnerability scanners generally trigger events against a high number of unique hosts when they are scanning a network for vulnerable hosts.
disabled                              = True
dispatch.earliest_time                = rt-65m@m
dispatch.latest_time                  = rt-5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | stats values(tag) as "tag",dc(dest) as "count" by "src" | where 'count'>25

###### Lookup Generating Searches ######

## Network - Vulnerability Signature Reference - Lookup Gen Breakdown
##   1-2 - get cve,bugtraq,cert,msft,mskb,xref values per signature,vendor_product
##     3 - field renaming
##     4 - read lookup
##  5-10 - make input data multi value
##    11 - consolidate results
## 12-17 - make cve,bugtraq,cert,msft,mskb,xref single value
##    18 - write lookup
##    19 - purge results
[Network - Vulnerability Signature Reference - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 20 * * * *
description              = Maintains a list of vulnerability signatures by vendor (including external reference information such as cve) and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` min(_time) as firstTime,max(_time) as lastTime,values(Vulnerabilities.bugtraq) as bugtraq,values(Vulnerabilities.cert) as cert,values(Vulnerabilities.cve) as cve,values(Vulnerabilities.msft) as msft,values(Vulnerabilities.mskb) as mskb,values(Vulnerabilities.xref) as xref from datamodel=Vulnerabilities.Vulnerabilities by Vulnerabilities.signature,Vulnerabilities.vendor_product | `drop_dm_object_name("Vulnerabilities")` | inputlookup append=T vuln_signature_reference | `makemv(bugtraq)` | `makemv(cert)` | `makemv(cve)` | `makemv(msft)` | `makemv(mskb)` | `makemv(xref)` | stats min(firstTime) as firstTime,max(lastTime) as lastTime,values(cve) as cve,values(bugtraq) as bugtraq,values(cert) as cert,values(msft) as msft,values(mskb) as mskb,values(xref) as xref by signature,vendor_product | `makesv(bugtraq)` | `makesv(cert)` | `makesv(cve)` | `makesv(msft)` | `makesv(mskb)` | `makesv(xref)` | outputlookup override_if_empty=false vuln_signature_reference | stats count
[ActiveDirectory: Create Computer Lookup]
disabled = 0
search =  `admon-computer-lookup-update`
run_on_startup = true
dispatch.earliest_time = 0
dispatch.latest_time = now

[ActiveDirectory: Update Computer Lookup]
disabled = 0
search =  `admon-computer-lookup-update`
enableSched = 1
cron_schedule = */15 * * * *
run_on_startup = true
dispatch.earliest_time = -30m
dispatch.latest_time = now

[ActiveDirectory: Create GPO Lookup]
disabled = 0
search =  `admon-gpo-lookup-update`
run_on_startup = true
dispatch.earliest_time = 0
dispatch.latest_time = now

[ActiveDirectory: Update GPO Lookup]
disabled = 0
search =  `admon-gpo-lookup-update`
enableSched = 1
cron_schedule = */15 * * * *
run_on_startup = true
dispatch.earliest_time = -30m
dispatch.latest_time = now

[ActiveDirectory: Create Group Lookup]
disabled = 0
search =  `admon-group-lookup-update`
run_on_startup = true
dispatch.earliest_time = 0
dispatch.latest_time = now

[ActiveDirectory: Update Group Lookup]
disabled = 0
search =  `admon-group-lookup-update`
enableSched = 1
cron_schedule = */15 * * * *
run_on_startup = true
dispatch.earliest_time = -30m
dispatch.latest_time = now

[ActiveDirectory: Create User Lookup]
disabled = 0
search =  `admon-user-lookup-update`
run_on_startup = true
dispatch.earliest_time = 0
dispatch.latest_time = now

[ActiveDirectory: Update User Lookup]
disabled = 0
search =  `admon-user-lookup-update`
enableSched = 1
cron_schedule = */15 * * * *
run_on_startup = true
dispatch.earliest_time = -30m
dispatch.latest_time = now

[DNS: Failing Domains]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Snd" response!="NOERROR"|top questiontype,questionname,response|`fix-dnsname(questionname)`
enableSched = 0


[DNS: Top Failing Domains]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Rcv" response!="NOERROR"|top questiontype,questionname|`fix-dnsname(questionname)`
enableSched = 0


[DNS: Top Hosts sending failing queries]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Rcv" response!="NOERROR"|top src_ip
enableSched = 0


[DNS: Top Non-Authoritative Responses]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Snd" response!="NOERROR" flags!="A*"|top questiontype,questionname|`fix-dnsname(questionname)`
enableSched = 0


[DNS: Top Querying Hosts]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Rcv"|top src_ip
enableSched = 0


[DNS: Top Recursive Failure Domains]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Rcv" flags="*DR" response!="NOERROR"|top questiontype,questionname|`fix-dnsname(questionname)`
enableSched = 0


[DNS: Top Requested Queries]
disabled = 0
search = eventtype=msad-dns-debuglog direction="Rcv"|top questiontype,questionname|`fix-dnsname(questionname)`
enableSched = 0


[DomainSelector_Lookup]
disabled = 0
search =  `domain-selector-search` \
| eval _key = host \
| outputlookup DomainSelector append=true
enableSched = 1
cron_schedule = */15 * * * *
realtime_schedule = 1
dispatch.earliest_time = -1h
dispatch.latest_time = now

[DomainSelector_Lookup_Migrate]
disabled = 0
search = | outputlookup DomainSelector \
| inputlookup append=true DomainSelector.csv \
| eval _key = host \
| outputlookup DomainSelector
enableSched = 0
[HostToDomain_Lookup_Update]
disabled = 0
search =  `domain-list` \
| sort host \
| eval _key = host \
| outputlookup HostToDomain append=true
enableSched = 1
cron_schedule = 30 2 * * *
realtime_schedule = 1
dispatch.earliest_time = -24h@h
dispatch.latest_time = now

[HostToDomain_Lookup_Migrate]
disabled = 0
search = | outputlookup HostToDomain \
| inputlookup append=true DomainList.csv \
| eval _key = host \
| outputlookup HostToDomain
enableSched = 0
[tHostInfo_Lookup_Update]
disabled = 0
search =  `thostinfo`|inputlookup append=T tHostInfo|where _time > relative_time(now(), "-30d@d")|sort 0 src_ip,src_hostdomain,_time|dedup consecutive=T src_ip,src_hostdomain|sort 0 -_time|outputlookup tHostInfo
enableSched = 1
cron_schedule = */5 * * * *
realtime_schedule = 1
dispatch.earliest_time = -5m
dispatch.latest_time = now

[tHostInfo_Lookup_Migrate]
disabled = 0
search = | inputlookup tHostInfo.csv | outputlookup tHostInfo
enableSched = 0

# This saved search runs per 10 min and get last 15 min data and append it to the lookup tSessions
[tSessions_Lookup_Update]
disabled = 0
search = `tsessions`|eval _key = session_id |sort 0 _time|outputlookup tSessions  append=true 
enableSched = 1
cron_schedule = */10 * * * *
realtime_schedule = 1
dispatch.earliest_time = -15m
dispatch.latest_time = now

# This saved search runs per sunday at 00:00 and maintain last 30days data in tSessions lookup so it remove data which is older than last 30days
[tSessions_Lookup_Update_Per_Day]
disabled = 0
search = | inputlookup tSessions | where _time > relative_time(now(), "-30d@d") | outputlookup tSessions
enableSched = 1
cron_schedule = 0 0 * * 0
realtime_schedule = 1

# This saves search runs per sunday at 01:02:00 and 02:02:00 and append data from 00:00 to a current time.
# This save search is used for retrieve missing data because of tSessions_Lookup_Update_Per_Day saved search.
# tSessions_Lookup_Update_Per_Day saved search takes long time so in between tSessions_Lookup_Update also runs so incase of any data missing, that will retrieved by this saved search.
[tSessions_Lookup_Update_For_Lost_Data]
disabled = 0
search = `tsessions`|eval _key = session_id |sort 0 _time|outputlookup tSessions  append=true 
enableSched = 1
cron_schedule = 2 1,2 * * 0
realtime_schedule = 1
dispatch.earliest_time = -0d@d
dispatch.latest_time = now

# This saved search will runs on the end of guided setup and fill last 30 days data into it.
# This will runs by javascript so it doesn't schedule here.
[tSessions_Lookup_Update_One_Time]
alert.track = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
search = `wineventlog-index` eventtype=wineventlog_security session_id="*x*" session_id!="0x3e7" earliest=-30d@d latest=now() \
| eval login_username = if(eventtype=="msad-successful-user-logons",user,NULL) \
    | eval login_domain=if(eventtype=="msad-successful-user-logons",dest_nt_domain,NULL) \
    | stats earliest(_time) as _time values(eventtype) as eventtype count as eventcount values(src_ip) as src_ip values(user) as user values(host) as host values(login_username) as login_username values(login_domain) as login_domain by session_id \
    | where eventtype=="msad-successful-user-logons" AND eventcount>=1 AND isnotnull(src_ip) AND isnotnull(user) \
    | eval login_host=if(src_ip=="127.0.0.1" OR src_ip=="::1" OR src_ip=="-",upper(host),src_ip) \
    | table _time,session_id,login_username,login_domain,login_host |eval _key = session_id |sort 0 _time|outputlookup tSessions  append=true

[tSessions_Lookup_Migrate]
disabled = 0
search = | inputlookup tSessions.csv | outputlookup tSessions
enableSched = 0

[SiteInfo_Lookup_Update]
disabled = 0
search =  eventtype=msad-dc-health \
| table host,Site \
| dedup host, Site \
| eval _key = host \
| outputlookup SiteInfo append=true
enableSched = 1
cron_schedule = 30 * * * *
realtime_schedule = 1
dispatch.earliest_time = -60m
dispatch.latest_time = now

[SiteInfo_Lookup_Migrate]
disabled = 0
search = | outputlookup SiteInfo \
| inputlookup append=true SiteInfo.csv \
| eval _key = host \
| outputlookup SiteInfo
enableSched = 0

#########################################################################################
######				Windows Application Infrastructure Searches					#########
#########################################################################################

##########################################
###### Lookup Tables Lists searches ######
##########################################

[WinApp_Lookup_Event - Event Details]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_details\
| table LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription\
| sort  LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription

[WinApp_Lookup_Event - Host]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_system\
| dedup Host\
| table Host\
| sort Host

###### Specific Fields Lists ######
[WinApp_Lookup_Event - EventCode Description]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_details\
| dedup EventCode\
| eval Event=EventCode.":".EventCodeDescription\
| table EventCode, EventCodeDescription, Event\
| sort EventCode

[WinApp_Lookup_Event - EventCode]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_details\
| dedup EventCode\
| table EventCode\
| sort EventCode

[WinApp_Lookup_Event - LogName]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_details\
| dedup LogName\
| table LogName\
| sort LogName

[WinApp_Lookup_Event - TaskCategory]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_event_details\
| dedup TaskCategory\
| table TaskCategory\
| sort TaskCategory

[WinApp_Lookup_Perfmon - Combined]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_perfmon_details | dedup instance | table object, counter , instance | sort object, counter, instance

[WinApp_Lookup_Perfmon - Object]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_perfmon_details\
| dedup object\
| table object\
| sort object

[WinApp_Lookup_Perfmon - Collections, Object, and counters]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_perfmon_details\
| stats values(counter) as Perfmon_counters by object\
| sort object

[WinApp_Lookup_Perfmon - counters and instances]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_perfmon_details\
| eval Perfmon_counters=object.": ".counter\
| stats values(instance) as Perfmon_instances by Perfmon_counters\
| sort Perfmon_counters

[WinApp_Lookup_Perfmon - Host]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = | inputlookup windows_perfmon_system\
| dedup Host\
| table Host\
| sort Host


######################################################
###### Lookup Tables -  UPDATE Lookups searches ######
######################################################

[WinApp_Lookup_Build_Perfmon - Update - Server]
disabled = 0
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 0 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="perfmon_windows" object=* \
| eval Host=if(isNull(Host),host,Host) \
| stats count by Host \
| eval _key = Host \
| outputlookup windows_perfmon_system append=true	

[WinApp_Lookup_Build_Perfmon - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 1 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="perfmon_windows" object=* \
| eval instance = if(isnull(instance), "NA", instance) \
| stats count by collection, object, counter, instance \
| sort collection, object, counter, instance \
| eval _key = collection . "___" . object . "___" . counter . "___" . instance \
| outputlookup windows_perfmon_details append=true

[WinApp_Lookup_Build_Event - Update - Server]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 2 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="wineventlog_common" \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| stats count by Host \
| eval _key = Host \
| outputlookup windows_event_system append=true

[WinApp_Lookup_Build_Event - Update - Detail]
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
cron_schedule = 3 * * * *
displayview = search
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
request.ui_dispatch_view = search
search =  eventtype="wineventlog_common" \
| dedup EventCode, LogName \
| fields + LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription, Message \
| eval EventCodeDescription=if(isnull(EventCodeDescription) OR len(trim(EventCodeDescription))==0 OR EventCode=="No Description Available-Update windows_eventcode_definitions", mvindex(split(Message, "."), 0), EventCodeDescription) \
| table LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription \
| eval _key = LogName . "___" . EventCode . "___" . SourceName . "___" . TaskCategory . "___" . Type . "___" . EventCodeDescription \
| outputlookup windows_event_details append=true

[WinApp_Lookup_Build_Hostmon - Update - Server]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 4 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="hostmon_windows" \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| stats count by Host \
| eval _key = Host \
| outputlookup windows_hostmon_system append=true

[WinApp_Lookup_Build_Hostmon_Machine - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 5 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="hostmon_windows" Type=OperatingSystem \
| join host [search eventtype=hostmon_windows Type=Computer earliest=-80m] \
| stats count by OS, Domain, Architecture, Manufacturer \
| eval _key = OS . "___" . Domain . "___" . Architecture . "___" . Manufacturer \
| outputlookup windows_hostmon_machine_details append=true

[WinApp_Lookup_Build_Hostmon_FS - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 6 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype=hostmon_windows Type=Disk \
| eval FreeSpacePct=round(FreeSpaceKB/TotalSpaceKB*100) \
| eval TotalSpaceGB=round(TotalSpaceKB/1024/1024) \
| stats count by FileSystem, DriveType, FreeSpacePct, TotalSpaceGB \
| eval _key = FileSystem . "___" . DriveType . "___" . FreeSpacePct . "___" . TotalSpaceGB \
| outputlookup windows_hostmon_fs_details append=true

[WinApp_Lookup_Build_Hostmon_Process - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 7 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype=hostmon_windows Type=Process \
| stats count by Name \
| eval _key = Name \
| outputlookup windows_hostmon_process_details append=true

[WinApp_Lookup_Build_Hostmon_Services - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 8 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype=hostmon_windows Type=Service \
| stats count by Name, StartMode, State \
| eval _key = Name . "___" . StartMode . "___" . State \
| outputlookup windows_hostmon_services_details append=true

[WinApp_Lookup_Build_Netmon - Update - Server]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 9 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="netmon_windows" \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| stats count by Host \
| eval _key = Host \
| outputlookup windows_netmon_system append=true

[WinApp_Lookup_Build_Netmon - Update - Detail]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 10 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  eventtype="netmon_windows" \
| stats count by Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| sort Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| eval _key = Direction . "___" . Protocol . "___" . PacketType . "___" . RemoteHostName . "___" . RemotePort . "___" . LocalPort . "___" . ProcessName . "___" . UserName \
| outputlookup windows_netmon_details append=true

[WinApp_Lookup_Build_Printmon - Update]
disabled = 0
is_visible = true
action.email.inline = 1
alert.digest_mode = True
alert.severity = 1
alert.suppress = 0
alert.track = 0
cron_schedule = 11 * * * *
enableSched = 1
dispatch.earliest_time = -80m
dispatch.latest_time = now
run_on_startup = true
search =  sourcetype=WinPrintMon \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| stats count by Host printer operation user \
| sort Host printer operation user \
| eval _key = Host . "___" . printer . "___" . operation . "___" . user \
| outputlookup windows_printmon append=true


######################################################
###### Lookup Tables -  CREATE Lookups searches ######
######################################################

[WinApp_Lookup_Build_Perfmon - CreateNew - Server]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="perfmon_windows" object=* earliest=-60m \
| eval Host=if(isNull(Host),host,Host) \
| stats count by Host \
| outputlookup windows_perfmon_system

[WinApp_Lookup_Build_Netmon - CreateNew - Server]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype="netmon_windows" \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| stats count by Host \
| outputlookup windows_netmon_system

[WinApp_Lookup_Build_Netmon - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype="netmon_windows" \
| fields Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| dedup Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| table Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| sort Direction Protocol PacketType RemoteHostName RemotePort LocalPort ProcessName UserName \
| outputlookup windows_netmon_details

[WinApp_Lookup_Build_Printmon - CreateNew]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = sourcetype=WinPrintMon \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| fields Host printer operation user \
| dedup Host printer operation user \
| table Host printer operation user \
| sort Host printer operation user \
| outputlookup windows_printmon

[WinApp_Lookup_Build_Perfmon - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="perfmon_windows" object=* \
| fillnull value=NA instance \
| dedup collection, object, counter, instance \
| table collection, object, counter, instance \
| outputlookup windows_perfmon_details

[WinApp_Lookup_Build_Event - CreateNew - Server]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" \
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| fields Host \
| dedup Host \
| table Host \
| sort Host \
| outputlookup windows_event_system

[WinApp_Lookup_Build_Event - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" \
| dedup EventCode \
| fields + LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription \
| dedup EventCode, Type \
| table LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription \
| sort  LogName, EventCode, SourceName, TaskCategory, Type, EventCodeDescription \
| outputlookup windows_event_details

[WinApp_Lookup_Build_Hostmon - CreateNew - Server]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype="hostmon_windows"\
| eval Host=if(isnull(Host), upper(host), upper(Host)) \
| fields Host \
| dedup Host \
| table Host \
| sort Host \
| outputlookup windows_hostmon_system

[WinApp_Lookup_Build_Hostmon_Machine - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype="hostmon_windows" Type=OperatingSystem \
| join host [search eventtype=hostmon_windows Type=Computer] \
| dedup OS, Domain, Architecture, Manufacturer \
| table OS, Domain, Architecture, Manufacturer \
| outputlookup windows_hostmon_machine_details

[WinApp_Lookup_Build_Hostmon_FS - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype=hostmon_windows Type=Disk \
| eval FreeSpacePct=round(FreeSpaceKB/TotalSpaceKB*100) \
| eval TotalSpaceGB=round(TotalSpaceKB/1024/1024) \
| dedup FileSystem, DriveType, FreeSpacePct, TotalSpaceGB \
| table FileSystem, DriveType, FreeSpacePct, TotalSpaceGB \
| outputlookup windows_hostmon_fs_details

[WinApp_Lookup_Build_Hostmon_Process - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype=hostmon_windows Type=Process \
| dedup Name \
| table Name \
| outputlookup windows_hostmon_process_details

[WinApp_Lookup_Build_Hostmon_Services - CreateNew - Detail]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = 0
displayview = search
request.ui_dispatch_view = search
search = eventtype=hostmon_windows Type=Service \
| dedup Name, StartMode, State \
| table Name, StartMode, State \
| outputlookup windows_hostmon_services_details


####################################
###### Windows Event Searches ######
####################################

[Generic event counts]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -60m@m
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
description= Event search try
search = eventtype="wineventlog_common" \
| stats count by LogName, EventCode, Keywords, TaskCategory, Type

[Event categories and counts by host for the last 30 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" \
| fields host, TaskCategory \
| stats count as EvtCounts by host, TaskCategory \
| sort -EvtCounts \
| eval EvtCatCnt = TaskCategory." (".EvtCounts.")" \
| stats sum(EvtCounts) as Total_Events, values(EvtCatCnt) as Event_Category_Count by host \
| sort -Total_Events \
| eval Host_Count = host." (".Total_Events.")" \
| table Host_Count, Event_Category_Count

[Event severity counts by host for the last 30 days]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" (EventType=2 OR EventType=3 OR EventType=1) \
| eval EventSeverity=case(EventType == 2, "Error", EventType == 3,"Warning", EventType == 1, "Critical") \
| eval host=upper(host) \
| stats count by host EventSeverity \
| xyseries host EventSeverity count \
| eval t=1 \
| addcoltotals \
| sort t desc \
| eval host = if(t>1,"Totals",host) \
| fields - t \
| table host *

[Event severity counts by host for the last 7 days]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" (EventType=2 OR EventType=3 OR EventType=1) \
| eval EventSeverity=case(EventType == 2, "Error", EventType == 3,"Warning", EventType == 1, "Critical") \
| eval host=upper(host) \
| stats count by host EventSeverity \
| xyseries host EventSeverity count \
| eval t=1 \
| addcoltotals \
| sort t desc \
| eval host = if(t>1,"Totals",host) \
| fields - t \
| table host *

[Event severity counts by host for the last 24 hours]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = @d
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" (EventType=2 OR EventType=3 OR EventType=1) \
| eval EventSeverity=case(EventType == 2, "Error", EventType == 3,"Warning", EventType == 1, "Critical") \
| eval host=upper(host) \
| stats count by host EventSeverity \
| xyseries host EventSeverity count \
| eval t=1 \
| addcoltotals \
| sort t desc \
| eval host = if(t>1,"Totals",host) \
| fields - t \
| table host *


######################################
###### Windows Perfmon Searches ######
######################################

[Performance counter categories and counts by host for the last 7 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="perfmon_windows" \
| stats values(object) as Perfmon_counter_Category, dc(counter) as Perfmon_counter_Count by Host \
| table Host, Perfmon_counter_Category, Perfmon_counter_Count \
| sort Host

[Number of hosts with Average CPU utilization > 80% in the last 24 hours]
dispatch.earliest_time = -24h
dispatch.latest_time = now
dispatch.ttl = 2p
relation = None
search = eventtype=perfmon_windows Host=* object="processor" counter="% processor time"|stats avg(Value) as Threshold by Host \
| eval range=case(Threshold<10, "OK (<50%)", Threshold<50, "Warn (80%-94%)", Threshold>50, "Critical (95%+)") \
| chart values(Host), count by range

[Average Memory utilization per process, host in the last 24 hours]
action.email.sendresults = 0
dispatch.earliest_time = -24h
dispatch.latest_time = now
dispatch.ttl = 2p
relation = None
search = eventtype=perfmon_windows object=Process  counter="Private Bytes" \
| eval MB=Value/(1024*1024) \
| stats avg(MB) as "Avg. Memory Utilization in MB" by instance, host

[Average CPU utilization per process, host in the last 24 hours]
action.email.sendresults = 0
dispatch.earliest_time = -24h
dispatch.latest_time = now
dispatch.ttl = 2p
relation = None
search = eventtype=perfmon_windows object=Process counter="% Processor Time" \
| stats avg(Value) as "Avg. CPU utilization" by instance, Host


#############################################
###### Windows OS App Crashes Searches ######
#############################################

[Application crash count in the last 24 hours]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
search = eventtype="wineventlog_common" EventCode="1001" Event_Name="*" \
| eval application=P1." (version: ".P2.")" \
| timechart count by application

[Application crash count in the last 7 days]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -7d@d
dispatch.latest_time = now
search = eventtype="wineventlog_common" EventCode="1001" Event_Name="*" \
| eval application=P1." (version: ".P2.")" \
| timechart count by application

[Application crash count in the last 30 days]
disabled = 0
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
search = eventtype="wineventlog_common" EventCode="1001" Event_Name="*" \
| eval application=P1." (version: ".P2.")" \
| timechart count by application

##############################################
###### Windows OS App Installs Searches ######
##############################################

[Count of total installs per user for the last 7 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" SourceName=MsiInstaller EventCode=11707 \
| stats count by User \
| sort -count

[Count of total installs per user each day for the last 7 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" SourceName=MsiInstaller EventCode=11707 \
| timechart count by User

[System_App Installs - By Host - Timechart - 7days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" SourceName=MsiInstaller EventCode=11707 \
| dedup _raw \
| rex field=Message "(?s)Product: (?<product_name>.*) --" \
| timechart span=1d count by host

[Count of total installs per Application each day for the last 7 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" SourceName=MsiInstaller EventCode=11707 \
| rex field=Message "(?s)Product: (?<product_name>.*) --" \
| timechart span=1d count by product_name

[List of Applications, Time of install, User and Host for the last 7 days]
disabled = 0
action.email.reportServerEnabled = 0
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" SourceName=MsiInstaller EventCode=11707 \
| rex field=Message "(?s)Product: (?<product_name>.*) --" \
| table _time host User product_name


#####################################
###### Windows Update searches ######
#####################################

[List of Failed KB installs in the last 7 days]
action.email.inline = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -7d
dispatch.latest_time = now
search = NOT [ search eventtype="Update_Successful" | dedup package, host | fields + host, package ] \
eventtype="Update_Failed" package=* \
| dedup host package \
| stats count, max(_time) as latest_failure_time by host,package \
| sort - latest_failure_time | convert ctime(latest_failure_time) \
| eval kb_details="KB".package." (Total Fails=".tostring(count).") (Last Failure at:".latest_failure_time.")" \
| stats sum(count) as total_fails, values(kb_details) as latest_fail_details by host

[List of KB successful and failed KB installation for the last 30 days]
action.email.inline = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = tag=Windows_Update package=* \
| dedup package, host \
| eval status=if(eventtype=="Update_Successful", "Success", if(eventtype=="Update_Failed", "Failed", "NA")) \
| search NOT status="NA"  \
| stats latest(_time) as ltime, count by status, host, package \
| convert ctime(ltime) \
| eval lsuccess="Succesful at (".ltime.")" \
| eval lfail="Failed at (".ltime.")" \
| eval lstatus=if(status=="Success",lsuccess,lfail) \
| stats values(lstatus) as Status_History by host, package \
| sort host,package \
| eval scount=mvcount(Status_History) \
| eval Last_Status=if(scount>1,"Success",if(match(Status_History, "Success*"),"Success","Failed")) \
| table host, package, Last_Status, Status_History \
| sort host,package

[List of Successful installations (non-KB) for the last 7 days]
action.email.inline = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
dispatch.earliest_time = -7d
dispatch.latest_time = now
search = eventtype="Update_Successful" NOT package=* \
| dedup package, host \
| chart count,max(_time) as latest_install_time by package \
| sort - latest_install_time \
| convert ctime(latest_install_time)

[List of shutdowns for last 30 days]
action.email.sendresults = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
relation = None
search = source=wineventlog:system "EventCode=1076" OR "EventCode=6008" \
| rex field=Message "(?m)(?<cause>.*)$" \
| fields + _time,host,cause

[List of unexpected service terminations for the last 30 days]
action.email.sendresults = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
relation = None
search = source=wineventlog:system terminated ("EventCode=7034" OR "EventCode=7031") \
| rex field=Message "(?i)^The (?<Service_Name>.*) service terminated unexpectedly.\s+It has done this (?<num_failures>\d+)" \
| fields + _time,host,Service_Name

[List of failed service starts for the last 30 days]
action.email.sendresults = 0
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
relation = None
search = source=wineventlog:system SourceName="Microsoft-Windows-Service Control Manager" "service failed to start" \
| rex field=Message "^The (?<Service_Name>.*) service failed" \
| fields + _time,host,Service_Name

[WinMgmt_Security_Logon_Success Overall by Host]
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common"("EventCode=4776" AND Keywords="Audit Success") OR ("EventCode=680" AND "Success Audit") NOT (Logon_Account="*$" OR Logon_account="*$") \
| eval "User_Account" = coalesce(Logon_Account,Logon_account) \
| transaction "User_Account",Source_Workstation maxpause=5s \
| stats count by host \
| sort 10 -count

[WinMgmt_Security_Logon_Success Overtime]
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" ("EventCode=4776" AND Keywords="Audit Success") OR ("EventCode=680" AND "Success Audit") NOT (Logon_Account="*$" OR Logon_account="*$") \
| eval "User_Account" = coalesce(Logon_Account,Logon_account) \
| transaction "User_Account",Source_Workstation maxpause=5s \
| timechart bins=1000 count

[WinMgmt_Security_Logon_Unsuccessful]
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" ("EventCode=4776" AND Keywords="Audit Success") OR ("EventCode=680" AND "Success Audit") NOT (Logon_Account="*$" OR Logon_account="*$") \
| eval "User_Account" = coalesce(Logon_Account,Logon_account) \
| transaction "User_Account",Source_Workstation maxpause=5s  \
| stats latest(_time) as ltime, count by User_Account, Source_Workstation, dest_nt_host, field_match_sum, duration \
| convert ctime(ltime)

[WinMgmt_System_Reboot Overtime]
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = search
request.ui_dispatch_view = search
search = eventtype="wineventlog_common" EventCode=1074 SourceName="USER32" \
| rex field=_raw "Comment:.(?<comment>.*)" \
| rex field=Message "The process.(?<process>[^ ]+)" \
| transaction host maxspan=5m \
| eval user_count=mvcount(User) \
| eval final_user=case(user_count == 1, User, user_count > 1, mvindex(User, user_count-1))\
| eval process_count=mvcount(process) \
| eval final_process=case(process_count == 1, process, process_count > 1, mvindex(process, process_count-1)) \
| search host="*" final_user="*" \
| table _time host final_user final_process comment \
| rename _time AS Time \
| convert ctime(Time) \
| rename final_user AS Username \
| rename final_process AS "Process name" \
| rename comment AS "Comment"

##########################################
###### Lookup Migration Searches #########
##########################################

[WinApp_Lookup_Build_Event - Migrate - Detail]
disabled = 0
search = | outputlookup windows_event_details \
| inputlookup append=true windows_event_details.csv \
| eval _key = LogName . "___" . EventCode . "___" . SourceName . "___" . TaskCategory . "___" . Type . "___" . EventCodeDescription \
| outputlookup windows_event_details
enableSched = 0

[WinApp_Lookup_Build_Event - Migrate - Server]
disabled = 0
search = | outputlookup windows_event_system \
| inputlookup append=true windows_event_system.csv \
| eval _key = Host \
| outputlookup windows_event_system
enableSched = 0

[WinApp_Lookup_Build_Hostmon - Migrate - Server]
disabled = 0
search = | outputlookup windows_hostmon_system \
| inputlookup append=true windows_hostmon_system.csv \
| eval _key = Host \
| outputlookup windows_hostmon_system key_field=Host
enableSched = 0

[WinApp_Lookup_Build_Hostmon_FS - Migrate - Detail]
disabled = 0
search = | outputlookup windows_hostmon_fs_details \
| inputlookup append=true windows_hostmon_fs_details.csv \
| eval _key = FileSystem . "___" . DriveType . "___" . FreeSpacePct . "___" . TotalSpaceGB \
| outputlookup windows_hostmon_fs_details
enableSched = 0

[WinApp_Lookup_Build_Hostmon_Machine - Migrate - Detail]
disabled = 0
search = | outputlookup windows_hostmon_machine_details \
| inputlookup append=true windows_hostmon_machine_details.csv \
| eval _key = OS . "___" . Domain . "___" . Architecture . "___" . Manufacturer \
| outputlookup windows_hostmon_machine_details
enableSched = 0

[WinApp_Lookup_Build_Hostmon_Process - Migrate - Detail]
disabled = 0
search = | outputlookup windows_hostmon_process_details \
| inputlookup append=true windows_hostmon_process_details.csv \
| eval _key = Name \
| outputlookup windows_hostmon_process_details
enableSched = 0

[WinApp_Lookup_Build_Hostmon_Services - Migrate - Detail]
disabled = 0
search = | outputlookup windows_hostmon_services_details \
| inputlookup append=true windows_hostmon_services_details.csv \
| eval _key = Name . "___" . StartMode . "___" . State \
| outputlookup windows_hostmon_services_details
enableSched = 0

[WinApp_Lookup_Build_Netmon - Migrate - Detail]
disabled = 0
search = | outputlookup windows_netmon_details \
| inputlookup append=true windows_netmon_details.csv \
| eval _key = Direction . "___" . Protocol . "___" . PacketType . "___" . RemoteHostName . "___" . RemotePort . "___" . LocalPort . "___" . ProcessName . "___" . UserName \
| outputlookup windows_netmon_details
enableSched = 0

[WinApp_Lookup_Build_Netmon - Migrate - Server]
disabled = 0
search = | outputlookup windows_netmon_system \
| inputlookup append=true windows_netmon_system.csv \
| eval _key = Host \
| outputlookup windows_netmon_system key_field=Host
enableSched = 0

[WinApp_Lookup_Build_Perfmon - Migrate - Detail]
disabled = 0
search = | outputlookup windows_perfmon_details \
| inputlookup append=true windows_perfmon_details.csv \
| eval _key = collection . "___" . object . "___" . counter . "___" . instance \
| outputlookup windows_perfmon_details
enableSched = 0

[WinApp_Lookup_Build_Perfmon - Migrate - Server]
disabled = 0
search = | outputlookup windows_perfmon_system \
| inputlookup append=true windows_perfmon_system.csv \
| eval _key = Host \
| outputlookup windows_perfmon_system key_field=Host
enableSched = 0

[WinApp_Lookup_Build_Printmon - Migrate]
disabled = 0
search = | outputlookup windows_printmon \
| inputlookup append=true windows_printmon.csv \
| eval _key = Host . "___" . printer . "___" . operation . "___" . user \
| outputlookup windows_printmon
enableSched = 0

#####################
## Endpoint Changes
#####################

###### Context Generators ######
[Change - Total Change Count By User By Change Type Per Day - Context Gen]
action.email.sendresults   = 0
cron_schedule              = 0 0 * * *
disabled                   = False
dispatch.earliest_time     = -31d@d
dispatch.latest_time       = -1d@d
enableSched                = 1
is_visible                 = false    
schedule_window            = 20
search                     = | `tstats` count from datamodel=Endpoint.Filesystem where Filesystem.tag="change" by _time,Filesystem.user span=24h | eval change_type="filesystem",user='Filesystem.user' | `tstats` append=T count from datamodel=Endpoint.Registry where Registry.tag="change" by _time,Registry.user span=24h | eval change_type=if(isnull(change_type),"registry",change_type),user=if(isnull(user),'Registry.user',user) | `tstats` append=T count from datamodel=Change.All_Changes by _time,All_Changes.change_type,All_Changes.user span=24h | eval change_type=if(isnull(change_type),'All_Changes.change_type',change_type),user=if(isnull(user),'All_Changes.user',user) | stats count as change_count by _time,change_type,user | `context_stats(change_count, change_type)` | eval min=0 | eval max=median*2 | xsupdateddcontext name=change_count_by_user_by_change_type_1d container=change_analysis class=change_type type=domain app="SA-EndpointProtection" scope=app terms=`xs_default_magnitude_concepts` | stats count


#####################
## Endpoint
#####################

###### Correlation Searches ######
[Endpoint - Anomalous New Processes - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Anomalous New Process
action.correlationsearch.related_searches = ["Endpoint - Local Processes Tracker - Lookup Gen"]
action.customsearchbuilder                = 0
action.customsearchbuilder.enabled        = 1
action.customsearchbuilder.routine        = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec           = {\
    "version":  "1.0",\
    "searches": [\
        {"inputlookup":  {"lookupName": "localprocesses_tracker", "timeField":  "firstTime"},\
         "earliest":     "-24h@h",\
         "latest":       "+0s",\
         "aggregates":   [{"function": "dc", "attribute": "dest", "alias": "dest_count"},\
                          {"function": "values", "attribute": "dest", "alias": "dest"}\
                         ],\
         "splitby":      [{"attribute": "process"}],\
         "resultFilter": {"field": "dest_count", "comparator": ">", "value": "9"}\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["process"]\
}
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = endpoint
action.notable.param.severity             = medium
action.notable.param.rule_title           = Anomalous New Process ($process$)
action.notable.param.rule_description     = An suspicious number of new processes were identified. $dest_count$ hosts were discovered with new instances of $process$ in the last 24 hours.
action.notable.param.nes_fields           = process
action.notable.param.drilldown_name       = View all instances of $process$
action.notable.param.drilldown_search     = | from datamodel:"Endpoint"."Processes" | search process_name="$process|s$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = process
action.risk.param._risk_object_type       = other
action.risk.param._risk_score             = 60
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = process
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 25 * * * *
description                               = Alerts when an anomalous number hosts are detected with a new process.
disabled                                  = True
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
## This remains implemented using the localprocesses_tracker which will maintain true firstTime for us
schedule_window                           = 5
search                                    = | from inputlookup:"localprocesses_tracker" | eval earliestQual=case(match("-24h@h", "^\d"), tostring("-24h@h"),  match("-24h@h", "^([@\+-]){1}"), relative_time(time(), "-24h@h"),  true(), time()) | eval latestQual=case(match("+0s", "^\d"), tostring("+0s"),  match("+0s", "^([@\+-]){1}"), relative_time(time(), "+0s"),  true(), time()) | where ('firstTime'>=earliestQual AND 'firstTime'<=latestQual) | fields - earliestQual, latestQual | stats dc(dest) as "dest_count",values(dest) as "dest" by "process" | where 'dest_count'>9

[Endpoint - Anomalous New Services - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Anomalous New Service
action.correlationsearch.related_searches = ["Endpoint - Services Tracker - Lookup Gen"]
action.customsearchbuilder                = 0
action.customsearchbuilder.enabled        = 1
action.customsearchbuilder.routine        = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec           = {\
    "version":  "1.0",\
    "searches": [\
        {"inputlookup":  {"lookupName": "services_tracker", "timeField":  "firstTime"},\
         "earliest":     "-24h@h",\
         "latest":       "+0s",\
         "aggregates":   [{"function": "dc", "attribute": "dest", "alias": "dest_count"},\
                          {"function": "values", "attribute": "dest", "alias": "dest"}\
                         ],\
         "splitby":      [{"attribute": "service"}],\
         "resultFilter": {"field": "dest_count", "comparator": ">", "value": "9"}\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["service"]\
}
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = endpoint
action.notable.param.severity             = medium
action.notable.param.rule_title           = Anomalous New Service ($service$)
action.notable.param.rule_description     = An suspicious number of new services were identified. $dest_count$ hosts were discovered with new instances of the $service$ service in the last 24 hours.
action.notable.param.nes_fields           = service
action.notable.param.drilldown_name       = View all instances of $service$
action.notable.param.drilldown_search     = | from datamodel:"Endpoint"."Services" | search service="$service$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = service
action.risk.param._risk_object_type       = other
action.risk.param._risk_score             = 60
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = service
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 25 * * * *
description                               = Alerts when an anomalous number hosts are detected with a new service.
disabled                                  = True
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
schedule_window                           = 5
## This remains implemented using the listeningports_tracker which will maintain true firstTime for us
search                                    = | from inputlookup:"services_tracker" | eval earliestQual=case(match("-24h@h", "^\d"), tostring("-24h@h"),  match("-24h@h", "^([@\+-]){1}"), relative_time(time(), "-24h@h"),  true(), time()) | eval latestQual=case(match("+0s", "^\d"), tostring("+0s"),  match("+0s", "^([@\+-]){1}"), relative_time(time(), "+0s"),  true(), time()) | where ('firstTime'>=earliestQual AND 'firstTime'<=latestQual) | fields - earliestQual, latestQual | stats dc(dest) as "dest_count",values(dest) as "dest" by "service" | where 'dest_count'>9

###### Lookup Generating Searches ######
[Endpoint - Listening Ports Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Endpoint",\
	    "object":        "Ports",\
        "earliest":      "-70m@m",\
        "latest":        "+0s",\
        "eventFilter":   "",\
		"aggregates":    [{"function": "min", "attribute": "_time", "alias": "firstTime"},\
	                      {"function": "max", "attribute": "_time", "alias": "lastTime"}\
	                     ],\
	    "splitby":       [\
	                      {"attribute": "Ports.dest", "alias": "dest"},\
	                      {"attribute": "Ports.transport", "alias": "transport"},\
	                      {"attribute": "Ports.dest_port", "alias": "dest_port"}\
	                     ],\
        "summariesonly": "1",\
        "outputlookup":  "listeningports_tracker",\
        "retention":     {\
            "earliestTime":  "-5y",\
            "timeField":     "lastTime",\
            "timeFormat":    "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 35 * * * *
description              = Maintains a list of all port and protocol combinations listening on each system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Endpoint"."Ports"  by "Ports.dest","Ports.transport","Ports.dest_port"  | rename "Ports.dest" as "dest","Ports.transport" as "transport","Ports.dest_port" as "dest_port" | inputlookup append=T "listeningports_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "dest","transport","dest_port" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "listeningports_tracker" | stats count

[Endpoint - Local Processes Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 40 * * * *
description              = Maintains a list of all processes on each system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` min(_time) as firstTime,max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest,Processes.process | `drop_dm_object_name("Processes")` | inputlookup append=T localprocesses_tracker | rex field=process "^\s*(?<process>[^\s]+)" | stats min(firstTime) as firstTime,max(lastTime) as lastTime by dest,process | outputlookup override_if_empty=false localprocesses_tracker | stats count

[Endpoint - Services Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 40 * * * *
description              = Maintains a list of all services (and the most recent startmode) for each system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` min(_time) as firstTime,max(_time) as lastTime,latest(Services.start_mode) as start_mode from datamodel=Endpoint.Services by Services.dest,Services.service | `drop_dm_object_name("Services")` | inputlookup append=T services_tracker | sort 0 - lastTime | stats min(firstTime) as firstTime,max(lastTime) as lastTime,first(start_mode) as start_mode by dest,service | outputlookup override_if_empty=false services_tracker | stats count


#####################
## Compute Inventory
#####################

###### Lookup Generating Searches ######
[Endpoint - System Version Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Compute_Inventory",\
	    "object":        "OS",\
        "earliest":      "-70m@m",\
        "latest":        "+0s",\
        "eventFilter":   "",\
		"aggregates":    [{"function": "max", "attribute": "_time", "alias": "_time"}],\
	    "splitby":       [\
	                      {"attribute": "All_Inventory.dest", "alias": "dest"},\
	                      {"attribute": "All_Inventory.OS.os", "alias": "os"}\
	                     ],\
        "summariesonly": "0",\
        "outputlookup":  "system_version_tracker",\
        "retention":     {\
            "earliestTime":  "-5y",\
            "timeField":     "_time",\
            "timeFormat":    "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 20 * * * *
description              = Maintains a list of the most recent operating system version for each system and the time we got this information
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=false allow_old_summaries=true max(_time) as "_time" from datamodel="Compute_Inventory"."All_Inventory" where   nodename="All_Inventory.OS"  by "All_Inventory.dest","All_Inventory.OS.os"  | rename "All_Inventory.dest" as "dest","All_Inventory.OS.os" as "os" | inputlookup append=T "system_version_tracker" | stats max(_time) as "_time" by "dest","os" | where strptime('_time', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "system_version_tracker" | stats count

[Endpoint - User Account Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 10 * * * *
description              = Maintains a list of all local user accounts on each system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | from datamodel:"Compute_Inventory"."User" | stats min(_time) as firstTime,max(_time) as lastTime,latest(interactive) as interactive by dest,user | inputlookup append=T useraccounts_tracker | eval _time=lastTime | stats min(firstTime) as firstTime,max(lastTime) as lastTime,latest(interactive) as interactive by dest,user | fields firstTime,lastTime,dest,user,interactive | outputlookup override_if_empty=false useraccounts_tracker | stats count


#####################
## Email
#####################

##### Context-updating searches #####
[Endpoint - Emails By Source - Context Gen]
action.email.sendresults = 0
cron_schedule            = 0 3 * * *
disabled                 = true
dispatch.earliest_time   = -25h@h
dispatch.latest_time     = -1h@h
enableSched              = 1
is_visible               = false
schedule_window          = 20
search                   = | tstats summariesonly=false allow_old_summaries=true sum(All_Email.recipient_count) as recipient_count from datamodel=Email.All_Email where NOT All_Email.src_category="email_servers" by "All_Email.src",_time span=1h | stats avg(recipient_count) as avg, count | eval min=0 | eval max=avg * 2 | xsUpdateDDContext app=SA-EndpointProtection name=recipients_by_src_1h container=email type=domain scope=app | stats count

[Endpoint - Emails By Destination Count - Context Gen]
action.email.sendresults = 0
cron_schedule            = 0 4 * * *
disabled                 = true
dispatch.earliest_time   = -25h@h
dispatch.latest_time     = -1h@h
enableSched              = 1
is_visible               = false
schedule_window          = 20
search                   = | tstats summariesonly=false allow_old_summaries=true dc(All_Email.dest) as dest_count from datamodel=Email.All_Email where NOT All_Email.src_category="email_servers" by "All_Email.src",_time span=1h | stats avg(dest_count) as avg, count | eval min=0 | eval max=avg * 2 | xsUpdateDDContext app=SA-EndpointProtection name=destinations_by_src_1h container=email type=domain scope=app | stats count


#####################
## Malware
#####################

##### Context-updating searches #####
[Endpoint - Malware Daily Count - Context Gen]
action.email.sendresults = 0
cron_schedule            = 0 3 * * *
dispatch.earliest_time   = -31d@d
dispatch.latest_time     = -1d@d
enableSched              = 1
is_visible               = false
schedule_window          = 20
search                   = | tstats `summariesonly` dc(Malware_Attacks.signature) as infection_count from datamodel=Malware.Malware_Attacks where earliest=-31d@d latest=-1d@d Malware_Attacks.action=allowed by Malware_Attacks.dest,_time span=1d | stats sum(infection_count) as total_infection_count by _time | stats count,median(total_infection_count) as median by _time | eval min=0 | eval max=median*2 | xsCreateDDContext name=count_1d container=malware type=domain terms="minimal,small,medium,large,extreme" scope=app app=SA-NetworkProtection | stats count

###### Correlation Searches ######
[Endpoint - Outbreak Observed - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Outbreak Detected
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Malware",\
         "object":        "Malware_Attacks",\
         "earliest":      "-1450m@m",\
         "latest":        "+0s",\
         "aggregates":    [{"function": "dc", "attribute": "Malware_Attacks.dest", "alias": "system_count"},\
                           {"function": "values", "attribute": "Malware_Attacks.tag", "alias": "tag"}\
                          ],\
         "splitby":       [{"attribute": "Malware_Attacks.signature", "alias": "signature"}],\
         "resultFilter":  {"field": "system_count", "comparator": ">", "value": "10"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["signature"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = high
action.notable.param.rule_title       = Outbreak Detected Of $signature$
action.notable.param.rule_description = A potential outbreak was noted. $system_count$ hosts have been detected as newly infected by $signature$ within the past 24 hours.
action.notable.param.nes_fields       = signature
action.notable.param.drilldown_name   = View events associated with potential outbreak of $signature$
action.notable.param.drilldown_search = | from datamodel:"Malware"."Malware_Attacks" | search signature="$signature$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = signature
action.risk.param._risk_object_type   = other
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = signature
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */15 * * * *
description                           = Alerts when a potential outbreak is observed based on newly infected systems all exhibiting the same infection
disabled                              = True
dispatch.earliest_time                = -1450m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
search                                = | tstats summariesonly=true allow_old_summaries=true dc(Malware_Attacks.dest) as "system_count",values(Malware_Attacks.tag) as "tag" from datamodel="Malware"."Malware_Attacks"   by "Malware_Attacks.signature"  | rename "Malware_Attacks.signature" as "signature" | where 'system_count'>10

[Endpoint - Recurring Malware Infection - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Host With A Recurring Malware Infection
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Malware",\
         "object":        "Malware_Attacks",\
         "earliest":      "-10090m@m",\
         "latest":        "+0s",\
         "aggregates":    [{"function": "dc", "attribute": "Malware_Attacks.date", "alias": "day_count"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "Malware_Attacks.dest", "alias": "dest"},\
                           {"attribute": "Malware_Attacks.signature", "alias": "signature"}\
                          ],\
         "resultFilter":  {"field": "day_count", "comparator": ">", "value": "3"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest","signature"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = high
action.notable.param.rule_title       = Host With A Recurring Malware Infection ($signature$ On $dest$)
action.notable.param.rule_description = The device $dest$ was detected with malware '$signature$' that has been detected as active for $day_count$ days in a row. AV has successfully removed the infection each time but the system is continually reinfected; this may indicate the presence of another form of malware is on the system that is prompting the download of '$signature$'.
action.notable.param.nes_fields       = dest,signature
action.notable.param.drilldown_name   = View related '$signature$' events for $dest$
action.notable.param.drilldown_search = | from datamodel:"Malware"."Malware_Attacks" | search dest="$dest$" signature="$signature$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest,signature
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 45 * * * *
description                           = Alerts when a host has an infection that has been re-infected remove multiple times over multiple days.
disabled                              = True
dispatch.earliest_time                = -10090m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
schedule_window                       = 5
search                                = | tstats summariesonly=true allow_old_summaries=true dc(Malware_Attacks.date) as "day_count",count from datamodel="Malware"."Malware_Attacks"   by "Malware_Attacks.dest","Malware_Attacks.signature" | rename "Malware_Attacks.dest" as "dest","Malware_Attacks.signature" as "signature" | where 'day_count'>3


###### Lookup Generating Searches ######

## Endpoint - Malware Tracker - Lookup Gen Breakdown
##   1 - get the most recent signature + dest pairings from datamodel=Malware
##   2 - field renaming
##   3 - input existing signature + det pairings
##   4 - consolidate event and tracker data
##   5 - write lookup
##   6 - purge results
[Endpoint - Malware Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Malware",\
	    "object":        "Malware_Attacks",\
        "earliest":      "-70m@m",\
        "latest":        "+0s",\
        "eventFilter":   "",\
		"aggregates":    [{"function": "min", "attribute": "_time", "alias": "firstTime"},\
	                      {"function": "max", "attribute": "_time", "alias": "lastTime"}\
	                     ],\
	    "splitby":       [\
	                      {"attribute": "Malware_Attacks.dest", "alias": "dest"},\
	                      {"attribute": "Malware_Attacks.signature", "alias": "signature"}\
	                     ],\
        "summariesonly": "1",\
        "outputlookup": "malware_tracker",\
        "retention":    {\
            "earliestTime":  "-5y",\
            "timeField":     "lastTime",\
            "timeFormat":    "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = 10 * * * *
description              = Maintains a list of all detections (regardless of status) for each system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Malware"."Malware_Attacks"  by "Malware_Attacks.dest","Malware_Attacks.signature"  | rename "Malware_Attacks.dest" as "dest","Malware_Attacks.signature" as "signature" | inputlookup append=T "malware_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "dest","signature" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "malware_tracker" | stats count

## Endpoint - Malware Operations Tracker - Lookup Gen Breakdown
##     1 - get the most recent malware operations data
##     2 - field renaming
##     3 - filter events that have a product or signature version
##     4 - create time_product_version==_time if product_version exists
##     5 - create time_signature_version==_time if signature_version exists
##     6 - consolidate events into _time,dest,dest_nt_domain,time_product_version,product_version,time_signature_version,signature_version,vendor_product
##    6a - this supports events the have either a product_version, a signature_version, or both
##     7 - perform a "| lookup" on the tracker to bring in "old" values for product_version and signature_version
##  8-11 - decide whether to keep old product and signature version values or new
##    8a - case1: if product_version_old isnull, take product_version
##    8b - case2: if product_version_old isnotnull (implied) and (product_version isnull OR product_version is older than product_version_old), keep product_version_old
##    8c - case3: if product_version_old isnotnull (implied) and (product_version isnotnull (implied) and product_version is newer than product_version_old (implied)) and product_version equal product_version_old, keep product_version_old
##    8d - case4: if product_version_old isnotnull (implied) and (product_version isnotnull (implied) and product_version is newer than product_version_old (implied)) and product_version not equal product_version_old (implied but specified anyway), take product_version
##  8-11 - repeat for time_product_version,signature_version, and time_signature_version respectively
##    12 - remove *_old fields
##    13 - inputlookup malware_operations_tracker data
##    14 - get latest _time,latest dest_nt_domain,latest vendor_product
##    15 - deduplicate based on dest
##    16 - write lookup
##    17 - purge results
[Endpoint - Malware Operations Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 15 0,4,8,12,16,20 * * *
dispatch.earliest_time   = -250m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 10
search                   = | from datamodel:"Malware"."Malware_Operations" | search (product_version=* OR signature_version=*) | eval time_product_version=if(isnotnull(product_version),_time,null()) | eval time_signature_version=if(isnotnull(signature_version),_time,null()) | stats latest(_time) as _time,latest(dest_nt_domain) as dest_nt_domain,latest(time_product_version) as time_product_version,latest(product_version) as product_version,latest(time_signature_version) as time_signature_version,latest(signature_version) as signature_version,latest(vendor_product) as vendor_product by dest | lookup malware_operations_tracker dest OUTPUT time_product_version as time_product_version_old,product_version as product_version_old,time_signature_version as time_signature_version_old,signature_version as signature_version_old | eval product_version=case(isnull(product_version_old),product_version,isnull(product_version) OR time_product_version<time_product_version_old,product_version_old,product_version==product_version_old,product_version_old,product_version!=product_version_old,product_version) | eval time_product_version=case(isnull(product_version_old),time_product_version,isnull(product_version) OR time_product_version<time_product_version_old,time_product_version_old,product_version==product_version_old,time_product_version_old,product_version!=product_version_old,time_product_version) | eval signature_version=case(isnull(signature_version_old),signature_version,isnull(signature_version) OR time_signature_version<time_signature_version_old,signature_version_old,signature_version==signature_version_old,signature_version_old,signature_version!=signature_version_old,signature_version) | eval time_signature_version=case(isnull(signature_version_old),time_signature_version,isnull(signature_version) OR time_signature_version<time_signature_version_old,time_signature_version_old,signature_version==signature_version_old,time_signature_version_old,signature_version!=signature_version_old,time_signature_version) | fields - *old | inputlookup append=T malware_operations_tracker | eventstats latest(_time) as _time by dest | eventstats latest(dest_nt_domain) as dest_nt_domain by dest | eventstats latest(vendor_product) as vendor_product by dest | dedup dest | outputlookup override_if_empty=false malware_operations_tracker | stats count

###### Summary Generating Searches ######
[Endpoint - Average Infection Length - Summary Gen]
action.email.sendresults   = 0
action.summary_index       = 1
action.summary_index._name = endpoint_summary
cron_schedule              = 50 * * * *
dispatch.earliest_time     = 0
dispatch.latest_time       = +0s
enableSched                = 1
is_visible                 = false
schedule_window            = 5
search                     = | from inputlookup:malware_tracker | eval dayDiff=(lastTime-firstTime)/86400 | stats avg(dayDiff) as avg_dayDiff by dest


#####################
## Performance
#####################

###### Correlation Searches ######

## Endpoint - Should Timesync Host Not Syncing - Rule Breakdown
## 1  - Get successful timesync data from Performance datamodel
## 2  - Drop All_Performance lineage from dest
## 3  - Get asset on dest
## 4  - Drop dest_ from the beginning of all fields
## 5  - Append entire asset list
## 6  - Filter on things that should timesync
## 7  - Consolidate entire asset list with data returned from Performance datamodel
## 8  - Filter on things without a lastTime
## 9  - addinfo
## 10 - Compute hourdiff
## 11 - Persist fields of interest
[Endpoint - Should Timesync Host Not Syncing - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Should Timesync Host Not Syncing
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = medium
action.notable.param.rule_title       = Should Timesync Host Not Syncing ($dest$)
action.notable.param.rule_description = The device $dest$ is expected to be synchronizing its clock and has not in the last $hourDiff$ hours.
action.notable.param.nes_fields       = dest
action.notable.param.drilldown_name   = View time-sync events for device $dest$
action.notable.param.drilldown_search = | from datamodel:"Performance"."Timesync" | search dest=$dest$
action.notable.param.default_status   =
action.notable.param.default_owner    =
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 30 8 * * *
description                           = Detects when hosts that are required to synchronize their clocks have failed to do so. Time synchronization is important because it ensures that the event logs are stamped with the proper time. Additionally, this is required by some regulatory compliance standards (such as PCI).
disabled                              = True
dispatch.earliest_time                = -1450m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
schedule_window                       = auto
search                                = | tstats `summariesonly` max(_time) as lastTime from datamodel=Performance.All_Performance where nodename=All_Performance.OS.Timesync All_Performance.OS.Timesync.action=success by All_Performance.dest | rename All_Performance.dest as dest | `get_asset(dest)` | rename dest_* as * | `assets` | search should_timesync=true | stats max(lastTime) as lastTime,first(should_timesync) as should_timesync,values(key) as dest by asset_id | where isnull(lastTime) | addinfo | eval hourDiff=floor((info_max_time-info_min_time)/3600) | fields dest,should_timesync,hourDiff


###############################
##  Primary Functions
###############################
[Endpoint - Multiple Primary Functions Detected - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Multiple Primary Functions Detected
action.correlationsearch.related_searches = [\
    "Endpoint - Local Processes Tracker - Lookup Gen",\
    "Endpoint - Services Tracker - Lookup Gen",\
    "Endpoint - Listening Ports Tracker - Lookup Gen"\
]
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = medium
action.notable.param.rule_title       = Multiple Primary Functions Detected
action.notable.param.rule_description = System $dest$ has multiple ($function_count$) primary functions ($function$) enabled
action.notable.param.nes_fields       = dest,signature
action.notable.param.drilldown_name   = View primary functions on $dest$
action.notable.param.drilldown_search = | `primary_functions_tracker`| search dest=$dest$ | table dest, dest_port, transport, function
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest 
alert.suppress.period                 = 86300s
alert.track                           = 0
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 25 * * * * 
description                           = Multiple Primary Functions Detected
disabled                              = True
dispatch.earliest_time                = 0
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
schedule_window                       = 5
search                                = | `primary_functions_tracker` | eval _time=lastTime | `hoursago(24)` | search is_primary=true | stats values(function) as function,dc(function) as function_count by dest | search function_count>1


#####################
## Processes
#####################
[Endpoint - Prohibited Process Detection - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Prohibited Process Detected
action.correlationsearch.related_searches = ["Endpoint - Local Processes Tracker - Lookup Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = endpoint
action.notable.param.severity             = medium
action.notable.param.rule_title           = Prohibited Process Detected ($process$)
action.notable.param.rule_description     = A prohibited process ($process$) was detected.
action.notable.param.nes_fields           = dest,app
action.notable.param.drilldown_name       = View instances of $process$
action.notable.param.drilldown_search     = | from datamodel:"Endpoint"."Processes" | search process=$process|s$
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = dest
action.risk.param._risk_object_type       = system
action.risk.param._risk_score             = 60
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = dest,process
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = */5 * * * *
description                               = Alerts when a service in the prohibited process list is detected.
disabled                                  = True
dispatch.earliest_time                    = rt-5m@m
dispatch.latest_time                      = rt+5m@m
dispatch.rt_backfill                      = 1
enableSched                               = 1
is_visible                                = false
search                                    = | from datamodel:"Endpoint"."Processes" | `get_interesting_processes` | search is_prohibited=true | `get_event_id` | fields + event_id,_raw,dest,process,note 

#####################
## Services
#####################
[Endpoint - Prohibited Service Detection - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Prohibited Service Detected
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = medium
action.notable.param.rule_title       = Prohibited Service Detected ($service$)
action.notable.param.rule_description = A prohibited service ($service$) was detected.
action.notable.param.nes_fields       = dest,app
action.notable.param.drilldown_name   = View instances of service $service$
action.notable.param.drilldown_search = | from datamodel:"Endpoint"."Services" | search service="$service$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest,service
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Alerts when a service in the prohibited service list is detected.
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = NOT sourcetype=stash `service` | `get_interesting_services` | search is_prohibited=true | `get_event_id` | fields + event_id,_raw,dest,service,note 


#####################
## Registry
#####################

## Endpoint - Registry Tracker - Lookup Gen Breakdown
## 1 - get registry events
## 2 - fill registry_value_name as empty (this is because it's used in splitby)
## 3 - stats
## 4 - input existing data
## 5 - stats
## 6 - filter any empty registry_value_name values
## 7 - write lookup
## 8 - purge results
[Endpoint - Registry Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 55 * * * *
disabled                 = True
description              = Maintains a list of registry paths, keys, and value information by system and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = sourcetype=WinRegistry | fillnull value="" registry_value_name | stats min(_time) as firstTime,max(_time) as lastTime,values(registry_value_data) as registry_value_data by registry_path,registry_key_name,registry_value_name,dest | inputlookup append=T registry_tracker | stats min(firstTime) as firstTime,max(lastTime) as lastTime,values(registry_value_data) as registry_value_data by registry_path,registry_key_name,registry_value_name,dest | eval registry_value_name=mvfilter(registry_value_name!="") | outputlookup override_if_empty=false registry_tracker | stats count


#####################
## Time
#####################

## Endpoint - Index Time Delta 2 - Summary Gen Breakdown
## 1  - Perform non-datamodel tstats w/ prestats
## 1a - Filter in all non-underscore indexes
## 1b - Filter out sourcetype=stash
## 1c - Use subsearch to generate index time constraints (-1d@d -> @d) 
## 2  - Compute timeDiff
## 3  - Remove preserved (sistats) fields
## 4  - Filter anything with less than 300s diff
## 5  - Perform consolidating stats
## 6  - Set _time to now()
[Endpoint - Index Time Delta 2 - Summary Gen]
action.email.sendresults   = 0
action.summary_index       = 1
action.summary_index._name = endpoint_summary
## Every Wednesday at Midnight
cron_schedule              = 0 0 * * 3
disabled                   = False
dispatch.earliest_time     = -72h@h
dispatch.latest_time       = +72h@h
enableSched                = 1
is_visible                 = false
schedule_window            = 20
search                     = | tstats prestats=true count where index=* NOT sourcetype=stash [| makeresults | `make_ts_value("-1d@d",start)` | `make_ts_value("+0s",end)` | eval search="(_indextime>=".start." AND _indextime<=".end.")"] by _time,_indextime,host,sourcetype span=1s | eval timeDiff=_time-_indextime | fields - psrsvd* | where timeDiff>300 | stats min(timeDiff) as min_timeDiff,max(timeDiff) as max_timeDiff,sum(timeDiff) as sum_timeDiff,count by host,sourcetype | eval _time=now()


#####################
## Updates
#####################

###### Lookup Generating Searches ######

## Endpoint - Update Signature Reference - Lookup Gen Breakdown
##  1 - Get update events
##  2 - field renaming
##  3 - zip signature and signature_id into a single MV field
##  4 - mvexpand events based on signature_zipo
##  5 - extract SV signature and signature_id fields
##  6 - stats
##  7 - input existing data
##  8 - consolidate event and tracker data
##  9 - write lookup
## 10 - purge results
[Endpoint - Update Signature Reference - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 0 * * * *
description              = Maintains a list of all updates by vendor and the first and last time they were seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
schedule_window          = 5
search                   = | from datamodel:"Updates"."Updates" | eval signature_zip=mvzip(signature,signature_id) | mvexpand signature_zip | rex field=signature_zip "(?<signature>.*)\,(?<signature_id>.*)" | stats min(_time) as firstTime,max(_time) as lastTime,latest(signature) as signature by signature_id,vendor_product | inputlookup append=T update_signature_reference_lookup | eval _time=lastTime | stats min(firstTime) as firstTime,max(lastTime) as lastTime,latest(signature) as signature by signature_id,vendor_product | outputlookup override_if_empty=false update_signature_reference_lookup | stats count
[Endpoint - Recurring Malware Infection - Rule]
disabled = 0

###### Correlation Searches ######
[Asset - Asset Ownership Unspecified - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Asset Ownership Unspecified
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":	 "Identity_Management",\
         "object":		 "All_Assets",\
         "earliest":     "0",\
         "latest":       "+0s",\
         "eventFilter":  "isnotnull('All_Assets.priority') AND len('All_Assets.priority')>0 AND isnotnull('All_Assets.category') AND len('All_Assets.category')>0 AND (isnull('All_Assets.owner') OR len('All_Assets.owner')==0) AND (isnull('All_Assets.ip') OR len('All_Assets.ip')==0 OR mvcount('All_Assets.ip')==1)",\
         "aggregates":   [{"function": "count"}],\
         "resultFilter": {"field": "count", "comparator": ">", "value": "0"}\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["const_dedup_id"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = identity
action.notable.param.severity         = low
action.notable.param.rule_title       = Identified $count$ Asset(s) without Ownership
action.notable.param.rule_description = $count$ asset(s) were identified as having a defined priority and category without an assigned owner. This may indicate a potential responsibility gap.
action.notable.param.drilldown_name   = View Affected Asset(s)
action.notable.param.drilldown_search = | from datamodel:"Identity_Management"."All_Assets" | where isnotnull('priority') AND len('priority')>0 AND isnotnull('category') AND len('category')>0 AND (isnull('owner') OR len('owner')==0) AND (isnull('ip') OR len('ip')==0 OR mvcount('ip')==1)
action.notable.param.default_status   = 
action.notable.param.default_owner    = 
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = const_dedup_id
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
description                           = Alerts when there are assets that define a specific priority and category but do not have an assigned owner. 
disabled                              = 1
dispatch.earliest_time                = 0
dispatch.latest_time                  = +0s
enableSched                           = 1
cron_schedule                         = 0 */12 * * *
is_visible                            = false
schedule_window                       = 20
search                                = | from datamodel:"Identity_Management"."All_Assets" | where isnotnull('priority') AND len('priority')>0 AND isnotnull('category') AND len('category')>0 AND (isnull('owner') OR len('owner')==0) AND (isnull('ip') OR len('ip')==0 OR mvcount('ip')==1) | stats count | where 'count'>0 | eval const_dedup_id="const_dedup_id"

[Identity - Activity from Expired User Identity - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Activity from Expired User Identity
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":	"Identity_Management",\
         "object":		"Expired_Identity_Activity",\
         "earliest":    "rt-5m@m",\
         "latest":      "rt+5m@m",\
         "aggregates":  [{"function": "max", "attribute": "_time", "alias": "lastTime"},\
                         {"function": "latest", "attribute": "_raw", "alias": "orig_raw"},\
                         {"function": "count"}\
                        ],\
         "splitby":     [{"attribute": "Expired_Identity_Activity.expired_user", "alias": "user"}]\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["user"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = identity
action.notable.param.severity         = high
action.notable.param.rule_title       = Activity from Expired User Identity ($user$)
action.notable.param.rule_description = Activity from an expired identity was observed. This is indicative of activity from a user whose access should have been disabled.
action.notable.param.nes_fields       = user
action.notable.param.drilldown_name   = View activity from $user$
action.notable.param.drilldown_search = | from datamodel:"Identity_Management"."Expired_Identity_Activity" | search (user="$user$" OR src_user="$user$")
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = user
action.risk.param._risk_object_type   = user
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = user
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Alerts when an event is discovered from a user associated with identity that is now expired (that is, the end date of the identity has been passed).
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
search                                = | from datamodel:"Identity_Management"."Expired_Identity_Activity" | stats max(_time) as "lastTime",latest(_raw) as "orig_raw",count by "expired_user" | rename "expired_user" as "user"

###### Report Searches ######
[Assets - Assets By Priority]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
search                                    = | pivot Identity_Management All_Assets count(All_Assets) AS "count" SPLITROW priority AS "priority" | sort - count

[Assets - Assets By Business Unit]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
search                                    = | pivot Identity_Management All_Assets count(All_Assets) AS "count" SPLITROW bunit AS "bunit" | sort - count

[Assets - Assets By Category]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
search                                    = | pivot Identity_Management All_Assets count(All_Assets) AS "count" SPLITROW category AS "category" | sort - count

[Assets - Asset Information]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | from datamodel:"Identity_Management"."All_Assets" | fields dns,nt_host,ip,mac,owner,priority,city,country,lat,long,bunit,category

[Identities - Identities By Priority]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
search                                    = | pivot Identity_Management All_Identities count(All_Identities) AS "count" SPLITROW priority AS "priority" | sort - count

[Identities - Identities By Business Unit]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
search                                    = | pivot Identity_Management All_Identities count(All_Identities) AS "count" SPLITROW bunit AS "bunit" | sort - count

[Identities - Identities By Category]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
search                                    = | pivot Identity_Management All_Identities count(All_Identities) AS "count" SPLITROW category AS "category" | sort - count

[Identities - Identity Information]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | from datamodel:"Identity_Management"."All_Identities" | `uitime(startDate)` | `uitime(endDate)` | fields identity,prefix,nick,first,last,suffix,email,phone,phone2,managedBy,priority,bunit,category,watchlist,startDate,endDate

[Sessions - Network Sessions Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = | tstats `summariesonly` count from datamodel=Network_Sessions.All_Sessions by _time,nodename span=10m | search nodename!=All_Sessions nodename!=All_Sessions.Session_* | rex field=nodename "All_Sessions.(?<session_type>.*)" | timechart minspan=10m sum(count) as count by session_type

[Sessions - Network Session Details]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | from datamodel:"Network_Sessions"."All_Sessions" | rename dest_ip as ip, dest_mac as mac, dest_nt_host as nt_host, dest_dns as dns | `mvappend_field(src,src_ip)` | `mvappend_field(src,src_mac)` | `mvappend_field(src,src_nt_host)` | `mvappend_field(src,src_dns)` | head 1000 | table _time,src,ip,mac,nt_host,dns,user


##### Context-generating searches #####

##### Email #####
[Identity - Email Activity to Non-corporate Domains by Users Per 1d - Context Gen]
action.email.sendresults   = 0
cron_schedule              = 0 0 * * *
disabled                   = true
dispatch.earliest_time     = -25h@h
dispatch.latest_time       = -1h@h
enableSched                = 1
is_visible                 = false    
schedule_window            = 20
search                     = | tstats `summariesonly` sum(All_Email.size) as bytes, values(All_Email.recipient) as recipient from datamodel=Email.All_Email  where NOT `cim_corporate_email_domain_search("All_Email.recipient")` by _time, All_Email.src_user, All_Email.src_user_bunit span=1h | `drop_dm_object_name("All_Email")` | stats avg(bytes) as avg, stdev(bytes) as stdev, count by src_user_bunit | eval min=0 | eval max=avg + 3*stdev | xsUpdateDDContext name="email_volume_1h_noncorp" class=src_user_bunit scope=app terms=`xs_default_magnitude_concepts` uom="email_volume_bytes" type=domain app=SA-IdentityManagement | stats count

##### Web #####
[Identity - Web Uploads to Non-corporate Domains by Users Per 1d - Context Gen]
action.email.sendresults   = 0
cron_schedule              = 0 1 * * *
disabled                   = true
dispatch.earliest_time     = -25h@h
dispatch.latest_time       = -1h@h
enableSched                = 1
is_visible                 = false
search                     = | tstats `summariesonly` sum(Web.bytes) as bytes from datamodel=Web.Web where NOT(`cim_corporate_web_domain_search("Web.url")`) (Web.http_method="POST" OR Web.http_method="PUT") by _time, Web.user, Web.user_bunit span=1h | `drop_dm_object_name("Web")`| stats avg(bytes) as avg, stdev(bytes) as stdev, count by user_bunit | eval min=0 | eval max=avg + 3*stdev |  xsUpdateDDContext name="web_volume_1h_noncorp" class=user_bunit scope=app terms=`xs_default_magnitude_concepts` uom="web_volume_bytes" type=domain app=SA-IdentityManagement | stats count


##### Lookup-generating searches #####
[Identity - Asset String Matches - Lookup Gen]
enableSched = 0
is_visible  = false
search      = | `asset_sources` | `make_assets_str` | outputlookup output_format=splunk_mv_csv asset_lookup_by_str | stats count

[Identity - Asset CIDR Matches - Lookup Gen]
enableSched = 0
is_visible  = false
search      = | `asset_sources` | `make_assets_cidr` | outputlookup output_format=splunk_mv_csv asset_lookup_by_cidr | stats count

[Identity - Identity Matches - Lookup Gen]
enableSched = 0
is_visible  = false
search      = | `identity_sources` | `make_identities` | eval `iden_mktime_meval(startDate)`,`iden_mktime_meval(endDate)`,identity=mvsort(identity) | sort 0 +identity | outputlookup output_format=splunk_mv_csv identity_lookup_expanded | stats count

[Identity - Make Categories - Lookup Gen]
enableSched = 0
is_visible  = false
search      = | from inputlookup:category_lookup | fillnull value="static" category_source | inputlookup append=t asset_lookup_by_str | inputlookup append=t asset_lookup_by_cidr | fillnull value="asset" category_source | inputlookup append=t identity_lookup_expanded | fillnull value="identity" category_source | stats count by category, category_source | sort category, category_source | fields category category_source | outputlookup category_lookup | stats count

[Identity - Make PCI Domains - Lookup Gen]
enableSched = 0
is_visible  = false
search      = | from inputlookup:pci_domains_lookup | fillnull value="static" pci_domain_source | inputlookup append=t asset_lookup_by_str | inputlookup append=t asset_lookup_by_cidr | fillnull value="asset" pci_domain_source | stats count by pci_domain, pci_domain_source | sort pci_domain, pci_domain_source | fields pci_domain pci_domain_source | outputlookup pci_domains_lookup | stats count
# General
[instrumentation.lastSent]
search = index=_telemetry source=telemetry sourcetype=splunk_telemetry_log status=success | fillnull value=anonymous visibility | eval anonymous_send_time = if(visibility LIKE "%anonymous%", _time, null) | eval license_send_time = if(visibility LIKE "%license%", _time, null) | eval support_send_time = if(visibility LIKE "%support%", _time, null) | stats latest(anonymous_send_time) as latest_anonymous_send_time latest(license_send_time) as latest_license_send_time latest(support_send_time) as latest_support_send_time

[instrumentation.reportingErrorCount]
search = index=_telemetry source=telemetry sourcetype=splunk_telemetry_log status=failed | fillnull value=anonymous visibility | stats count(eval(visibility LIKE "%anonymous%")) as anonymous_errors count(eval(visibility LIKE "%license%")) as license_errors count(eval(visibility LIKE "%support%")) as support_errors

# Anonymous
# For splunk core <= 7.0.x and splunk_instrumentation <= 3.0.x, anonymous usage data is indexed in _telemtry
# For later versions, data is indexed in _introspection
[instrumentation.anonymized.eventsByTime]
search = (index=_introspection OR index=_telemetry) sourcetype=splunk_telemetry source="http-stream" visibility=*anonymous* | append [| savedsearch instrumentation.licenseUsage]

# Support
# For splunk core <= 7.0.x and splunk_instrumentation <= 3.0.x, support usage data is indexed in _telemtry
# For later versions, data is indexed in _introspection
[instrumentation.support.eventsByTime]
search = (index=_introspection OR index=_telemetry) sourcetype=splunk_telemetry source="http-stream" visibility=*support* | append [| savedsearch instrumentation.licenseUsage]

# Deployment
[instrumentation.deployment.clustering.indexer]
search = | makeresults annotate=true | append [localop | rest /services/cluster/config] | sort -mode | head 1 | eval data=if(mode=="master","{\"host\":\""+splunk_server+"\",\"timezone\":\""+strftime(now(),"%z")+"\",\"multiSite\":"+multisite+",\"summaryReplication\":"+if(summary_replication=1,"true","false")+",\"enabled\":true,\"replicationFactor\":"+tostring(replication_factor)+",\"siteReplicationFactor\":"+coalesce(replace(replace(site_replication_factor, "origin", "\"origin\""), "total", "\"total\""), "null")+",\"siteSearchFactor\":"+coalesce(replace(replace(site_search_factor, "origin", "\"origin\""), "total", "\"total\""),"null")+",\"searchFactor\":"+tostring(search_factor)+"}","{\"host\":\""+splunk_server+"\",\"timezone\":\""+strftime(now(),"%z")+"\",\"enabled\":false}") | eval _time=now() | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.deployment.forwarders]
search = index=_internal source=*metrics.log* TERM(group=tcpin_connections) (TERM(connectionType=cooked) OR TERM(connectionType=cookedSSL)) fwdType=* guid=* | rename sourceIp as forwarderHost | eval connectionType=case(fwdType=="uf" or fwdType=="lwf" or fwdType=="full", fwdType, 1==1,"Splunk fwder") | eval version=if(isnull(version),"pre 4.2",version) | bin _time span=1d | stats sum(kb) as kb, latest(connectionType) as connectionType, latest(arch) as arch, latest(os) as os, latest(version) as version latest(forwarderHost) as forwarderHost by guid _time | stats estdc(forwarderHost) as numHosts estdc(guid) as numInstances `instrumentation_distribution_values(kb)` by connectionType arch os version _time | eval data="{\"hosts\":"+tostring(numHosts)+",\"instances\":"+tostring(numInstances)+",\"architecture\":\""+arch+"\",\"os\":\""+os+"\",\"splunkVersion\":\""+version+"\",\"type\":\""+connectionType+"\",\"bytes\":{" + `instrumentation_distribution_strings("kb",1024,0)` + "}}" | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.deployment.app]
search = | rest /services/apps/local | eval _time=now() | fields splunk_server title updated version disabled | eval data="{\"host\":\""+splunk_server+"\",\"name\":\""+title+"\",\"version\":\""+coalesce(version, "")+"\",\"enabled\":"+if(disabled=0, "true", "false")+"}" | eval date=strftime(_time, "%Y-%m-%d") | fields data _time date

[instrumentation.deployment.node]
search = index=_introspection sourcetype=splunk_disk_objects component::Partitions | bin _time span=1d | stats latest(data.free) as partitionFree, latest(data.capacity) as partitionCapacity by host data.fs_type data.mount_point _time | eval partitionUtilized=round(1-partitionFree/partitionCapacity,2) | eval partitions="{\"utilization\":"+`instrumentation_number_format(partitionUtilized,1,2)`+",\"capacity\":"+`instrumentation_number_format(partitionCapacity,1048576,0)`+",\"fileSystem\":\""+'data.fs_type' + "\"}" | stats delim="," values(partitions) as partitions by host _time | rename _time as date | mvcombine partitions | rename date as _time | join type=left host _time [search index=_introspection sourcetype=splunk_resource_usage component::Hostwide | eval cpuUsage = 'data.cpu_system_pct' + 'data.cpu_user_pct' | rename data.mem_used as memUsage | bin _time span=1d | stats latest(data.cpu_count) as coreCount, latest(data.virtual_cpu_count) as virtualCoreCount, latest(data.mem) as memAvailable, latest(data.splunk_version) as splunkVersion, latest(data.cpu_arch) as cpuArch, latest(data.os_name) as osName, latest(data.os_name_ext) as osNameExt, latest(data.os_version) as osVersion, `instrumentation_distribution_values(cpuUsage)`, `instrumentation_distribution_values(memUsage)`, latest(data.instance_guid) as guid by host _time] | fillnull value="null" coreCount virtualCoreCount memAvailable | eval splunkVersion=coalesce("\""+splunkVersion+"\"", "null"), cpuArch=coalesce("\""+cpuArch+"\"", "null"), osName=coalesce("\""+osName + "\"", "null"), osNameExt=coalesce("\""+osNameExt+"\"", "null"), osVersion=coalesce("\""+osVersion+"\"", "null"), guid=coalesce("\""+guid+"\"", "null") | eval data = "{\"guid\":"+guid+",\"host\":\""+replace(host,"\"", "\\\"")+"\",\"partitions\": " + coalesce("[" + partitions + "]", "null") + ",\"cpu\":{\"architecture\":"+cpuArch+",\"coreCount\":" + tostring(coreCount)+ ",\"virtualCoreCount\":"+tostring(virtualCoreCount)+",\"utilization\":{" + `instrumentation_distribution_strings("cpuUsage",.01,2)` + "}},\"memory\":"+"{\"capacity\":"+ `instrumentation_number_format(memAvailable,1048576,0)`+",\"utilization\":{" + `instrumentation_distribution_strings("memUsage",1/memAvailable,2)` + "}},\"os\":"+osName+",\"osExt\":"+osNameExt + ",\"osVersion\":"+osVersion+",\"splunkVersion\":"+splunkVersion+"}" | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.deployment.index]
search = | rest /services/data/indexes | join type=outer splunk_server title [| rest /services/data/indexes-extended] \
| append [| rest /services/data/indexes datatype=metric | join type=outer splunk_server title [| rest /services/data/indexes-extended datatype=metric]] \
| eval warm_bucket_size = if(isnotnull('bucket_dirs.home.warm_bucket_size'), 'bucket_dirs.home.warm_bucket_size', 'bucket_dirs.home.size') \
| eval cold_bucket_size_gb = tostring(round(coalesce('bucket_dirs.cold.bucket_size', 'bucket_dirs.cold.size', 0) / 1024, 2)) \
| eval warm_bucket_size_gb = tostring(round(coalesce(warm_bucket_size,0) / 1024, 2)) \
| eval hot_bucket_size = tostring(round(coalesce(total_size / 1024 - cold_bucket_size_gb - warm_bucket_size_gb, 0),2)) \
| eval hot_bucket_size_gb = tostring(round(coalesce(hot_bucket_size,0) / 1024, 2)) \
| eval thawed_bucket_size_gb = tostring(round(coalesce('bucket_dirs.thawed.bucket_size', 'bucket_dirs.thawed.size',0) / 1024, 2)) \
| eval warm_bucket_count = tostring(coalesce('bucket_dirs.home.warm_bucket_count', 0)) \
| eval hot_bucket_count = tostring(coalesce('bucket_dirs.home.hot_bucket_count',0)) \
| eval cold_bucket_count = tostring(coalesce('bucket_dirs.cold.bucket_count',0)) \
| eval thawed_bucket_count = tostring(coalesce('bucket_dirs.thawed.bucket_count',0)) \
| eval home_event_count = tostring(coalesce('bucket_dirs.home.event_count',0)) \
| eval cold_event_count = tostring(coalesce('bucket_dirs.cold.event_count',0)) \
| eval thawed_event_count = tostring(coalesce('bucket_dirs.thawed.event_count',0)) \
| eval home_bucket_capacity_gb = coalesce(if('homePath.maxDataSizeMB' == 0, "\"unlimited\"", round('homePath.maxDataSizeMB' / 1024, 2)), "\"unlimited\"") \
| eval cold_bucket_capacity_gb = coalesce(if('coldPath.maxDataSizeMB' == 0, "\"unlimited\"", round('coldPath.maxDataSizeMB' / 1024, 2)), "\"unlimited\"") \
| eval currentDBSizeGB = tostring(round(coalesce(currentDBSizeMB,0) / 1024, 2)) \
| eval maxTotalDataSizeGB = tostring(if(maxTotalDataSizeMB = 0, "unlimited", coalesce(round(maxTotalDataSizeMB / 1024, 2), "null"))) \
| eval minTime = tostring(coalesce(strptime(minTime,"%Y-%m-%dT%H:%M:%S%z"),"null")) \
| eval maxTime = tostring(coalesce(strptime(maxTime,"%Y-%m-%dT%H:%M:%S%z"),"null")) \
| eval total_bucket_count = tostring(if(isnotnull(total_bucket_count), total_bucket_count, 0)) \
| eval totalEventCount = tostring(coalesce(totalEventCount, 0)) \
| eval total_raw_size_gb = tostring(coalesce(round(total_raw_size / 1024, 2), "null")) \
| eval index_type = coalesce(datatype ,"event") \
| rename eai:acl.app as App \
| eval _time=now() \
| fields splunk_server, title,index_type, \
currentDBSizeGB, totalEventCount, total_bucket_count, \
total_raw_size_gb, minTime, maxTime, home_bucket_capacity_gb, cold_bucket_capacity_gb, \
hot_bucket_size_gb, warm_bucket_size_gb, cold_bucket_size_gb, thawed_bucket_size_gb, \
hot_bucket_count, warm_bucket_count, cold_bucket_count, thawed_bucket_count, \
home_event_count, cold_event_count, thawed_event_count, \
maxTotalDataSizeGB, maxHotBuckets, maxWarmDBCount App _time | eval data="{\"host\":\""+splunk_server+"\",\"name\":\""+title+"\",\"type\":\""+index_type+"\",\"app\":\""+App+"\",\"total\":{\"currentDBSizeGB\":"+currentDBSizeGB+",\"maxDataSizeGB\":"+maxTotalDataSizeGB+",\"events\":"+totalEventCount+",\"buckets\":"+total_bucket_count+",\"rawSizeGB\":"+total_raw_size_gb+",\"minTime\":"+minTime+",\"maxTime\":"+maxTime+"},\"buckets\":{\"homeCapacityGB\":"+home_bucket_capacity_gb+",\"homeEventCount\":"+home_event_count+",\"coldCapacityGB\":"+cold_bucket_capacity_gb+",\"hot\":{\"sizeGB\":"+hot_bucket_size_gb+",\"count\":"+hot_bucket_count+",\"max\":"+maxHotBuckets+"},\"warm\":{\"sizeGB\":"+warm_bucket_size_gb+",\"count\":"+warm_bucket_count+"},\"cold\":{\"sizeGB\":"+cold_bucket_size_gb+",\"count\":"+cold_bucket_count+",\"events\":"+cold_event_count+"},\"thawed\":{\"sizeGB\":"+thawed_bucket_size_gb+",\"count\":"+thawed_bucket_count+",\"events\":"+thawed_event_count+"}}}" \
| eval date=strftime(_time, "%Y-%m-%d") | fields data _time date

# Licensing
[instrumentation.licenseUsage]
# Why start with append? Otherwise, when running this saved search by itself, the results of the
# stats command are not reflected in the events. Instead, the events tab will only show the events
# as they existed in the pipeline before stats.
search = NOT() | append [search index=_telemetry type=RolloverSummary | eval date=strftime(_time-43200, "%Y-%m-%d") | eval licenseIDs=coalesce(replace(replace(replace(replace(licenseGuids,"\[","[\""),"\]","\"]"),",","\",\"")," ", ""),"null"), subgroup_id=coalesce(subgroupId, "Production"), group_id=coalesce("\""+licenseGroup+"\"", "null"), lmGuid=coalesce("\""+guid+"\"", "null"), productType=coalesce("\""+productType+"\"", "null"), type_id=if(substr(stack,1,16)="fixed-sourcetype", "fixed-sourcetype",stack) | stats max(_time) as lastTime latest(stacksz) as stack_quota, latest(poolsz) as pool_quota, sum(b) as consumption by pool stack host lmGuid licenseIDs type_id group_id subgroup_id productType date | rename stack as stack_id | eval pool="{\"quota\":" + pool_quota+",\"consumption\":"+consumption+"}" | stats delim="," values(pool) as pools, max(lastTime) as lastTime max(stack_quota) as stack_quota sum(consumption) as stack_consumption by stack_id group_id subgroup_id type_id lmGuid host licenseIDs productType date | mvcombine pools | eval _raw="{\"component\":\"licensing.stack\",\"data\":{\"host\":\""+host+"\",\"guid\":"+lmGuid+",\"name\":\""+replace(stack_id,"\"", "\\\"")+"\",\"type\":\"" + type_id + "\",\"subgroup\":\"" + subgroup_id + "\",\"product\":"+productType+",\"quota\":" + stack_quota+",\"consumption\":"+stack_consumption+",\"pools\":["+pools+"],\"licenseIDs\":"+licenseIDs+"}, \"date\":\""+date+"\",\"visibility\":\"anonymous,license\"}", _time=lastTime]

[instrumentation.licensing.stack]
search = index=_telemetry source=*license_usage_summary.log* sourcetype=splunkd TERM(type=RolloverSummary) | eval date=strftime(_time, "%m-%d-%Y"), licenseIDs=coalesce(replace(replace(replace(replace(licenseGuids,"\[","[\""),"\]","\"]"),",","\",\"")," ", ""),"null"), subgroup_id=coalesce(subgroupId, "Production"), group_id=coalesce("\""+licenseGroup+"\"", "null"), lmGuid=coalesce("\""+guid+"\"", "null"), productType=coalesce("\""+productType+"\"", "null"), type_id=if(substr(stack,1,16)="fixed-sourcetype", "fixed-sourcetype",stack) | stats latest(stacksz) as stack_quota, latest(poolsz) as pool_quota, sum(b) as consumption by pool stack host lmGuid licenseIDs type_id group_id subgroup_id productType date | rename stack as stack_id | eval pool="{\"quota\":" + pool_quota+",\"consumption\":"+consumption+"}" | stats delim="," values(pool) as pools, max(stack_quota) as stack_quota sum(consumption) as stack_consumption by stack_id group_id subgroup_id type_id lmGuid host licenseIDs productType date | mvcombine pools | eval data="{\"host\":\""+host+"\",\"guid\":"+lmGuid+",\"name\":\""+replace(stack_id,"\"", "\\\"")+"\",\"type\":\"" + type_id + "\",\"subgroup\":\"" + subgroup_id + "\",\"product\":"+productType+",\"quota\":" + stack_quota+",\"consumption\":"+stack_consumption+",\"pools\":["+pools+"],\"licenseIDs\":"+licenseIDs+"}" | eval _time=strptime(date, "%m-%d-%Y")-43200 | fields data _time



# Performance
[instrumentation.performance.indexing]
search = index=_internal TERM(group=thruput) TERM(name=index_thruput) source=*metrics.log* | bin _time span=30s | stats sum(kb) as kb sum(instantaneous_kbps) as instantaneous_kbps by host _time | bin _time span=1d | stats sum(kb) as totalKB `instrumentation_distribution_values(instantaneous_kbps)` by host _time | eval data="{\"host\":\""+host+"\",\"thruput\":{\"total\":" + tostring(round(totalKB*1024)) + "," + `instrumentation_distribution_strings("instantaneous_kbps",1024,0)`+"}}" | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.performance.search]
search = index=_audit sourcetype=audittrail TERM(action=search) TERM(info=completed) total_run_time=* | eval search_et=if(search_et="N/A", 0, search_et) | eval search_lt=if(search_lt="N/A", exec_time, min(exec_time,search_lt)) | eval timerange=search_lt-search_et | bin _time span=1d | stats latest(searched_buckets) as searched_buckets latest(total_slices) as total_slices latest(scan_count) as scan_count latest(timerange) as timerange latest(total_run_time) as runtime by search_id _time | stats `instrumentation_distribution_values(runtime)`, `instrumentation_distribution_values(searched_buckets)`, `instrumentation_distribution_values(total_slices)`, `instrumentation_distribution_values(scan_count)`, `instrumentation_distribution_values(timerange)` count as numSearches by _time | eval data="{\"searches\":"+tostring(numSearches)+",\"latency\":{"+`instrumentation_distribution_strings("runtime",1,2)`+"},\"buckets\":{"+`instrumentation_distribution_strings("searched_buckets",1,2)`+"},\"slices\":{"+`instrumentation_distribution_strings("total_slices",1,2)`+"},\"scanCount\":{"+`instrumentation_distribution_strings("scan_count",1,2)`+"},\"dayRange\":{"+`instrumentation_distribution_strings("timerange",1/86400,2)`+"}}" | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data



# Templates
[instrumentation.anonymous.firstEvent]
search = (index=_introspection OR index=_telemetry) sourcetype=splunk_telemetry source="http-stream" visibility=*anonymous* | append [savedsearch instrumentation.licenseUsage] | where date >= "$beginDate$" AND date <= "$endDate$" | head 1

[instrumentation.support.firstEvent]
search = (index=_introspection OR index=_telemetry) sourcetype=splunk_telemetry source="http-stream" visibility=*support* | append [savedsearch instrumentation.licenseUsage] | where date >= "$beginDate$" AND date <= "$endDate$" | head 1

[instrumentation.license.firstEvent]
search = | savedsearch instrumentation.licenseUsage | where date >= "$beginDate$" AND date <= "$endDate$" | head 1

[instrumentation.reporting]
search = index=_telemetry source=telemetry sourcetype=splunk_telemetry_log | fields _raw | spath | eval time_formatted = strftime(_time, "%Y-%m-%d %H:%M:%S") | search (status=success OR status=failed)

[instrumentation.reporting.errors]
search = index=_telemetry source=telemetry sourcetype=splunk_telemetry_log status=failed visibility=*$visibility$*



# Usage
[instrumentation.usage.app.page]
search = index=_internal sourcetype=splunk_web_access uri_path="/*/app/*/*" NOT uri_path="/*/static/*" | eval uri_parts=split(uri_path, "/"),locale=mvindex(uri_parts,1), app=mvindex(uri_parts,3), page=mvindex(uri_parts,4) | bin _time span=1d | eventstats estdc(user) as appUsers count as appOccurrences by app _time | bin _time span=1d | stats latest(locale) as locale count as occurrences estdc(user) as users by app page appUsers appOccurrences _time | sort app -occurrences | streamstats count as pageRank by app _time | where pageRank<=10 | eval data="{\"app\":\""+app+"\",\"page\":\""+page+"\",\"locale\":\""+locale+"\",\"occurrences\":" + tostring(occurrences) + ",\"users\":" + tostring(users) + "}" | eval data=if(pageRank==1,data+";{\"app\":\""+app+"\",\"locale\":\""+locale+"\",\"occurrences\":" + tostring(appOccurrences) + ",\"users\":" + tostring(appUsers) + "}", data) | stats values(data) as data by app appOccurrences appUsers _time | sort _time -appOccurrences | streamstats count as appRank by _time | where appRank<=25 | mvexpand data | makemv delim=";" data | mvexpand data | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.usage.indexing.sourcetype]
search = index=_internal source=*metrics.log* TERM(group=per_sourcetype_thruput) | bin _time span=1d | stats sum(ev) as events, sum(kb) as size, estdc(host) as hosts by series _time | eval data="{\"name\":\""+replace(series,"\"", "\\\"") + "\",\"events\":"+tostring(events)+",\"bytes\":"+tostring(round(size*1024))+",\"hosts\":"+tostring(hosts)+"}" | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.usage.search.concurrent]
search = index=_introspection sourcetype=splunk_resource_usage component::PerProcess data.search_props.sid::* | bin _time span=10s | stats estdc(data.search_props.sid) AS concurrent_searches by _time host | bin _time span=1d | stats `instrumentation_distribution_values(concurrent_searches)` by host _time | eval data="{\"host\":\""+host+"\",\"searches\":{" + `instrumentation_distribution_strings("concurrent_searches",1,0)` +"}}" | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.usage.search.type]
search = index=_introspection sourcetype=splunk_resource_usage component::PerProcess data.search_props.sid::* | rename data.search_props.type as searchType | bin _time span=1d | stats estdc(data.search_props.sid) AS search_count by searchType _time | eval data="\""+searchType+"\":"+tostring(search_count) | stats delim="," values(data) as data by _time | rename _time as date | mvcombine data | eval data="{"+data+"}" | rename date as _time | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.usage.users.active]
search = index=_audit sourcetype=audittrail TERM(action=search) user!="splunk-system-user" user!="n/a" | bin _time span=1d | stats estdc(user) as active by _time | eval data="{\"active\":"+tostring(active)+"}" | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data


#Topology
[instrumentation.topology.deployment.clustering.member]
search = | localop | rest /services/cluster/master/peers | eval data="{\"master\":\""+splunk_server+"\",\"member\":{\"host\":\""+label+"\",\"guid\":\""+title+"\",\"status\":\""+status+"\"},\"site\":\""+site+"\"}" | where isnotnull(data) | eval _time=now() | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.topology.deployment.clustering.searchhead]
search = | localop | rest /services/cluster/master/searchheads | where splunk_server!=label | eval data="{\"master\":\""+splunk_server+"\",\"searchhead\":{\"host\":\""+label+"\",\"guid\":\""+title+"\",\"status\":\""+status+"\"},\"site\":\""+site+"\"}" | where isnotnull(data) | eval _time=now() | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.topology.deployment.shclustering.member]
search = | localop | rest /services/shcluster/captain/members | eval data="{\"site\":\""+site+"\",\"captain\":\""+splunk_server+"\",\"member\":{\"host\":\""+label+"\",\"guid\":\""+title+"\",\"status\":\""+status+"\"}}" | where isnotnull(data) | eval _time=now() | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.topology.deployment.distsearch.peer]
search = | localop | rest /services/search/distributed/peers | eval data="{\"host\":\""+splunk_server+"\",\"peer\":{\"host\":\""+peerName+"\",\"guid\":\""+guid+"\",\"status\":\""+status+"\"}}" | where isnotnull(data) | eval _time=now() | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

[instrumentation.topology.deployment.licensing.slave]
search = | localop | rest /services/licenser/slaves | eval data="{\"master\":\""+splunk_server+"\",\"slave\":{\"host\":\""+label+"\",\"guid\":\""+title+"\",\"pool\":\""+active_pool_ids+"\"}}" | where isnotnull(data) | eval _time=now() | eval date=strftime(_time, "%Y-%m-%d") | fields _time date data

#Metrics
[instrumentation.usage.search.report_acceleration]
search = | localop | rest /servicesNS/-/-/admin/summarization | stats count as existing_report_accelerations, sum(summary.access_count) as access_count_of_existing_report_accelerations | makejson access_count_of_existing_report_accelerations(int) existing_report_accelerations(int) output="data" | eval _time=now(), date=strftime(_time, "%Y-%m-%d") | fields _time date data
[Brute Force Destination Server]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$, brute_type="Brute Force Destination Server", app=$result.app$, src=$result.src$, dest=$result.dest$, src_user=$result.src_user$, Source=$result.source$, Sourcetype=$result.sourcetype$, eventcount=$result.eventcount$, app_count=$result.app_count$
action.logevent.param.index = bruteforce
action.logevent.param.source = bruteforce_basic
action.logevent.param.sourcetype = bruteforce_basic
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCBruteForceDetectionBasic
request.ui_dispatch_view = search
search = index=* OR index=_audit tag=authentication  action=fail* earliest=-10m latest=now | transaction src dest maxpause=10m | eval app_count=mvcount(app) | where (eventcount>1 AND app_count>1)

[Brute Force Destination Service]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$, brute_type="Brute Force Destination Service", app=$result.app$, src=$result.src$, dest=$result.dest$, src_user=$result.src_user$, Source=$result.source$, Sourcetype=$result.sourcetype$, eventcount=$result.eventcount$, user_count=$result.user_count$
action.logevent.param.index = bruteforce
action.logevent.param.source = bruteforce_basic
action.logevent.param.sourcetype = bruteforce_basic
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCBruteForceDetectionBasic
request.ui_dispatch_view = search
search = index=* OR index=_audit tag=authentication  action=fail* | transaction src dest maxpause=10m | eval user_count=mvcount(src_user) | eval src_count=mvcount(src) | eval dest_count=mvcount(dest) | where (eventcount>1 AND user_count>4)

[Brute Force Destination User]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$, brute_type="Brute Force Destination User", app=$result.app$, src=$result.src$, dest=$result.dest$, src_user=$result.src_user$, Source=$result.source$, Sourcetype=$result.sourcetype$, eventcount=$result.eventcount$
action.logevent.param.index = bruteforce
action.logevent.param.source = bruteforce_basic
action.logevent.param.sourcetype = bruteforce_basic
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCBruteForceDetectionBasic
request.ui_dispatch_view = search
search = index=* OR index=_audit tag=authentication  action=fail* | transaction src dest maxpause=10m | where eventcount>5

[Brute Force Source Server]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$, brute_type="Brute Force Source Server", app=$result.app$, src=$result.src$, dest=$result.dest$, src_user=$result.src_user$, Source=$result.source$, Sourcetype=$result.sourcetype$, eventcount=$result.eventcount$, user_count=$result.user_count$
action.logevent.param.index = bruteforce
action.logevent.param.source = bruteforce_basic
action.logevent.param.sourcetype = bruteforce_basic
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCBruteForceDetectionBasic
request.ui_dispatch_view = search
search = index=* OR index=_audit tag=authentication  action=fail* | transaction src dest maxpause=10m | eval user_count=mvcount(src_user) | where user_count>4
#############
# Automatically generated by generator.py in splunk/security-content
# On Date: 2019-04-29T21:24:59 UTC
# Author: Splunk Security Research
# Contact: research@splunk.com
#############

### ESCU DETECTIONS ###


[ESCU - AWS Cloud Provisioning From Previously Unseen City - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen cities.  Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a `GeoIP` lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the `firstTime` and `lastTime` field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the `firstTime` and `lastTime` for each city. It returns only those events from cities that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
\
 This search will fire any time a new city is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your city, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen City - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Cloud Provisioning From Previously Unseen City
action.notable = 1
action.notable.param.nes_fields = src_ip, city
action.notable.param.rule_description = Your AWS infrastructure was provisioned from a city, $city$, which has never before been seen provisioning your infrastructure.
action.notable.param.rule_title = AWS Provision Activity From $city$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get All AWS Activity From City\nESCU - Get All AWS Activity From Country\nESCU - Get All AWS Activity From Region\nESCU - Get All AWS Activity From IP Address\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search City=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search City=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by City | eval newCity=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCity=1 | table City] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, City, eventName, errorCode

[ESCU - AWS Cloud Provisioning From Previously Unseen Country - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen countries. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a `GeoIP` lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the `firstTime` and `lastTime` field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the `firstTime` and `lastTime` for each country. It returns only those events from countries that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching over plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
\
 This search will fire any time a new country is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen Country - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Cloud Provisioning From Previously Unseen Country
action.notable = 1
action.notable.param.nes_fields = src_ip, country
action.notable.param.rule_description = Your AWS infrastructure was provisioned from a country, $country$,  which has never before been seen provisioning your infrastructure.
action.notable.param.rule_title = AWS Provision Activity From $country$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get All AWS Activity From City\nESCU - Get All AWS Activity From Country\nESCU - Get All AWS Activity From Region\nESCU - Get All AWS Activity From IP Address\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by Country | eval newCountry=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCountry=1 | table Country] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, Country, eventName, errorCode

[ESCU - AWS Cloud Provisioning From Previously Unseen IP Address - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen IP addresses. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a `GeoIP` lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the `firstTime` and `lastTime` field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the `firstTime` and `lastTime` for each city. It returns only those events from IP addresses that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
\
 This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen IP Address - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Cloud Provisioning From Previously Unseen IP Address
action.notable = 1
action.notable.param.nes_fields = src_ip
action.notable.param.rule_description = Your AWS infrastructure was provisioned from an IP, $src_ip$, which has never before been seen provisioning your infrastructure.
action.notable.param.rule_title = AWS Provision Activity From $src_ip$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get All AWS Activity From City\nESCU - Get All AWS Activity From Country\nESCU - Get All AWS Activity From Region\nESCU - Get All AWS Activity From IP Address\n"}
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress | eval newIP=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newIP=1 | table sourceIPAddress] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, eventName, errorCode

[ESCU - AWS Cloud Provisioning From Previously Unseen Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AWS provisioning activities from previously unseen regions. Region in this context is similar to a state in the United States. Provisioning activities are defined broadly as any event that begins with "Run" or "Create."
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a `GeoIP` lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the `firstTime` and `lastTime` field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the `firstTime` and `lastTime` for each city. It returns only those events from regions that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.\
\
 This search will fire any time a new region is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your region, there should be few false positives. If you are located in regions where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen Region - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Cloud Provisioning From Previously Unseen Region
action.notable = 1
action.notable.param.nes_fields = src_ip, Region
action.notable.param.rule_description = Your AWS infrastructure was provisioned from a region, $Region$, which has never before been seen provisioning your infrastructure.
action.notable.param.rule_title = AWS Provision Activity From $region$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get All AWS Activity From City\nESCU - Get All AWS Activity From Country\nESCU - Get All AWS Activity From Region\nESCU - Get All AWS Activity From IP Address\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Region=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Region=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by Region | eval newRegion=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newRegion=1 | table Region] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, Region, eventName, errorCode

[ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for AssumeRole events where an IAM role in a different account is requested for the first time.
action.escu.mappings = {"mitre_attack": ["Credential Access"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 16"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
action.escu.eli5 = This search\
\
1. Retrieves the **AssumeRole** event\
\
1. Verifies that the log entry contains a value for the account ID of the requesting account\
\
1. Ensures that the requesting account ID does not match the account ID of the requested account\
\
1. Pulls in the previously seen requesting and requested account IDs\
\
1. Splits up and executes multiple search paths at the same.\
\
1. The first path determines the **firstTime** and **lastTime** entries for the cache file\
\
1. Outputs the data to the cache file.\
\
1. Creates a conditional statement that is always false (both because we don't want these values to exit the search pipeline and because we think we're clever).The second pipeline adds the **firstTime** and **lastTime** entries to search results. Next, it filters out any account pairs that haven't been seen for the first time within the last hour. The `isnotnull(_time)` will remove the entries from the cache file.\
\
The search finishes by gathering the data that it will display to the user.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the `Previously Seen AWS Cross Account Activity` support search only once to create the baseline of previously seen cross account activity. Thanks to Pablo Vega at Recurly for suggesting improvements to the search.
action.escu.known_false_positives = Using multiple AWS accounts and roles is perfectly valid behavior. It's suspicious when an account requests privileges of an account it hasn't before. You should validate with the account owner that this is a legitimate request.
action.escu.creation_date = 2018-02-01
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Cross Account Activity From Previously Unseen Account - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cross Account Activity"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Cross Account Activity From Previously Unseen Account
action.notable = 1
action.notable.param.nes_fields = requestingAccountId, requestedAccountId, src_user, dest_user
action.notable.param.rule_description = Access to $dest_user$ was requested for the first time by $src_user$
action.notable.param.rule_title = AWS Account $dest_user$ access by $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - AWS Investigate User Activities By AccessKeyId\nESCU - AWS Investigate User Activities By Source User\n"}
action.risk = 1
action.risk.param._risk_object = dest_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = requestingAccountId, requestedAccountId
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=AssumeRole | spath output=requestingAccountId path=userIdentity.accountId | spath output=requestedAccountId path=resources{}.accountId | search requestingAccountId=* | where requestingAccountId != requestedAccountId | inputlookup append=t previously_seen_aws_cross_account_activity | multireport [| stats min(eval(coalesce(firstTime, strptime(_time,"%Y-%m-%d %H:%M:%S")))) as firstTime max(eval(coalesce(strptime(_time,"%Y-%m-%d %H:%M:%S"), lastTime))) as lastTime by requestingAccountId, requestedAccountId | outputlookup previously_seen_aws_cross_account_activity | where fact=fiction] [| eventstats min(eval(coalesce(firstTime, strptime(_time,"%Y-%m-%d %H:%M:%S")))) as firstTime, max(eval(coalesce(strptime(_time,"%Y-%m-%d %H:%M:%S"), lastTime))) as lastTime by requestingAccountId, requestedAccountId | where firstTime >= relative_time(now(), "-70m@m") AND isnotnull(_time) | spath output=accessKeyId path=responseElements.credentials.accessKeyId | spath output=requestingARN path=resources{}.ARN | stats values(awsRegion) as awsRegion values(firstTime) as firstTime values(lastTime) as lastTime values(sharedEventID) as sharedEventID, values(requestingARN) as src_user, values(responseElements.assumedRoleUser.arn) as dest_user by _time, requestingAccountId, requestedAccountId, accessKeyId] | table _time, firstTime, lastTime, src_user, requestingAccountId, dest_user, requestedAccountId, awsRegion, accessKeyId, sharedEventID

[ESCU - AWS Network Access Control List Created with All Open Ports - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for CloudTrail events to detect if any network ACLs were created with all the ports open to a specified CIDR.
action.escu.mappings = {"mitre_attack": ["Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 11"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = A network access control list (ACL) is a layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets. Network ACLs with all open ports have a larger attack surface. This search looks for events within your CloudTrail logs to check if there were any Network ACLs created with ports ranging from 1024 to 65525. This search will create a table comprised of AWS account id, src, user and all parameters of the request made by the user and the server response.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS, version 4.4.0 or later, and configure your CloudTrail inputs.
action.escu.known_false_positives = It's possible that an admin has created this ACL with all ports open for some legitimate purpose however, this should be scoped and not allowed in production environment.
action.escu.creation_date = 2017-01-08
action.escu.modification_date = 2017-01-10
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Network Access Control List Created with All Open Ports - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -1d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Network Access Control List Created with All Open Ports
action.notable = 1
action.notable.param.nes_fields = account_id, src, src_user
action.notable.param.rule_description = $src_user$ created a network access control list with all ports open.
action.notable.param.rule_title = Network ACL created with all ports open by $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - AWS Network ACL Details from ID\nESCU - AWS Network Interface details via resourceId\nESCU - AWS Investigate User Activities By ARN\n"}
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=CreateNetworkAclEntry | mvexpand requestParameters | mvexpand responseElements | search requestParameters.portRange.from=1024 requestParameters.portRange.to=65525 requestParameters.ruleAction=allow | rename userIdentity.arn as arn | rename requestParameters.networkAclId as networkAclId | table _time aws_account_id src userName arn networkAclId requestParameters.* responseElements.*

[ESCU - AWS Network Access Control List Deleted - Rule]
action.escu = 0
action.escu.enabled = 1
description = Enforcing network-access controls is one of the defensive mechanisms used by cloud administrators to restrict access to a cloud instance. After the attacker has gained control of the AWS console by compromising an admin account, they can delete a network ACL and gain access to the instance from anywhere. This search will query the CloudTrail logs to detect users deleting network ACLs.
action.escu.mappings = {"mitre_attack": ["Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 11"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = The search looks for CloudTrail events to detect whether any network ACLs have been deleted and gives you values of error messages and error codes (if any), user details, user source IP, the user who initiated this request, and the name of the event.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = It's possible that a user has legitimately deleted a network ACL.
action.escu.creation_date = 2017-01-08
action.escu.modification_date = 2017-01-10
action.escu.confidence = medium
action.escu.full_search_name = ESCU - AWS Network Access Control List Deleted - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -1d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = AWS Network Access Control List Deleted
action.notable = 1
action.notable.param.nes_fields = src, src_user, eventName
action.notable.param.rule_description = AWS network ACL has been deleted by $src_user.
action.notable.param.rule_title = AWS Network ACL deleted by $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - AWS Network ACL Details from ID\nESCU - AWS Network Interface details via resourceId\nESCU - AWS Investigate User Activities By ARN\n"}
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=DeleteNetworkAcl|rename userIdentity.arn as arn  | stats count min(_time) as firstTime max(_time) as lastTime values(errorMessage) values(errorCode) values(userAgent) values(userIdentity.*) by src userName arn eventName | `ctime(lastTime)` | `ctime(firstTime)`

[ESCU - Abnormally High AWS Instances Launched by User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 13"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events where an instance is successfully launched by a particular user. Since we want to detect a high number of instances launched within a short period, we create event buckets for 10-minute windows. We then calculate the total number of instances launched by a particular user, as well as the average and standard deviation values. Assign a `threshold_value` in the search. Start with 3 (but it will likely need to be tweaked for your environment). The `eval` function will set the outlier 1 if the number of instances is greater than the average number of instances terminated, added to the multiplied value of threshold and standard deviation. For your reference, we then keep only the outliers and calculate the number of standard deviations away the value is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. The threshold value should be tuned to your environment.
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
action.escu.creation_date = 2018-02-26
action.escu.modification_date = 2018-02-26
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Launched by User - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
cron_schedule = */10 * * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Abnormally High AWS Instances Launched by User
action.notable = 1
action.notable.param.nes_fields = userName
action.notable.param.rule_description = An abnormally high number of instances were launched by a user within in a 10-minute window
action.notable.param.rule_title = High Number of instances launched by $userName$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get EC2 Instance Details by instanceId\nESCU - Investigate AWS activities via region name\nESCU - AWS Investigate User Activities By ARN\n"}
action.risk = 1
action.risk.param._risk_object = userName
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = userName
alert.suppress.period = 3600s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | bucket span=10m _time | stats count AS instances_launched by _time userName | eventstats avg(instances_launched) as total_launched_avg, stdev(instances_launched) as total_launched_stdev | eval threshold_value = 4 | eval isOutlier=if(instances_launched > total_launched_avg+(total_launched_stdev * threshold_value), 1, 0) | search isOutlier=1 AND _time >= relative_time(now(), "-10m@m") | eval num_standard_deviations_away = round(abs(instances_launched - total_launched_avg) / total_launched_stdev, 2) | table _time, userName, instances_launched, num_standard_deviations_away, total_launched_avg, total_launched_stdev

[ESCU - Abnormally High AWS Instances Terminated by User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where an abnormally high number of instances were successfully terminated by a user in a 10-minute window
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 13"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events where an instance is successfully terminated by a particular user. Since we want to detect a high number of instances terminated within a short period, we create event buckets for 10-minute windows. We then calculate the total number of instances terminated by a particular user, as well as the average- and standard-deviation values. Assign a `threshold_value` in the search. Try starting with 3 (but it will likely need to be tweaked for your environment). The `eval` function will set the outlier to 1 if the number of instances is greater than the average number of instances terminated, added to the multiplied value of threshold and standard deviation. We then filter out outliers with a value of 1 and show only those instance-termination events that happened within the previous 10 minutes.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = Many service accounts configured with your AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify whether this search alerted on a human user.
action.escu.creation_date = 2018-02-26
action.escu.modification_date = 2018-02-26
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Terminated by User - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS EC2 Activities"]
cron_schedule = */10 * * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Abnormally High AWS Instances Terminated by User
action.notable = 1
action.notable.param.nes_fields = userName
action.notable.param.rule_description = An abnormally high number of instances were terminated by a user in a 10-minute window
action.notable.param.rule_title = High number of instances terminated by $userName$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get EC2 Instance Details by instanceId\nESCU - Investigate AWS activities via region name\nESCU - AWS Investigate User Activities By ARN\n"}
action.risk = 1
action.risk.param._risk_object = userName
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = userName
alert.suppress.period = 3600s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=TerminateInstances errorCode=success | bucket span=10m _time | stats count AS instances_terminated by _time userName | eventstats avg(instances_terminated) as total_terminations_avg, stdev(instances_terminated) as total_terminations_stdev | eval threshold_value = 4 | eval isOutlier=if(instances_terminated > total_terminations_avg+(total_terminations_stdev * threshold_value), 1, 0) | search isOutlier=1 AND _time >= relative_time(now(), "-10m@m")| eval num_standard_deviations_away = round(abs(instances_terminated - total_terminations_avg) / total_terminations_stdev, 2) |table _time, userName, instances_terminated, num_standard_deviations_away, total_terminations_avg, total_terminations_stdev

[ESCU - Attempt To Add Certificate To Untrusted Store - Rule]
action.escu = 0
action.escu.enabled = 1
description = Attempt to add a certificate to the untrusted certificate store
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Disabling Security Tools"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers will often attempt to disable security tools in order to evade detection. It is also possible for end users to attempt to disable anti-virus or other security tools to circumvent restrictions they encounter while trying to execute other programs. One way malware may accomplish this is by adding the legitimate certificate used to sign the security software to the untrusted certificate store. This will cause the system to no longer trust the software signed with this certificate and disallow it from executing. This search simply looks for the execution of **certutil.exe** with the parameters `-addcert` and `disallowed`, which add a certification to the "untrusted" certificate store.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = There may be legitimate reasons for administrators to add a certificate to the untrusted certificate store. In such cases, this will typically be done on a large number of systems.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-11-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Attempt To Add Certificate To Untrusted Store - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Disabling Security Tools"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Attempt To Add Certificate To Untrusted Store
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = Attempt to add a certificate to the untrusted certificate store
action.notable.param.rule_title = Attempt To Add Certificate to Untrusted Store
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = process, dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=certutil.exe (Processes.process=*-addstore* AND Processes.process=*disallowed* ) by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name("Processes")` | `ctime(firstTime)`|`ctime(lastTime)`

[ESCU - Attempt To Set Default PowerShell Execution Policy To Unrestricted - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the execution of reg.exe with parameters that indicate an attempt to set the default PowerShell execution policy on the system to "Unrestricted"
action.escu.mappings = {"mitre_attack": ["Execution", "PowerShell", "Scripting"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the process reg.exe with the "add" parameter, which indicates the creation of a new value or modification of an existing value in the registry. In addition, it looks for parameters that specify the registry key to be added or modified, as well as the value of "Unrestricted". The appearance of "ExecutionPolicy" at the beginning of the search is there to optimize the search performance by first looking for that keyword, and then further searching through the matching events for further details.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators may attempt to change the default execution policy on a system for a variety of reasons. However, setting the policy to "Unrestricted" as this search is designed to identify would be unusual. Hits should be reviewed and investigated as appropriate.
action.escu.creation_date = 2018-08-28
action.escu.modification_date = 2018-12-03
action.escu.confidence = High
action.escu.full_search_name = ESCU - Attempt To Set Default PowerShell Execution Policy To Unrestricted - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Credential Dumping", "Malicious PowerShell"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Attempt To Set Default PowerShell Execution Policy To Unrestricted
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = An attempt to modify the default PowerShell execution policy in the registry to "Unrestricted" was detected on $dest$.
action.notable.param.rule_title = Attempt To Set PowerShell Execution Policy To "Unrestricted" On $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = High
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = process_name, dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=reg.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)`| search (process=*add*  process=*Software\\Microsoft\\Powershell\\1\\ShellIds\\Microsoft.PowerShell* process=*ExecutionPolicy* process=*Unrestricted*)

[ESCU - Attempt To Stop Security Service - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for attempts to stop security-related services on the endpoint.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Disabling Security Tools"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the processes **net.exe** and **sc.exe** with a parameter of `"stop"`. It then searches a list of security-related services included in a lookup file for matches on the command line. Results are subsequently returned in table format. The included lookup file can be modified to update the services to monitor.
action.escu.how_to_implement = You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data. The search is shipped with a lookup file, `security_services.csv`, that can be edited to update the list of services to monitor. This lookup file can be edited directly where it lives in `$SPLUNK_HOME/etc/apps/DA-ESS-ContentUpdate/lookups`, or via the Splunk console. You should add the names of services an attacker might use on the command line and surround with asterisks (*****), so that they work properly when searching the command line. The file should be updated with the names of any services you would like to monitor for attempts to stop the service.,
action.escu.known_false_positives = None identified. Attempts to disable security-related services should be identified and understood.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2017-09-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Attempt To Stop Security Service - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Disabling Security Tools"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Attempt To Stop Security Service
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = Attempt to stop a security-related service on $dest$
action.notable.param.rule_title = Attempt to Stop Security Service On $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name = net.exe OR  Processes.process_name = sc.exe) Processes.process="* stop *" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `ctime(firstTime)` | `ctime(lastTime)` |lookup security_services_lookup service as process OUTPUTNEW category, description | search category=security

[ESCU - Attempted Credential Dump From Registry Via Reg.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for execution of reg.exe with parameters specifying an export of keys that contain hashed credentials that attackers may try to crack offline,
action.escu.mappings = {"mitre_attack": ["Credential Access", "Credential Dumping"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 16"], "nist": ["PR.IP", "PR.AC", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the process reg.exe with the "save" parameter, which specifies a binary export from the registry. In addition, it looks for the keys that contain the hashed credentials, which attackers may retrieve and use for brute-force attacks in order to harvest legitimate credentials.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None identified.
action.escu.creation_date = 2018-08-28
action.escu.modification_date = 2018-12-02
action.escu.confidence = High
action.escu.full_search_name = ESCU - Attempted Credential Dump From Registry Via Reg.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Attempted Credential Dump From Registry Via Reg.exe
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = An attempt to save registry keys holding credentials was identified on $dest$.
action.notable.param.rule_title = Attempted Credential Dump From Registry on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = High
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = process_name, dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=reg.exe  by Processes.user Processes.process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)` | search process=*save* (process=*HKLM\\sam* OR process=*HKLM\\system*)

[ESCU - Batch File Write to System32 - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for a batch file (.bat) written to the Windows system directory tree.
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at file modifications across your hosts, as well as for evidence of batch files being written to paths that include "system32." This activity is consistent with some SamSam attacks and is, in general, suspicious.
action.escu.how_to_implement = You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = It is possible for this search to generate a notable event for a batch file write to a path that includes the string "system32", but is not the actual Windows system directory. As such, you should confirm the path of the batch file identified by the search. In addition, a false positive may be generated by an administrator copying a legitimate batch file in this directory tree. You should confirm that the activity is legitimate and modify the search to add exclusions, as necessary.
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.confidence = high
action.escu.full_search_name = ESCU - Batch File Write to System32 - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Batch File Write to System32
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A batch file was written to the system directory on $dest$.
action.notable.param.rule_title = Batch file write to system32 detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.dest) as dest values(Filesystem.file_name) as file_name values(Filesystem.user) as user from datamodel=Endpoint.Filesystem by Filesystem.file_path | `drop_dm_object_name(Filesystem)` | `ctime(lastTime)` | `ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | search file_path=*system32* AND file_extension=.bat

[ESCU - Child Processes of Spoolsv.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for child processes of spoolsv.exe. This activity is associated with a POC privilege-escalation exploit associated with CVE-2018-8440. Spoolsv.exe is the process associated with the Print Spooler service in Windows and typically runs as SYSTEM.
action.escu.mappings = {"mitre_attack": ["Privilege Escalation", "Exploitation for Privilege Escalation"], "kill_chain_phases": ["Exploitation"], "cis20": ["CIS 5", "CIS 8"], "nist": ["PR.AC", "PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for child processes of spoolsv.exe, which is associated with the Print Spooler service on Windows. Children of this process typically run under the SYSTEM context. This search should address the POC developed for the Windows local-privilege-escalation exploit announced in September of 2018. The associated vulnerability was assigned CVE-2018-8440. More information is available at https://doublepulsar.com/task-scheduler-alpc-exploit-high-level-analysis-ff08cda6ad4f.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Some legitimate printer-related processes may show up as children of spoolsv.exe. You should confirm that any activity as legitimate and may be added as exclusions in the search.
action.escu.creation_date = 2018-11-26
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Child Processes of Spoolsv.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Privilege Escalation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Child Processes of Spoolsv.exe
action.notable = 1
action.notable.param.nes_fields = dest, process_name, parent_process_name
action.notable.param.rule_description = A child process of spoolsv.exe was detected on $dest$.
action.notable.param.rule_title = Spoolsv.exe spawned a child process on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, parent_process_name
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process_name) as process_name values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process_name=spoolsv.exe AND Processes.process_name!=regsvr32.exe by Processes.dest Processes.parent_process Processes.user | `drop_dm_object_name(Processes)` | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Clients Connecting to Multiple DNS Servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to identify the endpoints that have connected to more than five DNS servers and made DNS Queries over the time frame of the search.
action.escu.mappings = {"mitre_attack": ["Command and Control", "Exfiltration", "Exfiltration Over Alternative Protocol", "Commonly Used Port", "Standard Application Layer Protocol"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 9", "CIS 12", "CIS 13"], "nist": ["PR.PT", "DE.AE", "PR.DS"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = DNS Queries with multiple DNS servers from a single client is unusual and may be indicative of malicious activity. This search works by performing a count by the source of the distinct destinations for the DNS traffic. The search uses the `Network_Resolution` data model.
action.escu.how_to_implement = This search requires that DNS data is being ingested and populating the `Network_Resolution` data model. This data can come from DNS logs or from solutions that parse network traffic for this data, such as Splunk Stream or Bro.
action.escu.known_false_positives = It's possible that an enterprise has more than five DNS servers that are configured in a round-robin rotation. Please customize the search, as appropriate.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Clients Connecting to Multiple DNS Servers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "DNS Hijacking", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Clients Connecting to Multiple DNS Servers
action.notable = 1
action.notable.param.nes_fields = src, dest
action.notable.param.rule_description = This search allows you to identify the endpoints that have connected to more than five DNS servers over the time frame specified in the search.
action.notable.param.rule_title = Client $src$ Connecting to Multiple DNS Servers
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get DNS Server History for a host\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count, values(DNS.dest) AS dest dc(DNS.dest) as dest_count from datamodel=Network_Resolution where DNS.message_type=QUERY by DNS.src | `drop_dm_object_name("Network_Resolution")` |where dest_count > 5

[ESCU - Common Ransomware Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for file modifications with extensions commonly used by Ransomware
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at file modifications across your hosts and identifies files with extensions that are commonly associated with the encrypted files generated by ransomware.
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = It is possible for a legitimate file with these extensions to be created. If this is a true ransomware attack, there will be a large number of files created with these extensions.
action.escu.creation_date = 2017-08-21
action.escu.modification_date = 2018-11-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Common Ransomware Extensions - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Ransomware", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Common Ransomware Extensions
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file modification was detected on $dest$ with an extension commonly used by ransomware.
action.notable.param.rule_title = Ransomware Extension detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `ctime(lastTime)` | `ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | `ransomware_extensions`

[ESCU - Common Ransomware Notes - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for files created with names matching those typically used in ransomware notes that tell the victim how to get their data back.
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at file modifications in the Change Analysis data model. It checks modified file names against an included lookup file, which contains the names of note files left behind by ransomware (to inform the victim how they can pay the ransom and retrieve their files). The search returns a list of files with matching names.
action.escu.how_to_implement = You must be ingesting data that records file-system activity from your hosts to populate the Endpoint Filesystem data-model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.
action.escu.known_false_positives = It's possible that a legitimate file could be created with the same name used by ransomware note files.
action.escu.creation_date = 2017-08-21
action.escu.modification_date = 2018-11-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Common Ransomware Notes - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Ransomware", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Common Ransomware Notes
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file modification associated with a ransomware victim notification file detected on $dest$
action.notable.param.rule_title = Ransomware Note File detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `ctime(lastTime)` | `ctime(firstTime)`|`ransomware_notes`

[ESCU - Create local admin accounts using net.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of local administrator accounts using net.exe.
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface", "Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Net.exe is a built-in Windows command-line tool that can be used to add, display, or modify user accounts. While Microsoft administrators use this tool to manage user groups, threat actors often leverage it to create local admin accounts to maintain persistence. In this search, we are looking for the execution of process net.exe with command-line parameters such as `localgroup`, `add`, or `user` that may correspond to the creation of local admin accounts or setting user/group properties.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators often leverage net.exe to create admin accounts.
action.escu.creation_date = 2018-03-28
action.escu.modification_date = 2018-11-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Create local admin accounts using net.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 8 * * *
dispatch.earliest_time = -1440m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Create local admin accounts using net.exe
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = Net.exe was used to create local administrator accounts on $dest$.
action.notable.param.rule_title = Local administrator account created on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.user) as user values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processs.process_name=net.exe OR Processes.process_name=net1.exe) by Processes.process Processes.process_name Processes.dest | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)`  | search (process=*localgroup* OR process=*/add* OR process=*user*)

[ESCU - Create or delete hidden shares using net.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation or deletion of hidden shares using net.exe.
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface", "Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Net.exe is a built-in command-line tool on Windows that can be used to create, delete, and manage shared resources on the computer, both locally and remotely. Though this tool is used by Microsoft administrators to manage the network shares, attackers also leverage it to create and delete hidden file shares by appending "$" after the name of the share. To look for hidden shares, use a regular expression to look for a `(name_file_share)$`. In this search, we are looking for the command-line execution of net.exe with command-line parameters such as `net`, `share`, or `delete` that may correspond to the creation of hidden shares
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators often leverage net.exe to create or delete network shares. You should verify that the activity was intentional and is legitimate.
action.escu.creation_date = 2018-06-14
action.escu.modification_date = 2018-11-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Create or delete hidden shares using net.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Hidden Cobra Malware"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Create or delete hidden shares using net.exe
action.notable = 1
action.notable.param.nes_fields = dest,process_name
action.notable.param.rule_description = Net.exe was used to create or delete hidden network shares by $user$ on $dest$
action.notable.param.rule_title = Hidden File shares created/deleted on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\nESCU - Get Outbound Emails to Hidden Cobra Threat Actors\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process_name
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.user) as user values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processs.process_name=net.exe OR Processes.process_name=net1.exe) by Processes.process Processes.process_name Processes.dest | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)` | search (process=*share* OR process=*delete*)| regex process="\S+[$]"

[ESCU - DNS Query Length With High Standard Deviation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to identify DNS requests and compute the standard deviation on the length of the names being resolved, then filter on two times the standard deviation to show you those queries that are unusually large for your environment.
action.escu.mappings = {"mitre_attack": ["Command and Control", "Exfiltration", "Commonly Used Port"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 8", "CIS 12"], "nist": ["PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = Attackers often use random, long domain names for their attack infrastructure. This search looks at all the queries observed over the search time frame, and identifies any domains being resolved with names that are greater that 2 times the standard deviation.
action.escu.how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model.
action.escu.known_false_positives = It's possible there can be long domain names that are legitimate.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - DNS Query Length With High Standard Deviation - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "Hidden Cobra Malware", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = DNS Query Length With High Standard Deviation
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = Filter DNS requests and compute the standard deviation then filter on 2 times the standard deviation
action.notable.param.rule_title = DNS query length with high standard deviation
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get DNS Server History for a host\nESCU - Get DNS traffic ratio\nESCU - Get Process responsible for the DNS traffic\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = query
alert.suppress.period = 43200s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count from datamodel=Network_Resolution by DNS.query DNS.record_type |  `drop_dm_object_name("DNS")` | eval query_length = len(query) | table query query_length record_type count stdev | eventstats stdev(query_length) AS stdev avg(query_length) AS avg p50(query_length) AS p50| where query_length>(stdev*2)

[ESCU - DNS Query Requests Resolved by Unauthorized DNS Servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect DNS requests resolved by unauthorized DNS servers. Legitimate DNS servers should be identified in the Enterprise Security Assets and Identity Framework.
action.escu.mappings = {"mitre_attack": ["Exfiltration", "Command and Control", "Defense Evasion", "Commonly Used Port"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 1", "CIS 3", "CIS 8", "CIS 12"], "nist": ["ID.AM", "PR.DS", "PR.IP", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = Clients should be resolving their DNS requests via a trusted DNS server. This search will identify DNS queries being sent to unauthorized DNS servers by comparing the destination and source of the traffic with assets marked as DNS servers.
action.escu.how_to_implement = To successfully implement this search you will need to ensure that DNS data is populating the Network_Resolution data model. It also requires that your DNS servers are identified correctly in the Assets and Identity table of Enterprise Security.
action.escu.known_false_positives = Legitimate DNS activity can be detected in this search. Investigate, verify and update the list of authorized DNS servers as appropriate.
action.escu.creation_date = 2017-07-08
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - DNS Query Requests Resolved by Unauthorized DNS Servers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "DNS Hijacking", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = DNS Query Requests Resolved by Unauthorized DNS Servers
action.notable = 1
action.notable.param.nes_fields = dest, src
action.notable.param.rule_description = The table represents a list of unauthorized DNS servers interacting with hosts in your network
action.notable.param.rule_title = DNS requests resolved by unauthorized DNS servers
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get DNS Server History for a host\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,src
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count from datamodel=Network_Resolution where DNS.dest_category != dns_server AND DNS.src_category != dns_server by DNS.src DNS.dest | `drop_dm_object_name("DNS")`

[ESCU - DNS record changed - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search takes the DNS records and their answers results of the discovered_dns_records lookup and finds if any records have changed by searching DNS response from the Network_Resolution datamodel across the last day.
action.escu.mappings = {"mitre_attack": ["Exfiltration", "Command and Control", "Defense Evasion", "Commonly Used Port"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 1", "CIS 3", "CIS 8", "CIS 12"], "nist": ["ID.AM", "PR.DS", "PR.IP", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = Using a lookup `discover_dns_records` generated by support search "Discover DNS records" we check previous network traffic and make sure the responses have not changed.
action.escu.how_to_implement = To successfully implement this search you will need to ensure that DNS data is populating the `Network_Resolution` data model. It also requires that the `discover_dns_record` lookup table be populated by the included support search "Discover DNS record". \
\
 **Splunk>Phantom Playbook Integration**\
\
If Splunk>Phantom is also configured in your environment, a Playbook called "DNS Hijack Investigation" can be configured to run when any results are found by this detection search. The playbook takes in the DNS record changed and uses Geoip, whois, Censys and PassiveTotal to detect if DNS issuers changed. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
\
(Playbook Link:`https://my.phantom.us/4.1/playbook/dns-hijack-investigation/`).\
\

action.escu.known_false_positives = Legitimate DNS changes can be detected in this search. Investigate, verify and update the list of provided current answers for the domains in question as appropriate.
action.escu.creation_date = 2019-02-14
action.escu.modification_date = 2019-02-14
action.escu.confidence = medium
action.escu.full_search_name = ESCU - DNS record changed - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src", "dest"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["DNS Hijacking"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = DNS record changed
action.notable = 1
action.notable.param.nes_fields = src
action.notable.param.rule_description = The table represents a list of DNS records and their responses for corporate domains that have recently changed
action.notable.param.rule_title = DNS record changed
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = runphantomplaybook, escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following                         steps:\n\n1. [[action|runphantomplaybook]]: Phantom playbook                         recommendations:\nSplunk>Phantom Response Playbook - Monitor enrichment of the                         Splunk>Phantom Playbook called DNS Hijack enrichment and answer any                         analyst prompt in Mission Control with a response decision.                         Link to the playbook https://my.phantom.us/4.2/playbook/dns-hijack-enrichment/\n2. [[action|escu_investigate]]:                         Based on ESCU investigate recommendations:\nESCU - Get DNS Server History for a host\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | inputlookup discovered_dns_records.csv | rename answer as discovered_answer | join domain[|tstats summariesonly=true count values(DNS.record_type) as type, values(DNS.answer) as current_answer values(DNS.src) as src from datamodel=Network_Resolution where DNS.message_type=RESPONSE DNS.answer!="unknown" DNS.answer!="" by DNS.query | rename DNS.query as query | where query!="unknown" | rex field=query "(?<domain>\w+\.\w+?)(?:$|/)"] | makemv delim=" " answer |  makemv delim=" " type | sort -count | table count,src,domain,type,query,current_answer,discovered_answer | makemv current_answer  | mvexpand current_answer | makemv discovered_answer | eval n=mvfind(discovered_answer, current_answer) | where isnull(n)

[ESCU - Deleting Shadow Copies - Rule]
action.escu = 0
action.escu.enabled = 1
description = The vssadmin.exe utility is used to interact with the Volume Shadow Copy Service.  Wmic is an interface to the Windows Management Instrumentation.  This search looks for either of these tools being used to delete shadow copies.
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8", "CIS 10"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for execution of vssadmin or wmic with both the "delete" and "shadows" parameters passed on the command-line. The two arguments are searched for separately because we can't predict the number of spaces between the words on the command-line. The search will return the number of times this activity was observed, and the times of the first and last event.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = vssadmin.exe and wmic.exe are standard applications shipped with modern versions of windows. They may be used by administrators to legitimately delete old backup copies, although this is typically rare.
action.escu.creation_date = 2017-02-17
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Deleting Shadow Copies - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "SamSam Ransomware", "Windows Log Manipulation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Deleting Shadow Copies
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = Using $process_name$ to delete shadow copies is common behavior by ransomware. This activity was observed on $dest$
action.notable.param.rule_title = Deleting Shadow Copies on $dest$ with $process_name$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process_name=vssadmin.exe OR Processes.process_name=wmic.exe)  by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)` | search process=*delete* AND process=*shadow*

[ESCU - Detect API activity from users without MFA - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user logged into the AWS account, is making API calls and has not enabled Multi Factor authentication. Multi factor authentication adds a layer of security by forcing the users to type a unique authentication code from an approved authentication device when they access AWS websites or services. AWS Best Practices recommend that you enable MFA for privileged IAM users.
action.escu.mappings = {"mitre_attack": ["Execution"], "cis20": ["CIS 16"], "nist": ["DE.DP", "PR.AC"]}
action.escu.eli5 =  In this search, we query CloudTrail logs and specifically look for events where the multi factor authentication context of the user's session is false which basically means, that the user does not have MFA enabled on AWS. We then filter out all the known AWS service accounts since service accounts typically do not have MFA enabled. The search then creates a table of the first and last time a user without MFA was detected, the values and count of the API calls made, the type of user identity, ARN and the name of the user.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Leverage the support search `Create a list of approved AWS service accounts`: run it once every 30 days to create a list of service accounts and validate them.
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure do not have multi factor authentication enabled. Please ignore the service accounts, if triggered and instead add them to the aws_service_accounts.csv file to fine tune the detection. It is also possible that the search detects users in your environment using Single Sign-On systems, since the MFA is not handled by AWS.
action.escu.creation_date = 2018-05-17
action.escu.modification_date = 2018-05-17
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect API activity from users without MFA - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 8 * * *
dispatch.earliest_time = -1d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect API activity from users without MFA
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = API Activity detected from $user$ without MFA enabled.
action.notable.param.rule_title = API Activity detected from $user$ without MFA enabled
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Investigate AWS User Activities by user field\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 84600s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail userIdentity.sessionContext.attributes.mfaAuthenticated=false | search NOT [| inputlookup aws_service_accounts | fields identity | rename identity as user]| stats  count min(_time) as firstTime max(_time) as lastTime values(eventName) by userIdentity.arn userIdentity.type user | `ctime(firstTime)`  | `ctime(lastTime)`

[ESCU - Detect AWS API Activities From Unapproved Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for successful CloudTrail activity by user accounts that are not listed in the identity table or <code>aws_service_accounts.csv</code>. It returns event names and count, as well as the first and last time a specific user or service is detected, grouped by users.
action.escu.mappings = {"mitre_attack": ["Credential Access", "Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 16"], "nist": ["DE.DP", "DE.CM", "PR.AC", "ID.AM"]}
action.escu.eli5 = In this search, we are looking for successful API calls via CloudTrail. We filter out events triggered by known users listed in the `identity_lookup_expanded` lookup file and the service accounts. Once filtered out, we output a table with the event names and count, as well as the first and last time a specific user or service is detected.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You must also populate the `identity_lookup_expanded` lookup shipped with the Asset and Identity framework to be able to look up users in your identity table in Enterprise Security (ES). Leverage the support search called "Create a list of approved AWS service accounts": run it once every 30 days to create and validate a list of service accounts.
action.escu.known_false_positives = It's likely that you'll find activity detected by users/service accounts that are not listed in the `identity_lookup_expanded` or ` aws_service_accounts.csv` file. If the user is a legitimate service account, update the `aws_service_accounts.csv` table with that entry.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-13
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect AWS API Activities From Unapproved Accounts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect AWS API Activities From Unapproved Accounts
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A successful API activity was invoked by $user$, an unapproved/unknown account.
action.notable.param.rule_title = Successful API activity by a non-approved account: $user$
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Investigate AWS User Activities by user field\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail errorCode=success | rename userName as identity | search NOT [| inputlookup identity_lookup_expanded | fields identity] | search NOT [| inputlookup aws_service_accounts | fields identity] | rename identity as user | stats count min(_time) as firstTime max(_time) as lastTime values(eventName) by user | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Detect Activity Related to Pass the Hash Attacks - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for specific authentication events from the Windows Security Event logs to detect potential attempts at using the Pass-the-Hash technique.
action.escu.mappings = {"mitre_attack": ["Lateral Movement", "Pass the Hash"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 16"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.eli5 = To detect pass the hash activity, we look at all events with event code 4624 or 4625 that specify a logon type 3 (network logons). We are looking for the NtLmSsP account, with a key length set to 0. These indicate lower level protocols that are typically used through Pass the Hash (WMI, SMB, etc.). The search also filters out events with an account name of 'Anonymous' to help reduce false positives.
action.escu.how_to_implement = To successfully implement this search, you must ingest your Windows Security Event logs and leverage the latest TA for Windows.
action.escu.known_false_positives = Legitimate logon activity by authorized NTLM systems may be detected by this search. Please investigate as appropriate.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2019-02-27
action.escu.confidence = low
action.escu.full_search_name = ESCU - Detect Activity Related to Pass the Hash Attacks - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Lateral Movement"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Activity Related to Pass the Hash Attacks
action.notable = 1
action.notable.param.nes_fields = src_ip, dest, user
action.notable.param.rule_description = This search looks for Authentication log events from the Windows Security Audit logs to detect potential attempts for Passing the Hash
action.notable.param.rule_title = Detect Activity Related to Pass the Hash
action.notable.param.security_domain = access
action.notable.param.severity = low
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = eventtype=wineventlog_security (signature_id=4624 OR signature_id=4625) Logon_Process=NtLmSsp Logon_Type=3 Account_Name !="ANONYMOUS LOGON" Key_Length=0 | table _time src_ip user dest dest_nt_domain signature_id signature

[ESCU - Detect DNS requests to Phishing Sites leveraging EvilGinx2 - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for DNS requests for phishing domains that are leveraging EvilGinx tools to mimic websites.
action.escu.mappings = {"mitre_attack": ["Spearphishing Link", "Command and Control"], "kill_chain_phases": ["Delivery", "Command and Control"], "cis20": ["CIS 8", "CIS 7"], "nist": ["ID.AM", "PR.DS", "PR.IP", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution", "Web"]
action.escu.eli5 = This search gathers all the answers to each system's DNS query, then filters for queries that have sub domains extracted from the EvilGinx toolkit. It will then run a regex to extract `legit_domains` from the query and remove that from the detection if it is listed in the `legit_domains.csv`
action.escu.how_to_implement = You need to ingest data from your DNS logs in the Network_Resolution datamodel. Specifically you must ingest the domain that is being queried and the IP of the host originating the request. Ideally, you should also be ingesting the answer to the query and the query type. This approach allows you to also create your own localized passive DNS capability which can aid you in future investigations. You will have to add legitimate domain names to the `legit_domains.csv` file shipped with the app. \
\
 **Splunk>Phantom Playbook Integration**\
\
If Splunk>Phantom is also configured in your environment, a Playbook called `Lets Encrypt Domain Investigate` can be configured to run when any results are found by this detection search. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
\
(Playbook Link:`https://my.phantom.us/4.2/playbook/lets-encrypt-domain-investigate/`).\
\

action.escu.known_false_positives = If a known good domain is not listed in the legit_domains.csv file, then the search could give you false postives. Please update that lookup file to filter out DNS requests to legitimate domains.
action.escu.creation_date = 2019-04-29
action.escu.modification_date = 2019-04-29
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect DNS requests to Phishing Sites leveraging EvilGinx2 - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["src"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Common Phishing Frameworks"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect DNS requests to Phishing Sites leveraging EvilGinx2
action.notable = 1
action.notable.param.nes_fields = src, query
action.notable.param.rule_description = The host $src$ issued a DNS request for a domain that could be a phishing site leverating EvilGinx toolkit.
action.notable.param.rule_title = DNS request for EvilGinx subdomain detected on $src$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = runphantomplaybook, escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following                         steps:\n\n1. [[action|runphantomplaybook]]: Phantom playbook                         recommendations:\nSplunk>Phantom Response Playbook - Monitor enrichment of the                         Splunk>Phantom Playbook called Domain Certificate Investigation and answer any                         analyst prompt in Mission Control with a response decision.                         Link to the playbook https://my.phantom.us/4.2/playbook/lets-encrypt-domain-investigate/\n2. [[action|escu_investigate]]:                         Based on ESCU investigate recommendations:\nESCU - Get Certificate logs for a domain\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src, query
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats summariesonly=true allow_old_summaries=true count min(_time) as firstTime max(_time) as lastTime values(DNS.answer) as answer from datamodel=Network_Resolution.DNS by DNS.dest DNS.src DNS.query host | `drop_dm_object_name(DNS)`| rex field=query ".*?(?<domain>[^./:]+\.(\S{2,3}|\S{2,3}.\S{2,3}))$" | stats count values(query) as query by domain dest src answer| search `evilginx_phishlets_amazon` OR `evilginx_phishlets_facebook` OR `evilginx_phishlets_github` OR `evilginx_phishlets_0365` OR `evilginx_phishlets_outlook` OR `evilginx_phishlets_aws` OR `evilginx_phishlets_google` | search NOT [ inputlookup legit_domains.csv | fields domain]| join domain type=outer [| tstats count summariesonly=true allow_old_summaries=true values(Web.url) as url from datamodel=Web.Web by Web.dest Web.site | rename "Web.*" as * | rex field=site ".*?(?<domain>[^./:]+\.(\S{2,3}|\S{2,3}.\S{2,3}))$" | table dest domain url] | table count src dest query answer domain url

[ESCU - Detect Excessive Account Lockouts From Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search identifies endpoints that have caused a relatively high number of account lockouts in a short period.
action.escu.mappings = {"mitre_attack": ["Valid Accounts"], "cis20": ["CIS 16"], "nist": ["PR.IP"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search queries the `Change.All_Changes` datamodel under the nodename is `Account_Management` , where the result is "lockout", which indicates that an account has been locked out. It then counts the number of times an endpoint has caused an account lockout within a four hour window and displays those hosts with a count greater than or equal to five.
action.escu.how_to_implement = You must ingest your Windows security event logs in the `Change` datamodel under the nodename is `Account_Management`, for this search to execute successfully. Please consider updating the cron schedule and the count of lockouts you want to monitor, according to your environment. \
\
 **Splunk>Phantom Playbook Integration**\
\
If Splunk>Phantom is also configured in your environment, a Playbook called "Excessive Account Lockouts Enrichment and Response" can be configured to run when any results are found by this detection search. The Playbook executes the Contextual and Investigative searches in this Story, conducts additional information gathering on Windows endpoints, and takes a response action to shut down the affected endpoint. To use this integration, install the Phantom App for Splunk `https://splunkbase.splunk.com/app/3411/`, add the correct hostname to the "Phantom Instance" field in the Adaptive Response Actions when configuring this detection search, and set the corresponding Playbook to active. \
\
(Playbook Link:`https://my.phantom.us/4.1/playbook/excessive-account-lockouts-enrichment-and-response/`).\
\

action.escu.known_false_positives = It's possible that a widely used system, such as a kiosk, could cause a large number of account lockouts.
action.escu.creation_date = 2017-08-17
action.escu.modification_date = 2019-04-18
action.escu.confidence = low
action.escu.full_search_name = ESCU - Detect Excessive Account Lockouts From Endpoint - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = ["dest"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -5m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Excessive Account Lockouts From Endpoint
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The system $dest$ has generated a high number of account lockouts.
action.notable.param.rule_title = $dest$ has generated a high number of account lockouts
action.notable.param.security_domain = access
action.notable.param.severity = low
action.notable.param.recommended_actions = runphantomplaybook, escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following                         steps:\n\n1. [[action|runphantomplaybook]]: Phantom playbook                         recommendations:\nSplunk>Phantom Response Playbook - Monitor enrichment of the                         Splunk>Phantom Playbook called Excessive Account Lockouts Enrichment And Response and answer any                         analyst prompt in Mission Control with a response decision.                         Link to the playbook https://my.phantom.us/4.1/playbook/excessive-account-lockouts-enrichment-and-response/\n2. [[action|escu_investigate]]:                         Based on ESCU investigate recommendations:\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.dest All_Changes.result |`drop_dm_object_name("All_Changes")` |`drop_dm_object_name("Account_Management")`| `ctime(firstTime)` | `ctime(lastTime)` | search count > 5

[ESCU - Detect Excessive User Account Lockouts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects user accounts that have been locked out a relatively high number of times in a short period.
action.escu.mappings = {"mitre_attack": ["Valid Accounts"], "cis20": ["CIS 16"], "nist": ["PR.IP"]}
action.escu.data_models = ["Change"]
action.escu.eli5 = This search queries the `Change.All_Changes` datamodel under the nodename is `Account_Management` , where the result is "lockout", which indicates that an account has been locked out. It then counts the number of times a user  has caused an account lockout within a four hour window and displays those users with a count greater than or equal to five.
action.escu.how_to_implement = ou must ingest your Windows security event logs in the `Change` datamodel under the nodename is `Account_Management`, for this search to execute successfully. Please consider updating the cron schedule and the count of lockouts you want to monitor, according to your environment.
action.escu.known_false_positives = It is possible that a legitimate user is experiencing an issue causing multiple account login failures leading to lockouts.
action.escu.creation_date = 2017-08-17
action.escu.modification_date = 2019-03-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Excessive User Account Lockouts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Excessive User Account Lockouts
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = The account $user$ has been locked out an excessive number of times
action.notable.param.rule_title = $user$ locked account an excessive number of times
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get Notable Info\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Logon Rights Modifications For User\nESCU - Get Logon Rights Modifications For Endpoint\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Change.All_Changes where nodename=All_Changes.Account_Management All_Changes.result="lockout" by All_Changes.user All_Changes.result |`drop_dm_object_name("All_Changes")` |`drop_dm_object_name("Account_Management")`| `ctime(firstTime)` | `ctime(lastTime)` | search count > 5

[ESCU - Detect Large Outbound ICMP Packets - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for outbound ICMP packets with a packet size larger than 1,000 bytes. Various threat actors have been known to use ICMP as a command and control channel for their attack infrastructure. Large ICMP packets from an endpoint to a remote host may be indicative of this activity.
action.escu.mappings = {"mitre_attack": ["Command and Control", "Standard Non-Application Layer Protocol"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 9", "CIS 12"], "nist": ["DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search works by looking at fields in the Network_Traffic data model, which is populated by various firewalls and passive networking monitoring technologies. Specifically, the search looks for ICMP packets larger than 1,000 bytes with a destination that is external to your organization.
action.escu.how_to_implement = In order to run this search effectively, we highly recommend that you leverage the Assets and Identity framework. It is important that you have a good understanding of how your network segments are designed and that you are able to distinguish internal from external address space. Add a category named `internal` to the CIDRs that host the company's assets in the `assets_by_cidr.csv` lookup file, which is located in `$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/`. More information on updating this lookup can be found here: https://docs.splunk.com/Documentation/ES/5.0.0/Admin/Addassetandidentitydata. This search also requires you to be ingesting your network traffic and populating the Network_Traffic data model
action.escu.known_false_positives = ICMP packets are used in a variety of ways to help troubleshoot networking issues and ensure the proper flow of traffic. As such, it is possible that a large ICMP packet could be perfectly legitimate. If large ICMP packets are associated with command and control traffic, there will typically be a large number of these packets observed over time. If the search is providing a large number of false positives, you can modify the search to adjust the byte threshold or whitelist specific IP addresses, as necessary.
action.escu.creation_date = 2018-06-01
action.escu.modification_date = 2018-06-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Large Outbound ICMP Packets - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Bro", "Splunk Stream", "Palo Alto Firewall"]
action.escu.analytic_story = ["Command and Control"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Large Outbound ICMP Packets
action.notable = 1
action.notable.param.nes_fields = src_ip, dest_ip
action.notable.param.rule_description = Large outbound ICMP packet detected.
action.notable.param.rule_title = Large ICMP packet from $src_ip$ to $dest_ip$ detected
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - AWS Network Interface details via resourceId\nESCU - Get Process Info\nESCU - Get Process responsible for the DNS traffic\nESCU - Get DNS Server History for a host\nESCU - Get DNS traffic ratio\nESCU - Get All AWS Activity From IP Address\nESCU - Get Process Information For Port Activity\n"}
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count earliest(_time) as earliest latest(_time) as latest values(All_Traffic.action) values(All_Traffic.bytes) from datamodel=Network_Traffic where All_Traffic.action !=blocked All_Traffic.dest_category !=internal (All_Traffic.protocol=icmp OR All_Traffic.transport=icmp) All_Traffic.bytes > 1000 by All_Traffic.src_ip All_Traffic.dest_ip | `drop_dm_object_name("All_Traffic")` | search ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | convert ctime(earliest) ctime(latest)

[ESCU - Detect Long DNS TXT Record Response - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to detect attempts to use DNS tunneling, by calculating the length of responses to DNS TXT queries. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting unusually large volumes of DNS traffic.
action.escu.mappings = {"mitre_attack": ["Command and Control", "Exfiltration", "Commonly Used Port"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 8", "CIS 12", "CIS 13"], "nist": ["PR.DS", "PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search uses the Network_Resolution data model and gathers all the answers to DNS queries for TXT records. The query then looks at the answer section and calculates the length of the answer. The search will then return information for those responses that exceed 100 characters in length.
action.escu.how_to_implement = To successfully implement this search you need to ingest data from your DNS logs, or monitor DNS traffic using Stream, Bro or something similar. Specifically, this query requires that the DNS data model is populated with information regarding the DNS record type that is being returned as well as the data in the answer section of the protocol.
action.escu.known_false_positives = It's possible that legitimate TXT record responses can be long enough to trigger this search. You can modify the packet threshold for this search to help mitigate false positives.
action.escu.creation_date = 2017-06-18
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Long DNS TXT Record Response - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Long DNS TXT Record Response
action.notable = 1
action.notable.param.nes_fields = src, query
action.notable.param.rule_description = A DNS TXT record response of over 100 characters was detected.
action.notable.param.rule_title = Long DNS TXT Record Response
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get DNS Server History for a host\nESCU - Get DNS traffic ratio\nESCU - Get Process responsible for the DNS traffic\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Resolution where DNS.message_type=response AND DNS.record_type=TXT by DNS.src DNS.dest DNS.answer DNS.record_type |  `drop_dm_object_name("DNS")` | eval anslen=len(answer) | search anslen>100 | `ctime(firstTime)` | `ctime(lastTime)` | rename src as "Source IP", dest as "Destination IP", answer as "DNS Answer" anslen as "Answer Length" record_type as "DNS Record Type" firstTime as "First Time" lastTime as "Last Time" count as Count | table "Source IP" "Destination IP" "DNS Answer" "DNS Record Type"  "Answer Length" Count "First Time" "Last Time"

[ESCU - Detect Mimikatz Via PowerShell And EventCode 4663 - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell reading lsass memory consistent with credential dumping.
action.escu.mappings = {"mitre_attack": ["Credential Access", "Credential Dumping"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 16"], "nist": ["PR.IP", "PR.AC", "DE.CM"]}
action.escu.eli5 = This search looks for Windows Event Code(signature_id) 4663 (object access), where the process performing the access is PowerShell.exe, the target process of the access is lsass.exe, and the access mask is given as 0x10. This is consistent with the use of PowerShell to execute Mimikatz using sekurlsa::logonpasswords. It will return the host where the activity occurred, the process and associated id, the enabled privilege, and the message in the event.
action.escu.how_to_implement = You must be ingesting Windows Security logs. You must also enable the account change auditing here: http://docs.splunk.com/Documentation/Splunk/7.0.2/Data/MonitorWindowseventlogdata. Additionally, this search requires you to enable your Group Management Audit Logs in your Local Windows Security Policy and to be ingesting those logs.  More information on how to enable them can be found here: http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/. Finally, please make sure that the local administrator group name is "Administrators" to be able to look for the right group membership changes.
action.escu.known_false_positives = The activity may be legitimate. PowerShell is often used by administrators to perform various tasks, and it's possible this event could be generated in those cases. In these cases, false positives should be fairly obvious and you may need to tweak the search to eliminate noise.
action.escu.creation_date = 2018-08-28
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Mimikatz Via PowerShell And EventCode 4663 - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Mimikatz Via PowerShell And EventCode 4663
action.notable = 1
action.notable.param.nes_fields = user, dest
action.notable.param.rule_description = Possible attempt at credential dumping via PowerShell was detected on $dest$ by $user$.
action.notable.param.rule_title = Event ID 4663 Specifying PowerShell Reading From LSASS.exe Identified on $dest$.
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest, process
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = eventtype = wineventlog_security signature_id=4663 Process_Name=*powershell.exe Object_Name=*lsass.exe Access_Mask=0x10 | stats count min(_time) as firstTime max(_time) as lastTime by dest, Process_Name, Process_ID, Message | rename Process_Name as process | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Detect Mimikatz Via PowerShell And EventCode 4703 - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell requesting privileges consistent with credential dumping.
action.escu.mappings = {"mitre_attack": ["Credential Access", "Credential Dumping"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 16"], "nist": ["PR.IP", "PR.AC", "DE.CM"]}
action.escu.eli5 = This search looks for Windows Event Code(signature_id) 4703 (token right adjusted), where the process requesting the token change is PowerShell.exe and the requested privilege is "SeDebugPrivilege". This is consistent with the use of PowerShell to execute Mimikatz using sekurlsa::logonpasswords. It will return the host where the activity occurred, the process and associated id, the enabled privilege, and the message in the event.
action.escu.how_to_implement = You must be ingesting Windows Security logs. You must also enable the account change auditing here: http://docs.splunk.com/Documentation/Splunk/7.0.2/Data/MonitorWindowseventlogdata. Additionally, this search requires you to enable your Group Management Audit Logs in your Local Windows Security Policy and to be ingesting those logs.  More information on how to enable them can be found here: http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/. Finally, please make sure that the local administrator group name is "Administrators" to be able to look for the right group membership changes.
action.escu.known_false_positives = The activity may be legitimate. PowerShell is often used by administrators to perform various tasks, and it's possible this event could be generated in those cases. In these cases, false positives should be fairly obvious and you may need to tweak the search to eliminate noise.
action.escu.creation_date = 2018-08-28
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Mimikatz Via PowerShell And EventCode 4703 - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Credential Dumping"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Mimikatz Via PowerShell And EventCode 4703
action.notable = 1
action.notable.param.nes_fields = user, dest
action.notable.param.rule_description = Possible attempt at credential dumping via PowerShell was detected on $dest$ by $user$.
action.notable.param.rule_title = Event Code 4703 Specifying PowerShell Acquiring A Token with SeDebugPrivilege Identified on $dest$.
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest, process
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = eventtype=wineventlog_security signature_id=4703 Process_Name=*powershell.exe | rex field=Message "Enabled Privileges:\s+(?<privs>\w+)\s+Disabled Privileges:" | where privs="SeDebugPrivilege" | stats count min(_time) as firstTime max(_time) as lastTime by dest, Process_Name, privs, Process_ID, Message | rename privs as "Enabled Privilege" | rename Process_Name as process |  `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Detect New Local Admin account - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for newly created accounts that have been elevated to local administrators.
action.escu.mappings = {"mitre_attack": ["Valid Accounts", "Defense Evasion", "Persistence"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "cis20": ["CIS 16"], "nist": ["PR.AC", "DE.CM"]}
action.escu.eli5 = This search looks for Windows Event Code 4720 (account creation) and 4732 (account added to a security-enabled local group), where the group name is "Administrators", and determines whether they are generated for the same user's Security ID within three hours of each other.  It will return the user account that was added, the Security ID, the group name to which the user was added, the account name of the user who initiated the action, and the subsequent message returned.
action.escu.how_to_implement = You must be ingesting Windows Security logs. You must also enable the account change auditing here:http://docs.splunk.com/Documentation/Splunk/7.0.2/Data/MonitorWindowseventlogdata. Additionally, this search requires you to enable your Group Management Audit Logs in your Local Windows Security Policy and to be ingesting those logs.  More information on how to enable them can be found here: http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/. Finally, please make sure that the local administrator group name is "Administrators" to be able to look for the right group membership changes.
action.escu.known_false_positives = The activity may be legitimate. For this reason, it's best to verify the account with an administrator and ask whether there was a valid service request for the account creation. If your local administrator group name is not "Administrators", this search may generate an excessive number of false positives
action.escu.creation_date = 2018-03-26
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect New Local Admin account - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 9 * * *
dispatch.earliest_time = -1440m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect New Local Admin account
action.notable = 1
action.notable.param.nes_fields = user,src_user, dest
action.notable.param.rule_description = The new user account $user$ was created on $dest$ by $src_user$.
action.notable.param.rule_title = New local admin account $user$ created by $src_user$.
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = eventtype = wineventlog_security signature_id=4720 OR (signature_id=4732 Group_Name= Administrators) | transaction Security_ID maxspan=180m | search signature_id=4720 signature_id=4732 | table _time user dest signature_id Security_ID Group_Name src_user Message

[ESCU - Detect New Login Attempts to Routers - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search queries the authentication logs for assets that are categorized as routers in the ES Assets and Identity Framework, to identify connections that have not been seen before in the last 30 days.
action.escu.mappings = {"kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 11"], "nist": ["PR.PT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Authentication"]
action.escu.eli5 = Attackers will often attempt to compromise network devices such as routers for a variety of nefarious purposes, including modifying VPN settings or re-routing network traffic. Typically, only a relatively small number of user accounts log into these devices on a regular basis. This search identifies 'new' connections to your routers by checking to see if a similar login was made in the last 30 days. Routers are identified by checking the IP address against those categorized as a "router" in the ES assets and identity framework.
action.escu.how_to_implement = To successfully implement this search, you must ensure the network router devices are categorized as "router" in the Assets and identity table. You must also populate the Authentication data model with logs related to users authenticating to routing infrastructure.
action.escu.known_false_positives = Legitimate router connections may appear as new connections
action.escu.creation_date = 2017-07-18
action.escu.modification_date = 2017-09-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect New Login Attempts to Routers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Active Directory", "Palo Alto Firewall"]
action.escu.analytic_story = ["Router & Infrastructure Security"]
cron_schedule = 0 0 * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect New Login Attempts to Routers
action.notable = 1
action.notable.param.nes_fields = dest, user
action.notable.param.rule_description = This search detects new connections made to the router devices at $dest$
action.notable.param.rule_title = Detected a New Router Login
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count earliest(_time) as earliest latest(_time) as latest from datamodel=Authentication where Authentication.dest_category=router by Authentication.dest Authentication.user| eval isOutlier=if(earliest >= relative_time(now(), "-30d@d"), 1, 0) | where isOutlier=1| `ctime(earliest)`| `ctime(latest)` | `drop_dm_object_name("Authentication")`

[ESCU - Detect New Open S3 buckets - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where a user has created an open/public S3 bucket.
action.escu.mappings = {"mitre_attack": ["Execution", "Initial Access", "Exfiltration"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 13"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.eli5 = This search queries CloudTrail logs for events with S3 bucket access controls given to the "All Users" group, which allows anyone in the world access to the resource. This search generates a table displaying the time when the bucket was made public, the permission of the S3 bucket, the bucket name, and the ARN of the user who created the bucket.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), and then configure your CloudTrail inputs. The threshold value should be tuned to your environment.
action.escu.known_false_positives = While this search has no known false positives, it is possible that an AWS admin has legitimately created a public bucket for a specific purpose. That said, AWS strongly advises against granting full control to the "All Users" group.
action.escu.creation_date = 2018-07-25
action.escu.modification_date = 2018-07-25
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect New Open S3 buckets - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = S3 Bucket
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect New Open S3 buckets
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = An open/public S3 bucket, $bucketName$, was created by $user$.
action.notable.param.rule_title = Public S3 bucket $bucketName$ created by $user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - AWS S3 Bucket details via bucketName\nESCU - Investigate AWS activities via region name\nESCU - AWS Investigate User Activities By ARN\nESCU - Get All AWS Activity From IP Address\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user,bucketName
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail AllUsers eventName=PutBucketAcl | spath output=userIdentityArn path=userIdentity.arn | spath output=bucketName path=requestParameters.bucketName | spath output=aclControlList path=requestParameters.AccessControlPolicy.AccessControlList | spath input=aclControlList output=grantee path=Grant{} | mvexpand grantee | spath input=grantee | search Grantee.URI=*AllUsers | rename userIdentityArn as user| table _time, src,awsRegion Permission, Grantee.URI, bucketName, user

[ESCU - Detect Oulook.exe writing a .zip file - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for execution of process `outlook.exe` where the process is writing a `.zip` file to the disk.
action.escu.mappings = {"mitre_attack": ["Spearphishing Attachment"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "cis20": ["CIS 7", "CIS 8"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = In this search, we are essentially trying to detect if outlook.exe is writing a `.zip` file to the disk. The way this search would run is, it will execute the the subsearch first which looks for all .zip files being written to the disk and outputs a crucial field "process\_id", that we use the main search to check if that process\_id belongs to a process\_name of outlook.exe. The search uses a join command to essentially give you an end result of the first and last time that zip file was written by outlook.exe, the dest and user logged on the system, the hash value and the complete path to the zip file on disk
action.escu.how_to_implement = You must be ingesting data that records filesystem and process activity from your hosts to populate the Endpoint data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon.
action.escu.known_false_positives = It is not uncommon for outlook to write legitimate zip files to the disk.
action.escu.creation_date = 2019-04-29
action.escu.modification_date = 2019-04-29
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect Oulook.exe writing a .zip file - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Phishing Payloads"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Oulook.exe writing a .zip file
action.notable = 1
action.notable.param.nes_fields = dest, process_name, file_name
action.notable.param.rule_description = Oulook.exe is writing a zip file $file_name$ on $dest$
action.notable.param.rule_title = Oulook.exe is writing a zip file $file_name$ on $dest$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly`  min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name=outlook.exe OR Processes.process_name=explorer.exe by _time span=5m Processes.parent_process_id Processes.process_id Processes.dest Processes.process_name Processes.parent_process_name Processes.user | `drop_dm_object_name(Processes)` | `ctime(firstTime)` | `ctime(lastTime)` | rename process_id as malicious_id| rename parent_process_id as outlook_id| join malicious_id type=inner[| tstats `summariesonly` count values(Filesystem.file_path) as file_path values(Filesystem.file_name) as file_name  FROM datamodel=Endpoint.Filesystem where (Filesystem.file_path=*zip*   OR Filesystem.file_name=*.lnk ) AND (Filesystem.file_path=C:\\Users* OR Filesystem.file_path=*Local\\Temp*) by  _time span=5m Filesystem.process_id Filesystem.file_hash Filesystem.dest  | `drop_dm_object_name(Filesystem)` | `ctime(firstTime)` | `ctime(lastTime)` | rename process_id as malicious_id| fields malicious_id outlook_id dest file_path file_name file_hash count file_id] | table firstTime lastTime user malicious_id outlook_id process_name parent_process_name file_name  file_path | where file_name != ""

[ESCU - Detect Outbound SMB Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for outbound SMB connections made by hosts within your network to the Internet. SMB traffic is used for Windows file-sharing activity. One of the techniques often used by attackers involves retrieving the credential hash using an SMB request made to a compromised server controlled by the threat actor.
action.escu.mappings = {"mitre_attack": ["Commonly Used Port", "Credential Access", "Lateral Movement"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "cis20": ["CIS 12"], "nist": ["DE.CM"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = In this search, we are looking for the network connections that were not blocked by the firewall and that are destined for destination port 139 or 445. We then filter out events that have Classless Inter-Domain Routing (CIDR) blocks categorized as internal in the `assets_by_cidr.csv` lookup file which is located in `$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/`. Since we are only looking for outbound traffic from the hosts made to the Internet, we filter out traffic whose destination IP address is private.
action.escu.how_to_implement = In order to run this search effectively, we highly recommend that you leverage the Assets and Identity framework. It is important that you have good understanding of how your network segments are designed, and be able to distinguish internal from external address space. Add a category named `internal` to the CIDRs that host the company's assets in `assets_by_cidr.csv` lookup file, which is located in `$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/`. More information on updating this lookup can be found here: https://docs.splunk.com/Documentation/ES/5.0.0/Admin/Addassetandidentitydata. This search also requires you to be ingesting your network traffic and populating the Network_Traffic data model
action.escu.known_false_positives = It is likely that the outbound Server Message Block (SMB) traffic is legitimate, if the company's internal networks are not well-defined in the Assets and Identity Framework. Categorize the internal CIDR blocks as `internal` in the lookup file to avoid creating notable events for traffic destined to those CIDR blocks. Any other network connection that is going out to the Internet should be investigated and blocked. Best practices suggest preventing external communications of all SMB versions and related protocols at the network boundary.
action.escu.creation_date = 2018-03-20
action.escu.modification_date = 2018-03-20
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Outbound SMB Traffic - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Hidden Cobra Malware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Outbound SMB Traffic
action.notable = 1
action.notable.param.nes_fields = src_ip, dest_ip
action.notable.param.rule_description = Outbound SMB network traffic detected.
action.notable.param.rule_title = Outbound SMB traffic from $src_ip$ to $dest_ip$ detected
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\nESCU - Get Outbound Emails to Hidden Cobra Threat Actors\n"}
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count earliest(_time) as earliest latest(_time) as latest values(All_Traffic.action) from datamodel=Network_Traffic where All_Traffic.action !=blocked All_Traffic.dest_category !=internal (All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb) by All_Traffic.src_ip All_Traffic.dest_ip | `drop_dm_object_name("All_Traffic")` | search ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | convert ctime(earliest) ctime(latest)

[ESCU - Detect Path Interception By Creation Of program.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search is looking for the creation of program.exe in the C: drive.  The creation of this file in that location may be driven by a motive to perform path interception.
action.escu.mappings = {"mitre_attack": ["Privilege Escalation", "Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search queries the Endpoint file-system data model node to list out all the values of destination machines, as well as the values of file hashes and file paths that have the file "program.exe" in the C: drive. Path interception occurs when an executable is placed in a specific path so that it is executed by an application instead of by the intended target. In this case, applications vulnerable to path interception (because of unquoted service paths with spaces in Windows registry) allow attackers to execute maliciously crafted program.exes.
action.escu.how_to_implement = You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file system reads and writes.
action.escu.known_false_positives = It is unlikely that a normal user may create and place this file in the C: drive.  Confirm with the user.
action.escu.creation_date = 2017-11-16
action.escu.modification_date = 2018-11-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Path Interception By Creation Of program.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = 
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Persistence Techniques"]
cron_schedule = 30 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Path Interception By Creation Of program.exe
action.notable = 1
action.notable.param.nes_fields = dest, file_path, file_name
action.notable.param.rule_description = A potentially malicious file program.exe was detected on the C: drive. The creation of this file is often associated with a motive to perform a path interception attack. 
action.notable.param.rule_title = Path Interception attempt discovered $dest$ via creation of program.exe
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, file_path, file_name
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_hash) as file_hash values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem where Filesystem.file_path="C:\\program.exe" by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `ctime(lastTime)` | `ctime(firstTime)`

[ESCU - Detect Prohibited Applications Spawning cmd.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for executions of cmd.exe spawned by a process that is often abused by attackers and that does not typically launch cmd.exe.
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface"], "kill_chain_phases": ["Exploitation"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Obtaining access to the Command-Line Interface (CLI) is typically a primary attacker goal. Once an attacker has obtained the ability to execute code on a target system, they will often further manipulate the system via commands passed to the CLI. It is also unusual for many applications to spawn a command shell during normal operation, while it is often observed if an application has been compromised in some way. As such, it is often beneficial to look for cmd.exe being executed by processes that are often targeted for exploitation, or that would not spawn cmd.exe in any other circumstances. A lookup file is provided to easily modify the processes that are being watched for execution of cmd.exe.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts and populates the Endpoint data model with the resultant dataset. This search includes a lookup file, `prohibited_apps_launching_cmd.csv`, that contains a list of processes that should not be spawning cmd.exe. You can modify this lookup to better suit your environment.
action.escu.known_false_positives = There are circumstances where an application may legitimately execute and interact with the Windows command-line interface. Investigate and modify the lookup file, as appropriate.
action.escu.creation_date = 2017-10-07
action.escu.modification_date = 2018-11-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Prohibited Applications Spawning cmd.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious Command-Line Executions", "Suspicious MSHTA Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Prohibited Applications Spawning cmd.exe
action.notable = 1
action.notable.param.nes_fields = dest, process, parent_process
action.notable.param.rule_description = A prohibited application from prohibited_apps_launching_cmd.csv was leveraged to launch cmd.exe
action.notable.param.rule_title = Prohibited application($parent_process$) used to launch cmd.exe on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Registry Activities\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, parent_process
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.user) as user values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=cmd.exe by Processes.parent_process_name Processes.process_name Processes.dest | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)` |search [`prohibited_apps_launching_cmd`]

[ESCU - Detect PsExec With accepteula Flag - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for events where <code>PsExec.exe</code> is run with the <code>accepteula</code> flag in the command line. PsExec is a built-in Windows utility that enables you to execute processes on other systems. It is fully interactive for console applications. This tool is widely used for launching interactive command prompts on remote systems. Threat actors leverage this extensively for executing code on compromised systems. If an attacker is running PsExec for the first time, they will be prompted to accept the end-user license agreement (EULA), which can be passed as the argument <code>accepteula</code> within the command line.
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = In this search, we are looking for the PsExec process with `accepteula` on the command line.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators can leverage PsExec for accessing remote systems and might pass `accepteula` as an argument if they are running this tool for the first time. However, it is not likely that you'd see multiple occurrences of this event on a machine
action.escu.creation_date = 2018-03-28
action.escu.modification_date = 2019-02-26
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect PsExec With accepteula Flag - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["DHS Report TA18-074A", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect PsExec With accepteula Flag
action.notable = 1
action.notable.param.nes_fields = dest,process_name
action.notable.param.rule_description = The process pssxec.exe was run with the -accepteula flag on $dest$ by $user$.
action.notable.param.rule_title = PsExec executed with accepteula flag on $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = PsExec.exe Processes.process = "*accepteula*" by Processes.process_name Processes.dest  Processes.parent_process_name | `drop_dm_object_name(Processes)`| `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Detect Rare Executables - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will return a table of rare processes, the names of the systems running them, and the users who initiated each process.
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Installation", "Command and Control", "Actions on Objectives"], "cis20": ["CIS 2", "CIS 8"], "nist": ["ID.AM", "PR.PT", "PR.DS", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search first executes the subsearch and counts all of your processes to determine the 10 most rare (the limit set is 10). It then filters out whitelisted processes and outputs the first and last time a rare process was encountered, the destination where the process is running, the count of occurrences, and the users who initiated the processes.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts and populating the endpoint data model with the resultant dataset. The macro `filter_rare_process_whitelist` searches two lookup files to whitelist your processes.  These consist of `rare_process_whitelist_default.csv` and `rare_process_whitelist_local.csv`. To add your own processes to the whitelist, add them to `rare_process_whitelist_local.csv`. If you wish to remove an entry from the default lookup file, you will have to modify the macro itself to set the whitelist value for that process to false. You can modify the limit parameter and search scheduling to better suit your environment.
action.escu.known_false_positives = Some legitimate processes may be only rarely executed in your environment. As these are identified, update `rare_process_whitelist_local.csv` to filter them out of your search results.
action.escu.creation_date = 2016-08-09
action.escu.modification_date = 2018-10-30
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Rare Executables - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Emotet Malware (TA18-201A)", "Unusual Processes"]
cron_schedule = 10 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Rare Executables
action.notable = 1
action.notable.param.nes_fields = dest, process
action.notable.param.rule_description = The process $process$ was detected running on $dest. This process is rare in your environment.
action.notable.param.rule_title = Rare Process $process$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.dest) as dest values(Processes.user) as user min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.process_name  | rename Processes.process_name as process | rex field=user "(?<user_domain>.*)\\\\(?<user_name>.*)" | `ctime(firstTime)`| `ctime(lastTime)`| search [| tstats count from datamodel=Endpoint.Processes by Processes.process_name | rare Processes.process_name limit=30 | rename Processes.process_name as process| `filter_rare_process_whitelist`| table process ]

[ESCU - Detect S3 access from a new IP - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks at S3 bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed an S3 bucket.
action.escu.mappings = {"mitre_attack": ["Execution", "Exfiltration"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 13", "CIS 14"], "nist": ["PR.DS", "PR.AC", "DE.CM"]}
action.escu.eli5 = Here the subsearch executes first and returns all successful S3 bucket-access attempts (HTTP code "200") within the last hour. It groups the results by the earliest and latest times it has seen a remote IP accessing a particular bucket. It appends this information to the historical data from the lookup file and then recalculates the `firstTime` and `lastTime` field for each remote IP accessing an S3 bucket. Next, it returns only those remote IP addresses that have first been seen accessing a specific bucket within the past hour. This is combined with the main search to return the time, bucket name, source IP, city, and country operations performed, as well as the requested URI of the resource 
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your S3 access logs' inputs. This search works best when you run the "Previously Seen S3 Bucket Access by Remote IP" support search once to create a history of previously seen remote IPs and bucket names.
action.escu.known_false_positives = S3 buckets can be accessed from any IP, as long as it can make a successful connection. This will be a false postive, since the search is looking for a new IP within the past hour
action.escu.creation_date = 2018-06-25
action.escu.modification_date = 2018-06-28
action.escu.confidence = low
action.escu.full_search_name = ESCU - Detect S3 access from a new IP - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = S3 Bucket
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect S3 access from a new IP
action.notable = 1
action.notable.param.nes_fields = bucket_name, src_ip
action.notable.param.rule_description = A remote IP, $src_ip$, has made a successful connection with an S3 $bucket_name$.
action.notable.param.rule_title = S3 bucket $bucketName$ was accessed by a new $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = low
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - AWS S3 Bucket details via bucketName\nESCU - Investigate AWS activities via region name\nESCU - AWS Investigate User Activities By ARN\nESCU - Get All AWS Activity From IP Address\n"}
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = bucket_name, src_ip
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:s3:accesslogs http_status=200  [search sourcetype=aws:s3:accesslogs http_status=200 | stats earliest(_time) as firstTime latest(_time) as lastTime by bucket_name remote_ip | inputlookup append=t previously_seen_S3_access_from_remote_ip.csv | stats min(firstTime) as firstTime, max(lastTime) as lastTime by bucket_name remote_ip | outputlookup previously_seen_S3_access_from_remote_ip.csv | eval newIP=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newIP=1 | convert ctime(firstTime) ctime(lastTime) | table bucket_name remote_ip]| iplocation remote_ip |rename remote_ip as src_ip | table _time bucket_name src_ip City Country operation request_uri

[ESCU - Detect Spike in AWS API Activity - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect users creating spikes of API activity in your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.mappings = {"mitre_attack": ["Credential Access", "Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 16"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.eli5 = This search and its corresponding subsearch run through a series of steps, as per the following: \
\
1. Retrieves all the AWS CloudTrail log entries that have recorded AWS API calls.\
\
1. Kicks off a subsearch that retrieves the same data and pulls out the ARN into a more friendly format.\
\
1. Counts the number of API calls per ARN.\
\
1. Loads the cache file that contains the number of data points, the count from the latest hour, the API call average, and the standard deviation for each ARN.\
\
1. Drops the count from the latest hour, since it is not necessary, and merges the rest of the data with the results of the stats command. \
\
1. Renames `apiCalls` as `latestCount`.\
\
1. Calculates the new average value for each ARN with the latest count, weighting the past much more heavily than the current hour. It does the same for the standard deviation--weighting the past more heavily than the current.\
\
1. Updates the cache file with the latest results.\
\
1. Sets the minimum threshold for the number of data points and sets the number of standard deviations away from the mean it must be to be considered a spike.\
\
1. Makes a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and the count is a sufficient number of standard deviations away from the average.\
\
1. Filters out anything that it determines is not a spike and returns the list of ARNs to the main search. The main search subsequently gets the names of all the API calls, the number of unique API calls, and the total number of API calls for each of these ARNs. Finally, it looks up the average and standard deviation and returns both the average and the number of standard deviations the spike is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike.
action.escu.known_false_positives = 
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-04-09
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Spike in AWS API Activity - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Spike in AWS API Activity
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A spike in the number of AWS API calls by $user$ was detected.
action.notable.param.rule_title = Spike in AWS API activity detected by $user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Investigate AWS User Activities by user field\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventType=AwsApiCall [search sourcetype=aws:cloudtrail eventType=AwsApiCall | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup api_call_by_user_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup api_call_by_user_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventNames, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user

[ESCU - Detect Spike in Network ACL Activity - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect users creating spikes in API activity related to network access-control lists (ACLs)in your AWS environment.
action.escu.mappings = {"mitre_attack": ["Persistence", "Exfiltration"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 12", "CIS 11"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.eli5 = This search and its corresponding subsearch run through the following series of steps: \
\
1. Retrieve all the AWS CloudTrail log entries that have recorded AWS API calls specifically for creating/modifying/replacing network Access Control Lists (ACLs).\
\
1. Kick off a subsearch that retrieves the same data and pulls out the ARN into a more friendly format.\
\
1. Count the number of API calls per Amazon Resource Name (ARN).\
\
1. Load the cache file that contains the number of data points, the count from the latest hour, the API call average, and the standard deviation for each ARN.\
\
1. Drop the count from the latest hour, since it is not necessary, and merge the rest of the data with the results of the stats command. \
\
1. Rename `apiCalls` as `latestCount`.\
\
1. Calculate the new average value for each ARN with the latest count, weighting the past much more heavily than the current hour. They do the same for the standard deviation--weighting the past more heavily than the current.\
\
1. Update the cache file with the latest results.\
\
1. Set the minimum threshold for the number of data points and set the number of standard deviations away from the mean it must be to be considered a spike.\
\
1. Make a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and the count is a sufficient number of standard deviations away from the average.\
\
1. Filter out anything that it determines is not a spike and return the list of ARNs to the main search. The main search subsequently gets the names of all the API calls, the number of unique API calls, and the total number of API calls for each of these ARNs. Finally, it looks up the average and standard deviation and returns both the average and the number of standard deviations the spike is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of Network ACL Activity by ARN" support search once to create a lookup file of previously seen Network ACL Activity. To add or remove API event names related to network ACLs, edit the macro `NetworkACLEvents`.
action.escu.known_false_positives = The false-positive rate may vary based on the values of`dataPointThreshold` and `deviationThreshold`. Please modify this according the your environment.
action.escu.creation_date = 2018-05-17
action.escu.modification_date = 2018-05-21
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Spike in Network ACL Activity - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity"]
cron_schedule = 10 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Spike in Network ACL Activity
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A spike in the number of AWS API calls related to network ACLs by $user$ was detected.
action.notable.param.rule_title = Spike in AWS Network ACL activity detected by $user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - AWS Network ACL Details from ID\nESCU - AWS Network Interface details via resourceId\nESCU - AWS Investigate User Activities By ARN\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `NetworkACLEvents` [search sourcetype=aws:cloudtrail `NetworkACLEvents` | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup network_acl_activity_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup network_acl_activity_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventNames, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user

[ESCU - Detect Spike in S3 Bucket deletion - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects users creating spikes in API activity related to deletion of S3 buckets in your AWS environment. It will also update the cache file that factors in the latest data.
action.escu.mappings = {"mitre_attack": ["Credential Access", "Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 13"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.eli5 = This search and its corresponding subsearch run through the following series of steps: \
\
1. Retrieve all the AWS CloudTrail log entries that have recorded AWS API calls specifically for deletion of S3 buckets.\
\
1. Kick off a subsearch that retrieves the same data and pulls out and converts the ARN into a more friendly format.\
\
1. Count the number of API calls per ARN.\
\
1. Load the cache file that contains the number of data points, the count from the latest hour, the API call average, and the standard deviation for each ARN.\
\
1. Drop the count from the latest hour, since it is unnecessary, and merge the rest of the data with the results of the `stats` command. \
\
1. Rename `apiCalls` as `latestCount`.\
\
1. Calculate the new average value for each ARN with the latest count, weighting the past more heavily than the current hour. It does the same for the standard deviation&#151;weighting the past more heavily than the current.\
\
1. Update the cache file with the latest results.\
\
1. Set the minimum threshold for the number of data points and the number of standard deviations away from the mean it must be to be considered a spike.\
\
1. Make a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and if the count is a sufficient number of standard deviations away from the average.\
\
1. Filter out anything that it determines is not a spike and returns the list of ARNs to the main search. The main search subsequently gets the names of the deleted S3 buckets, the number of unique API calls, and the total number of API calls for each of these user ARNs.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of S3 Bucket deletion activity by ARN" support search once to create a baseline of previously seen S3 bucket-deletion activity.
action.escu.known_false_positives = Based on the values of`dataPointThreshold` and `deviationThreshold`, the false positive rate may vary. Please modify this according the your environment.
action.escu.creation_date = 2018-07-17
action.escu.modification_date = 2018-11-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Spike in S3 Bucket deletion - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = S3 Bucket
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Spike in S3 Bucket deletion
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A spike in the number of S3 buckets deleted by $user$ was detected.
action.notable.param.rule_title = Spike detected in S3 bucket deletion activity by $user$.
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - AWS S3 Bucket details via bucketName\nESCU - Investigate AWS activities via region name\nESCU - AWS Investigate User Activities By ARN\nESCU - Get All AWS Activity From IP Address\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=DeleteBucket [search sourcetype=aws:cloudtrail eventName=DeleteBucket | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup s3_deletion_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup s3_deletion_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | spath output=bucketName path=requestParameters.bucketName | stats values(bucketName) as bucketName, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user

[ESCU - Detect Spike in Security Group Activity - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect users creating spikes in API activity related to security groups in your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.mappings = {"mitre_attack": ["Credential Access", "Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 16"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.eli5 = This search and its corresponding subsearch run through the following series of steps: \
\
1. Retrieves all the AWS CloudTrail log entries that have recorded AWS API calls specifically for security groups.\
\
1. Kicks off a subsearch that retrieves the same data and pulls out the ARN into a more friendly format.\
\
1. Counts the number of API calls per ARN.\
\
1. Loads the cache file that contains the number of data points, the count from the latest hour, the API call average, and the standard deviation for each ARN.\
\
1. Drops the count from the latest hour, since it is not necessary, and merges the rest of the data with the results of the stats command. \
\
1. Renames `apiCalls` as `latestCount`.\
\
1. Calculates the new average value for each ARN with the latest count, weighting the past much more heavily than the current hour. It does the same for the standard deviation--weighting the past more heavily than the current.\
\
1. Updates the cache file with the latest results.\
\
1. Sets the minimum threshold for the number of data points and sets the number of standard deviations away from the mean it must be to be considered a spike.\
\
1. Makes a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and the count is a sufficient number of standard deviations away from the average.\
\
1. Filters out anything that it determines is not a spike and returns the list of ARNs to the main search. The main search subsequently gets the names of all the API calls, the number of unique API calls, and the total number of API calls for each of these ARNs. Finally, it looks up the average and standard deviation and returns both the average and the number of standard deviations the spike is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike.This search works best when you run the "Baseline of Security Group Activity by ARN" support search once to create a history of previously seen Security Group Activity. To add or remove API event names for security groups, edit the macro `securityGroupAPIs`.
action.escu.known_false_positives = Based on the values of`dataPointThreshold` and `deviationThreshold`, the false positive rate may vary. Please modify this according the your environment.
action.escu.creation_date = 2018-04-17
action.escu.modification_date = 2018-04-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Spike in Security Group Activity - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Spike in Security Group Activity
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A spike in the number of AWS API calls related to security groups by $user$ was detected.
action.notable.param.rule_title = Spike in AWS Security Group activity detected by $user$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Investigate AWS User Activities by user field\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `securityGroupAPIs` [search sourcetype=aws:cloudtrail `securityGroupAPIs` | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup security_group_activity_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup security_group_activity_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventNames, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user

[ESCU - Detect Spike in blocked Outbound Traffic from your AWS - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search will detect spike in blocked outbound network connections originating from within your AWS environment.  It will also update the cache file that factors in the latest data.
action.escu.mappings = {"mitre_attack": ["Exfiltration", "Command and Control"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "cis20": ["CIS 11"], "nist": ["DE.AE", "DE.CM", "PR.AC"]}
action.escu.eli5 = This search retrieves all the VPC Flow log entries that have recorded a blocked outbound network connection originating from your AWS environment. Then it kicks off a subsearch, which looks at the same data and performs the following series of steps: \
\
1. Counts the number of blocked outbound connections by each source IP\
\
1. Loads the cache file that contains the number of data points, the count from the latest hour, the average blocked connections, and the standard deviation for each source IP.\
\
1. Drops the count from the latest hour, since it is not necessary, and merges the rest of the data with the results of the stats command. \
\
1. Renames `numberOfBlockedConnections` as `latestCount`.\
\
1. Calculates the new average value for each source IP with the latest count, weighting the past much more heavily than the current hour. It does the same for the standard deviation, weighting the past more heavily than the current.\
\
1. Updates the cache file with the latest results.\
\
1. Sets the minimum threshold for the number of data points and sets the number of standard deviations away from the mean it must be to be considered a spike.\
\
1. Makes a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and the count is a sufficient number of standard deviations away from the average.\
\
1. Filters out anything that it determines is not a spike and returns the list of source IPs to the main search. The main search subsequently gets the list of all destination IPs for which the traffic was blocked, the network interface ID, the number of unique destination IP, and the total number of blocked connections for each of these source IP addresses. Finally, it looks up the average and standard deviation and returns both the average and the number of standard deviations the spike is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your VPC Flow logs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the number of data points required to meet the definition of "spike." The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of Blocked Outbound Connection" support search once to create a history of previously seen blocked outbound connections.
action.escu.known_false_positives = The false-positive rate may vary based on the values of`dataPointThreshold` and `deviationThreshold`. Additionally, false positives may result when AWS administrators roll out policies enforcing network blocks, causing sudden increases in the number of blocked outbound connections.
action.escu.creation_date = 2018-04-26
action.escu.modification_date = 2018-05-07
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Spike in blocked Outbound Traffic from your AWS - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Spike in blocked Outbound Traffic from your AWS
action.notable = 1
action.notable.param.nes_fields = src_ip
action.notable.param.rule_description = A spike in the blocked outbound connection is detected from source $src_ip$.
action.notable.param.rule_title = Spike in blocked outbound network connections from $src_ip$ detected.
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - AWS Network Interface details via resourceId\nESCU - Get All AWS Activity From IP Address\n"}
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudwatchlogs:vpcflow action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  [search  sourcetype=aws:cloudwatchlogs:vpcflow action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  | stats count as numberOfBlockedConnections by src_ip | inputlookup baseline_blocked_outbound_connections append=t | fields - latestCount | stats values(*) as * by src_ip | rename numberOfBlockedConnections as latestCount | eval newAvgBlockedConnections=avgBlockedConnections + (latestCount-avgBlockedConnections)/720 | eval newStdevBlockedConnections=sqrt(((pow(stdevBlockedConnections, 2)*719 + (latestCount-newAvgBlockedConnections)*(latestCount-avgBlockedConnections))/720)) | eval avgBlockedConnections=coalesce(newAvgBlockedConnections, avgBlockedConnections), stdevBlockedConnections=coalesce(newStdevBlockedConnections, stdevBlockedConnections), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table src_ip, latestCount, numDataPoints, avgBlockedConnections, stdevBlockedConnections | outputlookup baseline_blocked_outbound_connections | eval dataPointThreshold = 5, deviationThreshold = 3 | eval isSpike=if((latestCount > avgBlockedConnections+deviationThreshold*stdevBlockedConnections) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | table src_ip] | stats values(dest_ip) as "Blocked Destination IPs", values(interface_id) as "resourceId" count as numberOfBlockedConnections, dc(dest_ip) as uniqueDestConnections by src_ip

[ESCU - Detect USB device insertion - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search is used to detect hosts that generate Windows Event ID 4663 for successful attempts to write to or read from a removable storage and Event ID 4656 for failures, which occurs when a USB drive is plugged in. In this scenario we are querying the Change_Analysis data model to look for Windows Event ID 4656 or 4663 where the priority of the affected host is marked as high in the ES Assets and Identity Framework.
action.escu.mappings = {"mitre_attack": ["Exfiltration"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "cis20": ["CIS 13"], "nist": ["PR.PT", "PR.DS"]}
action.escu.data_models = ["Change_Analysis"]
action.escu.eli5 = USB is a common attack vector for delivering or propagating malicious code, or the exfiltration of data. Your corporation may have a policy of not allowing removable media at all, or may only allow approved media to be used on specific hosts by specific users. By logging USB activity from Windows and other endpoints gathered using the Universal Forwarder, you can gain an understanding of what systems might be vulnerable to attack via removable media, or what users might need additional security training. This search is looking for event_id 4656 for failure and 4663 for successful USB read/write attempts from Windows Security Event logs, which is the event code generated when a files are read from and written to a removable storage device
action.escu.how_to_implement = To successfully implement this search, you must ingest Windows Security Event logs and track event code 4663 and 4656. Ensure that the field from the event logs is being mapped to the result_id field in the Change_Analysis data model. To minimize the alert volume, this search leverages the Assets and Identity framework to filter out events from those assets not marked high priority in the Enterprise Security Assets and Identity Framework.
action.escu.known_false_positives = Legitimate USB activity will also be detected. Please verify and investigate as appropriate.
action.escu.creation_date = 2017-08-03
action.escu.modification_date = 2017-11-27
action.escu.confidence = low
action.escu.full_search_name = ESCU - Detect USB device insertion - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Data Protection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect USB device insertion
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = Read/Write attempt to a USB was detected on this host
action.notable.param.rule_title = Read/Write attempt to a USB detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = low
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get DNS Server History for a host\nESCU - Get Process responsible for the DNS traffic\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count earliest(_time) AS earliest latest(_time) AS latest from datamodel=Change_Analysis where (nodename = All_Changes) All_Changes.result="Removable Storage device" (All_Changes.result_id=4663 OR All_Changes.result_id=4656) (All_Changes.src_priority=high) by All_Changes.dest | `drop_dm_object_name("All_Changes")`| `ctime(earliest)`| `ctime(latest)` 

[ESCU - Detect Unauthorized Assets by MAC address - Rule]
action.escu = 0
action.escu.enabled = 1
description = By populating the organization's assets within the assets_by_str.csv, we will be able to detect unauthorized devices that are trying to connect with the organization's network by inspecting DHCP request packets, which are issued by devices when they attempt to obtain an IP address from the DHCP server. The MAC address associated with the source of the DHCP request is checked against the list of known devices, and reports on those that are not found.
action.escu.mappings = {"mitre_attack": ["Defense Evasion"], "kill_chain_phases": ["Reconnaissance", "Delivery", "Actions on Objectives"], "cis20": ["CIS 1"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Network_Sessions"]
action.escu.eli5 = This search requires you to leverage the Enterprise Security Assets and Identity framework to populate assets_by_str.csv. Once the assets_by_str.csv is populated, we then query your DHCP logs to detect unknown systems connecting to your network. More documentation is available at: http://docs.splunk.com/Documentation/ES/4.7.1/Admin/Verifyassetandidentitydata.
action.escu.how_to_implement = This search uses the Network_Sessions data model shipped with Enterprise Security. It leverages the Assets and Identity framework to populate the assets_by_str.csv file located in SA-IdentityManagement, which will contain a list of known authorized organizational assets including their MAC addresses. Ensure that all inventoried systems have their MAC address populated.
action.escu.known_false_positives = This search might be prone to high false positives. Please consider this when conducting analysis or investigations. Authorized devices may be detected as unauthorized. If this is the case, verify the MAC address of the system responsible for the false positive and add it to the Assets and Identity framework with the proper information.
action.escu.creation_date = 2017-06-11
action.escu.modification_date = 2017-09-13
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Unauthorized Assets by MAC address - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Infrastructure
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Asset Tracking"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Unauthorized Assets by MAC address
action.notable = 1
action.notable.param.nes_fields = src, query
action.notable.param.rule_description = The host $src$ issued a DHCP request to connect with your network that does not belong to the list of authorized devices
action.notable.param.rule_title = Unauthorized Asset found with mac address: $src_mac$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get First Occurrence and Last Occurrence of a MAC Address\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_mac,src_ip
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count from datamodel=Network_Sessions where nodename=All_Sessions.DHCP All_Sessions.signature=DHCPREQUEST by All_Sessions.src_ip All_Sessions.src_mac | dedup All_Sessions.src_mac| `drop_dm_object_name("Network_Sessions")`|`drop_dm_object_name("All_Sessions")` | search NOT [| inputlookup asset_lookup_by_str |rename mac as src_mac | fields + src_mac]

[ESCU - Detect Use of cmd.exe to Launch Script Interpreters - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the execution of the cscript.exe or wscript.exe processes, with a parent of cmd.exe. The search will return the count, the first and last time this execution was seen on a machine, the user, and the destination of the machine
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface"], "kill_chain_phases": ["Exploitation"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers often leverage various scripting languages to execute their attacks. In a Windows environment, the Windows Script Host is the tool that interprets the scripts and is included in all modern versions of Windows. The Windows Script Host is available as a command-line tool called "cscript.exe" or "wscript.exe." To detect this behavior, the search looks for process-creation events for cscript.exe or wscript.exe with a parent process of cmd.exe. The search will return the count, the first and last times this behavior was seen on a destination machine, and user and process information.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = Some legitimate applications may exhibit this behavior.
action.escu.creation_date = 2017-10-09
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect Use of cmd.exe to Launch Script Interpreters - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Emotet Malware (TA18-201A)", "Suspicious Command-Line Executions"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect Use of cmd.exe to Launch Script Interpreters
action.notable = 1
action.notable.param.nes_fields = dest, process_name, parent_process
action.notable.param.rule_description = Potentially malicious script execution detected.
action.notable.param.rule_title = Command prompt is executing scripts on $dest$ using $process_name$ 
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process="*cmd.exe" (Processes.process_name=cscript.exe OR Processes.process_name =wscript.exe) by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name("Processes")` | `ctime(firstTime)`|`ctime(lastTime)`

[ESCU - Detect attackers scanning for vulnerable JBoss servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for specific GET or HEAD requests to web servers that are indicative of reconnaissance attempts to identify vulnerable JBoss servers. JexBoss is described as the exploit tool of choice for this malicious activity.
action.escu.mappings = {"mitre_attack": ["Discovery", "System Information Discovery"], "kill_chain_phases": ["Reconnaissance"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search returns the number of times a URL associated with this type of JexBoss probe is observed.
action.escu.how_to_implement = You must be ingesting data from the web server or network traffic that contains web specific information, and populating the Web data model.
action.escu.known_false_positives = It's possible for legitimate HTTP requests to be made to URLs containing the suspicious paths.
action.escu.creation_date = 2016-10-04
action.escu.modification_date = 2017-09-23
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect attackers scanning for vulnerable JBoss servers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Web Server
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Palo Alto Firewall", "Apache", "Bro"]
action.escu.analytic_story = ["JBoss Vulnerability", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect attackers scanning for vulnerable JBoss servers
action.notable = 1
action.notable.param.nes_fields = 
action.notable.param.rule_description = This search looks for specific GET/HEAD requests to web servers that are indicative of reconnaissance attempts to identify vulnerable JBoss servers.
action.notable.param.rule_title = Detect attackers scanning for vulnerable JBoss servers
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,url
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Web where (Web.http_method="GET" OR Web.http_method="HEAD") AND (Web.url="*/web-console/ServerInfo.jsp*" OR Web.url="*web-console*" OR Web.url="*jmx-console*" OR Web.url = "*invoker*") by Web.http_method, Web.url, Web.src, Web.dest | `drop_dm_object_name("Web")` | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Detect hosts connecting to dynamic domain providers - Rule]
action.escu = 0
action.escu.enabled = 1
description = Malicious actors often abuse legitimate Dynamic DNS services to host malicious payloads or interactive command and control nodes. Attackers will automate domain resolution changes by routing dynamic domains to countless IP addresses to circumvent firewall blocks, blacklists as well as frustrate a network defenders analytic and investigative processes. This search will look for DNS queries made from within your infrastructure to suspicious dynamic domains. 
action.escu.mappings = {"mitre_attack": ["Exfiltration", "Exfiltration Over Command and Control Channel", "Defense Evasion", "Commonly Used Port"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 8", "CIS 12", "CIS 13"], "nist": ["PR.DS", "PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = The search is querying an accelerated `Network_Resolution` data model to count and list the values of resolved domains for each DNS query and checks that against the list of Dynamic DNS providers (lookup - `dynamic_dns_providers`) by each host (DNS.src)
action.escu.how_to_implement = First, you'll need to ingest data from your DNS operations. This can be done by ingesting logs from your server or data collected passively by Splunk Stream or similar solutions. Specifically, data that contains the domain that is being queried and the IP of the host originating the request must be populating the Network_Resolution data model. This search also leverages a lookup file, `dynamic_dns_providers_default.csv`, which contains a non-exhaustive list of Dynamic DNS providers. Please consider updating the local lookup periodically by adding new domains to the list of `dynamic_dns_providers_local.csv`.
action.escu.known_false_positives = Some users and applications may leverage Dynamic DNS to reach out to some domains on the Internet since dynamic DNS by itself is not malicious, however this activity must be verified.
action.escu.creation_date = 2017-11-17
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect hosts connecting to dynamic domain providers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest", "query"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "DNS Hijacking", "Data Protection", "Dynamic DNS", "Prohibited Traffic Allowed or Protocol Mismatch", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect hosts connecting to dynamic domain providers
action.notable = 1
action.notable.param.nes_fields = answer, src, query
action.notable.param.rule_description = The search has detected a host making outbound queries to Dynamic DNS providers
action.notable.param.rule_title = Host $src$ detected to make a query to a Dynamic DNS provider
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get DNS Server History for a host\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src, query
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(DNS.answer) as "Dynamic DNS Resolutions" min(_time) as firstTime from datamodel=Network_Resolution by DNS.src, DNS.query | `drop_dm_object_name("DNS")` | `ctime(firstTime)` | `dynamic_dns_providers`

[ESCU - Detect malicious requests to exploit JBoss servers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to detect malicious HTTP requests crafted to exploit jmx-console in JBoss servers. The malicious requests have a long URL length, as the payload is embedded in the URL.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability"], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 12", "CIS 4", "CIS 18"], "nist": ["ID.RA", "PR.PT", "PR.IP", "DE.AE", "PR.MA", "DE.CM"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks for HTTP requests for a URL that has been used to exploit JBoss servers.
action.escu.how_to_implement = You must ingest data from the web server or capture network data that contains web specific information with solutions such as Bro or Splunk Stream, and populating the Web data model
action.escu.known_false_positives = No known false positives for this detection.
action.escu.creation_date = 2016-10-04
action.escu.modification_date = 2017-09-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect malicious requests to exploit JBoss servers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Web Server
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Palo Alto Firewall", "Apache", "Bro"]
action.escu.analytic_story = ["JBoss Vulnerability", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect malicious requests to exploit JBoss servers
action.notable = 1
action.notable.param.nes_fields = src, dest_ip
action.notable.param.rule_description = A search for detecting malicious requests made to exploit jmx-console in JBoss servers. The bad requests have a long url length since it serves the payload via the url
action.notable.param.rule_title = Detected malicious requests to exploit JBoss servers
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,url,src
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Web where (Web.http_method="GET" OR Web.http_method="HEAD") by Web.http_method, Web.url,Web.url_length Web.src, Web.dest | search Web.url="*jmx-console/HtmlAdaptor?action=invokeOpByName&name=jboss.admin*import*" AND Web.url_length > 200 | `drop_dm_object_name("Web")` | `ctime(firstTime)` | `ctime(lastTime)` | table src, dest_ip, http_method, url, firstTime, lastTime

[ESCU - Detect mshta.exe running scripts in command-line arguments - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the execution of "mshta.exe" with command-line arguments that launch a script. The search will return the first time and last time these command-line arguments were used for these executions, as well as the target system, the user, process "mshta.exe" and its parent process.
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface", "Persistence"], "kill_chain_phases": ["Exploitation"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Mshta.exe is a built-in Windows utility that can launch HTML files with .hta extensions (HTML applications), javascript, or VBScript. The search detects this behavior by looking for events where the process mshta.exe is executed with command-line arguments that indicate that a script is invoked
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with the process name, parent process, and command-line executions from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = Although unlikely, some legitimate applications may exhibit this behavior, triggering a false positive.
action.escu.creation_date = 2018-08-07
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect mshta.exe running scripts in command-line arguments - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious MSHTA Activity"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect mshta.exe running scripts in command-line arguments
action.notable = 1
action.notable.param.nes_fields = dest, process, parent_process_name
action.notable.param.rule_description = Mshta.exe is seen to be executing scripts via the command-line arguments
action.notable.param.rule_title = Mshta.exe is executing scripts on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Registry Activities\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process, parent_process_name
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=mshta.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)`| search (process=*vbscript* OR process=*javascript*)

[ESCU - Detect new API calls from user roles - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects new API calls that have either never been seen before or that have not been seen in the previous hour, where the identity type is <code>AssumedRole</code>.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch will execute first and return the user roles and names of the API calls completed within the last hour, where the type of user identity is `AssumedRole`. It then appends the historical data to those results in the lookup file. Next, it recalculates the `earliest` and `latest` fields for each user role, as well as the name of the API call, and returns only those roles and API calls that have first been seen in the past hour. This is combined with the main search to return the values of API calls, name of the user role, and the earliest and latest time of this activity. It is worth noting that the name of the role of a particular user is parsed as "userName" in the CloudTrail logs.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously seen API call per user roles in CloudTrail" support search once to create a history of previously seen user roles.
action.escu.known_false_positives = It is possible that there are legitimate user roles making new or infrequently used API calls in your infrastructure, causing the search to trigger.
action.escu.creation_date = 2018-04-01
action.escu.modification_date = 2018-04-16
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect new API calls from user roles - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 30 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect new API calls from user roles
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = A new API call made by $user$ has been detected. This API activity has either never been seen before or has not been seen within the last hour.
action.notable.param.rule_title = New API call by $user$ detected
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Investigate AWS User Activities by user field\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventType=AwsApiCall errorCode=success userIdentity.type=AssumedRole [search sourcetype=aws:cloudtrail eventType=AwsApiCall errorCode=success  userIdentity.type=AssumedRole | stats earliest(_time) as earliest latest(_time) as latest by userName eventName |  inputlookup append=t previously_seen_api_calls_from_user_roles | stats min(earliest) as earliest, max(latest) as latest by userName eventName | outputlookup previously_seen_api_calls_from_user_roles| eval newApiCallfromUserRole=if(earliest>=relative_time(now(), "-70m@m"), 1, 0) | where newApiCallfromUserRole=1 | `ctime(earliest)` | `ctime(latest)` | table eventName userName]  |rename userName as user| stats values(eventName) earliest(_time) as earliest latest(_time) as latest by user | `ctime(earliest)` | `ctime(latest)`

[ESCU - Detect new user AWS Console Login - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
action.escu.mappings = {"mitre_attack": ["Credential Access"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 16"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events that indicate that a user has attempted to log in to the AWS console and group the events using ARN value. Using the `previously_seen_users_console_logins.csv` lookup file created using the support search, we compare the ARN to all the previously seen users logging into the AWS console. The `eval` and `if` functions determine whether the earliest time we see this user ARN was seen within the last hour. The alert will be fired only when a user is seen for first time in the last hour.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.creation_date = 2018-02-26
action.escu.modification_date = 2018-02-26
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detect new user AWS Console Login - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
cron_schedule = 5 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect new user AWS Console Login
action.notable = 1
action.notable.param.nes_fields = arn
action.notable.param.rule_description = A new user has logged into the AWS console
action.notable.param.rule_title = AWS Console Login by New User
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - AWS Investigate User Activities By ARN\n"}
action.risk = 1
action.risk.param._risk_object = arn
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = arn
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=ConsoleLogin | rename userIdentity.arn as arn  |stats earliest(_time) as earliest latest(_time) as latest by arn | inputlookup append=t previously_seen_users_console_logins.csv  | stats min(earliest) as earliest max(latest) as latest by arn | outputlookup previously_seen_users_console_logins.csv | eval userStatus=if(earliest >= relative_time(now(), "-70m@m"), "First Time Logging into AWS Console","Previously Seen User") | convert ctime(earliest) ctime(latest) | where userStatus ="First Time Logging into AWS Console" 

[ESCU - Detect processes used for System Network Configuration Discovery - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for fast execution of processes used for system network configuration discovery on the endpoint.
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Installation", "Command and Control", "Actions on Objectives"], "cis20": ["CIS 2"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers have a range of built-in Windows tools they leverage to ascertain the topography of a network from the point of view of a compromised machine. It is uncommon to see these commands execute quickly within short periods of time. This search returns the number of times, as well as the first time and last times, that every process has run for each endpoint. It then executes the macro `system_network_configuration_discovery_tools`, which looks for processes that are typically used for network configuration discovery. Once you have a list of suspicious process launches for each destination, you can leverage the transaction command to see what processes are fired within a five-minute span on an endpoint and detect only those events where the count of these processes is greater than five.
action.escu.how_to_implement = You must be ingesting data that records registry activity from your hosts to populate the Endpoint data model in the processes node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is usually generated via logs that report reads and writes to the registry or that are populated via Windows event logs, after enabling process tracking in your Windows audit settings.
action.escu.known_false_positives = It is uncommon for normal users to execute a series of commands used for network discovery. System administrators often use scripts to execute these commands. These can generate false positives.
action.escu.creation_date = 2018-11-04
action.escu.modification_date = 2018-11-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect processes used for System Network Configuration Discovery - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect processes used for System Network Configuration Discovery
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = Fast execution of processes $related to network system configuration discovery seen on $dest$.
action.notable.param.rule_title = Fast execution of processes $process_name$ related to network discovery seen on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.process_name Processes.user _time | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name(Processes)` | search `system_network_configuration_discovery_tools` | transaction dest maxpause=5m |where eventcount>=5 | table firstTime lastTime dest user process_name process parent_process eventcount

[ESCU - Detect web traffic to dynamic domain providers - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for web connections to dynamic DNS providers.
action.escu.mappings = {"mitre_attack": ["Command and Control", "Web Service", "Exfiltration Over Command and Control Channel", "Defense Evasion"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 7", "CIS 8"], "nist": ["PR.IP", "DE.DP"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks for hosts in your environment that may be communicating with a dynamic DNS provider. It checks each URL an endpoint is connecting to against a list of dynamic DNS providers. It returns the source and destination IP address of the web request, the URL requested, and the first time the event occurred.
action.escu.how_to_implement = This search requires you to be ingesting web-traffic logs. You can obtain these logs from indexing data from a web proxy or by using a network-traffic-analysis tool, such as Bro or Splunk Stream. The web data model must contain the URL being requested, the IP address of the host initiating the request, and the destination IP. This search also leverages a lookup file, `dynamic_dns_providers_default.csv`, which contains a non-exhaustive list of dynamic DNS providers. Consider periodically updating this local lookup file with new domains.
action.escu.known_false_positives = It is possible that list of dynamic DNS providers is outdated and/or that the URL being requested is legitimate.
action.escu.creation_date = 2018-09-06
action.escu.modification_date = 2018-09-06
action.escu.confidence = high
action.escu.full_search_name = ESCU - Detect web traffic to dynamic domain providers - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.analytic_story = ["Dynamic DNS"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect web traffic to dynamic domain providers
action.notable = 1
action.notable.param.nes_fields = src, url, dest
action.notable.param.rule_description = The host $src$ has been detected making a web request to $url$, which is a listed as a dynamic DNS provider.
action.notable.param.rule_title = Dynamic DNS web traffic detected on $src$.
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get DNS Server History for a host\nESCU - Get DNS traffic ratio\nESCU - Get Process responsible for the DNS traffic\nESCU - Investigate Web Activity From src_ip\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src, url , dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats summariesonly=true allow_old_summaries=true count values(Web.url) as url min(_time) as firstTime from datamodel=Web where Web.status=200 by Web.src Web.dest Web.status | `drop_dm_object_name("Web")` | `ctime(firstTime)` | `dynamic_dns_web_traffic`

[ESCU - Detection of DNS Tunnels - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to detect DNS tunneling, by calculating the sum of the length of DNS queries and DNS answers. The search also filters out potential false positives by filtering out queries made to internal systems and the queries originating from internal DNS, Web, and Email servers. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting an unusually large volume of DNS traffic.
action.escu.mappings = {"mitre_attack": ["Command and Control", "Exfiltration", "Commonly Used Port"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 13"], "nist": ["PR.PT", "PR.DS"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = The search will calculate the distinct count and sum of the length of DNS queries made and DNS answers received by a particular host to alert the analyst if the combined length is greater than 10000, which is not typical behavior.
action.escu.how_to_implement = To successfully implement this search, we must ensure that DNS data is being ingested and mapped to the appropriate fields in the Network_Resolution data model. Fields like src_category are automatically provided by the Assets and Identity Framework shipped with Splunk Enterprise Security. You will need to ensure you are using the Assets and Identity Framework and populating the src_category field. You will also need to enable the `cim_corporate_web_domain_search()` macro which will essentially filter out the DNS queries made to the corporate web domains to reduce alert fatigue.
action.escu.known_false_positives = It's possible that normal DNS traffic will exhibit this behavior. If an alert is generated, please investigate and validate as appropriate. The threshold can also be modified to better suit your environment.
action.escu.creation_date = 2017-07-19
action.escu.modification_date = 2017-09-18
action.escu.confidence = low
action.escu.full_search_name = ESCU - Detection of DNS Tunnels - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "Data Protection", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detection of DNS Tunnels
action.notable = 1
action.notable.param.nes_fields = src
action.notable.param.rule_description = Potential DNS tunnel detected from $src$ which may be exfiltrating large data
action.notable.param.rule_title = DNS tunnel detected on $src$
action.notable.param.security_domain = network
action.notable.param.severity = low
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get DNS Server History for a host\nESCU - Get DNS traffic ratio\nESCU - Get Process responsible for the DNS traffic\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src, query
alert.suppress.period = 43200s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` dc("DNS.query") as count  from datamodel=Network_Resolution  where nodename=DNS "DNS.message_type"="QUERY" NOT (`cim_corporate_web_domain_search("DNS.query")`) NOT "DNS.query"="*.in-addr.arpa" NOT ("DNS.src_category"="svc_infra_dns" OR "DNS.src_category"="svc_infra_webproxy" OR "DNS.src_category"="svc_infra_email*"   ) by "DNS.src","DNS.query" | rename "DNS.src" as src  "DNS.query" as message | eval length=len(message) | stats sum(length) as length by src | append [ tstats `summariesonly` dc("DNS.answer") as count  from datamodel=Network_Resolution  where nodename=DNS "DNS.message_type"="QUERY" NOT (`cim_corporate_web_domain_search("DNS.query")`) NOT "DNS.query"="*.in-addr.arpa" NOT ("DNS.src_category"="svc_infra_dns" OR "DNS.src_category"="svc_infra_webproxy" OR "DNS.src_category"="svc_infra_email*"   ) by "DNS.src","DNS.answer" | rename "DNS.src" as src  "DNS.answer" as message | eval message=if(message=="unknown","", message) | eval length=len(message) | stats sum(length) as length by src ] | stats sum(length) as length by src | where length > 10000

[ESCU - Detection of tools built by NirSoft - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for specific command-line arguments that may indicate the execution of tools made by Nirsoft, which are legitimate, but may be abused by attackers.
action.escu.mappings = {"mitre_attack": ["Third-party Software", "Account Discovery"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "cis20": ["CIS 3"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for process-creation events accompanied by specific command-line arguments ("scomma" and "stext"). These parameters may be leveraged by a set of free, legitimate tools built by NirSoft. Attackers have been seen abusing the tools' capabilities to steal passwords, set up key loggers, recover account information from mail clients, and conduct other nefarious activities. The search will identify the count, the first and last times a process is executed, the command-line arguments, and the parent process.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = While legitimate, these NirSoft tools are prone to abuse. You should verfiy that the tool was used for a legitimate purpose.
action.escu.creation_date = 2018-09-11
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Detection of tools built by NirSoft - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Emotet Malware (TA18-201A)"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detection of tools built by NirSoft
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for specific arguments passed via the command line and detects execution of tools built by NirSoft, which are often abused by attackers.
action.notable.param.rule_title = Potential abuse of NirSoft tools on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where (Processes.process="* /stext *" OR Processes.process="* /scomma *" ) by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name(Processes)` | `ctime(firstTime)` |`ctime(lastTime)`

[ESCU - Disabling Remote User Account Control - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for modifications to registry keys that control the enforcement of Windows User Account Control (UAC).
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Modify Registry"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search checks to see if the registry key SOFTWARE\Microsoft\Windows\CurrentVersion\Policies\System\LocalAccountTokenFilterPolicy was modified.  This registry key can be used to disable remote User Account Control.  The search returns the count, the first time activity was seen, last time activity was seen, the registry path that was modified, the host where the modification took place and the user that performed the modification.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report registry modifications.
action.escu.known_false_positives = This registry key may be modified via administrators to implement a change in system policy. This type of change should be a very rare occurrence.
action.escu.creation_date = 2017-10-12
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Disabling Remote User Account Control - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Defense Evasion Tactics"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Disabling Remote User Account Control
action.notable = 1
action.notable.param.nes_fields = dest, user, registry_path
action.notable.param.rule_description = The registry key SOFTWARE\Microsoft\Windows\CurrentVersion\Policies\System\LocalAccountTokenFilterPolicy was modified.  This registry key is associated with disabling remote UAC on Windows.
action.notable.param.rule_title = Registry Key Associated With Disabling Remote UAC Modified on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user, registry_path
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where Registry.registry_path="*Windows\\CurrentVersion\\Policies\\System\\LocalAccountTokenFilterPolicy" by Registry.dest, Registry.registry_key_name Registry.status Registry.user Registry.registry_path Registry.action | `drop_dm_object_name(Registry)`

[ESCU - EC2 Instance Modified With Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being modified by users who have not previously modified them.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns the ARNs of all successful EC2 instance modifications within the last hour and then appends the historical data in the lookup file to those results. EC2 modification APIs are defined by the macro `ec2ModificationAPIs`. The search then recalculates the `firstTime` and `lastTime` field for each ARN and returns only those ARNs that have first been seen in the past hour. This is combined with the main search to return the time, user, and instance ID of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Launches By User" support search once to create a history of previously seen ARNs. To add or remove APIs that modify an EC2 instance, edit the macro `ec2ModificationAPIs`.
action.escu.known_false_positives = It's possible that a new user will start to modify EC2 instances when they haven't before for any number of reasons. Verify with the user that is modifying instances that this is the intended behavior.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-04-09
action.escu.confidence = medium
action.escu.full_search_name = ESCU - EC2 Instance Modified With Previously Unseen User - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Unusual AWS EC2 Modifications"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = EC2 Instance Modified With Previously Unseen User
action.notable = 1
action.notable.param.nes_fields = user, dest
action.notable.param.rule_description = The EC2 instance $dest$ was modified by $user$. This user has never modified an EC2 instance before.
action.notable.param.rule_title = EC2 Instance Modified By Previously Unseen User $user$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get EC2 Instance Details by instanceId\nESCU - AWS Investigate User Activities By ARN\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `ec2ModificationAPIs` [search sourcetype=aws:cloudtrail `ec2ModificationAPIs` errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by userIdentity.arn | rename userIdentity.arn as arn | inputlookup append=t previously_seen_ec2_modifications_by_user | stats min(firstTime) as firstTime, max(lastTime) as lastTime by arn | outputlookup previously_seen_ec2_modifications_by_user | eval newUser=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newUser=1 | `ctime(firstTime)` | `ctime(lastTime)` | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=dest responseElements.instancesSet.items{}.instanceId | spath output=user userIdentity.arn | table _time, user, dest

[ESCU - EC2 Instance Started In Previously Unseen Region - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for CloudTrail events where an instance is started in a particular region in the last one hour and then compares it to a lookup file of previously seen regions where an instance was started
action.escu.mappings = {"mitre_attack": ["Defense Evasion"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 12"], "nist": ["DE.DP", "DE.AE"]}
action.escu.eli5 = In this search, we query CloudTrail logs to look for events that indicate that an instance was started in a particular region. Using the `previously_seen_aws_regions.csv` lookup file created using the support search, we compare the region where this instance was started to all previously observed regions. The `eval` and `if` functions determine that the earliest times seen for this region and instance were within the last day. If a new region is detected, it will alert you with "Instance Started in a New Region". However, this region will be added to the list of `previously_seen_aws_regions.csv`. Please maintain `previously_seen_aws_regions.csv`
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen AWS Regions" support search only once to create of baseline of previously seen regions.
action.escu.known_false_positives = It's possible that a user has unknowingly started an instance in a new region. Please verify that this activity is legitimate.
action.escu.creation_date = 2018-02-01
action.escu.modification_date = 2018-02-23
action.escu.confidence = medium
action.escu.full_search_name = ESCU - EC2 Instance Started In Previously Unseen Region - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = EC2 Instance Started In Previously Unseen Region
action.notable = 1
action.notable.param.nes_fields = awsRegion
action.notable.param.rule_description = An AWS instance is started in a new, previously unseen, region
action.notable.param.rule_title = AWS instance is started in a new region
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get EC2 Instance Details by instanceId\nESCU - Investigate AWS activities via region name\nESCU - AWS Investigate User Activities By ARN\n"}
action.risk = 1
action.risk.param._risk_object = awsRegion
action.risk.param._risk_object_type = other
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = awsRegion
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail earliest=-1h StartInstances  | stats earliest(_time) as earliest latest(_time) as latest by awsRegion| inputlookup append=t previously_seen_aws_regions.csv | stats min(earliest) as earliest max(latest) as latest by awsRegion | outputlookup previously_seen_aws_regions.csv | eval regionStatus=if(earliest >= relative_time(now(), "-1d@d"), "Instance Started in a New Region","Previously Seen Region") | convert ctime(earliest) ctime(latest) | where regionStatus="Instance Started in a New Region"

[ESCU - EC2 Instance Started With Previously Unseen AMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being created with previously unseen AMIs.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns the AMI image ID of all successful EC2 instance launches within the last hour and then appends the historical data from the lookup file to those results.  It then recalculates the earliest and latest seen time field for each AMI image ID and returns only those AMI image IDs that have first been seen in the past hour.  This is combined with the main search to return the time, user, and instance id of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 AMIs" support search once to create a history of previously seen AMIs.
action.escu.known_false_positives = After a new AMI is created, the first systems created with that AMI will cause this alert to fire.  Verify that the AMI being used was created by a legitimate user.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen AMI - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = EC2 Instance Started With Previously Unseen AMI
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The EC2 instance $dest$ was created with previously unused AMI $amiID$
action.notable.param.rule_title = EC2 Instance Type $dest$ Created With New AMI
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get EC2 Launch Details\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances [search sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | stats earliest(_time) as earliest latest(_time) as latest by requestParameters.instancesSet.items{}.imageId | rename requestParameters.instancesSet.items{}.imageId as amiID | inputlookup append=t previously_seen_ec2_amis.csv | stats min(earliest) as earliest max(latest) as latest by amiID | outputlookup previously_seen_ec2_amis.csv | eval newAMI=if(earliest >= relative_time(now(), "-70m@m"), 1, 0) | convert ctime(earliest) ctime(latest) | where newAMI=1 | rename amiID as requestParameters.instancesSet.items{}.imageId | table requestParameters.instancesSet.items{}.imageId] | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest, userIdentity.arn as arn, requestParameters.instancesSet.items{}.imageId as amiID | table _time, arn, amiID, dest, instanceType

[ESCU - EC2 Instance Started With Previously Unseen Instance Type - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being created with previously unseen instance types.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns the instance types of all successful EC2 instance launches within the last hour and then appends the historical data in the lookup file to those results.  It then recalculates the earliest seen time field for each instance type and returns only those instance types that has first been seen in the past hour.  This is combined with the main search to return the time, user, and instance id of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Instance Types" support search once to create a history of previously seen instance types.
action.escu.known_false_positives = It is possible that an admin will create a new system using a new instance type never used before. Verify with the creator that they intended to create the system with the new instance type.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen Instance Type - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = EC2 Instance Started With Previously Unseen Instance Type
action.notable = 1
action.notable.param.nes_fields = instanceType
action.notable.param.rule_description = The EC2 instance type $instanceType$ was used for the first time to create $dest$.
action.notable.param.rule_title = New EC2 Instance Type $instanceType$ detected
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get EC2 Launch Details\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances [search sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | fillnull value="m1.small" requestParameters.instanceType | stats earliest(_time) as earliest latest(_time) as latest by requestParameters.instanceType | rename requestParameters.instanceType as instanceType | inputlookup append=t previously_seen_ec2_instance_types.csv | stats min(earliest) as earliest max(latest) as latest by instanceType | outputlookup previously_seen_ec2_instance_types.csv | eval newType=if(earliest >= relative_time(now(), "-70m@m"), 1, 0) | convert ctime(earliest) ctime(latest) | where newType=1 | rename instanceType as requestParameters.instanceType | table requestParameters.instanceType] | spath output=user userIdentity.arn | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest | table _time, user, dest, instanceType

[ESCU - EC2 Instance Started With Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for EC2 instances being created by users who have not created them before.
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.eli5 = The subsearch returns the ARNs of all successful EC2 instance launches within the last hour and then appends the historical data in the lookup file to those results.  It then recalculates the `firstTime` and `lastTime` field for each ARN and returns only those ARNs that have first been seen in the past hour.  This is combined with the main search to return the time, user, and instance id of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Launches By User" support search once to create a history of previously seen ARNs.
action.escu.known_false_positives = It's possible that a user will start to create EC2 instances when they haven't before for any number of reasons. Verify with the user that is launching instances that this is the intended behavior.
action.escu.creation_date = 2018-03-15
action.escu.modification_date = 2018-03-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen User - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = AWS Instance
action.escu.fields_required = []
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = EC2 Instance Started With Previously Unseen User
action.notable = 1
action.notable.param.nes_fields = user, dest
action.notable.param.rule_description = The EC2 instance $dest$ was created by $user$.  This user has never created an EC2 instance before.
action.notable.param.rule_title = EC2 Instance Created By Previously Unseen User $user$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get EC2 Instance Details by instanceId\nESCU - Investigate AWS activities via region name\nESCU - AWS Investigate User Activities By ARN\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances [search sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by userIdentity.arn | rename userIdentity.arn as arn | inputlookup append=t previously_seen_ec2_launches_by_user.csv | stats min(firstTime) as firstTime, max(lastTime) as lastTime by arn | outputlookup previously_seen_ec2_launches_by_user.csv | eval newUser=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newUser=1 | `ctime(firstTime)` | `ctime(lastTime)` | rename arn as userIdentity.arn | table userIdentity.arn] | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest, userIdentity.arn as user | table _time, user, dest, instanceType

[ESCU - Email Attachments With Lots Of Spaces - Rule]
action.escu = 0
action.escu.enabled = 1
description = Attackers often use spaces as a means to obfuscate an attachment's file extension. This search looks for messages with email attachments that have many spaces within the filename.
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 7"], "nist": ["PR.IP"]}
action.escu.data_models = ["Email"]
action.escu.eli5 = This search looks at any emails with file attachment names that contain many spaces relative to the length of the file name. Specifically, it checks if spaces make up more than 10% of the number of characters in the file name. This percentage can be tuned for each environment. The search will then output the message ID of the email, the count, the recipient address and the recipient user, first and last time this event was seen and the space ratio of the file attachment name.
action.escu.how_to_implement = You need to ingest data from emails. Specifically, the sender's address and the file names of any attachments must be mapped to the Email data model. The threshold ratio is set to 10%, but this value can be configured to suit each environment.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-09-19
action.escu.confidence = high
action.escu.full_search_name = ESCU - Email Attachments With Lots Of Spaces - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.analytic_story = ["Emotet Malware (TA18-201A)", "Suspicious Emails"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Email Attachments With Lots Of Spaces
action.notable = 1
action.notable.param.nes_fields = src_user, file_name
action.notable.param.rule_description = The sender $src_user$ has sent an email with a suspicious amount of spaces in the file name: $file_name$
action.notable.param.rule_title = Suspicious Email Attachment from $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Email Info\nESCU - Get Emails From Specific Sender\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(All_Email.recipient) as recipient_address min(_time) as firstTime max(_time) as lastTime from datamodel=Email where All_Email.file_name="*" by All_Email.src_user, All_Email.file_name All_Email.message_id | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Email")` | eval space_ratio = (mvcount(split(file_name," "))-1)/len(file_name) | search space_ratio >= 0.1 |  rex field=recipient_address "(?<recipient_user>.*)@"

[ESCU - Email files written outside of the Outlook directory - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks at the change-analysis data model and detects email files created outside the normal Outlook directory.
action.escu.mappings = {"mitre_attack": ["Collection", "Email Collection"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = In this search, we are looking for activities consistent with an adversary collecting email data from local machines. The search will detect email files (files with .pst or .ost extensions) created in directories other than the standard Outlook directory (c:\users\username\My Documents\Outlook Files\.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records the file-system activity from your hosts to populate the Endpoint.Filesystem data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or by other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.
action.escu.known_false_positives = Administrators and users sometimes prefer backing up their email data by moving the email files into a different folder. These attempts will be detected by the search.
action.escu.creation_date = 2017-12-13
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Email files written outside of the Outlook directory - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Email files written outside of the Outlook directory
action.notable = 1
action.notable.param.nes_fields = dest, file_path, action, file_name
action.notable.param.rule_description = The system $dest$ has email files outside of the normal Outlook directory 
action.notable.param.rule_title = Email files created or modified on $dest$ that are not in the normal Outlook directory
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, file_path
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Filesystem.file_path) as file_path min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Filesystem where (Filesystem.file_name=*.dll OR Filesystem.file_name=*.ost) Filesystem.file_path != "C:\\Users\\*\\My Documents\\Outlook Files\\*" by Filesystem.action Filesystem.process_id Filesystem.file_name Filesystem.dest | `drop_dm_object_name("Filesystem")` | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Email servers sending high volume traffic to hosts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
action.escu.mappings = {"mitre_attack": ["Collection", "Email Collection", "Commonly Used Port"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 7"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search may look complex, but it's a neat representation of how statistics can help you understand your dataset to bubble up events that are not normal compared to its behavior. The search consists of three parts. The first part of the SPL fetches the data you want to work on. In this search, we calculate the sum of bytes sent and bytes_out from systems categorized as email_server to each host. We then calculate the average and standard deviation for the bytes sent to all the hosts combined and on a per-host basis. Then we set threshold values to deviation_threshold and minimum_data_samples using eval statements. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.  We then check for byte transfers that are statistically significantly higher than normal. The search then gives IP address of the host, the time of the increased byte transfer, how much data was transferred, and the average amount of data transfer the email server normally sends to all hosts and to this specific host. Finally, it includes the number of standard deviations away the byte count was from these averages.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic and populating the Network_Traffic data model.  Your email servers must be categorized as "email_server" for the search to work, as well. You may need to adjust the deviation_threshold and minimum_data_samples values based on the network traffic in your environment. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.
action.escu.known_false_positives = The false-positive rate will vary based on how you set the deviation_threshold and data_samples values. Our recommendation is to adjust these values based on your network traffic to and from your email servers.
action.escu.creation_date = 2017-12-20
action.escu.modification_date = 2017-12-20
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Email servers sending high volume traffic to hosts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 0 * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Email servers sending high volume traffic to hosts
action.notable = 1
action.notable.param.nes_fields = dest_ip
action.notable.param.rule_description = High volume of traffic that originated from an email server is being sent to $dest_ip$
action.notable.param.rule_title = High volume of traffic from an email server sent to $dest_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` sum(All_Traffic.bytes_out) as bytes_out from datamodel=Network_Traffic where All_Traffic.src_category=email_server by All_Traffic.dest_ip _time span=1d | `drop_dm_object_name("All_Traffic")` | eventstats avg(bytes_out) as avg_bytes_out stdev(bytes_out) as stdev_bytes_out | eventstats count as num_data_samples avg(eval(if(_time < relative_time(now(), "@d"), bytes_out, null))) as per_source_avg_bytes_out stdev(eval(if(_time < relative_time(now(), "@d"), bytes_out, null))) as per_source_stdev_bytes_out by dest_ip | eval minimum_data_samples = 4, deviation_threshold = 3 | where num_data_samples >= minimum_data_samples AND bytes_out > (avg_bytes_out + (deviation_threshold * stdev_bytes_out)) AND bytes_out > (per_source_avg_bytes_out + (deviation_threshold * per_source_stdev_bytes_out)) AND _time >= relative_time(now(), "@d") | eval num_standard_deviations_away_from_server_average = round(abs(bytes_out - avg_bytes_out) / stdev_bytes_out, 2), num_standard_deviations_away_from_client_average = round(abs(bytes_out - per_source_avg_bytes_out) / per_source_stdev_bytes_out, 2) | table dest_ip, _time, bytes_out, avg_bytes_out, per_source_avg_bytes_out, num_standard_deviations_away_from_server_average, num_standard_deviations_away_from_client_average

[ESCU - Excessive DNS Failures - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search identifies DNS query failures by counting the number of DNS responses that do not indicate success, and trigger on more than 50 occurrences.
action.escu.mappings = {"mitre_attack": ["Exfiltration", "Exfiltration Over Alternative Protocol", "Command and Control", "Commonly Used Port"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 8", "CIS 9", "CIS 12"], "nist": ["PR.PT", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search looks at DNS traffic with a reply code that is NOT indicative of a successful response. Numerous unsuccessful replies may be indicative of DNS protocol tampering or other malicious activity. If more than 50 of these unsuccessful responses are observed over the time frame of the search, a notable event will be generated.
action.escu.how_to_implement = To successfully implement this search you must ensure that DNS data is populating the Network_Resolution data model.
action.escu.known_false_positives = It is possible legitimate traffic can trigger this rule. Please investigate as appropriate. The threshold for generating an event can also be customized to better suit your environment.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-18
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Excessive DNS Failures - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Command and Control", "Suspicious DNS Traffic"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Excessive DNS Failures
action.notable = 1
action.notable.param.nes_fields = src, query
action.notable.param.rule_description = This search identifies DNS query failures by counting the number of DNS responses that do not indicate success and triggers on more than 50 occurrences.
action.notable.param.rule_title = Excessive DNS Failures
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get DNS Server History for a host\nESCU - Get DNS traffic ratio\nESCU - Get Process responsible for the DNS traffic\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src,query
alert.suppress.period = 43200s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values("DNS.query") as queries from datamodel=Network_Resolution where nodename=DNS "DNS.reply_code"!="No Error" "DNS.reply_code"!="NoError" DNS.reply_code!="unknown" NOT "DNS.query"="*.arpa" "DNS.query"="*.*" by "DNS.src","DNS.query"| `drop_dm_object_name("DNS")`| lookup cim_corporate_web_domain_lookup domain as query OUTPUT domain| where isnull(domain)| lookup update=true alexa_lookup_by_str domain as query OUTPUT rank| where isnull(rank)| stats sum(count) as count mode(queries) as queries by src| `get_asset(src)`| where count>50

[ESCU - Execution of File With Spaces Before Extension - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launched from files with at least five spaces in the name before the extension. This is typically done to obfuscate the file extension by pushing it outside of the default view.
action.escu.mappings = {"mitre_attack": ["Execution", "Persistence", "Change Default File Association"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 8"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search uses the endpoint data model to look for process names with at least five spaces between the file name and its extension.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = None identified.
action.escu.creation_date = 2018-01-26
action.escu.modification_date = 2018-01-26
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Execution of File With Spaces Before Extension - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows File Extension and Association Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Execution of File With Spaces Before Extension
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The system $dest$ executed a file with spaces before its extension.
action.notable.param.rule_title = Process $process$ with spaces before extension Launched on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process_path) as process_path min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process = "*     .*" by Processes.dest Processes.user Processes.process Processes.process_name | `ctime(firstTime)`| `ctime(lastTime)` | `drop_dm_object_name(Processes)`

[ESCU - Execution of File with Multiple Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launched from files that have double extensions in the file name. This is typically done to obscure the "real" file extension and make it appear as though the file being accessed is a data file, as opposed to executable content.
action.escu.mappings = {"mitre_attack": ["Execution", "Persistence", "Change Default File Association"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 8"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search uses the "Application State" data model to look for process names with specific combinations of double extensions. Relatively straightforward, the search looks for strings in the "process" field that match what you're looking for.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node.
action.escu.known_false_positives = None identified.
action.escu.creation_date = 2018-01-26
action.escu.modification_date = 2018-11-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Execution of File with Multiple Extensions - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows File Extension and Association Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Execution of File with Multiple Extensions
action.notable = 1
action.notable.param.nes_fields = dest, process
action.notable.param.rule_description = The system $dest$ executed a file with a double extension.
action.notable.param.rule_title = Process With Multiple Extensions Launched on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process = *.doc.exe OR Processes.process = *.htm.exe OR Processes.process = *.html.exe OR Processes.process = *.txt.exe OR Processes.process = *.pdf.exe OR Processes.process = *.doc.exe by Processes.dest Processes.user Processes.process Processes.parent_process | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name(Processes)`

[ESCU - Extended Period Without Successful Netbackup Backups - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search returns a list of hosts that have not successfully completed a backup in over a week.
action.escu.mappings = {"cis20": ["CIS 10"], "nist": ["PR.IP"]}
action.escu.eli5 = This search finds all the successful backup messages in your logs, and then looks for the most recent backup time for each system. It then identifies those systems where the most recent successful backup time is over a week ago, and reports on them.
action.escu.how_to_implement = To successfully implement this search you need to first obtain data from your backup solution, either from the backup logs on your hosts, or from a central server responsible for performing the backups. If you do not use Netbackup, you can modify this search for your backup solution. Depending on how often you backup your systems, you may want to modify how far in the past to look for a successful backup, other than the default of seven days.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-06-15
action.escu.modification_date = 2017-09-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Extended Period Without Successful Netbackup Backups - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Netbackup"]
action.escu.analytic_story = ["Monitor Backup Solution"]
cron_schedule = 0 0 1 * *
dispatch.earliest_time = -7d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Extended Period Without Successful Netbackup Backups
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The system $dest$ has not had a successful backup for an extended period.
action.notable.param.rule_title = Extended period of no successful backups by $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - All backup logs for host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="netbackup_logs" MESSAGE="Disk/Partition backup completed successfully." | stats latest(_time) as latestTime by COMPUTERNAME | `ctime(latestTime)` | rename COMPUTERNAME as dest | eval isOutlier=if(latestTime <= relative_time(now(), "-7d@d"), 1, 0) | search isOutlier=1 | table latestTime, dest

[ESCU - File with Samsam Extension - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for file writes with extensions consistent with a SamSam ransomware attack.
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Installation"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at file modifications across your hosts and creates notable events when it identifies files with extensions associated with the SamSam ransomware, including `.stubbin`, `.berkshire`, `.satoshi`, `.sophos`, or `.keyxml`. Files with these extensions have been observed in SamSam attacks consisting of payload data or keying material.
action.escu.how_to_implement = You must be ingesting data that records file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = Because these extensions are not typically used in normal operations, you should investigate all results.
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.confidence = high
action.escu.full_search_name = ESCU - File with Samsam Extension - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = File with Samsam Extension
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file with an extension associated with SamSam ransomware was written on $dest$.
action.notable.param.rule_title = File with known SamSam extension detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem by Filesystem.file_name | `drop_dm_object_name(Filesystem)` | `ctime(lastTime)` | `ctime(firstTime)`| rex field=file_name "(?<file_extension>\.[^\.]+)$" | search file_extension=.stubbin OR file_extension=.berkshire OR file_extension=.satoshi OR file_extension=.sophos OR file_extension=.keyxml

[ESCU - First Time Seen Running Windows Service - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the first time a Windows service is seen running in your environment.
action.escu.mappings = {"mitre_attack": ["Execution", "New Service"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "cis20": ["CIS 2", "CIS 9"], "nist": ["ID.AM", "PR.DS", "PR.AC", "DE.AE"]}
action.escu.eli5 = This search looks for a change in the status of a Windows service and extracts the name of the service and the action taken by the service. Then the cache file of previously seen Windows services is added to the search. At this point, the search takes two different paths: the first updates the cache file with the latest information and the second searches for services that have never before been seen. It returns the time, the Windows host name, and the service name.
action.escu.how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows security-event logs in order for this search to execute successfully. The support search, `Previously Seen Running Windows Services`, should be run before this search to create the baseline of known Windows services.
action.escu.known_false_positives = A previously unseen service is not necessarily malicious. Verify that the service is legitimate and that was installed by a legitimate process.
action.escu.creation_date = 2018-07-22
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - First Time Seen Running Windows Service - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Orangeworm Attack Group", "Windows Service Abuse"]
cron_schedule = 30 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = First Time Seen Running Windows Service
action.notable = 1
action.notable.param.nes_fields = serviceName
action.notable.param.rule_description = The service $serviceName$ is running on $dest$. This is the first time this service has been run on any system.
action.notable.param.rule_title = First Time Seen Windows Service $serviceName$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = serviceName, dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = eventtype=wineventlog_system signature_id=7036 | rex field=Message "The (?<serviceName>[\w\s-]*) service entered the (?<action>\w*) state" | where action="running" | inputlookup append=t previously_seen_running_windows_services | multireport [| stats earliest(eval(coalesce(_time, firstTime))) as firstTime, latest(eval(coalesce(_time, lastTime))) as lastTime by serviceName | outputlookup previously_seen_running_windows_services | where fact=fiction] [| eventstats earliest(eval(coalesce(_time, firstTime))) as firstTime, latest(eval(coalesce(_time, lastTime))) as lastTime by serviceName | where firstTime >= relative_time(now(), "-60m@m") AND isnotnull(_time) | stats values(dest) as dest by _time, serviceName] | table _time, serviceName, dest

[ESCU - First time seen command line argument - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for command-line arguments that use a <code>/c</code> parameter to execute a command that has not previously been seen.
action.escu.mappings = {"mitre_attack": ["Execution", "Scripting", "Persistence", "Command-Line Interface"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The subsearch returns all events where `cmd.exe` was used with a `/c` parameter in the command-line arguments to execute other commands/programs. It appends the historical data to those results in the lookup file. Next, it recalculates the `firstTime` and `lastTime` field for command-line execution and outputs this data to the lookup file to update the local cache. It returns only those events that have first been seen in the past one hour. This is combined with the main search to return the time, user, destination, process, parent process, and value of the command-line argument.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must be ingesting logs with both the process name and command line from your endpoints. The complete process name with command-line arguments are mapped to the "process" field in the Endpoint data model. Please make sure you run the support search "Previously seen command line arguments,"&#151;which creates a lookup file called `previously_seen_cmd_line_arguments.csv`&#151;a historical baseline of all command-line arguments. You must also validate this list. For the search to do accurate calculation, ensure the search scheduling is the same value as the `relative_time` evaluation function.
action.escu.known_false_positives = Legitimate programs can also use command-line arguments to execute. Please verify the command-line arguments to check what command/program is being executed.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2019-03-04
action.escu.confidence = medium
action.escu.full_search_name = ESCU - First time seen command line argument - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Hidden Cobra Malware", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Suspicious Command-Line Executions"]
cron_schedule = 30 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = First time seen command line argument
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = The system $dest$ executed a command-line argument, $process$, that has not previously been seen.
action.notable.param.rule_title = First-time seen command-line argument was detected on $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process, process
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = cmd.exe Processes.process = "* /c *" by Processes.process Processes.process_name Processes.parent_process_name Processes.dest| `drop_dm_object_name(Processes)`| `ctime(firstTime)` | `ctime(lastTime)` | search [| tstats `summariesonly` earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = cmd.exe Processes.process = "* /c *" by Processes.process | `drop_dm_object_name(Processes)` | inputlookup append=t previously_seen_cmd_line_arguments | stats min(firstTime) as firstTime, max(lastTime) as lastTime by process | outputlookup previously_seen_cmd_line_arguments | eval newCmdLineArgument=if(firstTime >= relative_time(now(), "-70m@m"), 1, 0) | where newCmdLineArgument=1 | `ctime(firstTime)` | `ctime(lastTime)` | table process]

[ESCU - Hiding Files And Directories With Attrib.exe - Rule]
action.escu = 0
action.escu.enabled = 1
description = Attackers leverage an existing Windows binary, attrib.exe, to mark specific as hidden by using specific flags so that the victim does not see the file.  The search looks for specific command-line arguments to detect the use of attrib.exe to hide files.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search is looking to detect command-line execution with of attrib.exe binary with the +h flag set.  The +h flag is used to hide a file.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Some applications and users may legitimately use attrib.exe to interact with the files. 
action.escu.creation_date = 2017-10-23
action.escu.modification_date = 2018-11-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Hiding Files And Directories With Attrib.exe - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = 
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Defense Evasion Tactics", "Windows Persistence Techniques"]
cron_schedule = 30 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Hiding Files And Directories With Attrib.exe
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = Attrib.exe is often used by attackers to hide malware files and directories in windows environments. This rule detects command-line arguments used to hide a file/directory
action.notable.param.rule_title = Suspicious usage of attrib.exe on $dest$ 
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) values(Processes.process) as process max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=attrib.exe (Processes.process=*+h*) by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name("Processes")` | `ctime(firstTime)`|`ctime(lastTime)`

[ESCU - Hosts receiving high volume of network traffic from email server - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
action.escu.mappings = {"mitre_attack": ["Collection", "Commonly Used Port"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 7"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search may look complex, but it's a neat representation of how statistics can help you understand your dataset to bubble up events that are not normal compared to its behavior. The search consists of three parts. The first part of the SPL fetches the data you want to work on. In this search, we calculate the sum of bytes sent and bytes_out from systems categorized as email_server to each host. We then calculate the average and standard deviation for the bytes sent to all the hosts combined and on a per-host basis. Then we set threshold values to deviation_threshold and minimum_data_samples using eval statements. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.  We then check for byte transfers that are statistically significantly higher than normal. The search then gives IP address of the host, the time of the increased byte transfer, how much data was transferred, and the average amount of data transfer the email server normally sends to all hosts and to this specific host. Finally, it includes the number of standard deviations away the byte count was from these averages.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic and populating the Network_Traffic data model.  Your email servers must be categorized as "email_server" for the search to work, as well. You may need to adjust the deviation_threshold and minimum_data_samples values based on the network traffic in your environment. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.
action.escu.known_false_positives = The false-positive rate will vary based on how you set the deviation_threshold and data_samples values. Our recommendation is to adjust these values based on your network traffic to and from your email servers.
action.escu.creation_date = 2017-12-20
action.escu.modification_date = 2017-12-20
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Hosts receiving high volume of network traffic from email server - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 0 * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Hosts receiving high volume of network traffic from email server
action.notable = 1
action.notable.param.nes_fields = src_ip
action.notable.param.rule_description = $src_ip$ receiving high volume of traffic that originated from an email server
action.notable.param.rule_title = High volume traffic from email server received by $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` sum(All_Traffic.bytes_in) as bytes_in from datamodel=Network_Traffic where All_Traffic.dest_category=email_server by All_Traffic.src_ip _time span=1d | `drop_dm_object_name("All_Traffic")` | eventstats avg(bytes_in) as avg_bytes_in stdev(bytes_in) as stdev_bytes_in | eventstats count as num_data_samples avg(eval(if(_time < relative_time(now(), "@d"), bytes_in, null))) as per_source_avg_bytes_in stdev(eval(if(_time < relative_time(now(), "@d"), bytes_in, null))) as per_source_stdev_bytes_in by src_ip | eval minimum_data_samples = 4, deviation_threshold = 3 | where num_data_samples >= minimum_data_samples AND bytes_in > (avg_bytes_in + (deviation_threshold * stdev_bytes_in)) AND bytes_in > (per_source_avg_bytes_in + (deviation_threshold * per_source_stdev_bytes_in)) AND _time >= relative_time(now(), "@d") | eval num_standard_deviations_away_from_server_average = round(abs(bytes_in - avg_bytes_in) / stdev_bytes_in, 2), num_standard_deviations_away_from_client_average = round(abs(bytes_in - per_source_avg_bytes_in) / per_source_stdev_bytes_in, 2) | table src_ip, _time, bytes_in, avg_bytes_in, per_source_avg_bytes_in, num_standard_deviations_away_from_server_average, num_standard_deviations_away_from_client_average

[ESCU - Identify New User Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This detection search will help profile user accounts in your environment by identifying newly created accounts that have been added to your network in the past week.
action.escu.mappings = {"mitre_attack": ["Valid Accounts"], "cis20": ["CIS 16"], "nist": ["PR.IP"]}
action.escu.data_models = ["Identity_Management"]
action.escu.eli5 = Adversaries will often seek to create new user accounts as a means of maintaining access to a target environment. Using this search, we identify accounts created in the last week by comparing the start date in the Identity_Management data model against the current time.
action.escu.how_to_implement = To successfully implement this search, you need to be populating the Enterprise Security Identity_Management data model in the assets and identity framework.
action.escu.known_false_positives = If the Identity_Management data model is not updated regularly, this search could give you false positive alerts. Please consider this and investigate appropriately.
action.escu.creation_date = 2017-08-05
action.escu.modification_date = 2017-09-12
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Identify New User Accounts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Domain Server
action.escu.fields_required = []
action.escu.providing_technologies = ["Active Directory"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 0 * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Identify New User Accounts
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = Using the identities lookup and macro from Enterprise Security to identify (report) new users (6 month period) and temp users (3 months until account expiration)
action.notable.param.rule_title = Identify Temporary Users
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get Notable Info\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Logon Rights Modifications For User\nESCU - Get Logon Rights Modifications For Endpoint\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = identity
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | from datamodel Identity_Management.All_Identities  | eval empStatus=case((now()-startDate)<604800, "Accounts created in last week") | search empStatus="Accounts created in last week"| `ctime(endDate)` | `ctime(startDate)`| table identity empStatus endDate startDate

[ESCU - Large Volume of DNS ANY Queries - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search is used to identify attempts to use your DNS Infrastructure for DDoS purposes via a DNS amplification attack leveraging ANY queries.
action.escu.mappings = {"kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 11", "CIS 12"], "nist": ["PR.PT", "DE.AE", "PR.IP"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search counts the number of DNS ANY queries received in 5 minutes, and generates a Notable Event if the count exceeds a predefined threshold. The search returns the count, the first time, and the last time a DNS packet was observed with the ANY flag set.
action.escu.how_to_implement = To successfully implement this search you must ensure that DNS data is populating the Network_Resolution data model.
action.escu.known_false_positives = Legitimate ANY requests may trigger this search, however it is unusual to see a large volume of them under typical circumstances. You may modify the threshold in the search to better suit your environment.
action.escu.creation_date = 2016-08-24
action.escu.modification_date = 2017-09-20
action.escu.confidence = high
action.escu.full_search_name = ESCU - Large Volume of DNS ANY Queries - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = DNS Servers
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["DNS Amplification Attacks"]
cron_schedule = */5 * * * *
dispatch.earliest_time = -15m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Large Volume of DNS ANY Queries
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The search is used to identify attempts to use your DNS Infrastructure for DDoS purposes via a DNS amplification attack leveraging ANY queries.
action.notable.param.rule_title = Large Volume of DNS ANY Queries
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 7200s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count from datamodel=Network_Resolution where nodename=DNS "DNS.message_type"="QUERY" "DNS.record_type"="ANY" by "DNS.dest" | `drop_dm_object_name("DNS")` | where count>200

[ESCU - Malicious PowerShell Process - Connect To Internet With Hidden Window - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes started with parameters to modify the execution policy of the run, run in a hidden window, and connect to the Internet. This combination of command-line options is suspicious because it's overriding the default PowerShell execution policy, attempts to hide its activity from the user, and connects to the Internet.
action.escu.mappings = {"mitre_attack": ["Execution", "PowerShell", "Scripting"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 7", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes running with specific command-line arguments that indicate that the process will download a file from the Internet without display anything to the user. The search for "*-Exec*" is to check and see if the default execution policy for PowerShell is being overridden on the command-line. The search for "*-WindowStyle*" and "*hidden*" are to see if the window that would normally be displayed will be hidden from the user instead. Finally, the search for "*New-Object*" and "*System.Net.WebClient*" are there to check to see if a PowerShell object that can be used to download files will be created. This search will return the host, the user the process ran under, the process and it's command-line arguments, the number of times it's seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Legitimate process can have this combination of command-line options, but it's not common.
action.escu.creation_date = 2016-09-18
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Connect To Internet With Hidden Window - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Malicious PowerShell Process - Connect To Internet With Hidden Window
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = The system $dest$ executed a PowerShell process that connects to the Internet with a hidden window.
action.notable.param.rule_title = Malicious PowerShell Process detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = process_name, dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)` | search process="*-Exec*" process="*-WindowStyle*" process="*hidden*" process="*New-Object*" process="*System.Net.WebClient*"

[ESCU - Malicious PowerShell Process - Encoded Command - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes that have encoded the script within the command-line. Malware has been seen using this parameter, as it obfuscates the code and makes it relatively easy to pass a script on the command-line.
action.escu.mappings = {"mitre_attack": ["Execution", "PowerShell", "Scripting"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 7", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes that are passing encoded commands on the command-line. The flags "-EncodedCommand" and "-enc" are two different possible flags that can be used to pass base64 encoded commands to PowerShell.  This search will return the host, the user the process ran under, the process and it's command-line arguments, the number of times it's seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = System administrators may use this option, but it's not common.
action.escu.creation_date = 2016-09-18
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Encoded Command - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Malicious PowerShell Process - Encoded Command
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = The system $dest$ executed a PowerShell process that has an encoded command on the command-line
action.notable.param.rule_title = PowerShell process with an encoded command detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user, process_name
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)` | search process=*-EncodedCommand* OR  process=*-enc*

[ESCU - Malicious PowerShell Process - Execution Policy Bypass - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes started with parameters used to bypass the local execution policy for scripts. These parameters are often observed in attacks leveraging PowerShell scripts as they override the default PowerShell execution policy.
action.escu.mappings = {"mitre_attack": ["Execution", "PowerShell", "Scripting"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 7", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes that were launched using a parameter designed to bypass the local PowerShell execution policy. By default, the policy is set to "Restricted," which disables the execution of PowerShell scripts. In environments that make heavy use of PowerShell, the policy can be set to allow only scripts signed by a trusted publisher. Malicious PowerShell use almost always includes the parameter `-ExecutionPolicy bypass`. PowerShell is very liberal when it comes to interpreting command-line parameters passed to it. For example, the parameter we look for, `-ExecutionPolicy`, can be abbreviated to `-Execution`, `-Exec`, or even `-ex`. As such, we look for `* -ex*`, which should catch all variations of this parameter, followed by the keyword `bypass`. This search will return the host, the user the process ran under, the process and its command-line arguments, the number of times it has seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = There may be legitimate reasons to bypass the PowerShell execution policy. The PowerShell script being run with this parameter should be validated to ensure that it is legitimate.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Execution Policy Bypass - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 50 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Malicious PowerShell Process - Execution Policy Bypass
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = The system $dest$ executed a PowerShell process with parameters to bypass the local execution policy.
action.notable.param.rule_title = PowerShell process with -executionpolicy bypass detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)`| search process=* -ex* OR process=* bypass *

[ESCU - Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes started with a base64 encoded command-line passed to it, with parameters to modify the execution policy for the process, and those that prevent the display of an interactive prompt to the user. This combination of command-line options is suspicious because it overrides the default PowerShell execution policy, attempts to hide itself from the user, and passes an encoded script to be run on the command-line.
action.escu.mappings = {"mitre_attack": ["Execution", "PowerShell", "Scripting"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 7", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes that have a number of suspicious flags on the command-line. It is looking for flags are passing encoded commands on the command-line. The flags `-EncodedCommand` and `-enc` are two different possible flags that can be used to pass base64 encoded commands to PowerShell. The `*-Exec*` flag looks to see it the default execution policy of PowerShell is being overridden, while the `*-NonI*` flag tells the PowerShell process that this will be a noninteractive process, so the user doesn't know about the process. This search will return the host, the user the process ran under, the process and it's command-line arguments, the number of times it's seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Legitimate process can have this combination of command-line options, but it's not common.
action.escu.creation_date = 2016-09-18
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell"]
cron_schedule = 50 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments
action.notable = 1
action.notable.param.nes_fields = dest, user, process, process_name
action.notable.param.rule_description = The system $dest$ executed a PowerShell that had an encoded command on the command-line, attempted to bypass local execution policy, and prevented the display of an interactive prompt to the user.
action.notable.param.rule_title = PowerShell process with multiple suspicious command-line arguments detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)`| search (process=*-EncodedCommand* OR process=*-enc*) process=*-Exec* AND process=*-NonI*

[ESCU - Malicious PowerShell Process With Obfuscation Techniques - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for PowerShell processes launched with arguments that have characters indicative of obfuscation on the command-line.
action.escu.mappings = {"mitre_attack": ["Execution", "PowerShell", "Scripting"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 7", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for PowerShell processes that are passing command-line arguments with unusual characters (backticks and carets) that are PowerShell specific escape characters. Attackers use this obfuscation technique since it does not affect the functionality of PowerShell and it will bypass standard security controls that look for straight up malicious strings and commands. The search counts the occurrence of these obfuscation characters and lists out destination IPs running these PowerShell commands.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = These characters might be legitimately on the command-line, but it is not common.
action.escu.creation_date = 2017-04-25
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Malicious PowerShell Process With Obfuscation Techniques - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Malicious PowerShell Process With Obfuscation Techniques
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name, process
action.notable.param.rule_description = The system $dest$ executed a PowerShell process that has evidence of obfuscation on the command-line
action.notable.param.rule_title = PowerShell process with an obfuscation techniques detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process_name,process
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=powershell.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)`| eval num_obfuscation = (mvcount(split(process, "`"))-1) + (mvcount(split(process, "^"))-1) | search num_obfuscation > 0

[ESCU - Monitor DNS For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for DNS requests for faux domains similar to the domains that you want to have monitored for abuse.
action.escu.mappings = {"kill_chain_phases": ["Delivery", "Actions on Objectives"]}
action.escu.data_models = ["Network_Resolution"]
action.escu.eli5 = This search gathers all the answers to each system's DNS query, then filters out all queries that do not appear on the list of faux "look-a-like" domains that have been generated from the brand abuse domains you are monitoring.
action.escu.how_to_implement = You need to ingest data from your DNS logs. Specifically you must ingest the domain that is being queried and the IP of the host originating the request. Ideally, you should also be ingesting the answer to the query and the query type. This approach allows you to also create your own localized passive DNS capability which can aid you in future investigations. You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2017-09-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Monitor DNS For Brand Abuse - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Brand Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Monitor DNS For Brand Abuse
action.notable = 1
action.notable.param.nes_fields = src, query
action.notable.param.rule_description = The host $src$ issued a DNS request for a domain to that which you are monitoring for brand abuse.
action.notable.param.rule_title = DNS Query Brand Abuse from $src$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Email Info\nESCU - Get Emails From Specific Sender\nESCU - Investigate Web Activity From Host\nESCU - Get DNS Server History for a host\nESCU - Get Process responsible for the DNS traffic\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src,query
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(DNS.answer) as IPs min(_time) as firstTime from datamodel=Network_Resolution by DNS.src, DNS.query | `drop_dm_object_name("DNS")` | `ctime(firstTime)`| `brand_abuse_dns`

[ESCU - Monitor Email For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for emails claiming to be sent from a domain similar to one that you want to have monitored for abuse.
action.escu.mappings = {"kill_chain_phases": ["Delivery"], "cis20": ["CIS 7"], "nist": ["PR.IP"]}
action.escu.data_models = ["Email"]
action.escu.eli5 = This search looks at the sender address in email headers, and identifies those with a sender address using a domain name that matches the list of permutations generated for the domain you want to monitor.
action.escu.how_to_implement = You need to ingest email header data. Specifically the sender's address (src_user) must be populated.  You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2018-01-05
action.escu.confidence = high
action.escu.full_search_name = ESCU - Monitor Email For Brand Abuse - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Exchange", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Brand Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Monitor Email For Brand Abuse
action.notable = 1
action.notable.param.nes_fields = src_user, message_id
action.notable.param.rule_description = The sender $src_user$ has sent an email from a similar domain to that which you are monitoring for brand abuse.
action.notable.param.rule_title = Possible Brand Abuse from $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Email Info\nESCU - Get Emails From Specific Sender\nESCU - Investigate Web Activity From Host\nESCU - Get DNS Server History for a host\nESCU - Get Process responsible for the DNS traffic\n"}
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = message_id, src_user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(All_Email.recipient) as recipients, min(_time) as firstTime, max(_time) as lastTime from datamodel=Email by All_Email.src_user, All_Email.message_id | `drop_dm_object_name("All_Email")` | `ctime(firstTime)` | `ctime(lastTime)` | eval temp=split(src_user, "@") | eval email_domain=mvindex(temp, 1) | lookup update=true brandMonitoring_lookup domain as email_domain OUTPUT domain_abuse | search domain_abuse=true | table message_id, src_user, email_domain, recipients, firstTime, lastTime

[ESCU - Monitor Registry Keys for Print Monitors - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for registry activity associated with modifications to the registry key <code>HKLM\SYSTEM\CurrentControlSet\Control\Print\Monitors</code>. In this scenario, an attacker can load an arbitrary .dll into the print-monitor registry by giving the full path name to the after.dll. The system will execute the .dll with elevated (SYSTEM) permissions and will persist after reboot.
action.escu.mappings = {"mitre_attack": ["Persistence", "Privilege Escalation", "Local Port Monitor"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8", "CIS 5"], "nist": ["PR.PT", "DE.CM", "PR.AC"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = In this search, we look for modifications to registry keys used for adding print-monitor entries on Microsoft platforms via the `registry_path` field in the endpoint data model. It then provides the destination, command used to initiate the change, the user who conducted this activity, the resource affected (registry_key_name), and the entire path of the registry.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report registry modifications.
action.escu.known_false_positives = You will encounter noise from legitimate print-monitor registry entries.
action.escu.creation_date = 2017-12-01
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Monitor Registry Keys for Print Monitors - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Monitor Registry Keys for Print Monitors
action.notable = 1
action.notable.param.nes_fields = dest, user, registry_path
action.notable.param.rule_description = A registry key associated with adding print monitors can potentially be misused by giving it a path of a malicious .dll in the registry.
action.notable.param.rule_title = Registry Key changes for Print Monitors detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, registry_path
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where Registry.action=modified AND Registry.registry_path="*CurrentControlSet\\Control\\Print\\Monitors*" by Registry.dest, Registry.registry_key_name Registry.status Registry.user Registry.registry_path Registry.action | `drop_dm_object_name(Registry)`

[ESCU - Monitor Web Traffic For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for Web requests to faux domains similar to the one that you want to have monitored for abuse.
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 7"], "nist": ["PR.IP"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks at all the URLs an endpoint is connecting to and then checks the URL against a list of faux domains that could be indicative of brand abuse.
action.escu.how_to_implement = You need to ingest data from your web traffic. This can be accomplished by indexing data from a web proxy, or using a network traffic analysis tool, such as Bro or Splunk Stream. You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2017-09-23
action.escu.confidence = high
action.escu.full_search_name = ESCU - Monitor Web Traffic For Brand Abuse - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.analytic_story = ["Brand Monitoring"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Monitor Web Traffic For Brand Abuse
action.notable = 1
action.notable.param.nes_fields = src, url
action.notable.param.rule_description = The host $src$ connected to a web site with a domain similar to that which you are monitoring for brand abuse.
action.notable.param.rule_title = Web URL Brand Abuse from $src$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Email Info\nESCU - Get Emails From Specific Sender\nESCU - Investigate Web Activity From Host\nESCU - Get DNS Server History for a host\nESCU - Get Process responsible for the DNS traffic\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Web.url) as urls min(_time) as firstTime from datamodel=Web by Web.src | `drop_dm_object_name("Web")` | `ctime(firstTime)` | `brand_abuse_web`

[ESCU - No Windows Updates in a time frame - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for Windows endpoints that have not generated an event indicating a successful Windows update in the last 60 days. Windows updates are typically released monthly and applied shortly thereafter. An endpoint that has not successfully applied an update in this time frame indicates the endpoint is not regularly being patched for some reason.
action.escu.mappings = {"cis20": ["CIS 18"], "nist": ["PR.PT", "PR.MA"]}
action.escu.data_models = ["Updates"]
action.escu.eli5 = Keeping your systems up-to-date with the latest patches is an important step in keeping your systems secured. For Windows endpoints, Microsoft typically releases patches on the second Tuesday of every month. These patches contain fixes for vulnerabilities in the system that could potentially be exploited by malicious actors. This search checks for messages regarding Windows updates in the 'Update' data model. If a message indicating a successful update has not been observed in 60 days, a notable event will be generated. These systems should be checked to determine why it has not been updated in that time frame.
action.escu.how_to_implement = To successfully implement this search, it requires that the 'Update' data model is being populated. This can be accomplished by ingesting Windows events or the Windows Update log via a universal forwarder on the Windows endpoints you wish to monitor. The Windows add-on should be also be installed and configured to properly parse Windows events in Splunk. There may be other data sources which can populate this data model, including vulnerability management systems.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-08-15
action.escu.modification_date = 2017-09-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - No Windows Updates in a time frame - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Monitor for Updates"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = No Windows Updates in a time frame
action.notable = 1
action.notable.param.nes_fields = src, user
action.notable.param.rule_description = The system $src$ has not generated a successful Windows Update event in 60 days or more.
action.notable.param.rule_title = No Windows updates in last 60 days on $src$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats summariesonly=true allow_old_summaries=true latest(_time) as latestTime from datamodel=Updates where Updates.status=Installed Updates.vendor_product="Microsoft Windows" by Updates.dest Updates.status Updates.vendor_product | rename Updates.dest as Host | rename Updates.status as "Update Status" | rename Updates.vendor_product as Product | eval isOutlier=if(latestTime <= relative_time(now(), "-60d@d"), 1, 0)  | `ctime(latestTime)`  | search isOutlier=1 | rename latestTime as "Last Update Time", | table Host, "Update Status", Product, "Last Update Time"

[ESCU - Open Redirect in Splunk Web - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to look for evidence of exploitation for CVE-2016-4859, the Splunk Open Redirect Vulnerability.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability"], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 3", "CIS 4", "CIS 18"], "nist": ["ID.RA", "RS.MI", "PR.PT", "PR.AC", "PR.IP", "DE.CM"]}
action.escu.data_models = []
action.escu.eli5 = This search looks within Splunk's internal logs for evidence of CVE-2016-4859 open redirect exploitation attempts.
action.escu.how_to_implement = No extra steps needed to implement this search.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-19
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Open Redirect in Splunk Web - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Splunk Server
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Enterprise"]
action.escu.analytic_story = ["Splunk Enterprise Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Open Redirect in Splunk Web
action.notable = 1
action.notable.param.nes_fields = host
action.notable.param.rule_description = Search for exploitation of the Splunk Open Redirect Vulnerability
action.notable.param.rule_title = Open Redirect in Splunk Web
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\n"}
action.risk = 1
action.risk.param._risk_object = host
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = host
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = index=_internal sourcetype=splunk_web_access return_to="/%09/*"

[ESCU - Osquery pack - ColdRoot detection - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for ColdRoot events from the osx-attacks osquery pack.
action.escu.mappings = {"mitre_attack": ["Execution", "Persistence", "Command and Control"], "kill_chain_phases": ["Installation", "Command and Control"], "cis20": ["CIS 4", "CIS 8"], "nist": ["DE.DP", "DE.CM", "PR.PT"]}
action.escu.data_models = ["Alerts"]
action.escu.eli5 = The search looks at the Alerts data model to identify those  generated from the osquery osx-attacks.conf pack, which search for the ColdRoot RAT.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from your osquery deployed agents with the [osx-attacks.conf](https://github.com/facebook/osquery/blob/experimental/packs/osx-attacks.conf#L599) pack enabled. Also the [TA-OSquery](https://github.com/d1vious/TA-osquery) must be deployed across your indexers and universal forwarders in order to have the osquery data populate the Alerts data model
action.escu.known_false_positives = There are no known false positives.
action.escu.creation_date = 2019-01-29
action.escu.modification_date = 2019-01-29
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Osquery pack - ColdRoot detection - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["OSquery"]
action.escu.analytic_story = ["ColdRoot MacOS RAT"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Osquery pack - ColdRoot detection
action.notable = 1
action.notable.param.nes_fields = host, user
action.notable.param.rule_description = Host $host$ generated an alert for the macOS RAT ColdRoot
action.notable.param.rule_title = Osquery ColdRoot alert for $host$
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Investigate Network Traffic From src_ip\nESCU - Investigate Web Activity From src_ip\n"}
action.risk = 1
action.risk.param._risk_object = host
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = host
alert.suppress.period = 3600s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | from datamodel Alerts.Alerts | search app=osquery:results (name=pack_osx-attacks_OSX_ColdRoot_RAT_Launchd OR name=pack_osx-attacks_OSX_ColdRoot_RAT_Files) | rename columns.path as path | bucket _time span=30s | stats count(path) by _time, host, user, path

[ESCU - Overwriting Accessibility Binaries - Rule]
action.escu = 0
action.escu.enabled = 1
description = Microsoft Windows contains accessibility features that can be launched with a key combination before a user has logged in. An adversary can modify or replace these programs so they can get a command prompt or backdoor without logging in to the system. This search looks for modifications to these binaries.
action.escu.mappings = {"mitre_attack": ["Persistence", "Accessibility Features"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns all the different accessibility binaries that have been modified for each Windows host.
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = Microsoft may provide updates to these binaries. Verify that these changes do not correspond with your normal software update cycle.
action.escu.creation_date = 2017-12-07
action.escu.modification_date = 2018-11-15
action.escu.confidence = high
action.escu.full_search_name = ESCU - Overwriting Accessibility Binaries - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Windows Privilege Escalation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Overwriting Accessibility Binaries
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file, $file_name$, was created in the default shim database directory on $dest.
action.notable.param.rule_title = Modification to accessibility binary, $file_path$, was detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_path) as file_path from datamodel=Endpoint.Filesystem where (Filesystem.file_path=*\Windows\System32\sethc.exe* OR Filesystem.file_path=*\Windows\System32\utilman.exe* OR Filesystem.file_path=*\Windows\System32\osk.exe* OR Filesystem.file_path=*\Windows\System32\Magnify.exe* OR Filesystem.file_path=*\Windows\System32\Narrator.exe* OR Filesystem.file_path=*\Windows\System32\DisplaySwitch.exe* OR Filesystem.file_path=*\Windows\System32\AtBroker.exe*) by Filesystem.file_name Filesystem.dest | `drop_dm_object_name(Filesystem)` | `ctime(lastTime)` | `ctime(firstTime)`

[ESCU - Process Execution via WMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launched via WMI.
action.escu.mappings = {"mitre_attack": ["Execution", "Windows Management Instrumentation"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers are increasingly abusing Windows Management Infrastructure (WMI) for stealth, persistence, lateral movement, or just to leverage its functionality. This search looks for processes launched via WMI, either remotely or locally, by looking for processes launched by WmiPrvSE.exe, which is the process WMI uses to execute new processes and commands.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Although unlikely, administrators may use wmi to execute commands for legitimate purposes.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Process Execution via WMI - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Process Execution via WMI
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for child processes of WmiPrvSE.exe, which indicates that a process was launched via WMI.
action.notable.param.rule_title = Process launched via WMI on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Sysmon WMI Activity for Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name = "scrcons.exe" by Processes.user Processes.dest Processes.process_name  | `drop_dm_object_name("Processes")` | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Processes Tapping Keyboard Events - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes in an MacOS system that is tapping keyboard events in MacOS, and essentially monitoring all keystrokes made by a user. This is a common technique used by RATs to log keystrokes from a victim, although it can also be used by legitimate processes like Siri to react on human input
action.escu.mappings = {"mitre_attack": ["Collection"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 4", "CIS 8"], "nist": ["DE.DP"]}
action.escu.data_models = ["Alerts"]
action.escu.eli5 = The search leverages Alerts generated from the osquery osx-attacks.conf pack search `Keyboard_Event_Taps` to detect when a process is monitoring the keystrokes of a machine, This is a common technique used by macOS remote access trojans to log keystrokes from a machine
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from your osquery deployed agents with the [osx-attacks.conf](https://github.com/facebook/osquery/blob/experimental/packs/osx-attacks.conf#L599) pack enabled. Also the [TA-OSquery](https://github.com/d1vious/TA-osquery) must be deployed across your indexers and universal forwarders in order to have the osquery data populate the Alerts data model.
action.escu.known_false_positives = There might be some false positives as keyboard event taps are used by processes like Siri and Zoom video chat, for some good examples of processes to exclude please see [this](https://github.com/facebook/osquery/pull/5345#issuecomment-454639161) comment.
action.escu.creation_date = 2019-01-25
action.escu.modification_date = 2019-01-25
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Processes Tapping Keyboard Events - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["OSquery"]
action.escu.analytic_story = ["ColdRoot MacOS RAT"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Processes Tapping Keyboard Events
action.notable = 1
action.notable.param.nes_fields = host, cmd, process_id
action.notable.param.rule_description = Host $host$ has process $process_id$ tapping keyboard events with command $cmd$
action.notable.param.rule_title = Host $host has process $process_id$ monitoring its keystrokes
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Investigate Network Traffic From src_ip\nESCU - Investigate Web Activity From src_ip\n"}
action.risk = 1
action.risk.param._risk_object = host
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = host
alert.suppress.period = 3600s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | from datamodel Alerts.Alerts | search app=osquery:results name=pack_osx-attacks_Keyboard_Event_Taps | rename columns.cmdline as cmd, columns.name as process_name, columns.pid as process_id| dedup host,process_name | table host,process_name, cmd, process_id

[ESCU - Processes created by netsh - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launching netsh.exe to execute various commands via the netsh command-line utility. Netsh.exe is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper .dll when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe that are executing commands via the command line.
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface", "Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for all processes with the parent process "c:\Windows\System32\netsh.exe" and returns the process, the command line used to execute it, the host name, and the user context under which it ran.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting logs with the process name, command-line arguments, and parent processes from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = It is unusual for netsh.exe to have any child processes in most environments. It makes sense to investigate the child process and verify whether the process spawned is legitimate.
action.escu.creation_date = 2018-01-04
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Processes created by netsh - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Netsh Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Processes created by netsh
action.notable = 1
action.notable.param.nes_fields = dest, process, parent_process
action.notable.param.rule_description = A process, $process$, is spawned by netsh.exe. It is highly unlikely for netsh to have any child processes.
action.notable.param.rule_title = Process spawned by netsh.exe detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.parent_process="C:\Windows\System32\netsh.exe" by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name("Processes")` | `ctime(firstTime)`|`ctime(lastTime)`

[ESCU - Processes launching netsh - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for processes launching netsh.exe. Netsh is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper DLL when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe and executing commands via the command line.
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface", "Persistence", "Defense Evasion", "Disabling Security Tools"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for all the parent processes of netsh.exe and returns that process, the command-line used to execute it, the host name, and the user context under which it ran.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model
action.escu.known_false_positives = Some VPN applications are known to launch netsh.exe. Outside of these instances, it is unusual for an executable to launch netsh.exe and run commands.
action.escu.creation_date = 2017-01-08
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Processes launching netsh - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Netsh Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Processes launching netsh
action.notable = 1
action.notable.param.nes_fields = dest, process, parent_process, cmdline
action.notable.param.rule_description = A process detected on $dest$ is launching netsh.exe. 
action.notable.param.rule_title = Process launching netsh.exe detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, parent_process
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process=netsh.exe by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name("Processes")` | `ctime(firstTime)`|`ctime(lastTime)`

[ESCU - Prohibited Network Traffic Allowed - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic defined by port and transport layer protocol in the Enterprise Security lookup table "lookup_interesting_ports", that is marked as prohibited, and has an associated 'allow' action in the Network_Traffic data model. This could be indicative of a misconfigured network device.
action.escu.mappings = {"mitre_attack": ["Command and Control", "Commonly Used Port", "Exfiltration", "Exfiltration Over Alternative Protocol"], "kill_chain_phases": ["Delivery", "Command and Control"], "cis20": ["CIS 9", "CIS 12"], "nist": ["DE.AE", "PR.AC"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = The search looks for traffic marked 'is_prohibited' in the Enterprise Security lookup table 'interesting_ports_lookup', and then determines if any network devices have an associated 'allow' action on that traffic by checking the Network_Traffic data model.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from firewalls or other network control devices that mediate the traffic allowed into an environment. This is necessary so that the search can identify an 'action' taken on the traffic of interest. The search requires the Network_Traffic data model be populated.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-04-18
action.escu.modification_date = 2017-09-11
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Prohibited Network Traffic Allowed - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Palo Alto Firewall", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Command and Control", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Prohibited Network Traffic Allowed
action.notable = 1
action.notable.param.nes_fields = src_ip, dest_ip
action.notable.param.rule_description = This search looks for network traffic defined by port and transport in the ES lookup table "lookup_interesting_ports", that is marked as prohibited, and yet has an 'allow' action in the Network_Traffic data model. This should help to identify areas where a network device is not properly configured.
action.notable.param.rule_title = Prohibited Network Traffic Allowed from $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip,src_ip
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.action = allowed by All_Traffic.src_ip All_Traffic.dest_ip All_Traffic.dest_port All_Traffic.action | lookup update=true interesting_ports_lookup dest_port as All_Traffic.dest_port OUTPUT app is_prohibited note transport | search is_prohibited=true | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - Prohibited Software On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for applications on the endpoint that you have marked as prohibited.
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Installation", "Command and Control", "Actions on Objectives"], "cis20": ["CIS 2"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns the number of times, as well as the first and last time, every process has run for each endpoint and user. It then displays only those processes that you have marked as "prohibited" in the Enterprise Security "Interesting Processes" table.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the processes node. This is typically populated via endpoint detection-and-response products, such as Carbon Black or endpoint data sources, such as Sysmon. The data used for this search is usually generated via logs that report reads and writes to the registry or populated via Windows event logs, after enabling process tracking in your Windows audit settings. In addition, you must also have processes marked as "prohibited" in the Enterprise Security `interesting processes` table. To include the processes marked as "prohibited", which is included with ES Content Updates, run the included search `Support - Add Prohibited Processes to ES`.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-06-26
action.escu.modification_date = 2010-11-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Prohibited Software On Endpoint - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Emotet Malware (TA18-201A)", "Monitor for Unauthorized Software", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Prohibited Software On Endpoint
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = Prohibited software $process_name$ has been detected on $dest$.
action.notable.param.rule_title = Prohibited Software Detected On $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.user Processes.process | `ctime(firstTime)`| `ctime(lastTime)` | `drop_dm_object_name(Processes)` | `prohibited_softwares`

[ESCU - Protocol or Port Mismatch - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic on common ports where a higher layer protocol does not match the port that is being used. For example, this search should identify cases where protocols other than HTTP are running on TCP port 80. This can be used by attackers to circumvent firewall restrictions, or as an attempt to hide malicious communications over ports and protocols that are typically allowed and not well inspected.
action.escu.mappings = {"mitre_attack": ["Command and Control", "Commonly Used Port"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 9", "CIS 12"], "nist": ["DE.AE", "PR.AC"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search looks for instances in which the protocol observed is not consistent with the port and transport protocol typically used for that protocol. For example, looking for network traffic other than HTTP running over TCP port 80. Such behavior could indicate a misconfiguration or a custom command and control protocol that has been designed to look like ordinary web traffic. The search will also identify if HTTP traffic is observed running on unexpected ports. This can be common in many environments.
action.escu.how_to_implement = Running this search properly requires a technology that can inspect network traffic and identify common protocols. Technologies such as Bro and Palo Alto Networks firewalls are two examples that will identify protocols via inspection, and not just assume a specific protocol based on the transport protocol and ports.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-04-18
action.escu.modification_date = 2017-09-11
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Protocol or Port Mismatch - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Palo Alto Firewall", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Command and Control", "Prohibited Traffic Allowed or Protocol Mismatch"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Protocol or Port Mismatch
action.notable = 1
action.notable.param.nes_fields = dest_ip, src_ip
action.notable.param.rule_description = This search looks for network traffic on common ports where the underlying protocol does not match the port being used. For example, this search should identify cases where protocols other than HTTP are running on port 80. This can be used by attackers to circumvent firewall restrictions, or as an attempt to hide malicious communications in traffic that is typically allowed and not well inspected.
action.notable.param.rule_title = Protocol / Port Mismatch from $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Information For Port Activity\n"}
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip, dest_port
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where (All_Traffic.app=dns NOT All_Traffic.dest_port=53) OR ((All_Traffic.app=web-browsing OR All_Traffic.app=http) NOT (All_Traffic.dest_port=80 OR All_Traffic.dest_port=8080 OR All_Traffic.dest_port=8000)) OR (All_Traffic.app=ssl NOT (All_Traffic.dest_port=443 OR All_Traffic.dest_port=8443)) OR (All_Traffic.app=smtp NOT All_Traffic.dest_port=25) by All_Traffic.src_ip, All_Traffic.dest_ip, All_Traffic.app, All_Traffic.dest_port |`ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - Protocols passing authentication in cleartext - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for cleartext protocols at risk of leaking credentials. Currently, this consists of legacy protocols such as telnet, POP3, IMAP, and non-anonymous FTP sessions. While some of these protocols can be used over SSL, they typically run on different assigned ports in those cases.
action.escu.mappings = {"mitre_attack": ["Credential Access", "Lateral Movement", "Collection"], "kill_chain_phases": ["Reconnaissance", "Actions on Objectives"], "cis20": ["CIS 9", "CIS 14"], "nist": ["PR.PT", "DE.AE", "PR.AC", "PR.DS"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search is checking for traffic on well-known ports that are associated with protocols that pass authentication in cleartext.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic, and populating the Network_Traffic data model.
action.escu.known_false_positives = Some networks may use kerberized FTP or telnet servers, however, this is rare.
action.escu.creation_date = 2017-08-03
action.escu.modification_date = 2017-09-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Protocols passing authentication in cleartext - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Use of Cleartext Protocols"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Protocols passing authentication in cleartext
action.notable = 1
action.notable.param.nes_fields = src, dest, user
action.notable.param.rule_description = This search looks for the use of cleartext protocols that are known to pass authentication information in the clear. The cleartext credentials are typically passed at the beginning of the session.
action.notable.param.rule_title = Possible credential leak over cleartext protocol
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Information For Port Activity\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.protocol="tcp" AND (All_Traffic.dest_port="23" OR All_Traffic.dest_port="143" OR All_Traffic.dest_port="110" OR (All_Traffic.dest_port="21" AND All_Traffic.user != "anonymous")) groupby All_Traffic.user All_Traffic.src All_Traffic.dest All_Traffic.dest_port | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - Reg.exe Manipulating Windows Services Registry Keys - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for reg.exe modifying registry keys that define Windows services and their configurations.
action.escu.mappings = {"mitre_attack": ["Persistence", "Privilege Escalation", "New Service", "Modify Existing Service", "Defense Evasion", "Disabling Security Tools"], "kill_chain_phases": ["Installation"], "cis20": ["CIS 3", "CIS 5", "CIS 8"], "nist": ["PR.IP", "PR.PT", "PR.AC", "PR.AT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for modifications to registry paths that specify the definition and configuration of Windows services by reg.exe. Reg.exe is a Windows utility that allows for manipulation of the registry via the command line. Malware often uses the Windows services architecture to persist, hide in plain sight, and gain the ability to interact with the Windows kernel. While it is common to modify the configuration of Windows services (and new services may be created with software installs), the use of reg.exe to create or modify a service configuration is unusual and a technique commonly used by attackers. The search returns the count, the first time the activity was seen, the last time activity was seen, the registry path that was modified, the host where the modification took place, and the user that performed the modification.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting information on registry changes that include the name of the process responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Registry` nodes.
action.escu.known_false_positives = It is unusual for a service to be created or modified by directly manipulating the registry. However, there may be legitimate instances of this behavior. It is important to validate and investigate, as appropriate.
action.escu.creation_date = 2018-6-29
action.escu.modification_date = 2019-03-01
action.escu.confidence = high
action.escu.full_search_name = ESCU - Reg.exe Manipulating Windows Services Registry Keys - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Persistence Techniques", "Windows Service Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Reg.exe Manipulating Windows Services Registry Keys
action.notable = 1
action.notable.param.nes_fields = dest, process
action.notable.param.rule_description = A registry key associated with Windows services was modified via reg.exe on $dest$ by $src_user$.
action.notable.param.rule_title = Modification of Windows Services Via Reg.exe on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name = reg.exe by Processes.process_id Processes.dest | `drop_dm_object_name("Processes")` | `ctime(firstTime)` | `ctime(lastTime)` | join [| tstats `summariesonly` values(Registry.registry_path) as registry_path count  FROM datamodel=Endpoint.Registry where Registry.registry_path="*\\services\\*" by Registry.process_id Registry.dest | `drop_dm_object_name("Registry")` | table process_id dest registry_path]

[ESCU - Reg.exe used to hide files/directories via registry keys - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for command-line arguments used to hide a file or directory using the reg add command.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Reg.exe is a binary native to Windows platform used to edit the registry hives of the system. Attackers can leverage this binary to hide files by passing in arguments that are used to hide the files. In the search, we first gather results with keywords, add, Hidden, and REG_DWORD, that will be in the raw event and filter by process and the command-line. We then leverage regular expressions on the command-line field to look for /d value as 2 which is responsible for hiding a file or directory.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None at the moment
action.escu.creation_date = 2017-10-27
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Reg.exe used to hide files/directories via registry keys - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = 
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Defense Evasion Tactics", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Reg.exe used to hide files/directories via registry keys
action.notable = 1
action.notable.param.nes_fields = dest, process
action.notable.param.rule_description = Regedit.exe is used by attackers to hide malware files/directories in windows environments via registry key settings. This rule detects command-line arguments used to hide a file/directory
action.notable.param.rule_title = Regedit.exe used to hide a file/directory on $dest$ 
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = reg.exe Processes.process="*add*" Processes.process="*Hidden*" Processes.process="*REG_DWORD*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `ctime(firstTime)` |`ctime(lastTime)`| regex process = "(/d\s+2)"

[ESCU - Registry Keys Used For Persistence - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for modifications to registry keys that can be used to launch an application or service at system startup.
action.escu.mappings = {"mitre_attack": ["Persistence", "Registry Run Keys / Start Folder", "AppInit DLLs", "Authentication Package"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for specific registry paths that malware often uses to ensure survivability and persistence on system startup. The search returns the count, the first time the activity was seen, the last time the activity was seen, the registry path that was modified, the host where the modification took place and the user that performed the modification.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = There are many legitimate applications that must execute on system startup and will use these registry keys to accomplish that task.
action.escu.creation_date = 2017-08-23
action.escu.modification_date = 2017-10-10
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Registry Keys Used For Persistence - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Suspicious MSHTA Activity", "Suspicious Windows Registry Activities", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Registry Keys Used For Persistence
action.notable = 1
action.notable.param.nes_fields = dest, user, registry_path
action.notable.param.rule_description = A registry key that is used for persistence on Windows was modified on $dest$ by $src_user$.
action.notable.param.rule_title = Registry Key Associated With Persistence Modified on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,registry_path
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where (Registry.registry_path=*currentversion\\run* OR Registry.registry_path=*currentVersion\\Windows\\Appinit_Dlls* OR Registry.registry_path=CurrentVersion\\Winlogon\\Shell* OR Registry.registry_path=*CurrentVersion\\Winlogon\\Userinit* OR Registry.registry_path=*CurrentVersion\\Winlogon\\VmApplet* OR Registry.registry_path=*currentversion\\policies\\explorer\\run* OR Registry.registry_path=*currentversion\\runservices* OR Registry.registry_path=*\\CurrentControlSet\\Control\\Lsa\\* OR Registry.registry_path="*Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options*" OR Registry.registry_path=HKLM\\SOFTWARE\\Microsoft\\Netsh\\*) by Registry.dest , Registry.status, Registry.user | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name(Registry)`

[ESCU - Registry Keys Used For Privilege Escalation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for modifications to registry keys that can be used to elevate privileges. The registry keys under "Image File Execution Options" are used to intercept calls to an executable and can be used to attach malicious binaries to benign system binaries.
action.escu.mappings = {"mitre_attack": ["Privilege Escalation", "Persistence", "Accessibility Features"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for specific registry paths that malware often uses to elevate privileges. The search returns the count, the first time the activity was seen, the last time the activity was seen, the registry path that was modified, the host where the modification took place, and the user who performed the modification.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records registry activity from your hosts to populate the endpoint data model in the registry node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = There are many legitimate applications that must execute upon system startup and will use these registry keys to accomplish that task.
action.escu.creation_date = 2017-12-07
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Registry Keys Used For Privilege Escalation - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Privilege Escalation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Registry Keys Used For Privilege Escalation
action.notable = 1
action.notable.param.nes_fields = dest, user, registry_path
action.notable.param.rule_description = A registry key used for privilege escalation was modified on $dest$ by $user$.
action.notable.param.rule_title = Registry Key Associated With Privilege Escalation Modified on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user, registry_path
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where (Registry.registry_path="*Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options*") by Registry.dest , Registry.status, Registry.user | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name(Registry)`

[ESCU - Registry Keys for Creating SHIM Databases - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for registry activity associated with application compatibility shims, which can be leveraged by attackers for various nefarious purposes.
action.escu.mappings = {"mitre_attack": ["Persistence", "Application Shimming"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Change_Analysis"]
action.escu.eli5 = In this search, we look for modifications to registry keys used for shim databases on Microsoft platforms via the object_category and object_path field in the Change_Analysis data model and give you the destination, command used to initiate the change, the user who conducted this activity, the resource affected(object), and the whole path of the object. An application compatibility shim is a small library that transparently intercepts an API (via hooking), changes the parameters passed, handles the operation itself, or redirects the operation elsewhere, such as additional code stored on a system. This capability can be also leveraged by attackers to create and store malicious files in a shim database as observed in CARBANAK backdoor.
action.escu.how_to_implement = To successfully implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or other endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = There are many legitimate applications that leverage shim databases for compatibility purposes for legacy applications
action.escu.creation_date = 2017-08-27
action.escu.modification_date = 2017-09-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Registry Keys for Creating SHIM Databases - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Registry Keys for Creating SHIM Databases
action.notable = 1
action.notable.param.nes_fields = dest, user
action.notable.param.rule_description = A registry key that is used for persistence on Windows was modified on $dest$ by $user$
action.notable.param.rule_title = Registry Key Associated With SHIM databases on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,object_path
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="*CurrentVersion\\AppCompatFlags\\Custom*" OR All_Changes.object_path="*CurrentVersion\\AppCompatFlags\\InstalledSDB*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `drop_dm_object_name("All_Changes")`

[ESCU - Remote Desktop Network Bruteforce - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for RDP application network traffic and filters any source/destination pair generating more than twice the standard deviation of the average traffic.
action.escu.mappings = {"mitre_attack": ["Credential Access", "Remote Desktop Protocol", "Lateral Movement"], "kill_chain_phases": ["Reconnaissance", "Delivery"], "cis20": ["CIS 12", "CIS 9", "CIS 16"], "nist": ["DE.AE", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search monitors for abnormal amounts of remote-desktop (RDP) traffic from a source to a destination that may be indicative of a brute-force attack. It does this by filtering out RDP traffic from the Network_Traffic.All_Traffic data model, using twice the standard deviation of all source-to-destination connections. If any tuple is within more than two standard deviations of all other usual RDP traffic flows, it is indicative of a brute-force attack.
action.escu.how_to_implement = You must ensure that your network traffic data is populating the Network_Traffic data model.
action.escu.known_false_positives = RDP gateways may have unusually high amounts of traffic from all other hosts' RDP applications in the network.
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote Desktop Network Bruteforce - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote Desktop Network Bruteforce
action.notable = 1
action.notable.param.nes_fields = dest, src
action.notable.param.rule_description = Remote-desktop traffic detected from $src$ to $dest$. This activity is consistent with a brute-force attack.
action.notable.param.rule_title = Bruteforce Remote Desktop Network Traffic detected from $src$ to $dest$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,src
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.app=rdp by All_Traffic.src All_Traffic.dest All_Traffic.dest_port | eventstats stdev(count) AS stdev avg(count) AS avg p50(count) AS p50| where count>(stdev*2) | rename All_Traffic.src AS src All_Traffic.dest AS dest | table firstTime lastTime src dest count avg p50 stdev

[ESCU - Remote Desktop Network Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic on TCP/3389, the default port used by remote desktop. While remote desktop traffic is not uncommon on a network, it is usually associated with known hosts. This search allows for whitelisting both source and destination hosts to remove them from the output of the search so you can focus on the uncommon uses of remote desktop on your network.
action.escu.mappings = {"mitre_attack": ["Lateral Movement", "Remote Desktop Protocol", "Commonly Used Port"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 9", "CIS 16"], "nist": ["DE.AE", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = This search finds systems that do not commonly communicate use remote desktop.  It does this by filtering out all systems that have the "common_rdp_source" or "common_rdp_destination" category applied to that system.  Categories are applied to systems using the Assets and Identity framework.
action.escu.how_to_implement = To successfully implement this search you need to identify systems that commonly originate remote desktop traffic and that commonly receive remote desktop traffic. You can use the included support search "Identify Systems Creating Remote Desktop Traffic" to identify systems that originate the traffic and the search "Identify Systems Receiving Remote Desktop Traffic" to identify systems that receive a lot of remote desktop traffic. After identifying these systems, you will need to add the "common_rdp_source" or "common_rdp_destination" category to that system depending on the usage, using the Enterprise Security Assets and Identities framework.  This can be done by adding an entry in the assets.csv file located in SA-IdentityManagement/lookups.
action.escu.known_false_positives = Remote Desktop may be used legitimately by users on the network.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-15
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote Desktop Network Traffic - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote Desktop Network Traffic
action.notable = 1
action.notable.param.nes_fields = dest, src
action.notable.param.rule_description = Remote Desktop Traffic detected between $src$ and $dest$.  These two systems typically do not communicate with RDP
action.notable.param.rule_title = Uncommon Remote Desktop Network Traffic between $src$ and $dest$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,src
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.dest_port=3389 AND All_Traffic.dest_category!=common_rdp_destination AND All_Traffic.src_category!=common_rdp_source by All_Traffic.src All_Traffic.dest All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Remote Desktop Process Running On System - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the remote desktop process mstsc.exe running on systems upon which it doesn't typically run. This is accomplished by filtering out all systems that are noted in the <code>common_rdp_source category</code> in the Assets and Identity framework.
action.escu.mappings = {"mitre_attack": ["Lateral Movement", "Remote Desktop Protocol"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 9", "CIS 16"], "nist": ["DE.AE", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search finds systems that do not commonly use remote desktop, but which begin using it. It filters out all systems that have the "common_rdp_source" category applied. Categories are applied to systems using the Assets and Identity framework.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts to populate the endpoint data model in the processes node. The search requires you to identify systems that do not commonly use remote desktop. You can use the included support search "Identify Systems Using Remote Desktop" to identify these systems. After identifying them, you will need to add the "common_rdp_source" category to that system using the Enterprise Security Assets and Identities framework. This can be done by adding an entry in the assets.csv file located in `SA-IdentityManagement/lookups`.
action.escu.known_false_positives = Remote Desktop may be used legitimately by users on the network.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2018-11-02
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote Desktop Process Running On System - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote Desktop Process Running On System
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = The system $dest$ is running the remote desktop process, mstsc.exe. This system does not commonly run this application.
action.notable.param.rule_title = Remote Desktop Process Running On $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process=mstsc.exe AND Processes.dest_category!=common_rdp_source by Processes.dest Processes.user Processes.process | `ctime(firstTime)`| `ctime(lastTime)` | `drop_dm_object_name(Processes)`

[ESCU - Remote Process Instantiation via WMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for wmic.exe being launched with parameters to spawn a process on a remote system.
action.escu.mappings = {"mitre_attack": ["Execution", "Windows Management Instrumentation"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers are increasingly abusing native Windows utilities such as wmic.exe as a means to "live off the land", and avoid introducing new executables to the target system. In this search, we are looking for instances of wmic.exe being run with various parameters that are not typically used by administrators.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = The wmic.exe utility is a benign Windows application. It may be used legitimately by Administrators with these parameters for remote system administration, but it's relatively uncommon.
action.escu.creation_date = 2017-01-13
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote Process Instantiation via WMI - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote Process Instantiation via WMI
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for wmic.exe being launched with parameters to spawn a process on a remote system.
action.notable.param.rule_title = Remote process instantiation via WMI on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Sysmon WMI Activity for Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = wmic.exe Processes.process="*/node*" Processes.process="*process*" Processes.process="*call*" Processes.process="*create*"   by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `ctime(firstTime)` |`ctime(lastTime)`

[ESCU - Remote Registry Key modifications - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search monitors for remote modifications to registry keys.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Persistence", "Lateral Movement"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for modifications made to the Windows registry from remote locations using reg.exe&#151;a tool used to create/update/delete/modify Windows registry keys. It is accomplished through specifying the machine names in the registry path, by entering double backslashes, followed by a computer name. In this search, we look for registry changes where the registry path contains the name of a remote computer. The search returns the number of times the remote server has been accessed, the first and last times the activity occurred, the name of the modified registry path, the host on which the modification took place, and the name of the user that performed the modification.
action.escu.how_to_implement = To successfully implement this search, you must populate the `Change_Analysis` data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.known_false_positives = This technique may be legitimately used by administrators to modify remote registries, so it's important to filter these events out.
action.escu.creation_date = 2018-05-31
action.escu.modification_date = 2018-05-31
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote Registry Key modifications - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Lateral Movement", "Suspicious Windows Registry Activities", "Windows Defense Evasion Tactics", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote Registry Key modifications
action.notable = 1
action.notable.param.nes_fields = dest, user
action.notable.param.rule_description = A registry key was modified remotely using the machine $dest$ by $user$.
action.notable.param.rule_title = Remote Registry Key Modification detection on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user,registry_path
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Registry.registry_key_name) as registry_key_name values(Registry.registry_path) as registry_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where  Registry.registry_path="\\\\*"  by Registry.dest , Registry.status, Registry.user | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name(Registry)`

[ESCU - Remote WMI Command Attempt - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for wmic.exe being launched with parameters to operate on remote systems.
action.escu.mappings = {"mitre_attack": ["Execution", "Windows Management Instrumentation"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Many a times, attackers leverage native Windows utilities that are designed to help administrators better manage their systems, infrastructure, and auditing, but are instead leveraged for malicious purposes. In this case, we are looking for instances of wmic.exe being run with various parameters that are not typically used by administrators.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators may use this legitimately to gather info from remote systems.
action.escu.creation_date = 2017-01-13
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Remote WMI Command Attempt - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 50 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Remote WMI Command Attempt
action.notable = 1
action.notable.param.nes_fields = dest,user,process_name
action.notable.param.rule_description = This search looks for wmic.exe being launched with parameters to operate on remote systems.
action.notable.param.rule_title = Endpoint - Remote WMI command attempt
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Sysmon WMI Activity for Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,process_name
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=wmic.exe  AND Processes.process= */node* by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - RunDLL Loading DLL By Ordinal - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for DLLs under %AppData% being loaded by rundll32.exe that are calling the exported function at ordinal 2. Calling exported functions by ordinal is not as common as calling by exported name. There was a bug fixed in IDAPro on 2016-08-08 that would not display functions without names.  Calling functions by ordinal would overcome the lack of name and make it harder for analyst to reverse engineer.
action.escu.mappings = {"mitre_attack": ["Execution", "Rundll32"], "kill_chain_phases": ["Installation"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for rundll32.exe being run, loading a DLL out of a directory or subdirectory of AppData, and specifying the function at ordinal 2 be run.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = While not common, loading a DLL under %AppData% and calling a function by ordinal is possible by a legitimate process
action.escu.creation_date = 2016-08-09
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - RunDLL Loading DLL By Ordinal - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = RunDLL Loading DLL By Ordinal
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for DLLs under %AppData% being loaded by rundll32.exe that are calling the exported function at ordinal 2.  Calling exported functions by ordinal is not as common as calling by exported name.  There was a bug fixed in IDAPro on 2016-08-08 that would not display functions with no names.  Calling functions by ordinal would overcome the lack of name and make it harder for analyst to reverse engineer.
action.notable.param.rule_title = Endpoint - Suspicious RunDLL usage
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = rundll32.exe Processes.process="*AppData*" Processes.process="*,#2" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - SMB Traffic Spike - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for spikes in the number of Server Message Block (SMB) traffic connections.
action.escu.mappings = {"mitre_attack": ["Commonly Used Port"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = Server Message Block (SMB) traffic, a protocol used for Windows file sharing-activity, is often leveraged by attackers. One example of SMB abuse was the WannaCry ransomware, which leveraged a vulnerability in the SMB protocol to propagate to other systems. Attackers have also used SMB for lateral movement with a target environment and to test credentials against target systems. While SMB is highly prevalent in Windows environments, a spike in SMB traffic may still be indicative of this type of malicious activity. This search looks for a traffic spike in SMB traffic from a particular system. If such a spike is detected, you may want to investigate the source and analyze the cause of the abnormal traffic.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic logs and populating the `Network_Traffic` data model.
action.escu.known_false_positives = A file server may experience high-demand loads that could cause this analytic to trigger.
action.escu.creation_date = 2017-08-20
action.escu.modification_date = 2017-09-10
action.escu.confidence = medium
action.escu.full_search_name = ESCU - SMB Traffic Spike - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -7d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = SMB Traffic Spike
action.notable = 1
action.notable.param.nes_fields = src
action.notable.param.rule_description = There was a spike in SMB traffic from $src$.
action.notable.param.rule_title = SMB Traffic Spike from $src$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb by _time span=1h, All_Traffic.src | `drop_dm_object_name("All_Traffic")` | eventstats max(_time) as maxtime | stats count as num_data_samples max(eval(if(_time >= relative_time(maxtime, "-70m@m"), count, null))) as count avg(eval(if(_time<relative_time(maxtime, "-70m@m"), count, null))) as avg stdev(eval(if(_time<relative_time(maxtime, "-70m@m"), count, null))) as stdev by src | eval upperBound=(avg+stdev*2), isOutlier=if(count > upperBound AND num_data_samples >=50, 1, 0) | where isOutlier=1 | table src count

[ESCU - SQL Injection with Long URLs - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for long URLs that have several SQL commands visible within them.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability", "Execution", "Commonly Used Port"], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 4", "CIS 13", "CIS 18"], "nist": ["PR.DS", "ID.RA", "PR.PT", "PR.IP", "DE.CM"]}
action.escu.data_models = ["Web"]
action.escu.eli5 = This search looks only at your web servers and returns the source, the web server, the URL and its length, and the user agent associated with HTTP GET requests for extremely long URLs or user agent lengths with more than three common SQL commands found within the URL.
action.escu.how_to_implement = To successfully implement this search, you need to be monitoring network communications to your web servers or ingesting your HTTP logs and populating the Web data model. You must also identify your web servers in the Enterprise Security assets table.
action.escu.known_false_positives = It's possible that legitimate traffic will have long URLs or long user agent strings and that common SQL commands may be found within the URL. Please investigate as appropriate.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-19
action.escu.confidence = medium
action.escu.full_search_name = ESCU - SQL Injection with Long URLs - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Database Server
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["SQL Injection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = SQL Injection with Long URLs
action.notable = 1
action.notable.param.nes_fields = dest, src, url
action.notable.param.rule_description = Using the length of url or user agent to identify SQL injection
action.notable.param.rule_title = SQL Injection with Long URLs
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,src,url
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count from datamodel=Web where Web.dest_category=web_server AND (Web.url_length > 1024 OR Web.http_user_agent_length > 200) by Web.src Web.dest Web.url Web.url_length Web.http_user_agent | `drop_dm_object_name("Web")` | eval num_sql_cmds=mvcount(split(url, "alter%20table")) + mvcount(split(url, "between")) + mvcount(split(url, "create%20table")) + mvcount(split(url, "create%20database")) + mvcount(split(url, "create%20index")) + mvcount(split(url, "create%20view")) + mvcount(split(url, "delete")) + mvcount(split(url, "drop%20database")) + mvcount(split(url, "drop%20index")) + mvcount(split(url, "drop%20table")) + mvcount(split(url, "exists")) + mvcount(split(url, "exec")) + mvcount(split(url, "group%20by")) + mvcount(split(url, "having")) + mvcount(split(url, "insert%20into")) + mvcount(split(url, "inner%20join")) + mvcount(split(url, "left%20join")) + mvcount(split(url, "right%20join")) + mvcount(split(url, "full%20join")) + mvcount(split(url, "select")) + mvcount(split(url, "distinct")) + mvcount(split(url, "select%20top")) + mvcount(split(url, "union")) + mvcount(split(url, "xp_cmdshell")) - 24 | where num_sql_cmds > 3

[ESCU - Samsam Test File Write - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for a file named "test.txt" written to the windows system directory tree, which is consistent with Samsam propagation.
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at file modifications across your hosts and monitors for a file named "test.txt" written to "windows\system32". This file is copied to potential targets during SamSam ransomware attacks to test the attacker's ability to access remote systems. If the file is successfully copied to the system, the system is added to a list of targets on which to deploy ransomware.
action.escu.how_to_implement = You must be ingesting data that records the file-system activity from your hosts to populate the Endpoint file-system data-model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = No false positives have been identified.
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.confidence = high
action.escu.full_search_name = ESCU - Samsam Test File Write - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Samsam Test File Write
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file named "test.txt," which is indicative of a SamSam ransomware attack, was written to system32 on $dest$.
action.notable.param.rule_title = File consistent with SamSam probes detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.user) as user values(Filesystem.dest) as dest values(Filesystem.file_name) as file_name from datamodel=Endpoint.Filesystem where Filesystem.file_path=*\\windows\\system32\\test.txt by Filesystem.file_path | `drop_dm_object_name(Filesystem)` | `ctime(lastTime)` | `ctime(firstTime)`

[ESCU - Sc.exe Manipulating Windows Services - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for arguments to sc.exe indicating the creation or modification of a Windows service.
action.escu.mappings = {"mitre_attack": ["Persistence", "Privilege Escalation", "New Service", "Modify Existing Service", "Defense Evasion", "Disabling Security Tools"], "kill_chain_phases": ["Installation"], "cis20": ["CIS 3", "CIS 5", "CIS 8"], "nist": ["PR.IP", "PR.PT", "PR.AC", "PR.AT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the execution of sc.exe with parameters that indicate the utility is being used to create a new Windows service, or modify an existing one. Attackers often create a new service to host their malicious code, or they may take a non-critical service or one that is disabled, and modify it to point to their malware and enable the service if necessary. It is unusual for a service to be created or modified using the sc.exe utility.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Using sc.exe to manipulate Windows services is uncommon. However, there may be legitimate instances of this behavior. It is important to validate and investigate as appropriate.
action.escu.creation_date = 2017-11-03
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Sc.exe Manipulating Windows Services - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Orangeworm Attack Group", "Windows Persistence Techniques", "Windows Service Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Sc.exe Manipulating Windows Services
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for arguments to sc.exe indicating the creation or modification of a Windows service.
action.notable.param.rule_title = Sc.exe Manipulating Windows Services on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = sc.exe Processes.process="* create *" Processes.process="* config *" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Scheduled Task Name Used by Dragonfly Threat Actors - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate a task name associated with the Dragonfly threat actor was created or deleted.
action.escu.mappings = {"mitre_attack": ["Execution", "Scheduled Task"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate that a specific task "reset," whose name is associated with the Dragonfly threat actor--has been created or deleted. Schtasks.exe is a native Windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or establish persistence.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = No known false positives
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Scheduled Task Name Used by Dragonfly Threat Actors - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Scheduled Task Name Used by Dragonfly Threat Actors
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command line that indicate that a task--whose name is associated with the Dragonfly threat actor--has been created or deleted
action.notable.param.rule_title = Scheduled task used by Dragonfly threat actor detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name, process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=schtasks.exe  by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)` | search (process=*delete* OR process=*create*) process=*reset*

[ESCU - Scheduled tasks used in BadRabbit ransomware - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate that task names related to the execution of Bad Rabbit ransomware were created or deleted.
action.escu.mappings = {"mitre_attack": ["Persistence", "Lateral Movement", "Execution", "Scheduled Task"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate that specific task names related to the Bad Rabbit ransomware were created or deleted. The specific task name used are rhaegal, drogon and viserion_. Schtasks.exe is a native windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or establish persistence.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = No known false positives
action.escu.creation_date = 2017-11-03
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Scheduled tasks used in BadRabbit ransomware - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Scheduled tasks used in BadRabbit ransomware
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command-line that indicate that task names specific to Bad Rabbit ransomware has been created or deleted
action.notable.param.rule_title = Scheduled tasks used in BadRabbit ransomware detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process_name
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process) as process  from datamodel=Endpoint.Processes where Processes.process_name=schtasks.exe (Processes.process= "*create*"  OR Processes.process= "*delete*") by Processes.parent_process Processes.process_name Processes.user | `drop_dm_object_name("Processes")` | `ctime(firstTime)`|`ctime(lastTime)` | search (process=*rhaegal* OR process=*drogon* OR *viserion_*)

[ESCU - Schtasks scheduling job on remote system - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate a job is being scheduled on a remote system.
action.escu.mappings = {"mitre_attack": ["Persistence", "Lateral Movement", "Execution", "Scheduled Task", "Remote Services"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate a task is being scheduled on a remote host. Schtasks.exe is a native windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or malicious executables on remote systems.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Administrators may create jobs on remote systems, but this activity is usually limited to a small set of hosts or users. It is important to validate and investigate as appropriate.
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Schtasks scheduling job on remote system - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Lateral Movement"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Schtasks scheduling job on remote system
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command-line that indicate a job is being scheduled on a remote system.
action.notable.param.rule_title = Schtasks scheduling job on remote system
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = schtasks.exe Processes.process="*/create*" Processes.process="* /s *" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Schtasks used for forcing a reboot - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for flags passed to schtasks.exe on the command-line that indicate that a forced reboot of system is scheduled.
action.escu.mappings = {"mitre_attack": ["Persistence", "Execution", "Scheduled Task"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate a task is being scheduled that would cause a forced reboot on the host. Schtasks.exe is a native windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or establish persistence. This tactic is leveraged by the Bad Rabbit Ransomware.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = Administrators may create jobs on systems forcing reboots to perform updates, maintenance, etc.
action.escu.creation_date = 2017-11-03
action.escu.modification_date = 2019-02-27
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Schtasks used for forcing a reboot - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -5h@h
dispatch.latest_time = -1h@h
action.correlationsearch.enabled = 1
action.correlationsearch.label = Schtasks used for forcing a reboot
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for flags passed to schtasks.exe on the command-line that indicate a job is scheduled to force a reboot
action.notable.param.rule_title = Schtasks used for scheduling a force reboot
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = schtasks.exe Processes.process="*shutdown*" Processes.process="*/r*" Processes.process="*/f*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Script Execution via WMI - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for scripts launched via WMI.
action.escu.mappings = {"mitre_attack": ["Execution", "Windows Management Instrumentation"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = Attackers are increasingly abusing Windows Management Infrastructure for stealth, persistence, lateral movement, or just to leverage its functionality. This search looks for scripts launched via WMI, either remotely or locally, by looking for the execution of scrcons.exe, which is the scripting host used by WMI, similar to wscript or cscript.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Although unlikely, administrators may use wmi to launch scripts for legitimate purposes.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2019-03-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Script Execution via WMI - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Script Execution via WMI
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for scrcons.exe, which indicates that a script was launched via WMI.
action.notable.param.rule_title = Script execution via WMI on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Sysmon WMI Activity for Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name = "scrcons.exe" by Processes.user Processes.dest Processes.process_name  | `drop_dm_object_name("Processes")` | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Shim Database File Creation - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for shim database files being written to default directories. The sdbinst.exe application is used to install shim database files (.sdb). According to Microsoft, a shim is a small library that transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
action.escu.mappings = {"mitre_attack": ["Persistence", "Application Shimming"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for files being created in `Windows\AppPatch\Custom and Windows\AppPatch\Custom64`, the location where shim databases are installed. It will return all the files created, as well as the time of creation for the first and last file for each endpoint.
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. If you are using Sysmon, you will need a Splunk Universal Forwarder on each endpoint from which you want to collect data.
action.escu.known_false_positives = Because legitimate shim files are created and used all the time, this event, in itself, is not suspicious. However, if there are other correlating events, it may warrant further investigation.
action.escu.creation_date = 2017-10-03
action.escu.modification_date = 2018-11-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Shim Database File Creation - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Shim Database File Creation
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file, $file_name$, was created in the default shim database directory on $dest.
action.notable.param.rule_title = Shim database file created on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Filesystem.action) values(Filesystem.file_hash) as file_hash values(Filesystem.file_path) as file_path  min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem where Filesystem.file_path=*Windows\AppPatch\Custom* by Filesystem.file_name Filesystem.dest | `ctime(lastTime)` | `ctime(firstTime)` |`drop_dm_object_name(Filesystem)`

[ESCU - Shim Database Installation With Suspicious Parameters - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects the process execution and arguments required to silently create a shim database.  The sdbinst.exe application is used to install shim database files (.sdb). A shim is a small library which transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
action.escu.mappings = {"mitre_attack": ["Persistence", "Application Shimming"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the execution of sdbinst.exe with command-line arguments of -q and -p.  The -q option performs a silent installation with no visible window, status, or warning information.  The -p option allows the shim database to contain patches.  It will return the count, the first time, and the last time these command-line arguments were seen on each endpoint and by each user.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-10-03
action.escu.modification_date = 2019-03-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Shim Database Installation With Suspicious Parameters - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Persistence Techniques"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Shim Database Installation With Suspicious Parameters
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = The system $dest$ had a shim database installed.
action.notable.param.rule_title = Shim Database Installation on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = sdbinst.exe Processes.process="*-p*" Processes.process="*-q*" by Processes.process_name Processes.parent_process_name Processes.dest Processes.user | `drop_dm_object_name(Processes)` | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Short Lived Windows Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects accounts that were created and deleted in a short time period.
action.escu.mappings = {"mitre_attack": ["Valid Accounts"], "cis20": ["CIS 16"], "nist": ["PR.IP"]}
action.escu.data_models = ["Change_Analysis"]
action.escu.eli5 = This search looks for Windows Event Logs 4720 (account creation) and 4726 (account deletion) and determines if they happen for the same user within 4 hours of each other.  It will report the user and machine that reported the events and the time it first and last saw this activity.
action.escu.how_to_implement = This search requires you to have enabled your Group Management Audit Logs in your Local Windows Security Policy and be ingesting those logs.  More information on how to enable them can be found here: http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/
action.escu.known_false_positives = It is possible that an administrator created and deleted an account in a short time period.  Verifying activity with an administrator is advised.
action.escu.creation_date = 2018-01-05
action.escu.modification_date = 2018-01-05
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Short Lived Windows Accounts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
cron_schedule = 0 0,4,8,12,16,20 * * *
dispatch.earliest_time = -245m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Short Lived Windows Accounts
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = The account $user$ was created and deleted in a short amount of time.
action.notable.param.rule_title = Short lived account $user$ on $dest
action.notable.param.security_domain = access
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get Notable Info\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Logon Rights Modifications For User\nESCU - Get Logon Rights Modifications For Endpoint\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Change_Analysis where All_Changes.result_id=4720 OR All_Changes.result_id=4726 by All_Changes.result_id All_Changes.user All_Changes.dest | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes")` | transaction user maxspan=240m  | search result_id=4720 result_id=4726

[ESCU - Single Letter Process On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for process names that consist only of a single letter.
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 2"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns all the processes for each endpoint and user and filters out any process that isn't 5 characters long and ends with .exe.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = Single-letter executables are not always malicious. Investigate this activity with your normal incident-response process.
action.escu.creation_date = 2018-03-22
action.escu.modification_date = 2019-04-01
action.escu.confidence = high
action.escu.full_search_name = ESCU - Single Letter Process On Endpoint - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Single Letter Process On Endpoint
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = A process with a single letter, $process_name$ was detected on $dest$
action.notable.param.rule_title = Single-letter executable $process_name$ on $dest$.
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest, Processes.user, Processes.process, Processes.process_name | `drop_dm_object_name(Processes)` | `ctime(lastTime)` | `ctime(firstTime)` | eval process_name_length = len(process_name), endExe = if(substr(process_name, -4) == ".exe", 1, 0) | search process_name_length=5 AND endExe=1 | table count, firstTime, lastTime, dest, user, process, process_name

[ESCU - Spectre and Meltdown Vulnerable Systems - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search is used to detect systems that are still vulnerable to the Spectre and Meltdown vulnerabilities.
action.escu.mappings = {"cis20": ["CIS 4"], "nist": ["ID.RA", "RS.MI", "PR.IP", "DE.CM"]}
action.escu.data_models = ["Vulnerabilities"]
action.escu.eli5 = This search looks for the three CVEs associated with the Spectre and Meltdown vulnerabilities.
action.escu.how_to_implement = The search requires that you are ingesting your vulnerability-scanner data and that it reports the CVE of the vulnerability identified.
action.escu.known_false_positives = It is possible that your vulnerability scanner is not detecting that the patches have been applied.
action.escu.creation_date = 2018-01-07
action.escu.modification_date = 2017-01-07
action.escu.confidence = high
action.escu.full_search_name = ESCU - Spectre and Meltdown Vulnerable Systems - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Nessus", "Qualys"]
action.escu.analytic_story = ["Spectre And Meltdown Vulnerabilities"]
cron_schedule = 0 6 * * *
dispatch.earliest_time = -25h@h
dispatch.latest_time = -1h@h
action.correlationsearch.enabled = 1
action.correlationsearch.label = Spectre and Meltdown Vulnerable Systems
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = $dest is vulnerable to the Spectre or Meltdown CPU vulnerabilities.
action.notable.param.rule_title = $dest is vulnerable to the Spectre or Meltdown CPU vulnerabilities
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 100
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Vulnerabilities where Vulnerabilities.cve ="CVE-2017-5753" OR Vulnerabilities.cve ="CVE-2017-5715" OR Vulnerabilities.cve ="CVE-2017-5754" by Vulnerabilities.dest

[ESCU - Spike in File Writes - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for a sharp increase in the number of files written to a particular host
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search calculates counts the number of file modification events per hour per host in your environment. It then takes the average and standard deviations of those numbers and displays any hosts with more than 20 events that have over four times the standard deviation more than the average number of file modifications.
action.escu.how_to_implement = In order to implement this search, you must populate the Endpoint file-system data model node. This is typically populated via endpoint detection and response products, such as Carbon Black or endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the file system.
action.escu.known_false_positives = It is important to understand that if you happen to install any new applications on your hosts or are copying a large number of files, you can expect to see a large increase of file modifications.
action.escu.creation_date = 2017-08-20
action.escu.modification_date = 2018-12-03
action.escu.confidence = low
action.escu.full_search_name = ESCU - Spike in File Writes - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "SamSam Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -7d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Spike in File Writes
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = A sharp increase in file writes was detected on $dest
action.notable.param.rule_title = Spike in file writes on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = low
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Investigate Successful Remote Desktop Authentications\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 7200s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count FROM datamodel=Endpoint.Filesystem where Filesystem.action=created by _time span=1h, Filesystem.dest | `drop_dm_object_name(Filesystem)` | eventstats max(_time) as maxtime | stats count as num_data_samples max(eval(if(_time >= relative_time(maxtime, "-1d@d"), count, null))) as "count" avg(eval(if(_time<relative_time(maxtime, "-1d@d"), count,null))) as avg stdev(eval(if(_time<relative_time(maxtime, "-1d@d"), count, null))) as stdev by "dest" | eval upperBound=(avg+stdev*4), isOutlier=if((count > upperBound) AND num_data_samples >=20, 1, 0) | search isOutlier=1

[ESCU - Splunk Enterprise Information Disclosure - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search allows you to look for evidence of exploitation for CVE-2018-11409, a Splunk Enterprise Information Disclosure Bug.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability"], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 3", "CIS 4", "CIS 18"], "nist": ["ID.RA", "RS.MI", "PR.PT", "PR.AC", "PR.IP", "DE.CM"]}
action.escu.eli5 = This search searches Splunk's internal logs for evidence of CVE-2018-11409 exploitation attempts.
action.escu.how_to_implement = The REST endpoint that exposes system information is also necessary for the proper operation of Splunk clustering and instrumentation. Whitelisting your Splunk systems will reduce false positives.
action.escu.known_false_positives = Retrieving server information may be a legitimate API request. Verify that the attempt is a valid request for information.
action.escu.creation_date = 2018-06-14
action.escu.modification_date = 2018-06-14
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Splunk Enterprise Information Disclosure - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Splunk Server
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Enterprise"]
action.escu.analytic_story = ["Splunk Enterprise Vulnerability CVE-2018-11409"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Splunk Enterprise Information Disclosure
action.notable = 1
action.notable.param.nes_fields = dest, src_ip
action.notable.param.rule_description = The Splunk Server $dest$ had a possible Splunk information-disclosure possibility from $src_ip$
action.notable.param.rule_title = Possible Splunk Information Disclosure Exploitation Attempt from $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get Risk Modifiers For Endpoint\nESCU - Investigate Web Activity From src_ip\nESCU - Investigate Network Traffic From src_ip\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, src_ip
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = index=_internal sourcetype=splunkd_ui_access server-info | search clientip!=127.0.0.1 uri_path="*raw/services/server/info/server-info" | rename clientip as src_ip, splunk_server as dest | stats earliest(_time) as firstTime, latest(_time) as lastTime, values(uri) as uri, values(useragent) as http_user_agent, values(user) as user by src_ip, dest | convert ctime(firstTime) ctime(lastTime)

[ESCU - Suspicious Changes to File Associations - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for changes to registry values that control Windows file associations, executed by a process that is not typical for legitimate, routine changes to this area.
action.escu.mappings = {"mitre_attack": ["Persistence", "Change Default File Association"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 8"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for changes made to the registry that control Windows file associations. It is typical for users to change the file association to open certain types of files with specific applications. However, when these changes are legitimately performed, they are typically done via the processes explorer.exe or openwith.exe. The search first executes the subsearch that looks at the Registry node, which specifies setting a value in the registry and creates a table of process_id and dest. It then uses those arguments to find out what process and parent process were responsible for making those registry changes.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting information on registry changes that include the name of the process responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Registry` nodes.
action.escu.known_false_positives = There may be other processes in your environment that users may legitimately use to modify file associations. If this is the case and you are finding false positives, you can modify the search to add those processes as exceptions.
action.escu.creation_date = 2018-01-26
action.escu.modification_date = 2018-01-26
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious Changes to File Associations - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious Windows Registry Activities", "Windows File Extension and Association Abuse"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious Changes to File Associations
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name, process
action.notable.param.rule_description = The system $dest$ had an unusual change to a file association
action.notable.param.rule_title = Suspicious File Association Change on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name!=Explorer.exe AND Processes.process_name!=OpenWith.exe by Processes.process_id Processes.dest | `drop_dm_object_name("Processes")` | `ctime(firstTime)` | `ctime(lastTime)` | join [| tstats `summariesonly` values(Registry.registry_path) as registry_path count  FROM datamodel=Endpoint.Registry where Registry.registry_path=*\\Explorer\\FileExts* by Registry.process_id Registry.dest | `drop_dm_object_name("Registry")` | table process_id dest registry_path]

[ESCU - Suspicious Email Attachment Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for emails that have attachments with suspicious file extensions.
action.escu.mappings = {"mitre_attack": ["Execution", "Defense Evasion"], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 3", "CIS 7", "CIS 12"], "nist": ["DE.AE", "PR.IP"]}
action.escu.data_models = ["Email"]
action.escu.eli5 = This search looks at any email messages with attachments and checks the file names of those attachments against an included lookup file to see if it has a suspicious file extension.
action.escu.how_to_implement = You need to ingest data from emails. Specifically, the sender's address and the file names of any attachments must be mapped to the Email data model.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-04-20
action.escu.modification_date = 2017-09-19
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious Email Attachment Extensions - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.analytic_story = ["Emotet Malware (TA18-201A)", "Suspicious Emails"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious Email Attachment Extensions
action.notable = 1
action.notable.param.nes_fields = src_user, file_name
action.notable.param.rule_description = The sender $src_user$ has sent an email with a suspicious file named $file_name$
action.notable.param.rule_title = Suspicious Email Attachment from $src_user$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Email Info\nESCU - Get Emails From Specific Sender\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user,message_id
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Email where All_Email.file_name="*" by All_Email.src_user, All_Email.file_name All_Email.message_id | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Email")` | `suspicious_email_attachments`

[ESCU - Suspicious File Write - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for files created with names that have been linked to malicious activity.
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks at files being created or modified in the Endpoint file-system data model. The names of those files are checked against an included lookup file, which contains the names of files associated with malware or attack activity. The search returns any files with matching names, along with a note (also specified in the lookup file) that gives or points to more information about the files.
action.escu.how_to_implement = You must be ingesting data that records the filesystem activity from your hosts to populate the Endpoint file-system data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or via other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file system reads and writes. In addition, this search leverages an included lookup file that contains the names of the files to watch for, as well as a note to communicate why that file name is being monitored. This lookup file can be edited to add or remove file the file names you want to monitor.
action.escu.known_false_positives = It's possible for a legitimate file to be created with the same name as one noted in the lookup file. Filenames listed in the lookup file should be unique enough that collisions are rare. Looking at the location of the file and the process responsible for the activity can help determine whether or not the activity is legitimate.
action.escu.creation_date = 2018-06-14
action.escu.modification_date = 2019-04-25
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious File Write - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Hidden Cobra Malware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious File Write
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A write to a filename associated with malicious activity detected on $dest$.
action.notable.param.rule_title = Suspicious File Write Detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\nESCU - Get Outbound Emails to Hidden Cobra Threat Actors\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Filesystem.action) as action values(Filesystem.file_path) as file_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem by Filesystem.file_name Filesystem.dest | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name(Filesystem)` | `suspicious_writes`

[ESCU - Suspicious Java Classes - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for suspicious Java classes that are often used to exploit remote command execution in common Java frameworks, such as Apache Struts.
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Exploitation"], "cis20": ["CIS 7", "CIS 12"], "nist": ["DE.AE"]}
action.escu.eli5 = The search leverages HTTP form data from typically POST events that can be captured with Splunk streams or similar wire data capture tools. The search looks for java classes like `processbuilder` and `runtime` are used to create a new process and execute commands inside java, and are synonymous with spawning a shell. There are very exceptional reasons to ever these classes in Java via an HTTP API and hence when seen are highly suspicious. Also, this is a common vectors leverage to exploit Apache Struts.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from your web-traffic appliances that serve or sit in the path of your Struts application servers. This can be accomplished by indexing data from a web proxy, or by using network traffic-analysis tools, such as Splunk Stream or Bro.
action.escu.known_false_positives = There are no known false positives.
action.escu.creation_date = 2018-12-06
action.escu.modification_date = 2018-12-06
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious Java Classes - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Apache"]
action.escu.analytic_story = ["Apache Struts Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious Java Classes
action.notable = 1
action.notable.param.nes_fields = src, url, http_user_agent
action.notable.param.rule_description = The host $src$ with user agent $http_user_agent$ is sending web traffic to $url$, which contains suspicious Java classes. These classes may be indicative of remote code execution in Java frameworks, such as Apache Struts.
action.notable.param.rule_title = Suspicious Java Classes: Possible RCE against Struts or similar Java framework from $src$
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Investigate Suspicious Strings in HTTP Header\nESCU - Investigate Web POSTs From src\n"}
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src, url, http_user_agent
alert.suppress.period = 3600s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="stream:http" http_method=POST http_content_length>1 | regex form_data="(?i)java\.lang\.(?:runtime|processbuilder)" | rename src_ip as src | stats count earliest(_time) as firstTime, latest(_time) as lastTime, values(url) as uri, values(status) as status, values(http_user_agent) as http_user_agent by src, dest | convert ctime(firstTime) ctime(lastTime)

[ESCU - Suspicious LNK file launching a process - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for a ``*.lnk` file under `C:\User*` or `*\Local\Temp\*` executing a process. This is common behavior used by various spear phishing tools.
action.escu.mappings = {"mitre_attack": ["Spearphishing Attachment"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "cis20": ["CIS 7", "CIS 8"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = In this search, we are essentially trying to detect if a LNK file created under the C:\User* or *\Local\Temp\* directory structures is launching a process with in 1 hour of its creation. LNK files or also known as Windows shortcut files are commonly associated with phishing and are a [preferred method used for exploitation](https://www.fireeye.com/blog/threat-research/2017/04/fin7-phishing-lnk.html).
action.escu.how_to_implement = You must be ingesting data that records filesystem and process activity from your hosts to populate the Endpoint data model. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or endpoint data sources, such as Sysmon.
action.escu.known_false_positives = This detection should yield little or no false positive results. It is uncommon for LNK files to execute process from temporary or user directories.
action.escu.creation_date = 2019-04-29
action.escu.modification_date = 2019-04-29
action.escu.confidence = high
action.escu.full_search_name = ESCU - Suspicious LNK file launching a process - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = ["dest"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Phishing Payloads"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious LNK file launching a process
action.notable = 1
action.notable.param.nes_fields = dest, process_name, file_name
action.notable.param.rule_description = suspicious LNK file from $file_name$ is executing a process $process_name$ on $dest$
action.notable.param.rule_title = LNK file $file_name$ is executing process $process_name$ on $dest$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = 
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,file_name
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem where Filesystem.file_name="*.lnk" AND (Filesystem.file_path="C:\\Users*" OR Filesystem.file_path="*Local\\Temp*")  by _time span=1h Filesystem.process_id Filesystem.file_name Filesystem.file_path Filesystem.file_hash Filesystem.user | `drop_dm_object_name(Filesystem)` | rename process_id as lnk_pid | join lnk_pid, _time [| tstats `summariesonly` count FROM datamodel=Endpoint.Processes where Processes.process_name=*  by _time span=1h Processes.parent_process_id Processes.process_id Processes.process_name Processes.dest Processes.process_path Processes.process | `drop_dm_object_name(Processes)` | rename parent_process_id as lnk_pid | fields _time lnk_pid process_id dest process_name process_path process] | `ctime(firstTime)` | `ctime(lastTime)` | table firstTime, lastTime, lnk_pid, process_id, user, dest, file_name, file_path, process_name, process, process_path, file_hash

[ESCU - Suspicious Reg.exe Process - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for reg.exe being launched from a command prompt not started by the user. When a user launches cmd.exe, the parent process is usually explorer.exe. This search filters out those instances.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Modify Registry", "Disabling Security Tools"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the execution of reg.exe with a parent process of cmd.exe. It then executes a subsearch looking for those cmd.exe processes with a parent that is not explorer.exe. It then joins those two searches to make sure that the reg.exe process is a grandchild of the non explorer.exe process. The search will return the number of such instances and the first and last time this activity has been seen on each endpoint and user.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = It's possible for system administrators to write scripts that exhibit this behavior. If this is the case, the search will need to be modified to filter them out.
action.escu.creation_date = 2017-10-11
action.escu.modification_date = 2019-03-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious Reg.exe Process - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Windows Defense Evasion Tactics"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious Reg.exe Process
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = The system $dest$ had reg.exe process run not initiated by a user.
action.notable.param.rule_title = Suspicious reg.exe process detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.parent_process_name != explorer.exe Processes.process_name =cmd.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest Processes.process_id Processes.parent_process_id | `drop_dm_object_name("Processes")` | `ctime(firstTime)` | `ctime(lastTime)` | search [| tstats `summariesonly` count FROM datamodel=Endpoint.Processes where Processes.parent_process_name=cmd.exe Processes.process_name= reg.exe by Processes.parent_process_id Processes.dest Processes.process_name | `drop_dm_object_name("Processes")` | `ctime(firstTime)` | `ctime(lastTime)` | rename parent_process_id as process_id |dedup process_id| table process_id dest]

[ESCU - Suspicious wevtutil Usage - Rule]
action.escu = 0
action.escu.enabled = 1
description = The wevtutil.exe application is the windows event log utility. This searches for wevtutil.exe with parameters for clearing the application, security, setup, or system event logs.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Indicator Removal on Host"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 6"], "nist": ["DE.DP", "PR.IP", "PR.PT", "PR.AC", "PR.AT", "DE.AE"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for execution of wevtutil.exe with command-line arguments that indicate that it has been used to delete the setup, application, security, or system event logs. The search returns the number of times the behavior was observed, the first and last time it was seen, the host exhibiting the behavior and the user context of the process execution.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = The wevtutil.exe application is a legitimate Windows event log utility. Administrators may use it to manage Windows event logs.
action.escu.creation_date = 2017-02-17
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious wevtutil Usage - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = 
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Windows Log Manipulation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious wevtutil Usage
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = wevtutil is the windows event log tool. This searches for wevtutil clearing the security or system logs.
action.notable.param.rule_title = Suspicious wevtutil Usage
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = wevtutil.exe Processes.process="*cl*" (Processes.process="*System*" OR Processes.process="*Security*" OR Processes.process="*Setup*" OR Processes.process="*Application*") by Processes.process_name Processes.parent_process_name Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `ctime(firstTime)` |`ctime(lastTime)`

[ESCU - Suspicious writes to System Volume Information - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects writes to the 'System Volume Information' folder by something other than the System process.
action.escu.mappings = {"mitre_attack": ["Collection", "Data Staged"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.eli5 = This search uses data on file writes captured via Sysmon to watch for writes to the "System Volume Information" folder by processes other than the system process. The search looks for event code 11 in the Sysmon events, which indicates a file-creation event. It then looks for a file created with a path that includes "System Volume Information" and a process ID (PID) other than 4. PID 4 is assigned to the System process on Windows systems. Excluding these writes allows us to filter out legitimate activity. It will report the system where the activity occurred, the path to which the file was written, the process responsible for the write, and the times it first and last saw this activity.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = It is possible that other utilities or system processes may legitimately write to this folder. Investigate and modify the search to include exceptions as appropriate.
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious writes to System Volume Information - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = []
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious writes to System Volume Information
action.notable = 1
action.notable.param.nes_fields = dest, file_name, process
action.notable.param.rule_description = The process $process$ on $dest$ wrote $file_name$ to 'System Volume Information'.
action.notable.param.rule_title = Suspicious process $process$ wrote to 'System Volume Information' on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) EventCode=11 process_id!=4 file_path=*System\ Volume\ Information* | stats count min(_time) as firstTime max(_time) as lastTime by dest, Image, file_path | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Suspicious writes to windows Recycle Bin - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search detects writes to the recycle bin by a process other than explorer.exe.
action.escu.mappings = {"mitre_attack": ["Collection", "Data Staged"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search uses data on file writes captured via Sysmon to watch for writes to the Recycle Bin by processes other than explorer.exe. The search looks for event code 11 in the Sysmon events, which indicates a file-creation event. Next, it looks for files created with a path that includes the string "$Recycle.Bin" by processes other than explorer.exe, which is the process responsible for copying files to the Recycle Bin on delete. It will report the system where the activity occurred, the path to which the file was written, the process responsible for the write, and the times it first and last saw this activity.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting information on filesystem and process logs responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Filesystem` nodes.
action.escu.known_false_positives = Because the Recycle Bin is a hidden folder in modern versions of Windows, it would be unusual for a process other than explorer.exe to write to it. Incidents should be investigated as appropriate.
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2019-03-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Suspicious writes to windows Recycle Bin - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Windows
action.escu.fields_required = []
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Collection and Staging"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Suspicious writes to windows Recycle Bin
action.notable = 1
action.notable.param.nes_fields = dest, file_name, process_name
action.notable.param.rule_description = The process $process_name$ on $dest$ wrote $file_name$ to the Recycle Bin.
action.notable.param.rule_title = Suspicious process $process_name$ wrote to the Recycle Bin on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime values(Filesystem.file_path) as file_path values(Filesystem.file_name) as file_name FROM datamodel=Endpoint.Filesystem where Filesystem.filepath = "*$Recycle.Bin*" by Filesystem.process_id Filesystem.dest | `drop_dm_object_name("Filesystem")`| search [| tstats `summariesonly` values(Processes.user) as user values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name != "explorer.exe" by Processes.process_id Processes.dest| `drop_dm_object_name("Processes")` | table process_id dest]

[ESCU - System Processes Run From Unexpected Locations - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for system processes that normally run out of C:\Windows\System32\ or C:\Windows\SysWOW64 that are not run from that location.  This can indicate a malicious process that is trying to hide as a legitimate process.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Masquerading"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns all the processes that are not executing out of the C:\Windows\System32 or C:\Windows\SysWOW64 directories. It then uses a regular expression to extract the file name of the running process. Next, it takes the filename and looks it up in a table of files that should normally run out of the C:\Windows\System32 or C:\Windows\SysWOW64 directory. Any matches are then returned.
action.escu.how_to_implement = To successfully implement this search you need to ingest details about process execution from your hosts. Specifically, this search requires the process name and the full path to the process executable.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2016-08-24
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - System Processes Run From Unexpected Locations - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Suspicious Command-Line Executions", "Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = System Processes Run From Unexpected Locations
action.notable = 1
action.notable.param.nes_fields = user, process_name, dest
action.notable.param.rule_description = The system $dest$ has a process that normally runs out of Windows\System32\ that is not being run from that location.
action.notable.param.rule_title = System Processes Run From Unexpected Location on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process_name
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_path !="C:\\Windows\\System32*" Processes.process_path !="C:\\Windows\\SysWOW64*" by Processes.user Processes.dest Processes.process_name Processes.process_path Processes.process_id | `drop_dm_object_name("Processes")` | `ctime(firstTime)`| `ctime(lastTime)`| `isWindowsSystemFile`

[ESCU - TOR Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for network traffic identified as The Onion Router (TOR), a benign anonymity network which can be abused for a variety of nefarious purposes.
action.escu.mappings = {"mitre_attack": ["Command and Control", "Commonly Used Port", "Exfiltration"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 9", "CIS 12"], "nist": ["DE.AE"]}
action.escu.data_models = ["Network_Traffic"]
action.escu.eli5 = The search leverages the Enterprise Security Network_Traffic data model to look for network traffic that has been identified as TOR and marked as 'allowed'.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from firewalls or other network control devices that mediate the traffic allowed into an environment. This is necessary so that the search can identify an 'action' taken on the traffic of interest. The search requires the Network_Traffic data model be populated.
action.escu.known_false_positives = None at this time
action.escu.creation_date = 2017-08-21
action.escu.modification_date = 2017-09-11
action.escu.confidence = medium
action.escu.full_search_name = ESCU - TOR Traffic - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Palo Alto Firewall", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Command and Control", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = TOR Traffic
action.notable = 1
action.notable.param.nes_fields = src_ip, dest_ip
action.notable.param.rule_description = Network traffic accessing TOR detected from $src_ip$
action.notable.param.rule_title = TOR Network Traffic Allowed from $src_ip$
action.notable.param.security_domain = network
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Backup Logs For Endpoint\nESCU - Get Update Logs For Endpoint\nESCU - Get Vulnerability Logs For Endpoint\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Process Information For Port Activity\nESCU - Investigate Web Activity From Host\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.app=tor AND All_Traffic.action=allowed by All_Traffic.src_ip All_Traffic.dest_ip All_Traffic.dest_port All_Traffic.action | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - USN Journal Deletion - Rule]
action.escu = 0
action.escu.enabled = 1
description = The fsutil.exe application is a legitimate Windows utility used to perform tasks related to the file allocation table (FAT) and NTFS file systems. The update sequence number (USN) change journal provides a log of all changes made to the files on the disk. This search looks for fsutil.exe deleting the USN journal.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Indicator Removal on Host"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 6", "CIS 8", "CIS 10"], "nist": ["DE.CM", "PR.PT", "DE.AE", "DE.DP", "PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search looks for the execution of fsutil.exe with command-line arguments to delete the USN journal. The search returns the count of the number of times it's seen this process execution with these arguments, the first and last time it's seen this behavior, the hosts it was executed on, and the user context under which it was executed.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-06-27
action.escu.modification_date = 2018-12-03
action.escu.confidence = medium
action.escu.full_search_name = ESCU - USN Journal Deletion - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Windows Log Manipulation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = USN Journal Deletion
action.notable = 1
action.notable.param.nes_fields = dest, user, process_name
action.notable.param.rule_description = The system $dest$ deleted its NTFS journals.
action.notable.param.rule_title = File System Journal Deleted on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,process_name
alert.suppress.period = 14400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process values(Processes.parent_process) as parent_process min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name=fsutil.exe by Processes.user Processes.process_name Processes.parent_process_name Processes.dest  | `drop_dm_object_name(Processes)` | `ctime(firstTime)`| `ctime(lastTime)` | search process="*deletejournal*" AND process="*usn*"

[ESCU - Uncommon Processes On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for applications on the endpoint that you have marked as uncommon.
action.escu.mappings = {"mitre_attack": ["Execution", "Accessibility Features"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 2"], "nist": ["ID.AM", "PR.DS"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search returns the number of times, as well as the first and last time, it has seen every process run for each endpoint and user, and then displays only those processes that you have marked as uncommon in the `uncommon_processes_default.csv` table.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model. This search uses a lookup file `uncommon_processes_default.csv` to track various features of process names that are usually uncommon in most environments. Please consider updating `uncommon_processes_local.csv` to hunt for processes that are uncommon in your environment.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-12-08
action.escu.modification_date = 2019-04-01
action.escu.confidence = high
action.escu.full_search_name = ESCU - Uncommon Processes On Endpoint - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Unusual Processes", "Windows Privilege Escalation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Uncommon Processes On Endpoint
action.notable = 1
action.notable.param.nes_fields = dest, process_name, user
action.notable.param.rule_description = Prohibited software $process_name$ has been detected on $dest$
action.notable.param.rule_title = Prohibited Software Detected On $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Parent Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes by Processes.dest Processes.user Processes.process Processes.process_name | `ctime(firstTime)`| `ctime(lastTime)` | `drop_dm_object_name(Processes)` | `uncommon_processes`

[ESCU - Unsuccessful Netbackup backups - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search gives you the hosts where a backup was attempted and then failed.
action.escu.mappings = {"cis20": ["CIS 10"], "nist": ["PR.IP"]}
action.escu.eli5 = This search looks across the most recent backup events for each host, and returns those messages that indicate there was a backup failure.
action.escu.how_to_implement = To successfully implement this search you need to obtain data from your backup solution, either from the backup logs on your endpoints or from a central server responsible for performing the backups. If you do not use Netbackup, you can modify this search for your specific backup solution.
action.escu.known_false_positives = None identified
action.escu.creation_date = 2017-06-15
action.escu.modification_date = 2017-09-12
action.escu.confidence = high
action.escu.full_search_name = ESCU - Unsuccessful Netbackup backups - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Netbackup"]
action.escu.analytic_story = ["Monitor Backup Solution"]
cron_schedule = 0 7 * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Unsuccessful Netbackup backups
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The system $dest$ attempted a backup but encountered an error.
action.notable.param.rule_title = Failed backup attempt by $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - All backup logs for host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="netbackup_logs" | stats latest(_time) as latestTime by COMPUTERNAME, MESSAGE | search MESSAGE="An error occurred, failed to backup." | `ctime(latestTime)` | rename COMPUTERNAME as dest, MESSAGE as signature | table latestTime, dest, signature

[ESCU - Unusually Long Command Line - Rule]
action.escu = 0
action.escu.enabled = 1
description = Command-lines that are extremely long can be indicative of malicious activity on your hosts.
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This search calculates the average and standard deviation for the length of the command-lines on each of your endpoints and alerts when a command-line is found with a length over 10 times the standard deviation larger than the average command-line.
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model. Please consider changing the value of threshold in the search for reducing false positives.
action.escu.known_false_positives = Some legitimate applications start with long command-lines.
action.escu.creation_date = 2017-08-23
action.escu.modification_date = 2019-02-28
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Unusually Long Command Line - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = 
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Suspicious Command-Line Executions", "Unusual Processes"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -1d@d
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Unusually Long Command Line
action.notable = 1
action.notable.param.nes_fields = dest, process, user
action.notable.param.rule_description = An unusually long command-line $cmdline$ was found on $dest$
action.notable.param.rule_title = Unusually Long Command-Line on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Investigate Web Activity From Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes by Processes.user Processes.dest Processes.process_name Processes.process | `drop_dm_object_name("Processes")` | `ctime(firstTime)`| `ctime(lastTime)`|  eval processlen=len(process) | eventstats stdev(processlen) as stdev, avg(processlen) as avg by dest | stats max(processlen) as maxlen, values(stdev) as stdevperhost, values(avg) as avgperhost by dest, user, process_name, process| eval threshold = 10 | where maxlen > ((threshold*stdevperhost) + avgperhost)

[ESCU - Unusually Long Content-Type Length - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for unusually long strings in the Content-Type http header that the client sends the server.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability"], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 3", "CIS 4", "CIS 18", "CIS 12"], "nist": ["ID.RA", "RS.MI", "PR.PT", "PR.IP", "DE.AE", "PR.MA", "DE.CM"]}
action.escu.eli5 = This detection search uses HTTP traffic data captured with Splunk Stream.  The search is constructed to use "stream:http" sourcetype and counts of the number of times an HTTP request is received by a destination which the length of the Content-Type header value the client sends the server is greater than 100 characters long. We calculate this content_type_length field and output the results.
action.escu.how_to_implement = This particular search leverages data extracted from Stream:HTTP. You must configure the http stream using the Splunk Stream App on your Splunk Stream deployment server to extract the cs_content_type field.
action.escu.known_false_positives = Very few legitimate Content-Type fields will have a length greater than 100 characters.
action.escu.creation_date = 2017-03-14
action.escu.modification_date = 2017-10-13
action.escu.confidence = high
action.escu.full_search_name = ESCU - Unusually Long Content-Type Length - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Web Server
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream"]
action.escu.analytic_story = ["Apache Struts Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Unusually Long Content-Type Length
action.notable = 1
action.notable.param.nes_fields = src_ip, dest_ip, url
action.notable.param.rule_description = This search looks for unusually long strings in the Content-Type http header
action.notable.param.rule_title = Unusually Long Content-Type Length
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Investigate Suspicious Strings in HTTP Header\nESCU - Investigate Web POSTs From src\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=stream:http | eval cs_content_type_length = len(cs_content_type) | where cs_content_type_length > 100 | table endtime src_ip dest_ip cs_content_type_length cs_content_type url

[ESCU - WMI Permanent Event Subscription - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of WMI permanent event subscriptions.
action.escu.mappings = {"mitre_attack": ["Execution", "Windows Management Instrumentation", "Persistence", "Windows Management Instrumentation Event Subscription"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.eli5 = Attackers are increasingly abusing Windows Management Infrastructure (WMI) for stealth, persistence, lateral movement, or just to leverage its functionality. This search looks for the creation of a WMI event subscription by watching for Windows event ID 5861.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting the Windows WMI activity logs. This can be done by adding a stanza to inputs.conf on the system generating logs with a title of [WinEventLog://Microsoft-Windows-WMI-Activity/Operational].
action.escu.known_false_positives = Although unlikely, administrators may use event subscriptions for legitimate purposes.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.confidence = medium
action.escu.full_search_name = ESCU - WMI Permanent Event Subscription - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = WMI Permanent Event Subscription
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = This search looks for the creation of a permanent WMI event subscription via Windows event logs.
action.notable.param.rule_title = WMI Event Subscription Detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Sysmon WMI Activity for Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="wineventlog:microsoft-windows-wmi-activity/operational" EventCode=5861 Binding | rex field=Message "Consumer =\s+(?<consumer>[^;|^$]+)" | search consumer!="NTEventLogEventConsumer=\"SCM Event Log Consumer\"" | stats count min(_time) as firstTime max(_time) as lastTime by ComputerName, consumer, Message | `ctime(firstTime)`| `ctime(lastTime)` | rename ComputerName as dest

[ESCU - WMI Permanent Event Subscription - Sysmon - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of WMI permanent event subscriptions.
action.escu.mappings = {"mitre_attack": ["Execution", "Windows Management Instrumentation", "Persistence", "Windows Management Instrumentation Event Subscription"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.eli5 = Attackers are increasingly abusing Windows Management Infrastructure (WMI) for stealth, persistence, lateral movement, or just to leverage its functionality. This search looks for the creation of a WMI event subscription by watching for Sysmon event ID 21.
action.escu.how_to_implement = To successfully implement this search, you must be collecting Sysmon data using Sysmon version 6.1 or greater and have Sysmon configured to generate alerts for WMI activity. In addition, you must have at least version 6.0.4 of the Sysmon TA installed to properly parse the fields.
action.escu.known_false_positives = Although unlikely, administrators may use event subscriptions for legitimate purposes.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.confidence = medium
action.escu.full_search_name = ESCU - WMI Permanent Event Subscription - Sysmon - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = WMI Permanent Event Subscription - Sysmon
action.notable = 1
action.notable.param.nes_fields = dest, user
action.notable.param.rule_description = This search looks for the creation of a permanent WMI event subscription via Sysmon logs.
action.notable.param.rule_title = WMI Event Subscription Detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Sysmon WMI Activity for Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" EventCode=21 | rename host as dest | table _time, dest, user, Operation, EventType, Query, Consumer, Filter

[ESCU - WMI Temporary Event Subscription - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for the creation of WMI temporary event subscriptions.
action.escu.mappings = {"mitre_attack": ["Execution", "Windows Management Instrumentation", "Persistence", "Windows Management Instrumentation Event Subscription"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.eli5 = Attackers are increasingly abusing Windows Management Infrastructure (WMI) for stealth, persistence, lateral movement, or just to leverage its functionality. This search looks for the creation of a WMI temporary event subscription by watching for Windows event ID 5860.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting the Windows WMI activity logs. This can be done by adding a stanza to inputs.conf on the system generating logs with a title of [WinEventLog://Microsoft-Windows-WMI-Activity/Operational].
action.escu.known_false_positives = Some software may create WMI temporary event subscriptions for various purposes. The included search contains an exception for two of these that occur by default on Windows 10 systems. You may need to modify the search to create exceptions for other legitimate events.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.confidence = medium
action.escu.full_search_name = ESCU - WMI Temporary Event Subscription - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Suspicious WMI Use"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = WMI Temporary Event Subscription
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for the creation of a temporary WMI event subscription via Windows event logs.
action.notable.param.rule_title = Temporary WMI Event Subscription Detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\nESCU - Get Sysmon WMI Activity for Host\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype="wineventlog:microsoft-windows-wmi-activity/operational" EventCode=5860 Temporary | rex field=Message "NotificationQuery =\s+(?<query>[^;|^$]+)" | search query!="SELECT * FROM Win32_ProcessStartTrace WHERE ProcessName = 'wsmprovhost.exe'" AND query!="SELECT * FROM __InstanceOperationEvent WHERE TargetInstance ISA 'AntiVirusProduct' OR TargetInstance ISA 'FirewallProduct' OR TargetInstance ISA 'AntiSpywareProduct'" | stats count min(_time) as firstTime max(_time) as lastTime by ComputerName, query  | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Web Fraud - Account Harvesting - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to identify the creation of multiple user accounts using the same email domain name.
action.escu.mappings = {"mitre_attack": ["Create Account"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 16"], "nist": ["DE.CM", "DE.DP"]}
action.escu.eli5 = When a fraudster is setting the stage for a campaign, they will often create many user accounts on the website. This is a simple example of how to detect a many-account creation hosted on a Magento2 e-commerce platform, where the fraudster is using email addresses from a single email domain.
action.escu.how_to_implement = We start with a dataset that provides visibility into the email address used for the account creation. In this example, we are narrowing our search down to the single web page that hosts the Magento2 e-commerce platform (via URI) used for account creation, the single http content-type to grab only the user's clicks, and the http field that provides the username (form_data), for performance reasons.  After we have the username and email domain, we look for numerous account creations per email domain.  Common data sources used for this detection are customized Apache logs or Splunk Stream.
action.escu.known_false_positives = As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosely written detections that simply detect anamolous behavior. This search will need to be customized to fit your environment&#151;improving its fidelity by counting based on something much more specific, such as a device ID that may be present in your dataset. Consideration for whether the large number of registrations are occuring from a first-time seen domain may also be important.  Extending the search window to look further back in time, or even calculating the average per hour/day for each email domain to look for an anomalous spikes, will improve this search.  You can also use Shannon entropy or Levenshtein Distance (both courtesy of URL Toolbox) to consider the randomness or similarity of the email name or email domain, as the names are often machine-generated.
action.escu.creation_date = 2018-07-12
action.escu.modification_date = 2018-10-08
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Web Fraud - Account Harvesting - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Account
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Palo Alto Firewall", "Bro"]
action.escu.analytic_story = ["Web Fraud Detection"]
cron_schedule = 0 1 * * *
dispatch.earliest_time = -1445m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Web Fraud - Account Harvesting
action.notable = 1
action.notable.param.nes_fields = src_user
action.notable.param.rule_description = This search is used to identify multiple created accounts tied to a specific email domain. Such activity is often indicative of account harvesting. A list of $src_user$ accounts were created.
action.notable.param.rule_title = Web Fraud Detection: Possible Account Harvesting
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get Emails From Specific Sender\nESCU - Get Web Session Information via session_id\n"}
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 3600s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=stream:http http_content_type=text* uri="/magento2/customer/account/loginPost/" | rex field=cookie "form_key=(?<SessionID>\w+)" | rex field=form_data "login\[username\]=(?<Username>[^&|^$]+)" | search Username=* | rex field=Username "@(?<email_domain>.*)"|stats dc(Username) as UniqueUsernames list(Username) as src_user by email_domain|where UniqueUsernames> 25

[ESCU - Web Fraud - Anomalous User Clickspeed - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to examine web sessions to identify those where the clicks are occurring too quickly for a human or are occurring with a near-perfect cadence (high periodicity or low standard deviation), resembling a script driven session.
action.escu.mappings = {"mitre_attack": ["Valid Accounts"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 6"], "nist": ["DE.AE", "DE.CM"]}
action.escu.eli5 = It's suspicious when someone or something is moving throughout your website too quickly or with a perfect click cadence. Fortunately, it's easy to detect by calculating the time between clicks for each session and highlighting the anomalous behavior.
action.escu.how_to_implement = Start with a dataset that allows you to see clickstream data for each user click on the website. That data must have a time stamp and must contain a reference to the session identifier being used by the website. This ties the clicks together into clickstreams. This value is usually found in the http cookie. With a bit of tuning, a version of this search could be used in high-volume scenarios, such as scraping, crawling, application DDOS, credit-card testing, account takeover, etc. Common data sources used for this detection are customized Apache logs, customized IIS, and Splunk Stream.
action.escu.known_false_positives = As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosly written detections that simply detect anamoluous behavior.
action.escu.creation_date = 2018-07-12
action.escu.modification_date = 2018-10-08
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Web Fraud - Anomalous User Clickspeed - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = account
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Palo Alto Firewall", "Bro"]
action.escu.analytic_story = ["Web Fraud Detection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Web Fraud - Anomalous User Clickspeed
action.notable = 1
action.notable.param.nes_fields = session_id
action.notable.param.rule_description = This search is used to examine web sessions in order to identify unnaturally rapid clicks with near-perfect cadence (high periodicity or low standard deviation), which resemble a script-driven session.
action.notable.param.rule_title = Web Fraud Detection: Anomalous User Clickspeed
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get Emails From Specific Sender\nESCU - Get Web Session Information via session_id\n"}
action.risk = 1
action.risk.param._risk_object = session_id
action.risk.param._risk_object_type = other
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = session_id
alert.suppress.period = 3600s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=stream:http http_content_type=text* | rex field=cookie "form_key=(?<session_id>\w+)" | streamstats window=2 current=1 range(_time) as TimeDelta by session_id | where TimeDelta>0 |stats count stdev(TimeDelta) as ClickSpeedStdDev avg(TimeDelta) as ClickSpeedAvg by session_id | where count>5 AND (ClickSpeedStdDev<.5 OR ClickSpeedAvg<.5)

[ESCU - Web Fraud - Password Sharing Across Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search is used to identify user accounts that share a common password.
action.escu.mappings = {"cis20": ["CIS 16"], "nist": ["DE.DP"]}
action.escu.eli5 = A common password across user accounts generally indicates that the users are choosing poor passwords or that a fraudster has a common password across multiple accounts embedded within a script. The search will extract the username and password information from the form_data field, then calculate the number and values for usernames that have the same passwords. Finally, it outputs the values where the unique usernames sharing passwords are greater than 5
action.escu.how_to_implement = We need to start with a dataset that allows us to see the values of usernames and passwords that users are submitting to the website hosting the Magento2 e-commerce platform (commonly found in the HTTP form_data field). A tokenized or hashed value of a password is acceptable and certainly preferable to a clear-text password. Common data sources used for this detection are customized Apache logs, customized IIS, and Splunk Stream.
action.escu.known_false_positives = As is common with many fraud-related searches, we are usually looking to attribute risk or synthesize relevant context with loosely written detections that simply detect anamoluous behavior.
action.escu.creation_date = 2018-07-12
action.escu.modification_date = 2018-10-08
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Web Fraud - Password Sharing Across Accounts - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = account
action.escu.fields_required = []
action.escu.providing_technologies = ["Splunk Stream", "Palo Alto Firewall", "Bro"]
action.escu.analytic_story = ["Web Fraud Detection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Web Fraud - Password Sharing Across Accounts
action.notable = 1
action.notable.param.nes_fields = user
action.notable.param.rule_description = This search is used to identify user accounts, $user$, that share common passwords
action.notable.param.rule_title = Web Fraud Detection: Password Sharing Across Accounts
action.notable.param.security_domain = threat
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get Emails From Specific Sender\nESCU - Get Web Session Information via session_id\n"}
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = other
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 3600s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = sourcetype=stream:http http_content_type=text* uri=/magento2/customer/account/loginPost*  | rex field=form_data "login\[username\]=(?<Username>[^&|^$]+)" | rex field=form_data "login\[password\]=(?<Password>[^&|^$]+)" | stats dc(Username) as UniqueUsernames values(Username) as user list(src_ip) as src_ip by Password|where UniqueUsernames>5

[ESCU - Web Servers Executing Suspicious Processes - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for suspicious processes on all systems labeled as web servers.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability", "Execution", "Discovery", "System Information Discovery"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3"], "nist": ["PR.IP"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = This detection search uses the Enterprise Security Endpoint data model. The search uses tstats to search within an accelerated data model to find suspicious applications or processes such as whoami, ping, iptables, wget, service, or curl, running on hosts which are marked as web servers in the Assets and Identity Framework of ES.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must also be ingesting logs with both the process name and command line from your endpoints. The command-line arguments are mapped to the "process" field in the Endpoint data model. In addition, web servers will need to be identified in the Assets and Identity Framework of Enterprise Security.
action.escu.known_false_positives = Some of these processes may be used legitimately on web servers during maintenance or other administrative tasks.
action.escu.creation_date = 2017-03-14
action.escu.modification_date = 2019-04-01
action.escu.confidence = medium
action.escu.full_search_name = ESCU - Web Servers Executing Suspicious Processes - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Web Server
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Apache Struts Vulnerability"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Web Servers Executing Suspicious Processes
action.notable = 1
action.notable.param.nes_fields = dest, user, process
action.notable.param.rule_description = This search looks for suspicious processes on all systems labeled as web servers
action.notable.param.rule_title = Web Servers Executing Suspicious Processes
action.notable.param.security_domain = endpoint
action.notable.param.severity = medium
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Investigate Suspicious Strings in HTTP Header\nESCU - Investigate Web POSTs From src\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.dest_category="web_server" AND (Processes.process="*whoami*" OR Processes.process="*ping*" OR Processes.process="*iptables*" OR Processes.process="*wget*" OR Processes.process="*service*" OR Processes.process="*curl*") by Processes.process Processes.process_name, Processes.dest Processes.user| `drop_dm_object_name(Processes)` | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Windows Event Log Cleared - Rule]
action.escu = 0
action.escu.enabled = 1
description = This search looks for Windows events that indicate one of the Windows event logs has been purged.
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Indicator Removal on Host"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 6"], "nist": ["DE.DP", "PR.IP", "PR.AC", "PR.AT", "DE.AE"]}
action.escu.eli5 = This search looks at the Windows security and system event logs. EventCode 1002 in the security log indicates that the log has been cleared, EventCode 1000 in the security log indicates the event logging service has been shut down, and EventCode 104 in the system log indicates the application log has been cleared. If any of these events are found, a notable will be generated.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting Windows event logs from your hosts.
action.escu.known_false_positives = It is possible that these logs may be legitimately cleared by Administrators.
action.escu.creation_date = 2017-02-17
action.escu.modification_date = 2019-02-27
action.escu.confidence = high
action.escu.full_search_name = ESCU - Windows Event Log Cleared - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Ransomware", "Windows Log Manipulation"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Windows Event Log Cleared
action.notable = 1
action.notable.param.nes_fields = dest
action.notable.param.rule_description = The Event Logging System has been cleared or shutdown on $dest$
action.notable.param.rule_title = Windows Event Log Cleared on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Get Process Info\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, signature_id
alert.suppress.period = 28800s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = ((eventtype=wineventlog_security) AND (signature_id=1102 OR signature_id=1100)) OR ((eventtype=wineventlog_system) AND signature_id=104) | stats count min(_time) as firstTime max(_time) as lastTime by signature_id dest user| `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Windows hosts file modification - Rule]
action.escu = 0
action.escu.enabled = 1
description = The search looks for modifications to the hosts file on all Windows endpoints across your environment.
action.escu.mappings = {"mitre_attack": ["Command and Control", "Exfiltration"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 3", "CIS 8", "CIS 12"], "nist": ["PR.IP", "PR.PT", "PR.AC", "DE.AE", "DE.CM"]}
action.escu.data_models = ["Endpoint"]
action.escu.eli5 = The hosts file is present on both Windows and Linux endpoints. The purpose of the hosts file is to provide a mapping between hostnames and IP addresses, the same way DNS is used to provide such a mapping. However, the information in the hosts file takes precedence over information received via DNS and a DNS query will not be issued if the hostname of interest is found in the hosts file. As such, attackers have been observed adding entries to the host file to override any DNS resolution. For this reason, it is useful to monitor for changes to this file, which typically do not occur very often in legitimate cases.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records the file-system activity from your hosts to populate the Endpoint.Filesystem data model node. This is typically populated via endpoint detection-and-response products, such as Carbon Black, or by other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file-system reads and writes.
action.escu.known_false_positives = There may be legitimate reasons for system administrators to add entries to this file.
action.escu.creation_date = 2017-06-07
action.escu.modification_date = 2018-11-02
action.escu.confidence = high
action.escu.full_search_name = ESCU - Windows hosts file modification - Rule
action.escu.search_type = detection
action.escu.asset_at_risk = Endpoint
action.escu.fields_required = []
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Host Redirection"]
cron_schedule = 0 * * * *
dispatch.earliest_time = -70m@m
dispatch.latest_time = -10m@m
action.correlationsearch.enabled = 1
action.correlationsearch.label = Windows hosts file modification
action.notable = 1
action.notable.param.nes_fields = dest, file_name
action.notable.param.rule_description = A file modification was noted for the hosts file on $dest$.
action.notable.param.rule_title = Modification of hosts file detected on $dest$
action.notable.param.security_domain = endpoint
action.notable.param.severity = high
action.notable.param.recommended_actions = escu_investigate
action.notable.param.next_steps = {"version": 1, "data": "Recommended following steps:\n\n1.                         [[action|escu_investigate]]: Based on ESCU investigate recommendations:\nESCU - Get Notable Info\nESCU - Get Notable History\nESCU - Get User Information from Identity Table\nESCU - Get Authentication Logs For Endpoint\nESCU - Get Risk Modifiers For User\nESCU - Get Risk Modifiers For Endpoint\nESCU - Investigate Web Activity From Host\nESCU - Get DNS Server History for a host\nESCU - Get Process responsible for the DNS traffic\n"}
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 86400s
is_visible = false
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Filesystem  by Filesystem.file_name Filesystem.file_path Filesystem.dest | `ctime(lastTime)` | `ctime(firstTime)` | search Filesystem.file_name=hosts AND Filesystem.file_path=*Windows\\System32\\* | `drop_dm_object_name(Filesystem)`

### END ESCU DETECTIONS ###

### ESCU INVESTIGATIONS ###

[ESCU - AWS Investigate User Activities By ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate User Activities By ARN
description = This search lists all the logged CloudTrail activities by a specific user ARN and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and all the user's identity information.
action.escu.creation_date = 2018-01-22
action.escu.modification_date = 2018-02-25
action.escu.analytic_story = ["AWS Cryptomining", "AWS Network ACL Activity", "Suspicious AWS EC2 Activities", "Suspicious AWS Login Activities", "Suspicious AWS S3 Activities", "Unusual AWS EC2 Modifications"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["arn"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail userIdentity.arn={arn} | table _time userIdentity.type userIdentity.userName userIdentity.arn aws_account_id src awsRegion eventName eventType 

[ESCU - AWS Investigate User Activities By AccessKeyId]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate User Activities By AccessKeyId
description = This search retrieves the times, ARN, source IPs, AWS regions, event names, and the result of the event for specific credentials.
action.escu.creation_date = 2018-06-08
action.escu.modification_date = 2018-06-08
action.escu.analytic_story = ["AWS Cross Account Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["accessKeyId"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail userIdentity.accessKeyId={accessKeyId} | spath output=user path=userIdentity.arn  | rename sourceIPAddress as src_ip | table _time, user, src_ip, awsRegion, eventName, errorCode, errorMessage

[ESCU - AWS Investigate User Activities By Source User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Investigate User Activities By Source User
description = This search retrieves the times, ARN, source IPs, AWS regions, event names, and the result of the event for specific ARNs.
action.escu.creation_date = 2018-06-08
action.escu.modification_date = 2018-06-08
action.escu.analytic_story = ["AWS Cross Account Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_user"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail userIdentity.arn={src_user} | spath output=user path=userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, awsRegion, eventName, errorCode, errorMessage

[ESCU - AWS Network ACL Details from ID]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Network ACL Details from ID
description = This search queries AWS description logs and returns all the information about a specific network ACL via network ACL ID
action.escu.creation_date = 2018-01-18
action.escu.modification_date = 2017-01-22
action.escu.analytic_story = ["AWS Network ACL Activity"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["networkAclId"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:description id={networkAclId} | table id account_id vpc_id network_acl_entries{}.*

[ESCU - AWS Network Interface details via resourceId]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS Network Interface details via resourceId
description = This search queries AWS configuration logs and returns the information about a specific network interface via network interface ID. The information will include the ARN of the network interface, its relationships with other AWS resources, the public and the private IP associated with the network interface.
action.escu.creation_date = 2018-05-07
action.escu.modification_date = 2018-05-07
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS configuration inputs
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["resourceId"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:config resourceId={resourceId} | table _time ARN relationships{}.resourceType relationships{}.name relationships{}.resourceId  configuration.privateIpAddresses{}.privateIpAddress configuration.privateIpAddresses{}.association.publicIp

[ESCU - AWS S3 Bucket details via bucketName]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - AWS S3 Bucket details via bucketName
description = This search queries AWS configuration logs and returns the information about a specific S3 bucket. The information returned includes the time the S3 bucket was created, the resource ID, the region it belongs to, the value of action performed, AWS account ID, and configuration values of the access-control lists associated with the bucket.
action.escu.creation_date = 2018-06-26
action.escu.modification_date = 2018-06-26
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = To implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later) and configure your AWS inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["bucketName"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:config resourceId={bucketName} | table resourceCreationTime resourceId awsRegion action aws_account_id supplementaryConfiguration.AccessControlList

[ESCU - All backup logs for host]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - All backup logs for host
description = Retrieve the backup logs for the last 2 weeks for a specific host in order to investigate why backups are not completing successfully.
action.escu.creation_date = 2017-06-19
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Monitor Backup Solution"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Netbackup"]
action.escu.eli5 = none
action.escu.how_to_implement = The successfully implement this search you must first send your backup logs to Splunk.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype="netbackup_logs" dest={dest}

[ESCU - Get All AWS Activity From City]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From City
description = This search retrieves all the activity from a specific city and will create a table containing the time, city, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["City"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search City={City} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, City, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From Country]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From Country
description = This search retrieves all the activity from a specific country and will create a table containing the time, country, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["Country"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search Country={Country} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, Country, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From IP Address]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From IP Address
description = This search retrieves all the activity from a specific IP address and will create a table containing the time, ARN, username, the type of user, the IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Network ACL Activity", "AWS Suspicious Provisioning Activities", "Command and Control", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search sourceIPAddress={src_ip} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get All AWS Activity From Region]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get All AWS Activity From Region
description = This search retrieves all the activity from a specific geographic region and will create a table containing the time, geographic region, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API called, and whether or not the API call was successful.
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["Region"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search Region={Region} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, Region, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get Authentication Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Authentication Logs For Endpoint
description = This search returns all users that have attempted to access a particular endpoint.
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-11-01
action.escu.analytic_story = ["Account Monitoring and Controls", "Apache Struts Vulnerability", "Asset Tracking", "Brand Monitoring", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "Credential Dumping", "DHS Report TA18-074A", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router & Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Authentication"]
action.escu.providing_technologies = ["Microsoft Windows", "Linux", "macOS"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you need to be ingesting authentication logs from your various systems and populating the Authentication data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | tstats count from datamodel=Authentication where Authentication.dest={dest} by _time, Authentication.dest, Authentication.user, Authentication.app, Authentication.action | `drop_dm_object_name("Authentication")`

[ESCU - Get Backup Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Backup Logs For Endpoint
description = This search will tell you the backup status from your netbackup_logs of a specific endpoint for the last week.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = ["Command and Control", "DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Netbackup"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting your backup logs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype="netbackup_logs" COMPUTERNAME={dest} | rename COMPUTERNAME as dest, MESSAGE as signature | table _time, dest, signature

[ESCU - Get Certificate logs for a domain]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Certificate logs for a domain
description = This search queries the Certificates datamodel and give you all the information for a specific domain. Please note that if the certificate information 
action.escu.creation_date = 2019-04-29
action.escu.modification_date = 2019-04-29
action.escu.analytic_story = ["Common Phishing Frameworks"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Certificates"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting your certificates or SSL logs from your network traffic into your Certificates datamodel. Please note the wildcard(*) before domain in the search syntax, we use to match for all domain and subdomain combinations
action.escu.known_false_positives = None at this time
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Certificates.All_Certificates where All_Certificates.SSL.ssl_subject_common_name=*{domain}  by All_Certificates.dest All_Certificates.src All_Certificates.SSL.ssl_issuer_common_name All_Certificates.SSL.ssl_subject_common_name All_Certificates.SSL.ssl_hash | `drop_dm_object_name(All_Certificates)` | `drop_dm_object_name(SSL)` | rename ssl_subject_common_name as domain | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Get DNS Server History for a host]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get DNS Server History for a host
description = While investigating any detections it is important to understand which and how many DNS servers a host has connected to in the past. This search uses data that is tagged as DNS and gives you a count and list of DNS servers that a particular host has connected to the previous 24 hours.
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "Command and Control", "DNS Hijacking", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Host Redirection", "Prohibited Traffic Allowed or Protocol Mismatch", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be ingesting your DNS traffic
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip"]
disabled=true
schedule_window = auto
is_visible = false
search = | search tag=dns src_ip={src_ip} dest_port=53 | streamstats time_window=1d count values(dest_ip) as dcip by src_ip | table date_mday src_ip dcip count | sort -count

[ESCU - Get DNS traffic ratio]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get DNS traffic ratio
description = This search calculates the ratio of DNS traffic originating and coming from a host to a list of DNS servers over the last 24 hours. A high value of this ratio could be very useful to quickly understand if a src_ip (host) is sending a high volume of data out via port 53, could be an indicator of data exfiltration via DNS.  
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Command and Control", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Network_Traffic"]
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting your network traffic
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip", "dest_ip"]
disabled=true
schedule_window = auto
is_visible = false
search = | tstats allow_old_summaries=true sum(All_Traffic.bytes_out) as "bytes_out" sum(All_Traffic.bytes_in) as "bytes_in" from datamodel=Network_Traffic where nodename=All_Traffic All_Traffic.dest_port=53 All_Traffic.src={src_ip} All_Traffic.dest={dest_ip} | eval ratio = (bytes_out/bytes_in) | table ratio

[ESCU - Get EC2 Instance Details by instanceId]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get EC2 Instance Details by instanceId
description = This search queries AWS description logs and returns all the information about a specific instance via the instanceId field
action.escu.creation_date = 2018-02-12
action.escu.modification_date = 2018-02-12
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities", "Unusual AWS EC2 Modifications"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["instanceId"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype="aws:description" source="*:ec2_instances"| dedup id sortby -_time | search id={instanceId} | spath output=tags path=tags | eval tags=mvzip(key,value," = "), ip_address=if((ip_address == "null"),private_ip_address,ip_address) | table id, tags.Name, aws_account_id, placement, instance_type, key_name, ip_address, launch_time, state, vpc_id, subnet_id, tags | rename aws_account_id as "Account ID", id as ID, instance_type as Type, ip_address as "IP Address", key_name as "Key Pair", launch_time as "Launch Time", placement as "Availability Zone", state as State, subnet_id as Subnet, "tags.Name" as Name, vpc_id as VPC

[ESCU - Get EC2 Launch Details]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get EC2 Launch Details
description = This search returns some of the launch details for a EC2 instance.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS Cryptomining"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail responseElements.instancesSet.items{}.instanceId={dest} |rename userIdentity.arn as arn, responseElements.instancesSet.items{}.instanceId as instanceId, responseElements.instancesSet.items{}.privateIpAddress as privateIpAddress, responseElements.instancesSet.items{}.imageId as amiID, responseElements.instancesSet.items{}.architecture as architecture, responseElements.instancesSet.items{}.keyName as keyName | table arn, awsRegion, instanceId, architecture, privateIpAddress, amiID, keyName

[ESCU - Get Email Info]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Email Info
description = This search returns all the information Splunk might have collected a specific email message over the last 2 hours.
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "Emotet Malware (TA18-201A)", "Suspicious Emails"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Email"]
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting your email logs or capturing unencrypted network traffic which contains email communications.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["message_id"]
disabled=true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search message_id={message_id}

[ESCU - Get Emails From Specific Sender]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Emails From Specific Sender
description = This search returns all the emails from a specific sender over the last 24 and next hours.
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "Emotet Malware (TA18-201A)", "Suspicious Emails", "Web Fraud Detection"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Email"]
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must ingest your email logs or capture unencrypted email communications within network traffic, and populate the Email data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_user"]
disabled=true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search src_user={src_user}

[ESCU - Get First Occurrence and Last Occurrence of a MAC Address]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get First Occurrence and Last Occurrence of a MAC Address
description = This search allows you to gather more context around a notable which has detected a new device connecting to your network. Use this search to determine the first and last occurrences of the suspicious device attempting to connect with your network.
action.escu.creation_date = 2017-06-14
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = ["Asset Tracking"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Network_Sessions"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Microsoft Windows"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be ingesting the logs from your DHCP server.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_mac"]
disabled=true
schedule_window = auto
is_visible = false
search = | tstats allow_old_summaries=true count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Sessions where nodename=All_Sessions.DHCP All_Sessions.signature=DHCPREQUEST All_Sessions.All_Sessions.src_mac= {src_mac} by All_Sessions.src_ip All_Sessions.user | `ctime(lastTime)` | `ctime(firstTime)`

[ESCU - Get History Of Email Sources]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get History Of Email Sources
description = This search returns a list of all email sources seen in the 48 hours prior to the notable event to 24 hours after, and the number of emails from each source.
action.escu.creation_date = 2019-02-21
action.escu.modification_date = 2019-02-21
action.escu.analytic_story = []
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Email"]
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must ingest your email logs or capture unencrypted email communications within network traffic, and populate the Email data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src"]
disabled=true
schedule_window = auto
is_visible = false
search = |tstats `summariesonly` values(All_Email.dest) as dest values(All_Email.recipient) as recepient  min(_time) as firstTime max(_time) as lastTime count from datamodel=Email.All_Email by All_Email.src |`drop_dm_object_name(All_Email)` | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Get Logon Rights Modifications For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Logon Rights Modifications For Endpoint
description = This search allows you to retrieve any modifications to logon rights associated with a specific host.
action.escu.creation_date = 2017-08-16
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting your Windows event logs
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | search eventtype=wineventlog_security (signature_id=4718 OR signature_id=4717) dest={dest} | rename user as "Account Modified" | table _time, dest, "Account Modified", Access_Right, signature

[ESCU - Get Logon Rights Modifications For User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Logon Rights Modifications For User
description = This search allows you to retrieve any modifications to logon rights for a specific user account.
action.escu.creation_date = 2017-08-16
action.escu.modification_date = 2019-02-27
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting your Windows event logs
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["user"]
disabled=true
schedule_window = auto
is_visible = false
search = | search eventtype=wineventlog_security (signature_id=4718 OR signature_id=4717) user={user} | rename user as "Account Modified" | table _time, dest, "Account Modified", Access_Right, signature

[ESCU - Get Notable History]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Notable History
description = This search queries the notable index and returns all the Notable Events for the particular destination host, giving the analyst an overview of the incidents that may have occurred with the host under investigation.
action.escu.creation_date = 2017-03-15
action.escu.modification_date = 2017-09-20
action.escu.analytic_story = ["AWS Cross Account Activity", "AWS Cryptomining", "AWS Network ACL Activity", "AWS User Monitoring", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Asset Tracking", "Brand Monitoring", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "Credential Dumping", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Lateral Movement", "Malicious PowerShell", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router & Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Splunk Enterprise Vulnerability CVE-2018-11409", "Suspicious AWS EC2 Activities", "Suspicious AWS Login Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual AWS EC2 Modifications", "Unusual Processes", "Use of Cleartext Protocols", "Web Fraud Detection", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = none
action.escu.how_to_implement = If you are using Enterprise Security you are likely already creating notable events with your correlation rules. No additional configuration is necessary.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | search `notable` | search dest={dest} | table _time, rule_name, owner, priority, severity, status_description

[ESCU - Get Notable Info]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Notable Info
description = This search queries the notable index to retrieve detailed information captured within the notable. Every notable has a unique ID associated with it, which is used to point us directly to the notable event under investigation.
action.escu.creation_date = 2017-03-15
action.escu.modification_date = 2017-09-20
action.escu.analytic_story = ["AWS Cryptomining", "AWS Network ACL Activity", "AWS User Monitoring", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Asset Tracking", "Brand Monitoring", "Collection and Staging", "Command and Control", "Credential Dumping", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Lateral Movement", "Malicious PowerShell", "Monitor for Updates", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Ransomware", "Router & Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Splunk Enterprise Vulnerability CVE-2018-11409", "Suspicious AWS EC2 Activities", "Suspicious AWS Login Activities", "Suspicious AWS S3 Activities", "Suspicious AWS Traffic", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Web Fraud Detection", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = none
action.escu.how_to_implement = If you are using Enterprise Security you are likely already creating notable events with your correlation rules. No additional configuration is necessary.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["event_id"]
disabled=true
schedule_window = auto
is_visible = false
search = | search `notable_by_id({event_id})` | table time, rule_name, dest, dest_asset_id, dest_owner, priority, severity, owner, status_description

[ESCU - Get Outbound Emails to Hidden Cobra Threat Actors]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Outbound Emails to Hidden Cobra Threat Actors
description = This search returns the information of the users that sent emails to the accounts controlled by the Hidden Cobra Threat Actors: specifically to <code>misswang8107@gmail.com</code>, and from <code>redhat@gmail.com</code>.
action.escu.creation_date = 2018-06-14
action.escu.modification_date = 2018-06-14
action.escu.analytic_story = ["DHS Report TA18-074A", "Hidden Cobra Malware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Email"]
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must ingest your email logs or capture unencrypted email communications within network traffic, and populate the Email data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_user", "recipient"]
disabled=true
schedule_window = auto
is_visible = false
search = | from datamodel Email.All_Email | search recipient=misswang8107@gmail.com OR src_user=redhat@gmail.com | stats count earliest(_time) as firstTime, latest(_time) as lastTime values(dest) values(src) by src_user recipient | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Get Parent Process Info]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Parent Process Info
description = This search queries the Endpoint data model to give you details about the parent process of a process running on a host which is under investigation. Enter the values of the process name in question and the dest
action.escu.creation_date = 2017-08-22
action.escu.modification_date = 2019-02-28
action.escu.analytic_story = ["Collection and Staging", "Command and Control", "Credential Dumping", "DHS Report TA18-074A", "Disabling Security Tools", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Phishing Payloads", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious Command-Line Executions", "Suspicious MSHTA Activity", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting endpoint data that tracks process activity, including parent-child relationships from your endpoints to populate the Endpoint data model in the Processes node. The command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["process_name", "dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count values(Processes.process) as process min(_time) as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Processes where Processes.process_name = {process_name} Processes.dest = {dest} by Processes.user Processes.parent_process_name  Processes.process_name  | `drop_dm_object_name("Processes")` | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Get Process Info]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Info
description = This search queries the Endpoint data model to give you details about the process running on a host which is under investigation. To gather the process info, enter the values for the process name in question and the destination IP address.
action.escu.creation_date = 2017-03-15
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["Collection and Staging", "Command and Control", "Credential Dumping", "DHS Report TA18-074A", "Disabling Security Tools", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious Command-Line Executions", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data and populating the Endpoint data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["process_name", "dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time)  max(_time) as lastTime from datamodel=Endpoint.Processes where Proceses.dest={dest} Proceses.process_name={process_name} by Processes.parent_process Processes.process_name Processes.user Processes.dest | `drop_dm_object_name(Processes)` | `ctime(firstTime)`|`ctime(lastTime)` 

[ESCU - Get Process Information For Port Activity]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process Information For Port Activity
description = This search will return information about the process associated with observed network traffic to a specific destination port from a specific host.
action.escu.creation_date = 2017-06-25
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["Command and Control", "DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Use of Cleartext Protocols"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data that associates processes with network events and populate the Endpoint Datamodel
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest_port", "dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time)  max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.dest = {dest} by Processes.process_name Processes.user Processes.dest Processes.process_id | `drop_dm_object_name(Processes)` | `ctime(firstTime)`|`ctime(lastTime)` | search [| tstats `summariesonly` count from datamodel=Endpoint.Ports where Ports.dest_port={dest_port} by Ports.process_id Ports.src  | `drop_dm_object_name(Ports)` | rename src as dest]

[ESCU - Get Process responsible for the DNS traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Process responsible for the DNS traffic
description = While investigating, an analyst will want to know what process and parent_process is responsible for generating suspicious DNS traffic. Use the following search and enter the value of `dest` in the search to get specific details on the process responsible for creating the DNS traffic.
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["Brand Monitoring", "Command and Control", "Data Protection", "Dynamic DNS", "Hidden Cobra Malware", "Host Redirection", "Suspicious DNS Traffic"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be ingesting endpoint data that associates processes with network events into the Endpoint datamodel. This can come from endpoint protection products such as carbon black, or endpoint data sources such as Sysmon.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time)  max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.dest = {dest} by Processes.parent_process Processes.process_name Processes.user Processes.dest Processes.process_id | `drop_dm_object_name(Processes)` | `ctime(firstTime)`|`ctime(lastTime)` | search [| tstats `summariesonly` count from datamodel=Endpoint.Ports where Ports.dest_port=53 by Ports.process_id Ports.src | `drop_dm_object_name(Ports)` | rename src as dest]

[ESCU - Get Registry Activities]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Registry Activities
description = This search queries the Endpoint Datamodel to give you details of the latest registry values for a specific destination computer.
action.escu.creation_date = 2018-08-07
action.escu.modification_date = 2019-03-01
action.escu.analytic_story = ["Suspicious Command-Line Executions", "Suspicious MSHTA Activity", "Suspicious Windows Registry Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Endpoint"]
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you need to be ingesting information on registry changes that include the name of the process responsible for the changes from your endpoints into the `Endpoint` datamodel in the `Processes` and `Registry` nodes.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Registry.registry_path) as registry_path values(Registry.registry_key_name) as registry_key_name count FROM datamodel=Endpoint.Registry where Registry.dest = "{dest}" by Registry.process_id Registry.dest | `drop_dm_object_name("Registry")` | join [| tstats `summariesonly` count values(Processes.user) as user values(Processes.process_name) as process_name values(Processes.parent_process_name) as parent_process_name FROM datamodel=Endpoint.Processes where Processes.process_name = reg.exe by Processes.process_id | `drop_dm_object_name("Processes")`]

[ESCU - Get Risk Modifiers For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Risk Modifiers For Endpoint
description = For the last 7 days, the search will query the Risk data model in Splunk Enterprise Security and calculate the count, sum of the risk\_scores, names of the correlation searches that contributed to create a risk score for a specific endpoint(machine\_name) 
action.escu.creation_date = 2017-10-14
action.escu.modification_date = 2017-10-19
action.escu.analytic_story = ["Account Monitoring and Controls", "Apache Struts Vulnerability", "Asset Tracking", "Brand Monitoring", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "Credential Dumping", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Lateral Movement", "Malicious PowerShell", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router & Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Splunk Enterprise Vulnerability CVE-2018-11409", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Risk"]
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = none
action.escu.how_to_implement = Enable the correlation searches included in Splunk Enterprise Security that include Risk Analysis alert actions by leveraging the Risk Analysis Framework
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | from datamodel:Risk.All_Risk | search risk_object_type=system risk_object={dest} | stats count sum(risk_score) as risk_score values(search_name)  min(_time) as firstTime max(_time) as lastTime by risk_object | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Get Risk Modifiers For User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Risk Modifiers For User
description = For the last 7 days, the search will query the Risk data model in Splunk Enterprise Security and calculate the count, sum of the risk_scores, names of the correlation searches that contributed to create a risk score for a specific user 
action.escu.creation_date = 2017-10-14
action.escu.modification_date = 2017-10-19
action.escu.analytic_story = ["Account Monitoring and Controls", "Apache Struts Vulnerability", "Asset Tracking", "Brand Monitoring", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "Credential Dumping", "DHS Report TA18-074A", "DNS Amplification Attacks", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Lateral Movement", "Malicious PowerShell", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router & Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Risk"]
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = none
action.escu.how_to_implement = Enable the correlation searches included in Splunk Enterprise Security that include Risk Analysis alert actions by leveraging the Risk Analysis Framework
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["user"]
disabled=true
schedule_window = auto
is_visible = false
search = | from datamodel:Risk.All_Risk | search risk_object_type=user risk_object={user} | stats count sum(risk_score) as risk_score values(search_name)  min(_time) as firstTime max(_time) as lastTime by risk_object |`ctime(firstTime)` |`ctime(lastTime)` 

[ESCU - Get Sysmon WMI Activity for Host]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Sysmon WMI Activity for Host
description = This search queries Sysmon WMI events for the host of interest.
action.escu.creation_date = 2018-10-23
action.escu.modification_date = 2018-10-23
action.escu.analytic_story = ["Ransomware", "Suspicious WMI Use"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Sysmon"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be collecting Sysmon data using Sysmon version 6.1 or greater and have Sysmon configured to generate events for WMI activity. In addition, you must have at least version 6.0.4 of the Sysmon TA installed to properly parse the fields.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["process", "dest"]
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" EventCode>18 EventCode<22 host={dest} | rename host as dest | table _time, dest, user, Name, Operation, EventType, Type, Query, Consumer, Filter

[ESCU - Get Update Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Update Logs For Endpoint
description = This search will tell you give you the update logs for a specific endpoint for the last week.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-08-24
action.escu.analytic_story = ["Command and Control", "DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Updates"]
action.escu.providing_technologies = ["Microsoft Windows", "Linux", "macOS"]
action.escu.eli5 = none
action.escu.how_to_implement = You need to be ingesting the update logs from your various systems.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | from datamodel Updates.Updates  | search (vendor_product="Microsoft Windows" OR vendor_product="OSX:Update" OR vendor_product="Linux:Update") dest={dest}

[ESCU - Get User Information from Identity Table]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get User Information from Identity Table
description = Gather more information about the user identified in the Notable Event.
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-09-20
action.escu.analytic_story = ["AWS Cryptomining", "AWS Network ACL Activity", "Account Monitoring and Controls", "Apache Struts Vulnerability", "Asset Tracking", "Brand Monitoring", "ColdRoot MacOS RAT", "Collection and Staging", "Command and Control", "Credential Dumping", "DHS Report TA18-074A", "Data Protection", "Disabling Security Tools", "Dynamic DNS", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Lateral Movement", "Malicious PowerShell", "Monitor for Unauthorized Software", "Monitor for Updates", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "Router & Infrastructure Security", "SQL Injection", "SamSam Ransomware", "Spectre And Meltdown Vulnerabilities", "Splunk Enterprise Vulnerability", "Suspicious AWS EC2 Activities", "Suspicious AWS Login Activities", "Suspicious AWS S3 Activities", "Suspicious Command-Line Executions", "Suspicious DNS Traffic", "Suspicious Emails", "Suspicious MSHTA Activity", "Suspicious WMI Use", "Suspicious Windows Registry Activities", "Unusual Processes", "Use of Cleartext Protocols", "Windows Defense Evasion Tactics", "Windows File Extension and Association Abuse", "Windows Log Manipulation", "Windows Persistence Techniques", "Windows Privilege Escalation", "Windows Service Abuse"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must have populated the identity table with information about your users.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["user"]
disabled=true
schedule_window = auto
is_visible = false
search = | `identities` | search identity={user} | table _time, identity, first, last, email, category, watchlist

[ESCU - Get Vulnerability Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Vulnerability Logs For Endpoint
description = This search will show you any vulnerabilities noted for a specific endpoint for the last week.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-10
action.escu.analytic_story = ["ColdRoot MacOS RAT", "Command and Control", "DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Vulnerabilities"]
action.escu.providing_technologies = ["Nessus"]
action.escu.eli5 = none
action.escu.how_to_implement = You need to be ingesting the logs from your vulnerability scanner.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | from datamodel Vulnerabilities.Vulnerabilities | search dest={dest}

[ESCU - Get Web Session Information via session_id]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Get Web Session Information via session_id
description = This search helps an analyst investigate a notable event to find out more about a specific web session. The search looks for a specific web session ID in the HTTP web traffic and outputs the URL and user agents, grouped by source IP address and HTTP status code.
action.escu.creation_date = 2018-10-08
action.escu.modification_date = 2018-10-08
action.escu.analytic_story = ["Web Fraud Detection"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Stream"]
action.escu.eli5 = none
action.escu.how_to_implement = This search leverages data extracted from Stream:HTTP. You must configure the HTTP stream using the Splunk Stream App on your Splunk Stream deployment server.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["session_id"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=stream:http {session_id} | stats values(url) values(http_user_agent) by src_ip status

[ESCU - Investigate AWS User Activities by user field]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate AWS User Activities by user field
description = This search lists all the logged CloudTrail activities by a specific user and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and the user's identity information.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS User Monitoring"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["user"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail user={user} | table _time userIdentity.type userIdentity.userName userIdentity.arn aws_account_id src awsRegion eventName eventType 

[ESCU - Investigate AWS activities via region name]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate AWS activities via region name
description = This search lists all the user activities logged by CloudTrail for a specific region in question and will create a table of the values of parameters requested, the type of the event and the response from the AWS API by each user
action.escu.creation_date = 2018-02-09
action.escu.modification_date = 2018-02-09
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities", "Suspicious AWS S3 Activities"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = none
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["awsRegion"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=aws:cloudtrail awsRegion={awsRegion}| rename requestParameters.instancesSet.items{}.instanceId as instanceId| stats values(eventName) by userName instanceId

[ESCU - Investigate Network Traffic From src_ip]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Network Traffic From src_ip
description = This search allows you to find all the network traffic from a specific IP address.
action.escu.creation_date = 2018-06-15
action.escu.modification_date = 2018-06-15
action.escu.analytic_story = ["ColdRoot MacOS RAT", "Splunk Enterprise Vulnerability CVE-2018-11409"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Network_Traffic"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Palo Alto Firewall"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be ingesting your web-traffic logs and populating the web data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip"]
disabled=true
schedule_window = auto
is_visible = false
search = | from datamodel Network_Traffic.All_Traffic | search src_ip={src_ip}

[ESCU - Investigate Successful Remote Desktop Authentications]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Successful Remote Desktop Authentications
description = This search returns the source, destination, and user for all successful remote-desktop authentications. A successful authentication after a brute-force attack on a destination machine is suspicious behavior. 
action.escu.creation_date = 2018-12-14
action.escu.modification_date = 2018-12-14
action.escu.analytic_story = ["DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Monitor for Unauthorized Software", "Ransomware", "SamSam Ransomware"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Authentication"]
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = none
action.escu.how_to_implement = You must be populating the Authentication data model with security events from your Windows event logs.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Authentication where Authentication.signature_id=4624 Authentication.app=win:remote by Authentication.src Authentication.dest Authentication.app Authentication.user Authentication.signature Authentication.src_nt_domain | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("Authentication")`| table firstTime lastTime src src_nt_domain dest user app count | sort count

[ESCU - Investigate Suspicious Strings in HTTP Header]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Suspicious Strings in HTTP Header
description = This search helps an analyst investigate a notable event related to a potential Apache Struts exploitation. To investigate, we will want to isolate and analyze the "payload" or the commands that were passed to the vulnerable hosts by creating a few regular expressions to carve out the commands focusing on common keywords from the payload, such as cmd.exe, /bin/bash and whois. The search returns these suspicious strings found in the HTTP logs of the system of interest.
action.escu.creation_date = 2017-06-26
action.escu.modification_date = 2017-10-20
action.escu.analytic_story = ["Apache Struts Vulnerability"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.providing_technologies = ["Splunk Stream"]
action.escu.eli5 = none
action.escu.how_to_implement = This particular search leverages data extracted from Stream:HTTP. You must configure the http stream using the Splunk Stream App on your Splunk Stream deployment server to extract the cs_content_type field.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip", "dest_ip"]
disabled=true
schedule_window = auto
is_visible = false
search = | search sourcetype=stream:http src_ip="{src_ip}" dest_ip="{dest_ip}" | eval cs_content_type_length = len(cs_content_type) | search cs_content_type_length > 100 | rex field="cs_content_type" (?<suspicious_strings>cmd.exe) | eval suspicious_strings_found=if(match(cs_content_type, "application"), "True", "False")  | rename suspicious_strings_found AS "Suspicious Content-Type Found" | fields "Suspicious Content-Type Found", dest_ip, src_ip, suspicious_strings, cs_content_type, cs_content_type_length, url

[ESCU - Investigate Web Activity From Host]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Web Activity From Host
description = This search allows you to find all the web activity from a specific host. During an investigation, it is important to profile web activity to characterize user or host activity.
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-11-09
action.escu.analytic_story = ["Brand Monitoring", "Command and Control", "Credential Dumping", "DHS Report TA18-074A", "Disabling Security Tools", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "Host Redirection", "JBoss Vulnerability", "Lateral Movement", "Monitor for Unauthorized Software", "Netsh Abuse", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware", "Suspicious Command-Line Executions", "Suspicious Emails", "Unusual Processes"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Web"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search you must be ingesting your web traffic and populating the Web data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["dest"]
disabled=true
schedule_window = auto
is_visible = false
search = | from datamodel Web.Web | search src={dest}

[ESCU - Investigate Web Activity From src_ip]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Web Activity From src_ip
description = This search searches for all web activity from a specific host. During an investigation, it is important to profile web activity to characterize user or host activity.
action.escu.creation_date = 2018-06-15
action.escu.modification_date = 2018-06-15
action.escu.analytic_story = ["ColdRoot MacOS RAT", "Dynamic DNS", "Splunk Enterprise Vulnerability CVE-2018-11409"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Web"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be ingesting your web traffic and populating the web data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src_ip"]
disabled=true
schedule_window = auto
is_visible = false
search = | from datamodel Web.Web | search src={src_ip}

[ESCU - Investigate Web POSTs From src]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = investigative
action.escu.full_search_name = ESCU - Investigate Web POSTs From src
description = This investigative search retrieves POST requests from a specified source IP or hostname. Identifying the POST requests, as well as their associated destination URLs and user agent(s), may help you scope and characterize the suspicious traffic. 
action.escu.creation_date = 2018-12-06
action.escu.modification_date = 2018-12-06
action.escu.analytic_story = ["Apache Struts Vulnerability"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
action.escu.data_models = ["Web"]
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.eli5 = none
action.escu.how_to_implement = To successfully implement this search, you must be ingesting your web-traffic logs and populating the web data model.
action.escu.known_false_positives = None at this time
action.escu.fields_required = ["src"]
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` values(Web.url) as url from datamodel=Web by Web.src,Web.http_user_agent,Web.http_method | `drop_dm_object_name("Web")`| where like(src, "{src}") and like(http_method, "POST")

### END ESCU INVESTIGATIONS ###

### ESCU BASELINES ###

[ESCU - Add Prohibited Processes to Enterprise Security]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Add Prohibited Processes to Enterprise Security
action.escu.description = This search takes the existing interesting process table from ES, filters out any existing additions added by ESCU and then updates the table with processes identified by ESCU that should be prohibited on your endpoints.
action.escu.creation_date = 2017-06-27
action.escu.modification_date = 2017-09-15
action.escu.analytic_story = ["DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Monitor for Unauthorized Software", "Ransomware", "SamSam Ransomware"]
action.escu.data_models = []
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = This search outputs the interesting processes lookup table and filters out all processes in the table that haven't already been inserted by ESCU. It then appends to those results all the processes currently identified by ESCU that should be prohibited. Next, it fills in the required fields with processes identified by ESCU, and then writes the results back to the interesting process lookup table. This is done so any new processes identified that should be prohibited will be added to the lookup table without creating any duplicate entries.
action.escu.how_to_implement = This search should be run on each new install of ESCU.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = | inputlookup interesting_processes_lookup | search note!=ESCU* | inputlookup append=T prohibitedProcesses_lookup | fillnull value=* dest dest_pci_domain | fillnull value=false is_required is_secure | fillnull value=true is_prohibited | outputlookup interesting_processes_lookup | stats count

[ESCU - Baseline of API Calls per User ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of API Calls per User ARN
action.escu.description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-04-09
action.escu.analytic_story = ["AWS User Monitoring"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = This search returns all log events that are API calls, pulls out the ARN that initiated each call, and collects them in one-hour groupings. Next, it calculates the number of API calls made per ARN per hour. For each ARN, it calculates the average and standard deviation of this count on a per-hour basis.  It also includes the number of data points each ARN had. This table is then stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventType=AwsApiCall | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup api_call_by_user_baseline | stats count

[ESCU - Baseline of Network ACL Activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Network ACL Activity by ARN
action.escu.description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls that were related to network ACLs made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-05-21
action.escu.modification_date = 2018-05-21
action.escu.analytic_story = ["AWS Network ACL Activity"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = Use this search to create a baseline for API calls related to network ACLs for the users who initiated this activity. It returns all logged API calls for network activity, pulls out the ARN that initiated each call, and collects the `eventNames` in one-hour groupings. Next, it calculates the number of API calls made per ARN per-hour. For each ARN, it calculates the average and standard deviation of this count on a per-hour basis. It also includes the number of data points for each ARN. This table is stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove API event names for network ACLs, edit the macro `NetworkACLEvents`.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `NetworkACLEvents` | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup network_acl_activity_baseline | stats count

[ESCU - Baseline of S3 Bucket deletion activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of S3 Bucket deletion activity by ARN
action.escu.description = This search establishes, on a per-hour basis, the average and standard deviation for the number of API calls related to deleting an S3 bucket by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-07-17
action.escu.modification_date = 2018-07-17
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = Use this search to create a baseline for API calls related to deleting an S3 bucket, grouped by the users who initiated this activity. It returns all logged API calls for S3 bucket-deletion activity and then pulls out the ARN that initiated each call. Next, it calculates the number of API calls made per ARN per hour. For each ARN, it calculates the average and standard deviation of this count on a per-hour basis. It also includes the number of data points for each ARN. This table is stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=DeleteBucket | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup s3_deletion_baseline | stats count

[ESCU - Baseline of Security Group Activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of Security Group Activity by ARN
action.escu.description = This search establishes, on a per-hour basis, the average and the standard deviation for the number of API calls related to security groups made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-04-17
action.escu.modification_date = 2018-04-17
action.escu.analytic_story = ["AWS User Monitoring"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = Use this search to create a baseline for API calls related to security groups by the users who initiated this activity. It returns all logged API calls for all security-group-related activity, pulls out the ARN that initiated each call, and collects the `eventNames` in one-hour groupings. Next, it calculates the number of API calls made per ARN per hour. For each ARN, it calculates the average and standard deviation of this count on a per-hour basis. It also includes the number of data points for each ARN. This table is stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove API event names for security groups, edit the macro `securityGroupAPIs`.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `securityGroupAPIs` | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup security_group_activity_baseline | stats count

[ESCU - Baseline of blocked outbound traffic from AWS]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Baseline of blocked outbound traffic from AWS
action.escu.description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of outbound connections blocked in your VPC flow logs by each source IP address (IP address of your EC2 instances). Also recorded is the number of data points for each source IP. This table outputs to a lookup file to allow the detection search to operate quickly.
action.escu.creation_date = 2018-04-26
action.escu.modification_date = 2018-05-07
action.escu.analytic_story = ["AWS Network ACL Activity", "Command and Control", "Suspicious AWS Traffic"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = Use this search to create a baseline of blocked outbound network connections by each source IP in your AWS environment. This search returns all log events that correspond to a blocked outbound network connection, extracts the source IP from where the outbound connection was initiated, and collects the events in one-hour groupings. Next, it calculates the number of outbound connections blocked per hour. For each source IP, it calculates the average and standard deviation of this count on a per-hour basis.  It also includes the number of data points each source IP had. This table is then stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your `VPC flow logs.`.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudwatchlogs:vpcflow action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | bucket _time span=1h | stats count as numberOfBlockedConnections by _time, src_ip | stats count(numberOfBlockedConnections) as numDataPoints, latest(numberOfBlockedConnections) as latestCount, avg(numberOfBlockedConnections) as avgBlockedConnections, stdev(numberOfBlockedConnections) as stdevBlockedConnections by src_ip | table src_ip, latestCount, numDataPoints, avgBlockedConnections, stdevBlockedConnections | outputlookup baseline_blocked_outbound_connections | stats count

[ESCU - Count of Unique IPs Connecting to Ports]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Count of Unique IPs Connecting to Ports
action.escu.description = The search counts the number of times a connection was observed to each destination port, and the number of unique source IPs connecting to them.
action.escu.creation_date = 2017-06-24
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = ["Command and Control", "Prohibited Traffic Allowed or Protocol Mismatch"]
action.escu.data_models = ["Network_Traffic"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = For each port being accessed on the network, this search gives the total number of connections observed, and the number of unique IP addresses making those connections.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting network traffic, and populating the Network_Traffic data model.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count dc(All_Traffic.src) as numberOfUniqueHosts from datamodel=Network_Traffic by All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Count of assets by category]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Count of assets by category
action.escu.description = This search shows you every asset category you have and the assets that belong to those categories.
action.escu.creation_date = 2017-06-11
action.escu.modification_date = 2017-09-13
action.escu.analytic_story = ["Asset Tracking"]
action.escu.data_models = ["Identity_Management"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.eli5 = This search gives you the number and the names of the hosts of each host in your environment by category. It will then sort them by the count.
action.escu.how_to_implement = To successfully implement this search you must first leverage the Assets and Identity framework in Enterprise Security to populate your assets_by_str.csv file which should then be mapped to the Identity_Management data model. The Identity_Management data model will contain a list of known authorized company assets. Ensure that all inventoried systems are constantly vetted and updated.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = | from datamodel Identity_Management.All_Assets | stats count values(nt_host) by category | sort -count

[ESCU - Create a list of approved AWS service accounts]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Create a list of approved AWS service accounts
action.escu.description = This search looks for successful API activity in CloudTrail within the last 30 days, filters out known users from the identity table, and outputs values of users into <code>aws_service_accounts.csv</code> lookup file.
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-12-03
action.escu.analytic_story = ["AWS User Monitoring"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = We first look for all successful CloudTrail API activity caused by types of user accounts and then remove all the events caused by users in the Identity table. This generates a list of accounts--typically service accounts--configured in your AWS environment. We output this list of service accounts to `aws_service_accounts.csv`.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the service account entires in `aws_service_accounts.csv`, which is a lookup file created as a result of running this support search. Please remove the entries of service accounts that are not legitimate.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail errorCode=success | rename userName as identity | search NOT [inputlookup identity_lookup_expanded | fields identity] | stats count by identity | table identity | outputlookup aws_service_accounts | stats count

[ESCU - DNSTwist Domain Names]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - DNSTwist Domain Names
action.escu.description = This search creates permutations of your existing domains, removes the valid domain names and stores them in a specified lookup file so they can be checked for in the associated detection searches.
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2018-10-08
action.escu.analytic_story = ["Brand Monitoring"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Enterprise"]
action.escu.eli5 = This search starts with the dnstwist command consuming domains from a file called domains.csv in the DA-ESS-SOC/lookups directory. This search then adds a domain\_abuse=true term to each permutation, removes all the valid domain names and stores all that information into a lookup file that is used in the associated detection search. Alternatively domain dnstwist permutations can be calculated from domains in the `cim_corporate_email_domains.csv` and `cim_corporate_web_domains.csv` lookups located in **Splunk\_SA\_CIM** using argument `populate_from_cim=true`. Also an individual domain can be passed using argument `domain=<domain>`
action.escu.how_to_implement = To successfully implement this search you need to update the file called domains.csv in the DA-ESS-SOC/lookup directory. Or `cim_corporate_email_domains.csv` and `cim_corporate_web_domains.csv` from **Splunk\_SA\_CIM**.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = | dnstwist domainlist=domains.csv | `remove_valid_domains` | eval domain_abuse="true" | table domain, domain_abuse | outputlookup brandMonitoring_lookup | stats count

[ESCU - Discover DNS records]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Discover DNS records
action.escu.description = The search takes corporate and common cloud provider domains configured under `cim_corporate_email_domains.csv`, `cim_corporate_web_domains.csv`, and `cloud_domains.csv` finds their responses across the last 30 days from data in the `Network_Resolution ` datamodel, then stores the output under the `discovered_dns_records.csv` lookup
action.escu.creation_date = 2019-02-14
action.escu.modification_date = 2019-02-14
action.escu.analytic_story = ["DNS Hijacking"]
action.escu.data_models = ["Network_Resolution"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = Discover the DNS records and their answers for domains owned by the company using network traffic events. The discovered events are exported as a lookup named `discovered_dns_records.csv`
action.escu.how_to_implement = To successfully implement this search, you must be ingesting DNS logs, and populating the Network_Resolution data model. Also make sure that the cim_corporate_web_domains and cim_corporate_email_domains lookups are populated with the domains owned by your corporation
action.escu.known_false_positives = Please vet the lookup created by this baseline search 
action.escu.fields_required = ["query", "answer"]
disabled=true
schedule_window = auto
is_visible = false
search = | inputlookup cim_corporate_email_domains.csv | inputlookup append=T cim_corporate_web_domains.csv | inputlookup append=T cim_cloud_domains.csv | eval domain = trim(replace(domain, "\*", "")) | join domain [|tstats summariesonly=true count values(DNS.record_type) as type, values(DNS.answer) as answer from datamodel=Network_Resolution where DNS.message_type=RESPONSE DNS.answer!="unknown" DNS.answer!="" by DNS.query | rename DNS.query as query | where query!="unknown" | rex field=query "(?<domain>\w+\.\w+?)(?:$|/)"] | makemv delim=" " answer |  makemv delim=" " type | sort -count | table count,domain,type,query,answer | outputlookup createinapp=true discovered_dns_records.csv

[ESCU - Identify Systems Creating Remote Desktop Traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Creating Remote Desktop Traffic
action.escu.description = This search counts the numbers of times the system has generated remote desktop traffic.
action.escu.creation_date = 2017-04-24
action.escu.modification_date = 2017-09-15
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement"]
action.escu.data_models = ["Network_Traffic"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = This search counts the numbers of times the system has tried to connect to another system on TCP/3389, the default port used for RDP traffic.
action.escu.how_to_implement = To successfully implement this search, you must ingest network traffic and populate the Network_Traffic data model.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=3389 by All_Traffic.src | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Identify Systems Receiving Remote Desktop Traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Receiving Remote Desktop Traffic
action.escu.description = This search counts the numbers of times the system has created remote desktop traffic
action.escu.creation_date = 2017-04-24
action.escu.modification_date = 2017-09-15
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement"]
action.escu.data_models = ["Network_Traffic"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.eli5 = This search counts the numbers of times the system has received a connection to TCP/ 3389, the default port used for RDP traffic.
action.escu.how_to_implement = To successfully implement this search you must ingest network traffic and populate the Network_Traffic data model. If a system receives a lot of remote desktop traffic, you can apply the category common_rdp_destination to it.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=3389 by All_Traffic.dest | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Identify Systems Using Remote Desktop]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Identify Systems Using Remote Desktop
action.escu.description = This search counts the numbers of times the remote desktop process, mstsc.exe, has run on each system.
action.escu.creation_date = 2017-04-18
action.escu.modification_date = 2019-04-01
action.escu.analytic_story = ["Hidden Cobra Malware", "Lateral Movement"]
action.escu.data_models = ["Endpoint"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = This search counts the numbers of times the remote desktop process, mstsc.exe, has run on each system. It does this by looking for the process name in the Endpoint data model.
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data that records process activity.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count from datamodel=Endpoint.Processes where Processes.process_name="*mstsc.exe*" by Processes.dest Processes.process_name | `drop_dm_object_name(Processes)` | sort - count

[ESCU - Monitor Successful Backups]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Monitor Successful Backups
action.escu.description = This search is intended to give you a feel for how often successful backups are conducted in your environment. Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Command and Control", "DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Netbackup"]
action.escu.eli5 = This search gives you the count and the hostname of all the systems that had a successful backup each day.
action.escu.how_to_implement = To successfully implement this search you must be ingesting your backup logs.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype="netbackup_logs" "Disk/Partition backup completed successfully." | bucket _time span=1d | stats dc(COMPUTERNAME) as count values(COMPUTERNAME) as dest by _time, MESSAGE

[ESCU - Monitor Unsuccessful Backups]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Monitor Unsuccessful Backups
action.escu.description = This search is intended to give you a feel for how often backup failures happen in your environments.  Fluctuations in these numbers will allow you to determine when you should investigate.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-12
action.escu.analytic_story = ["Command and Control", "DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Monitor Backup Solution", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Netbackup"]
action.escu.eli5 = This search gives you the count and hostname of all the systems that had a backup failure each day
action.escu.how_to_implement = To successfully implement this search you must be ingesting your backup logs.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype="netbackup_logs" "An error occurred, failed to backup." | bucket _time span=1d | stats dc(COMPUTERNAME) as count values(COMPUTERNAME) as dest by _time, MESSAGE

[ESCU - Previously Seen AWS Cross Account Activity]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Cross Account Activity
action.escu.description = This search looks for <b>AssumeRole</b> events where the requesting account differs from the requested account, then writes these relationships to a lookup file.
action.escu.creation_date = 2018-06-04
action.escu.modification_date = 2018-06-04
action.escu.analytic_story = ["AWS Cross Account Activity"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we look for **AssumeRole** events where the requesting account is different from the requested account. The first and last times these events are seen are written to a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Validate the user name entries in `previously_seen_aws_cross_account_activity.csv`, a lookup file created by this support search.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=AssumeRole | spath output=requestingAccountId path=userIdentity.accountId | spath output=requestedAccountId path=resources{}.accountId | search requestingAccountId=* | where requestingAccountId!=requestedAccountId | stats earliest(_time) as firstTime latest(_time) as lastTime by requestingAccountId, requestedAccountId | outputlookup previously_seen_aws_cross_account_activity | stats count

[ESCU - Previously Seen AWS Provisioning Activity Sources]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Provisioning Activity Sources
action.escu.description = This search builds a table of the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity. This is broadly defined as any event that runs or creates something.
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = This search includes any event name that begins with "run" or "create," and then determines the first and last time these events were seen for each IP address that initiated the action. The search then consults a **GeoIP** database to determine the physical location of this IP address. This table outputs to a file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats count

[ESCU - Previously Seen AWS Regions]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen AWS Regions
action.escu.description = This search looks for CloudTrail events where an AWS instance is started and creates a baseline of most recent time (latest) and the first time (earliest) we've seen this region in our dataset grouped by the value awsRegion for the last 30 days
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we create a table of the first time (earliest) and most recent time (latest) that this region has been seen in our dataset, grouped by the value `awsRegion`. We only look for those events where an instance has been started. All of these entries will be added to the `previously_seen_aws_regions.csv` lookup file, which will act like a baseline for detections. Please validate the entries of region names in the lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail StartInstances | stats earliest(_time) as earliest latest(_time) as latest by awsRegion | outputlookup previously_seen_aws_regions.csv | stats count

[ESCU - Previously Seen EC2 AMIs]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 AMIs
action.escu.description = This search builds a table of previously seen AMIs used to launch EC2 instances
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.analytic_story = ["AWS Cryptomining"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we create a table of the earliest and latest time that a specific AMI ID has been seen. This table is then outputted to a csv file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | rename requestParameters.instancesSet.items{}.imageId as amiID | stats earliest(_time) as earliest latest(_time) as latest by amiID | outputlookup previously_seen_ec2_amis.csv | stats count

[ESCU - Previously Seen EC2 Instance Types]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Instance Types
action.escu.description = This search builds a table of previously seen EC2 instance types
action.escu.creation_date = 2018-03-08
action.escu.modification_date = 2018-03-08
action.escu.analytic_story = ["AWS Cryptomining"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we create a table of the earliest and latest time that a specific EC2 instance type has been seen. The instanceType request field is not required and defaults to m1.small, so any time this field is null, the search defaults the field to m1.small. This table is then outputted to a csv file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | rename requestParameters.instanceType as instanceType | fillnull value="m1.small" instanceType | stats earliest(_time) as earliest latest(_time) as latest by instanceType | outputlookup previously_seen_ec2_instance_types.csv | stats count

[ESCU - Previously Seen EC2 Launches By User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Launches By User
action.escu.description = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.creation_date = 2018-03-15
action.escu.modification_date = 2018-03-15
action.escu.analytic_story = ["AWS Cryptomining", "Suspicious AWS EC2 Activities"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we create a table of the earliest and latest times that an ARN has launched a EC2 instance. This table is then outputted to a csv file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | rename userIdentity.arn as arn | stats earliest(_time) as firstTime latest(_time) as lastTime by arn | outputlookup previously_seen_ec2_launches_by_user.csv | stats count

[ESCU - Previously Seen EC2 Modifications By User]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen EC2 Modifications By User
action.escu.description = This search builds a table of previously seen ARNs that have launched a EC2 instance.
action.escu.creation_date = 2018-04-05
action.escu.modification_date = 2018-04-05
action.escu.analytic_story = ["Unusual AWS EC2 Modifications"]
dispatch.earliest_time = -90d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we create a table of the earliest and latest times that an ARN has modified a EC2 instance. The list of APIs that modify an EC2 are defined in the `ec2ModificationAPIs` macro for ease of use. This table is then outputted to a file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove APIs that modify an EC2 instance, edit the macro `ec2ModificationAPIs`.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail `ec2ModificationAPIs` errorCode=success | spath output=arn userIdentity.arn | stats earliest(_time) as firstTime latest(_time) as lastTime by arn | outputlookup previously_seen_ec2_modifications_by_user | stats count

[ESCU - Previously Seen Running Windows Services]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously Seen Running Windows Services
action.escu.description = This collects the services that have been started across your entire enterprise.
action.escu.creation_date = 2018-07-20
action.escu.modification_date = 2019-02-27
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Orangeworm Attack Group", "Windows Persistence Techniques", "Windows Service Abuse"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = In this support search, we look for Windows system-event code that indicates a status change of a Windows service. It extracts both the name of the service and the action taken by the service from the logs. It keeps only services that have entered the running state. Finally, it finds the first time the service has been seen running across the enterprise and writes that file to a lookup table.
action.escu.how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows security-event logs for it to execute successfully.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = eventtype=wineventlog_system signature_id=7036 | rex field=Message "The (?<serviceName>[\w\s-]*) service entered the (?<action>\w*) state" | where action="running" | stats earliest(_time) as firstTime, latest(_time) as lastTime by serviceName | outputlookup previously_seen_running_windows_services | stats count

[ESCU - Previously seen API call per user roles in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen API call per user roles in CloudTrail
action.escu.description = This search looks for successful API calls made by different user roles, then creates a baseline of the earliest and latest times we have encountered this user role. It also returns the name of the API call in our dataset--grouped by user role and name of the API call--that occurred within the last 30 days. In this support search, we are only looking for events where the user identity is Assumed Role.
action.escu.creation_date = 2018-04-01
action.escu.modification_date = 2018-04-16
action.escu.analytic_story = ["AWS User Monitoring"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we are looking for successful API calls made by user roles within your AWS infrastructure. The intent is to create an initial baseline cache of names of the API calls per security role for the previous 30 days--including the earliest and latest times seen in our dataset--grouped by the value of user role and the name of the API call. It is also worth noting that the role of a particular user is parsed as "userName" in the CloudTrail logs.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user role entries in `previously_seen_api_calls_from_user_roles.csv`, which is a lookup file created as a result of running this support search.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventType=AwsApiCall errorCode=success userIdentity.type=AssumedRole | stats earliest(_time) as earliest latest(_time) as latest by userName eventName | outputlookup previously_seen_api_calls_from_user_roles | stats count

[ESCU - Previously seen S3 bucket access by remote IP]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen S3 bucket access by remote IP
action.escu.description = This search looks for successful access to S3 buckets from remote IP addresses, then creates a baseline of the earliest and latest times we have encountered this remote IP within the last 30 days. In this support search, we are only looking for S3 access events where the HTTP response code from AWS is "200"
action.escu.creation_date = 2018-06-28
action.escu.modification_date = 2018-06-28
action.escu.analytic_story = ["Suspicious AWS S3 Activities"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we are looking for successful S3 bucket-access attempts made from remote IPs. The intent is to create an initial baseline cache of remote IP addresses per bucket name for the previous 30 days--including the earliest and latest times seen in our dataset--grouped by the value of remote IP and the name of the S3 bucket.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your S3 access-logs inputs. You must validate the remote IP and bucket name entries in `previously_seen_S3_access_from_remote_ip.csv`, which is a lookup file created as a result of running this support search.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:s3:accesslogs http_status=200  | stats  earliest(_time) as earliest latest(_time) as latest by bucket_name remote_ip | outputlookup previously_seen_S3_access_from_remote_ip | stats count

[ESCU - Previously seen command line arguments]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen command line arguments
action.escu.description = This search looks for command-line arguments where <code>cmd.exe /c</code> is used to execute a program, then creates a baseline of the earliest and latest times we have encountered this command-line argument in our dataset within the last 30 days.
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2019-03-01
action.escu.analytic_story = ["DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "Malicious PowerShell", "Orangeworm Attack Group", "Possible Backdoor Activity Associated With MUDCARP Espionage Campaigns", "Suspicious Command-Line Executions"]
action.escu.data_models = ["Endpoint"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = In this support search, we look for command-line arguments using the parameter `/c` to execute processes and create an initial baseline cache for the previous 30 days. This will include the earliest and latest times a particular command-line argument is seen in our dataset, grouped by the command-line value.
action.escu.how_to_implement = You must be ingesting data that records process activity from your hosts to populate the Endpoint data model in the Processes node. You must be ingesting logs with both the process name and command line from your endpoints. The complete process name with command-line arguments are mapped to the "process" field in the Endpoint data model.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Endpoint.Processes where Processes.process_name = cmd.exe Processes.process = "* /c *" by Processes.process | `drop_dm_object_name(Processes)`

[ESCU - Previously seen users in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Previously seen users in CloudTrail
action.escu.description = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times we have encountered this user in our dataset, grouped by ARN, within the last 30 days.
action.escu.creation_date = 2018-02-23
action.escu.modification_date = 2018-02-23
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["AWS"]
action.escu.eli5 = In this support search, we look for console login events by a particular user and create an initial baseline cache for the previous seven days, including the earliest and latest times a particular user ARN is seen in our dataset, grouped by the ARN value.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user name entries in `previously_seen_users_console_logins.csv`, which is a lookup file created as a result of running this support search.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = sourcetype=aws:cloudtrail eventName=ConsoleLogin | rename userIdentity.arn as arn | stats earliest(_time) as earliest latest(_time) as latest by arn | outputlookup previously_seen_users_console_logins.csv | stats count

[ESCU - Systems Ready for Spectre-Meltdown Windows Patch]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Systems Ready for Spectre-Meltdown Windows Patch
action.escu.description = Some AV applications can cause the Spectre/Meltdown patch for Windows not to install successfully. This registry key is supposed to be created by the AV engine when it has been patched to be able to handle the Windows patch. If this key has been written, the system can then be patched for Spectre and Meltdown.
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.analytic_story = ["Spectre And Meltdown Vulnerabilities"]
action.escu.data_models = ["Change_Analysis"]
dispatch.earliest_time = -1d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.eli5 = This search looks to see if a registry key was created at `HKLM\Software\Microsoft\Windows\CurrentVersion\QualityCompat`. It will tell you when it was created and, if possible, what process created it.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="HKLM\Software\Microsoft\Windows\CurrentVersion\QualityCompat*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes")`

[ESCU - Windows Updates Install Failures]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Windows Updates Install Failures
action.escu.description = This search is intended to give you a feel for how often Windows updates fail to install in your environment. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = ["Command and Control", "DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware"]
action.escu.data_models = ["Updates"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = This search gives you the count of the number of systems that attempted and failed to install a Windows update each day.
action.escu.how_to_implement = You must be ingesting your Windows Update Logs
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` dc(Updates.dest) as count FROM datamodel=Updates where Updates.vendor_product="Microsoft Windows" AND Updates.status=failure by _time span=1d

[ESCU - Windows Updates Install Successes]
action.escu = 0
action.escu.enabled = 1
action.escu.search_type = support
action.escu.full_search_name = ESCU - Windows Updates Install Successes
action.escu.description = This search is intended to give you a feel for how often successful Windows updates are applied in your environments. Fluctuations in these numbers will allow you to determine when you should be concerned.
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-14
action.escu.analytic_story = ["Command and Control", "DHS Report TA18-074A", "Emotet Malware (TA18-201A)", "Hidden Cobra Malware", "JBoss Vulnerability", "Lateral Movement", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware", "SamSam Ransomware"]
action.escu.data_models = ["Updates"]
dispatch.earliest_time = -30d@d
dispatch.latest_time = -10m@m
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.eli5 = This search gives you the count and name of all the systems that had a successful update applied each day
action.escu.how_to_implement = You must be ingesting your Windows Update Logs
action.escu.known_false_positives = 
disabled=true
schedule_window = auto
is_visible = false
search = | tstats `summariesonly` dc(Updates.dest) as count FROM datamodel=Updates where Updates.vendor_product="Microsoft Windows" AND Updates.status=installed by _time span=1d

### END ESCU BASELINES ###[ESCU - Detect DNS requests to Phishing Sites leveraging EvilGinx2 - Rule]
action.customsearchbuilder.spec = {}
action.email = 1
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.to = cyrus_tam@macroview.com
action.notable.param.extract_assets = ["src","dest","dvc","orig_host"]
action.notable.param.extract_identities = ["src_user","user"]
action.notable.param.next_steps = {"version":1,"data":"Recommended following                         steps:\n\n1. [[action|runphantomplaybook]]: Phantom playbook                         recommendations:\nSplunk>Phantom Response Playbook - Monitor enrichment of the                         Splunk>Phantom Playbook called Domain Certificate Investigation and answer any                         analyst prompt in Mission Control with a response decision.                         Link to the playbook https://my.phantom.us/4.2/playbook/lets-encrypt-domain-investigate/\n2. [[action|escu_investigate]]:                         Based on ESCU investigate recommendations:\nESCU - Get Certificate logs for a domain\n"}
[default]

[Ransomware_Basic_rule]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result.human_readable_time$ , app=$result.app$, Source=$result.source$, Sourcetype=$result.sourcetype$, malware=$result.malware$, bytes=$result.bytes$, matching=$result.matching$, priority=$result.priority$, registrar=$result.registrar$, src_ip=$result.src_ip$, status=$result.status$, dest_ip=$result.dest_ip$, dest_port=$result.dest_port$, event_name=$result.event_name$, killchain=$result.kilchain$, threat=$result.threat$, URL=$result.URL$ , domain=$result.domain$, RAW='$result._raw$'
action.logevent.param.index = ransomware_basic
action.logevent.param.source = ransomware_basic
action.logevent.param.sourcetype = ransomware_basic
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -6m@m
dispatch.latest_time = -1m@m
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCRansomwareBasic
request.ui_dispatch_view = search
search = index=* (tag::eventtype="web" OR tag::eventtype="proxy" ) | rex mode=sed field=url "s/http:\/\///" | rex mode=sed field=url  "s/https:\/\///" | rex mode=sed field=url  "s/:443//" | rex mode=sed field=url  "s/\/$//" | rename url as URL | join URL [ | inputlookup ransomware.csv | rex mode=sed field=url "s/http:\/\///" | rex mode=sed field=url  "s/https:\/\///" | rex mode=sed field=url  "s/\/$//" | rename url as URL   | eval matching="url"]  | append [ search index=* (tag::eventtype="web" OR tag::eventtype="proxy" OR tag::eventtype="communicate" OR tag::eventtype="network") | join dest_ip [ |inputlookup ransomware.csv | search ip_address=* |rename ip_address as dest_ip ] | eval matching="ip" ] | append [ search index=* (tag::eventtype="web" OR tag::eventtype="proxy") | rex field=url "((http:\/\/)?(?<domain>[a-zA-Z0-9\-\.]+)(\:|\/)?(\d+)?.*)"  | join domain [ |inputlookup ransomware.csv | rename host as domain ] | eval matching="domain" ] | eval priority = case(threat == "C2" AND ( matching == "domain" OR matching == "ip" ), "3",threat == "C2" AND matching == "url", "9", threat == "Distribution Site" AND (matching == "ip" OR matching == "domain"), "3", threat == "Distribution Site" AND matching == "url", "7", threat == "Payment Site" and ( matching == "domain" OR matching == "ip" ), "4", threat == "Payment Site" and  matching == "url", "9" ) | eval event_name = case( action == "allowed" AND threat == "C2" AND ( matching == "domain" OR matching == "ip" ), "Ransomware - Successful Connection to C2 IP or Domain", action == "allowed" AND threat == "C2" AND matching == "url", "Ransomware - Successful Connection to C2 URL", action == "allowed" AND threat == "Distribution Site" AND (matching == "ip" OR matching == "domain"), "Ransomware - Successful Connection to Distribution IP or Domain", action == "allowed" AND threat == "Distribution Site" AND matching == "url", "Ransomware - Successful Connection to Distribution URL", action == "allowed" AND threat == "Payment Site" and ( matching == "domain" OR matching == "ip" ), "Ransomware - Successful Connection to Payment IP or Domain", action == "allowed" AND threat == "Payment Site" and  matching == "url", "Ransomware - Successful Connection to Payment URL", ( action == "blocked" OR action == "dropped" ) AND threat == "C2" AND matching == "url", "Ransomware - Unsuccessful Connection to C2 URL", ( action == "blocked" OR action == "dropped" ) AND threat == "Payment Site" and  matching == "url", "Ransomware - Unsuccessful Connection to Payment URL") | eval kilchain= case( event_name == "Ransomware - Successful Connection to C2 IP or Domain", "C2", event_name == "Ransomware - Successful Connection to C2 URL", "C2", event_name == "Ransomware - Successful Connection to Distribution IP or Domain", "Delivery", event_name == "Ransomware - Successful Connection to Distribution URL", "Delivery",  event_name == "Ransomware - Successful Connection to Payment IP or Domain", "Payment Site", event_name == "Ransomware - Successful Connection to Payment URL", "Actions on Objective", event_name == "Ransomware - Unsuccessful Connection to C2 URL", "C2", event_name == "Ransomware - Unsuccessful Connection to Payment URL", "Actions on Objective") | where status="online" | eval human_readable_time=strftime(_time, "%Y-%d-%m %H:%M:%S")
[Database Total Daily (Last 30d)]
alert.track = 0
cron_schedule = 0 3 * * *
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.charting.chart.stackMode = stacked
enableSched = 1
search = | loadjob [| rest /services/search/jobs count=0 | search isDone=1 isSavedSearch=1  | where label="Build trend" | head 1 | return $sid]  | lookup services dest_port OUTPUT traffic_type  | search traffic_type="Database Traffic"| eval in_mB=Bytes/1000000 |chart sum(in_mB) over day by dest_port

[DNS Total Daily (Last 30d)]
alert.track = 0
cron_schedule = 0 2 * * *
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.charting.chart.stackMode = stacked
enableSched = 1
search = | loadjob [| rest /services/search/jobs count=0 | search isDone=1 isSavedSearch=1  | where label="Build trend" | head 1 | return $sid]  | lookup services dest_port OUTPUT traffic_type  | search traffic_type="DNS Traffic"| eval in_mB=Bytes/1000000 |chart sum(in_mB) over day by dest_port

[FTP Total Daily (Last 30d)]
alert.track = 0
cron_schedule = 0 1 * * *
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.charting.chart.stackMode = stacked
enableSched = 1
search = | loadjob [| rest /services/search/jobs count=0 | search isDone=1 isSavedSearch=1  | where label="Build trend" | head 1 | return $sid]  | lookup services dest_port OUTPUT traffic_type  | search traffic_type="FTP Traffic"| eval in_mB=Bytes/1000000 |chart sum(in_mB) over day by dest_port

[HTTP Total Daily (Last 30d)]
alert.track = 0
cron_schedule = 0 4 * * *
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.charting.chart.stackMode = stacked
enableSched = 1
search = | loadjob [| rest /services/search/jobs count=0 | search isDone=1 isSavedSearch=1  | where label="Build trend" | head 1 | return $sid]  | lookup services dest_port OUTPUT traffic_type  | search traffic_type="HTTP(S) Traffic"| eval in_mB=Bytes/1000000 |chart sum(in_mB) over day by dest_port

[MAIL Total Daily (Last 30d)]
alert.track = 0
cron_schedule = 0 2 * * *
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.charting.chart.stackMode = stacked
enableSched = 1
search = | loadjob [| rest /services/search/jobs count=0 | search isDone=1 isSavedSearch=1  | where label="Build trend" | head 1 | return $sid]  | lookup services dest_port OUTPUT traffic_type  | search traffic_type="MAIL (SMTP;POP3) Traffic"| eval in_mB=Bytes/1000000 |chart sum(in_mB) over day by dest_port

[NETBIOS Total Daily (Last 30d)]
alert.track = 0
cron_schedule = 0 4 * * *
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.charting.chart.stackMode = stacked
enableSched = 1
search = | loadjob [| rest /services/search/jobs count=0 | search isDone=1 isSavedSearch=1  | where label="Build trend" | head 1 | return $sid]  | lookup services dest_port OUTPUT traffic_type  | search traffic_type="NETBIOS Traffic"| eval in_mB=Bytes/1000000 |chart sum(in_mB) over day by dest_port

[NTP Total Daily (Last 30d)]
alert.track = 0
cron_schedule = 0 3 * * *
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.charting.chart.stackMode = stacked
enableSched = 1
search = | loadjob [| rest /services/search/jobs count=0 | search isDone=1 isSavedSearch=1  | where label="Build trend" | head 1 | return $sid]  | lookup services dest_port OUTPUT traffic_type  | search traffic_type="NTP Traffic"| eval in_mB=Bytes/1000000 |chart sum(in_mB) over day by dest_port

[RDP Total Daily (Last 30d)]
alert.track = 0
cron_schedule = 0 1 * * *
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.charting.chart.stackMode = stacked
enableSched = 1
search = | loadjob [| rest /services/search/jobs count=0 | search isDone=1 isSavedSearch=1  | where label="Build trend" | head 1 | return $sid]  | lookup services dest_port OUTPUT traffic_type  | search traffic_type="RDP Traffic"| eval in_mB=Bytes/1000000 |chart sum(in_mB) over day by dest_port

[AVG Traffic by Services (Last 30d)]
alert.track = 0
cron_schedule = 0 5 * * *
dispatch.earliest_time = 0
display.general.type = statistics
enableSched = 1
search = | loadjob [| rest /services/search/jobs count=0 | search isDone=1 isSavedSearch=1  | where label="Build trend" | head 1 | return $sid]  | lookup services dest_port OUTPUT traffic_type  | eval in_mB=Bytes/1000000 |stats sum(in_mB) as MBytes by day traffic_type | chart max(MBytes) min(MBytes) avg(MBytes) by traffic_type | rename traffic_type as "Traffic Type" max(MBytes) as MAX(MBytes) min(MBytes) as MIN(MBytes) avg(MBytes) as AVG(MBytes)

[DNS Traffic]
action.email.useNSSubject = 1
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = */10 * * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.custom.type = timeline_app.timeline
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = MTLSOCNetflowSecurityMonitorBasic
request.ui_dispatch_view = search
search = index=* eventtype=netflow | lookup services dest_port OUTPUT traffic_type | where traffic_type="DNS Traffic" | timechart span=10m count

[Database Traffic]
action.email.useNSSubject = 1
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = */10 * * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.custom.type = timeline_app.timeline
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = MTLSOCNetflowSecurityMonitorBasic
request.ui_dispatch_view = search
search = index=* eventtype=netflow | lookup services dest_port OUTPUT traffic_type | where traffic_type="Database Traffic" | timechart span=10m count

[FTP Traffic]
action.email.useNSSubject = 1
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = */10 * * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.custom.type = timeline_app.timeline
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = MTLSOCNetflowSecurityMonitorBasic
request.ui_dispatch_view = search
search = index=* eventtype=netflow | lookup services dest_port OUTPUT traffic_type | where traffic_type="FTP Traffic" | timechart span=10m count

[HTTP(S) Traffic]
action.email.useNSSubject = 1
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = */10 * * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.custom.type = timeline_app.timeline
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = MTLSOCNetflowSecurityMonitorBasic
request.ui_dispatch_view = search
search = index=* eventtype=netflow | lookup services dest_port OUTPUT traffic_type | where traffic_type="HTTP(S) Traffic" | timechart span=10m count

[MAIL (SMTP;POP3) Traffic]
action.email.useNSSubject = 1
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = */10 * * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.custom.type = timeline_app.timeline
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = MTLSOCNetflowSecurityMonitorBasic
request.ui_dispatch_view = search
search = index=* eventtype=netflow | lookup services dest_port OUTPUT traffic_type | where traffic_type="MAIL (SMTP;POP3) Traffic" | timechart span=10m count

[RDP Traffic]
action.email.useNSSubject = 1
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = */10 * * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.custom.type = timeline_app.timeline
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = MTLSOCNetflowSecurityMonitorBasic
request.ui_dispatch_view = search
search = index=* eventtype=netflow | lookup services dest_port OUTPUT traffic_type | where traffic_type="RDP Traffic" | timechart span=10m count

[SSH Traffic]
action.email.useNSSubject = 1
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = */10 * * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.custom.type = timeline_app.timeline
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = MTLSOCNetflowSecurityMonitorBasic
request.ui_dispatch_view = search
search = index=*  eventtype=netflow | lookup services dest_port OUTPUT traffic_type | where traffic_type="SSH Traffic" | timechart span=10m count

[Build trend]
action.email.useNSSubject = 1
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.custom.type = timeline_app.timeline
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = MTLSOCNetflowSecurityMonitorBasic
request.ui_dispatch_view = search
search = index=cr | bucket _time span=1d as day  | eval day=strftime(day,"%Y-%m-%d") | stats sum(bytes) as Bytes by  src_ip dest_ip dest_port day | table src_ip dest_ip dest_port day Bytes


[SSH Total Daily (Last 30d)]
alert.track = 0
cron_schedule = 0 3 * * *
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.charting.chart.stackMode = stacked
enableSched = 1
search = | loadjob [| rest /services/search/jobs count=0 | search isDone=1 isSavedSearch=1  | where label="Build trend" | head 1 | return $sid]  | lookup services dest_port OUTPUT traffic_type  | search traffic_type="SSH Traffic"| eval in_mB=Bytes/1000000 |chart sum(in_mB) over day by dest_port

[All Other Traffic]
action.email.useNSSubject = 1
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = */10 * * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.custom.type = timeline_app.timeline
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = MTLSOCNetflowSecurityMonitorBasic
request.ui_dispatch_view = search
search = index=* eventtype=netflow NOT [|inputlookup known_attacker_ports.csv | rename port as src_port | table src_port] | lookup services dest_port OUTPUT traffic_type | fillnull traffic_type | search traffic_type=0 | timechart span=10m count

[Daily license usage]
search =  index=_internal source=*license_usage.log* type="Usage" | eval _time=_time - 43200 | eval idx=if(len(idx)=0 OR isnull(idx),"(UNKNOWN)",idx) | bin _time span=1d | stats sum(b) as b by _time, idx  | timechart span=1d sum(b) AS volumeB by idx | fields - _timediff  | foreach * [eval <<FIELD>>=round('<<FIELD>>'/1024/1024/1024, 3)] | eval time=strftime(_time,"%m/%d") | table time em_metrics main
enableSched=1
cron_schedule = 0 */1 * * *
dispatch.ttl = 3600
dispatch.earliest_time = -10d@d
dispatch.latest_time = @h
## Update the cache on the hour

[OS type telemetry]
search = | inputlookup em_entities \
  | rename dimensions.os AS osTypes \
  | stats count by osTypes \
  | eval salted_os_type="Infra_Insights" . osTypes, hashed_os_types=sha256(salted_os_type) \
  | rename hashed_os_types as data.os_name, count as data.os_count \
  | makejson name data.* output=event
action.outputtelemetry                     = 1
action.outputtelemetry.param.anonymous     = 1
action.outputtelemetry.param.support       = 0
action.outputtelemetry.param.license       = 0
action.outputtelemetry.param.optinrequired = 3
action.outputtelemetry.param.component     = app.sii.os_type
action.outputtelemetry.param.input         = event
action.outputtelemetry.param.type          = aggregate
enableSched=1
cron_schedule = 0 22 * * *
dispatch.earliest_time = -1d

[App Version telemetry]
search = | rest /services/apps/local \
  | search disabled=0 label="Splunk App for Infrastructure" \
  | rename label as data.app_name, version as data.app_version \
  | makejson name data.* output=event
enableSched=1
action.outputtelemetry                     = 1
action.outputtelemetry.param.anonymous     = 1
action.outputtelemetry.param.support       = 0
action.outputtelemetry.param.license       = 0
action.outputtelemetry.param.optinrequired = 3
action.outputtelemetry.param.component     = app.sii.app_version
action.outputtelemetry.param.input         = event
action.outputtelemetry.param.type          = aggregate
cron_schedule = 0 22 * * *
dispatch.earliest_time = -1d

[Alert definition telemetry]
search =  | rest /servicesNS/-/-/saved/searches \
  | search eai:acl.app="splunk_app_infrastructure" action.em_write_alerts = 1 \
  | rex field=search "metric_name\=\"(?<metric_name>[^\"]*)" \
  | rex field=search "aggregation_method\=\"(?<aggregation_method>[^\"]*)" \
  | eval salted_alert_title= "Infra_Insights" . title, hashed_alert_title=sha256(salted_alert_title) \
  | rename hashed_alert_title as data.hashed_alert_title, metric_name as data.alert_metric_name, aggregation_method as data.alert_aggregation_method \
  | makejson name data.* output=event
enableSched=1
action.outputtelemetry                     = 1
action.outputtelemetry.param.anonymous     = 1
action.outputtelemetry.param.support       = 0
action.outputtelemetry.param.license       = 0
action.outputtelemetry.param.optinrequired = 3
action.outputtelemetry.param.component     = app.sii.alert_definitions
action.outputtelemetry.param.input         = event
action.outputtelemetry.param.type          = aggregate
cron_schedule = 0 22 * * *
dispatch.earliest_time = -1d

[Group definition telemetry]
search = | inputlookup em_groups \
| makemv delim="," filter \
| mvexpand filter \
| rex field=filter "(?<dimension_key>.*)\=(?<dimension_value>.*)" \
| eval salted_dimension_value= "Infra_Insights" . dimension_value, \
  salted_dimension_key= "Infra_Insights" . dimension_key, \
  salted_group_title= "Infra_Insights" . title, \
  hashed_dim_key=sha256(salted_dimension_key), \
  hashed_dim_value=sha256(salted_dimension_value), \
  hashed_group_title=sha256(salted_group_title), \
  filtered=if(in(dimension_key,"ImageId","InstanceId", "os", "os_version", "ip", "host", "VolumeId", "LoadBalancerName"), dimension_key,""), \
  hashed_dim_key=if(filtered != "", filtered, hashed_dim_key) \
| rename hashed_dim_key as data.dimension_key, hashed_dim_value as data.dimension_value, hashed_group_title as data.group_title \
| stats list(data.*) as data.* by data.group_title \
| makejson name data.* output=event
enableSched=1
action.outputtelemetry                     = 1
action.outputtelemetry.param.anonymous     = 1
action.outputtelemetry.param.support       = 0
action.outputtelemetry.param.license       = 0
action.outputtelemetry.param.optinrequired = 3
action.outputtelemetry.param.component     = app.sii.group_definitions
action.outputtelemetry.param.input         = event
action.outputtelemetry.param.type          = aggregate
cron_schedule = 0 22 * * *
dispatch.earliest_time = -1d

###### Correlation Searches #######
[Threat - UEBA Threat Detected (Notable) - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = UBA Threat Detected
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = threat
action.notable.param.severity         = informational
action.notable.param.rule_title       = $threat_category$
action.notable.param.rule_description = UBA Threat: $description$
action.notable.param.nes_fields       = 
action.notable.param.drilldown_name   = View threat history
action.notable.param.drilldown_search = | from datamodel:"UEBA"."UEBA_Threats" | search uba_event_id="$uba_event_id$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = uba_host,uba_event_id
alert.suppress.period                 = 188697600s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */2 * * * *
description                           = Detects UBA threat events
disabled                              = False
dispatch.earliest_time                = -2m@m
dispatch.latest_time                  = @m
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"UEBA"."UEBA_Threats" | stats values(app) as app,values(dvc) as dvc,values(user) as user,dc(user) as user_count,values(url) as url,latest(action) as action,latest(uba_event_type) as uba_event_type,latest(description) as description,latest(link) as link,latest(modify_time) as modify_time,latest(severity) as severity,latest(signature) as signature,latest(start_time) as start_time,latest(threat_category) as threat_category by uba_host,uba_event_id

[Threat - UEBA Threat Detected (Risk) - Rule]
action.correlationsearch            = 0
action.correlationsearch.enabled    = 1
action.correlationsearch.label      = UBA Threat Detected (Risk)
action.email.sendresults            = 0
action.notable.param.rule_title     = UBA Threat Detected (Risk)
action.risk                         = 1
action.risk.param._risk_object      = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score       = 80
alert.digest_mode                   = 1
alert.suppress                      = 1
alert.suppress.fields               = uba_event_id,risk_object,risk_object_type
alert.suppress.period               = 188697600s
alert.track                         = false
counttype                           = number of events
relation                            = greater than
quantity                            = 0
cron_schedule                       = */2 * * * *
description                         = Detects UBA threat events
disabled                            = False
dispatch.earliest_time              = -2m@m
dispatch.latest_time                = @m
enableSched                         = 1
is_visible                          = false
search                              = | from datamodel:"UEBA"."UEBA_Threats" | stats latest(description) as description,values(dvc) as dvc,max(severity_id) as score,values(user) as user by uba_host,uba_event_id | eval risk_object_type="system" | eval risk_object=dvc | appendpipe [stats first(description) as description,max(score) as score,values(user) as user by uba_host,uba_event_id] | eval risk_object_type=if(isnull(risk_object_type),"user",risk_object_type) | eval risk_object=if(isnull(risk_object),user,risk_object) | mvexpand risk_object | eval dvc=if(risk_object_type="system",risk_object,null()) | eval user=if(risk_object_type="user",risk_object,null()) | eval risk_score=score*10

[Threat - UEBA Anomaly Detected (Risk) - Rule]
action.correlationsearch            = 0
action.correlationsearch.enabled    = 1
action.correlationsearch.label      = UBA Anomaly Detected (Risk)
action.email.sendresults            = 0
action.notable.param.rule_title     = UBA Anomaly Detected (Risk)
action.risk                         = 1
action.risk.param._risk_object      = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score       = 80
alert.digest_mode                   = 1
alert.suppress                      = 1
alert.suppress.fields               = uba_event_id,risk_object,risk_object_type
alert.suppress.period               = 188697600s
alert.track                         = false
counttype                           = number of events
relation                            = greater than
quantity                            = 0
cron_schedule                       = */2 * * * *
description                         = Detects UBA anomaly events
disabled                            = False
dispatch.earliest_time              = -2m@m
dispatch.latest_time                = @m
enableSched                         = 1
is_visible                          = false
search                              = | from datamodel:"UEBA"."UEBA_Anomalies" | stats latest(short_description) as description,values(dvc) as dvc,max(severity_id) as score,values(user) as user by uba_host,uba_event_id | eval risk_object_type="system" | eval risk_object=dvc | appendpipe [stats first(description) as description,max(score) as score,values(user) as user by uba_host,uba_event_id] | eval risk_object_type=if(isnull(risk_object_type),"user",risk_object_type) | eval risk_object=if(isnull(risk_object),user,risk_object) | mvexpand risk_object | eval dvc=if(risk_object_type="system",risk_object,null()) | eval user=if(risk_object_type="user",risk_object,null()) | eval risk_score=score*10

###### Key Indicator Searches ######
[Notable - Total Event From UEBA]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = UBA Notables
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.group.0.name              = security_posture
action.keyindicator.group.0.order             = 7
action.keyindicator.group.1.name              = uba_anomalies
action.keyindicator.group.1.order             = 0
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = UEBA Notable Events
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `es_notable_events` | search rule_name="UBA Threat Detected" | stats sum(count) as count by timeDiff_type | transpose | sort 1 + column | rename "row 1" as current_count,"row 2" as historical_count | `get_delta` | table current_count,historical_count,delta

[UBA - Anomaly Actors]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = UBA Anomaly Actors
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.group.0.name              = uba_anomalies
action.keyindicator.group.0.order             = 1
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = UBA Anomaly Actors
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` estdc(All_UEBA_Events.dvc) as dvc,estdc(All_UEBA_Events.user) as user from datamodel=UEBA.All_UEBA_Events where nodename=All_UEBA_Events.UEBA_Anomalies earliest=-24h@h latest=+0s | addtotals fieldname=current_count | table current_count | appendcols [| tstats `summariesonly` estdc(All_UEBA_Events.dvc) as dvc,estdc(All_UEBA_Events.user) as user from datamodel=UEBA.All_UEBA_Events where nodename=All_UEBA_Events.UEBA_Anomalies earliest=-48h@h latest=-24h@h | addtotals fieldname=historical_count | table historical_count] | `get_delta`

[UBA - Anomaly Signatures]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = UBA Anomaly Signatures
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.group.0.name              = uba_anomalies
action.keyindicator.group.0.order             = 2
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = UBA Anomaly Signatures
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` dc(All_UEBA_Events.signature) as current_count from datamodel=UEBA.All_UEBA_Events where nodename=All_UEBA_Events.UEBA_Anomalies earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` dc(All_UEBA_Events.signature) as historical_count from datamodel=UEBA.All_UEBA_Events where nodename=All_UEBA_Events.UEBA_Anomalies earliest=-48h@h latest=-24h@h] | `get_delta`

[UBA - Anomalies Per Threat]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = UBA Anomalies (pT)
action.keyindicator.subtitle                  = Per Threat
action.keyindicator.value                     = current_anomaliesper
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.group.0.name              = uba_anomalies
action.keyindicator.group.0.order             = 3
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = UBA Anomalies Per Threat
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` count from datamodel=UEBA.All_UEBA_Events where earliest=-24h@h latest=+0s by nodename | eval threats=if(nodename="All_UEBA_Events.UEBA_Threats",count,0),anomalies=if(nodename="All_UEBA_Events.UEBA_Anomalies",count,0) | stats sum(threats) as threats,sum(anomalies) as anomalies | eval current_anomaliesper=floor(anomalies/threats) | table current_anomaliesper | appendcols [| tstats `summariesonly` count from datamodel=UEBA.All_UEBA_Events where earliest=-48h@h latest=-24h@h by nodename | eval threats=if(nodename="All_UEBA_Events.UEBA_Threats",count,0),anomalies=if(nodename="All_UEBA_Events.UEBA_Anomalies",count,0) | stats sum(threats) as threats,sum(anomalies) as anomalies | eval historical_anomaliesper=floor(anomalies/threats) | table historical_anomaliesper] | `get_delta(current_anomaliesper,historical_anomaliesper)`

[UBA - Total Anomalies]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = UBA Anomalies
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.group.0.name              = uba_anomalies
action.keyindicator.group.0.order             = 4
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = UBA Anomalies
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | tstats `summariesonly` count as current_count from datamodel=UEBA.All_UEBA_Events where nodename=All_UEBA_Events.UEBA_Anomalies earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` count as historical_count from datamodel=UEBA.All_UEBA_Events where nodename=All_UEBA_Events.UEBA_Anomalies earliest=-48h@h latest=-24h@h] | `get_delta`

###### Swim Lane Searches ######
[UEBA - UEBA Threats By Asset - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = UEBA Threats
action.swimlane.color                             = red
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = dvc
action.swimlane.drilldown_search                  = | from datamodel:"UEBA"."UEBA_Threats" | search $constraints$
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 7
is_visible                                        = false
search                                            = | tstats `summariesonly` values(All_UEBA_Events.app) as Apps,latest(All_UEBA_Events.description) as Description,latest(All_UEBA_Events.start_time) as "Detection Time",values(All_UEBA_Events.dvc) as Devices,values(All_UEBA_Events.url) as Domains,latest(All_UEBA_Events.link) as Link,latest(All_UEBA_Events.severity_id) as Score,latest(All_UEBA_Events.severity) as Severity,latest(All_UEBA_Events.threat_category) as Type,latest(All_UEBA_Events.modify_time) as "Update Time",values(All_UEBA_Events.user) as Users,count from datamodel=UEBA.All_UEBA_Events where nodename="All_UEBA_Events.UEBA_Threats" $constraints$ by _time,All_UEBA_Events.uba_event_id span=$span$ | `uitime("Detection Time")` | `uitime("Update Time")` | rename All_UEBA_Events.uba_event_id as "Event ID" | fields _time,"Detection Time","Update Time","Event ID",Type,Description,Severity,Users,Devices,Score,Apps,Domains,Link,count

[UEBA - UEBA Threats By Identity - Swimlane]
action.swimlane                                      = 1
action.swimlane.title                                = UEBA Threats
action.swimlane.color                                = red
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = user
action.swimlane.drilldown_search                     = | from datamodel:"UEBA"."UEBA_Threats" | search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 7
is_visible                                           = false
search                                               = | tstats `summariesonly` values(All_UEBA_Events.app) as Apps,latest(All_UEBA_Events.description) as Description,latest(All_UEBA_Events.start_time) as "Detection Time",values(All_UEBA_Events.dvc) as Devices,values(All_UEBA_Events.url) as Domains,latest(All_UEBA_Events.link) as Link,latest(All_UEBA_Events.severity_id) as Score,latest(All_UEBA_Events.severity) as Severity,latest(All_UEBA_Events.threat_category) as Type,latest(All_UEBA_Events.modify_time) as "Update Time",values(All_UEBA_Events.user) as Users,count from datamodel=UEBA.All_UEBA_Events where nodename="All_UEBA_Events.UEBA_Threats" $constraints$ by _time,All_UEBA_Events.uba_event_id span=$span$ | `uitime("Detection Time")` | `uitime("Update Time")` | rename All_UEBA_Events.uba_event_id as "Event ID" | fields _time,"Detection Time","Update Time","Event ID",Type,Description,Severity,Users,Devices,Score,Apps,Domains,Link,count

[UBA - UBA Anomalies By Asset - Swimlane]
action.swimlane                                   = 1
action.swimlane.title                             = UBA Anomalies
action.swimlane.color                             = red
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = dvc
action.swimlane.drilldown_search                  = | from datamodel:"UEBA"."UEBA_Anomalies" | search $constraints$
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 8
is_visible                                        = false
search                                            = | tstats `summariesonly` values(All_UEBA_Events.app) as Apps,latest(All_UEBA_Events.start_time) as "Detection Time",values(All_UEBA_Events.dvc) as Devices,values(All_UEBA_Events.url) as Domains,latest(All_UEBA_Events.link) as Link,latest(All_UEBA_Events.severity_id) as Score,latest(All_UEBA_Events.severity) as Severity,values(All_UEBA_Events.user) as Users,values(All_UEBA_Events.signature) as "Signature", values(All_UEBA_Events.category) as "Category",count from datamodel=UEBA.All_UEBA_Events where nodename="All_UEBA_Events.UEBA_Anomalies" $constraints$ by _time,All_UEBA_Events.uba_event_id span=$span$ | `uitime("Detection Time")` | rename All_UEBA_Events.uba_event_id as "Event ID" | fields _time,"Detection Time","Event ID","Signature","Category",Severity,Users,Devices,Score,Apps,Domains,Link,count

[UBA - UBA Anomalies By Identity - Swimlane]
action.swimlane                                      = 1
action.swimlane.title                                = UBA Anomalies
action.swimlane.color                                = red
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = user
action.swimlane.drilldown_search                     = | from datamodel:"UEBA"."UEBA_Anomalies" | search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 8
is_visible                                           = false
search                                               = | tstats `summariesonly` values(All_UEBA_Events.app) as Apps,latest(All_UEBA_Events.start_time) as "Detection Time",values(All_UEBA_Events.dvc) as Devices,values(All_UEBA_Events.url) as Domains,latest(All_UEBA_Events.link) as Link,latest(All_UEBA_Events.severity_id) as Score,latest(All_UEBA_Events.severity) as Severity,values(All_UEBA_Events.user) as Users,values(All_UEBA_Events.signature) as "Signature", values(All_UEBA_Events.category) as "Category",count from datamodel=UEBA.All_UEBA_Events where nodename="All_UEBA_Events.UEBA_Anomalies" $constraints$ by _time,All_UEBA_Events.uba_event_id span=$span$ | `uitime("Detection Time")` | rename All_UEBA_Events.uba_event_id as "Event ID" | fields _time,"Detection Time","Event ID","Signature","Category",Severity,Users,Devices,Score,Apps,Domains,Link,count
###### Base Searches ######
[ESS - Content Profile - Base]
action.email.reportServerEnabled      = 0
action.keyindicator.invert            = 0
alert.suppress                        = 0
alert.track                           = 0
enableSched                           = 0
is_visible                            = false
display.general.timeRangePicker.show  = 0
display.visualizations.show           = 0
search                                = | `cim_datamodelinfo` | fields datamodel size | join max=0 datamodel [| contentinfo | eval datamodel=mvdedup(datamodel), name=case(isnotnull(search_name), search_name,isnotnull(panel_title), if(isnotnull(view_label), view_label, view_name) + " - " + panel_title, isnotnull(view_label), view_label, isnotnull(view_name), view_name, 1==1, null()), subtype=coalesce(subtype, if(isnotnull(panel_title), "panel", "-")) | fields app datamodel name type subtype| stats list(*) as *, count by datamodel app | eval name=mvjoin(name, ";"), type=mvjoin(type, ";"), subtype=mvjoin(subtype, ";")] | fields datamodel app size name type subtype count | makemv delim=";" name | makemv delim=";" type | makemv delim=";" subtype

###### Key Indicator Searches ######
[Notable - Total Events By Access Domain]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Access Notables
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.drilldown_uri             = incident_review?form.security_domain_form=Access&earliest=-24h%40h&latest=now
action.keyindicator.group.0.name              = security_posture
action.keyindicator.group.0.order             = 1
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Access Notable Events
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `es_notable_events` | search security_domain=access | stats sum(count) as count by timeDiff_type | transpose | sort 1 + column | rename "row 1" as current_count,"row 2" as historical_count | `get_delta` | table current_count,historical_count,delta

[Notable - Total Events By Endpoint Domain]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Endpoint Notables
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.drilldown_uri             = incident_review?form.security_domain_form=Endpoint&earliest=-24h%40h&latest=now
action.keyindicator.group.0.name              = security_posture
action.keyindicator.group.0.order             = 2
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Endpoint Notable Events
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `es_notable_events` | search security_domain=endpoint | stats sum(count) as count by timeDiff_type | transpose | sort 1 + column | rename "row 1" as current_count,"row 2" as historical_count | `get_delta` | table current_count,historical_count,delta

[Notable - Total Events By Network Domain]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Network Notables
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.drilldown_uri             = incident_review?form.security_domain_form=Network&earliest=-24h%40h&latest=now
action.keyindicator.group.0.name              = security_posture
action.keyindicator.group.0.order             = 3
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Network Notable Events
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `es_notable_events` | search security_domain=network | stats sum(count) as count by timeDiff_type | transpose | sort 1 + column | rename "row 1" as current_count,"row 2" as historical_count | `get_delta` | table current_count,historical_count,delta

[Notable - Total Events By Identity Domain]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Identity Notables
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.drilldown_uri             = incident_review?form.security_domain_form=Identity&earliest=-24h%40h&latest=now
action.keyindicator.group.0.name              = security_posture
action.keyindicator.group.0.order             = 4
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Identity Notable Events
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `es_notable_events` | search security_domain=identity | stats sum(count) as count by timeDiff_type | transpose | sort 1 + column | rename "row 1" as current_count,"row 2" as historical_count | `get_delta` | table current_count,historical_count,delta

[Notable - Total Events By Audit Domain]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Audit Notables
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.drilldown_uri             = incident_review?form.security_domain_form=Audit&earliest=-24h%40h&latest=now
action.keyindicator.group.0.name              = security_posture
action.keyindicator.group.0.order             = 5
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Audit Notable Events
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `es_notable_events` | search security_domain=audit | stats sum(count) as count by timeDiff_type | transpose | sort 1 + column | rename "row 1" as current_count,"row 2" as historical_count | `get_delta` | table current_count,historical_count,delta

[Notable - Total Events By Threat Domain]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Threat Notables
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.drilldown_uri             = incident_review?form.security_domain_form=Threat&earliest=-24h%40h&latest=now
action.keyindicator.group.0.name              = security_posture
action.keyindicator.group.0.order             = 6
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Threat Notable Events
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `es_notable_events` | search security_domain=threat | stats sum(count) as count by timeDiff_type | transpose | sort 1 + column | rename "row 1" as current_count,"row 2" as historical_count | `get_delta` | table current_count,historical_count,delta

[Notable - Notable Events Exceeding Analyst Capacity]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Excess Notable Events
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# `notable` | search NOT status_group="Closed" | stats count by owner
action.keyindicator.drilldown_uri             = search?q=%60notable%60%20%7C%20search%20NOT%20status_group%3D%22Closed%22%20%7C%20stats%20count%20by%20owner&earliest=-24h%40h&latest=now
action.keyindicator.group.0.name              = 
action.keyindicator.group.0.order             = 
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Excess Notable Events
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `es_notable_events` | search NOT status_group="Closed" | stats sum(count) as count by timeDiff_type | transpose | sort 1 + column | rename "row 1" as current_count,"row 2" as historical_count | appendcols [| `incident_review_capacity`] | eval current_count=if(current_count>incident_review_capacity, current_count-incident_review_capacity, 0) | eval historical_count=if(historical_count>incident_review_capacity,historical_count-incident_review_capacity,0) | `get_delta` | table current_count,historical_count,delta

###### Key Indicator Searches ######
[Modular Actions - Action Invocations]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Action Invocations
action.keyindicator.subtitle                  = count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count as current_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-24h@h latest=+0s by Modular_Actions.action_name
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20as%20current_count%20from%20datamodel%3DSplunk_Audit.Modular_Actions%20where%20nodename%3D%22Modular_Actions.Modular_Action_Invocations%22%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Modular_Actions.action_name
action.keyindicator.group.0.name              = modular_action_center
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Modular Action Invocations
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count as current_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-48h@h latest=-24h@h] | `get_delta`

[Modular Actions - Distinct Action Names]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Action Names
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count as current_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-24h@h latest=+0s by Modular_Actions.action_name
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20as%20current_count%20from%20datamodel%3DSplunk_Audit.Modular_Actions%20where%20nodename%3D%22Modular_Actions.Modular_Action_Invocations%22%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Modular_Actions.action_name
action.keyindicator.group.0.name              = modular_action_center
action.keyindicator.group.0.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Modular Actions
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` dc(Modular_Actions.action_name) as current_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` dc(Modular_Actions.action_name) as historical_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-48h@h latest=-24h@h] | `get_delta`

[Modular Actions - Distinct Search Names]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Action Search Names
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-24h@h latest=+0s by Modular_Actions.search_name
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20as%20count%20from%20datamodel%3DSplunk_Audit.Modular_Actions%20where%20nodename%3D%22Modular_Actions.Modular_Action_Invocations%22%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Modular_Actions.search_name
action.keyindicator.group.0.name              = modular_action_center
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Modular Action Search Names
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` dc(Modular_Actions.search_name) as current_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` dc(Modular_Actions.search_name) as historical_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-48h@h latest=-24h@h] | `get_delta`

[Modular Actions - Distinct Users]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Action Users
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count as count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-24h@h latest=+0s by Modular_Actions.user
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20as%20count%20from%20datamodel%3DSplunk_Audit.Modular_Actions%20where%20nodename%3D%22Modular_Actions.Modular_Action_Invocations%22%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Modular_Actions.user
action.keyindicator.group.0.name              = modular_action_center
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Users
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` dc(Modular_Actions.user) as current_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` dc(Modular_Actions.user) as historical_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-48h@h latest=-24h@h] | `get_delta`

[Modular Actions - Distinct Searches]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Action Searches
action.keyindicator.subtitle                  = Distinct Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count as count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-24h@h latest=+0s by Modular_Actions.sid
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20as%20count%20from%20datamodel%3DSplunk_Audit.Modular_Actions%20where%20nodename%3D%22Modular_Actions.Modular_Action_Invocations%22%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Modular_Actions.sid
action.keyindicator.group.0.name              = modular_action_center
action.keyindicator.group.0.order             = 4
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Distinct Modular Action Searches
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Modular_Actions.sid) as current_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Modular_Actions.sid) as historical_count from datamodel=Splunk_Audit.Modular_Actions where nodename="Modular_Actions.Modular_Action_Invocations" earliest=-48h@h latest=-24h@h] | `get_delta`

[Modular Actions - Average Duration]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Action Duration
action.keyindicator.subtitle                  = Average (ms)
action.keyindicator.value                     = current_avg
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | from datamodel:"Splunk_Audit"."Modular_Actions"
action.keyindicator.drilldown_uri             = search?earliest=-24h%40h&latest=now&q=%7C%20from%20datamodel%3A%22Splunk_Audit%22.%22Modular_Actions%22
action.keyindicator.group.0.name              = modular_action_center
action.keyindicator.group.0.order             = 5
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Average Modular Action Duration (ms)
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` avg(Modular_Actions.duration) as current_avg from datamodel=Splunk_Audit.Modular_Actions where earliest=-24h@h latest=+0s Modular_Actions.component="main" | appendcols [| tstats `summariesonly` avg(Modular_Actions.duration) as historical_avg from datamodel=Splunk_Audit.Modular_Actions where earliest=-48h@h latest=-24h@h Modular_Actions.component="main"] | `get_delta(current_avg,historical_avg)`


###### Output Message Searches ######
[Audit - ES System Requirements]
action.email.reportServerEnabled     = 0
action.output_message                = 1
action.output_message.param.name     = HEALTH_CHECK:ES_SYSTEM_REQUIREMENTS
action.output_message.param.msgid    = healthcheck_es_system_requirements
action.output_message.param.fields   = splunk_server
action.output_message.param.purge    = 1
alert.digest_mode                    = true
alert.track                          = 0
counttype                            = number of events
cron_schedule                        = 15 3 * * *
dispatch.earliest_time               = 0
dispatch.latest_time                 = +0s
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
enableSched                          = 1
quantity                             = 0
relation                             = greater than
schedule_window                      = auto
search                               = | rest splunk_server=* count=0 /services/server/info | eval numberOfVirtualCores=if(isnum(numberOfVirtualCores) AND numberOfVirtualCores>0,numberOfVirtualCores,null()) | where ((server_roles="search_head" AND (max(numberOfCores,numberOfVirtualCores)<16 OR physicalMemoryMB<32000)) OR (server_roles="indexer" AND (max(numberOfCores,numberOfVirtualCores)<16 OR physicalMemoryMB<32000))) | fields + splunk_server,server_roles,numberOfCores,numberOfVirtualCores,physicalMemoryMB

[Audit - Investigation Collection ACLs]
action.email.reportServerEnabled     = 0
action.output_message                = 1
action.output_message.param.name     = HEALTH_CHECK:INVESTIGATION_COLLECTION_ACLS
action.output_message.param.msgid    = healthcheck_investigation_collection_acls
action.output_message.param.fields   = collection
action.output_message.param.purge    = 1
alert.digest_mode                    = true
alert.track                          = 0
counttype                            = number of events
cron_schedule                        = 15 3 * * *
dispatch.earliest_time               = 0
dispatch.latest_time                 = +0s
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
enableSched                          = 1
quantity                             = 0
relation                             = greater than
schedule_window                      = auto
search                               = | rest splunk_server=local count=0 /servicesNS/nobody/search/storage/collections/config | rename title as collection,"eai:acl.perms.read" as read_perms,"eai:acl.perms.write" as write_perms | where 'collection' in ("investigative_canvas", "investigative_canvas_entries", "files", "investigation", "investigation_event", "investigation_attachment") AND ('read_perms' in ("*", "ess_user", "ess_analyst", "pci_user", "pci_analyst") OR 'write_perms' in ("*", "ess_user", "ess_analyst", "pci_user", "pci_analyst")) | table collection,read_perms,write_perms


###### Report Searches ######
[Audit - ES View Activity Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -7d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = | `tstats` count from datamodel=Splunk_Audit.View_Activity where `es_context_only("View_Activity")` by _time,View_Activity.view span=1h | timechart span=1h useother=`useother` count by View_Activity.view | `drop_dm_object_name("View_Activity")`

[Audit - Expected ES View Activity]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -7d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `expected_view_tracker("-7d")` | eval view=app."|".view | bin _time span=1d | `ctime(_time,"%m-%d-%Y")` | chart sum(count) as count over view by _time | rex field=view "(?<app>[^|]+)\|(?<view>.*)" | fields app,view,*

[Notable - Events By Urgency]
action.email.reportServerEnabled          = 0
alert.track                               = 0
## dispatch times are for drilldown purposes only
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
search                                    = | `es_notable_events` | search timeDiff_type=current | stats sum(count) as count by urgency

[Notable - Events Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
## dispatch times are for drilldown purposes only
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.timeRangePicker.show                = false
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = | `es_notable_events` | search timeDiff_type=current | timechart minspan=30m sum(count) as count

[Notable - Events Over Time By Security Domain]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
## dispatch times are for drilldown purposes only
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.timeRangePicker.show                = false
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = | `es_notable_events` | search timeDiff_type=current | timechart minspan=30m sum(count) as count by security_domain

[Notable - Top Events]
action.email.reportServerEnabled     = 0
alert.track                          = 0
## dispatch times are for drilldown purposes only
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `es_notable_events` | search timeDiff_type=current | stats sparkline(sum(count),30m) as sparkline,sum(count) as count by rule_name | sort 100 - count

[Notable - Top Notable Event Sources]
action.email.reportServerEnabled     = 0
alert.track                          = 0
## dispatch times are for drilldown purposes only
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `es_notable_events` | search timeDiff_type=current src!=unknown | stats sparkline(sum(count),30m) as sparkline,dc(rule_name) as correlation_search_count,dc(security_domain) as security_domain_count,sum(count) as count by src | sort 100 - count,correlation_search_count

[Notable - Top Notable Event Destinations]
action.email.reportServerEnabled     = 0
alert.track                          = 0
## dispatch times are for drilldown purposes only
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `es_notable_events` | search timeDiff_type=current dest!=unknown | stats sparkline(sum(count),30m) as sparkline,dc(rule_name) as correlation_search_count,dc(security_domain) as security_domain_count,sum(count) as count by dest | sort 100 - count,correlation_search_count


###### UI Searches ######
[ESS - Notable Events]
cron_schedule          = */5 * * * *
alert.suppress         = 0
description            = Maintains a list containing pertinent information for the last 48 hours of notable events
dispatch.earliest_time = -48h@h
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = true
## Full cache rebuild needed b/c suppression need to be calculated
search                 = `notable` | search NOT `suppression` | eval timeDiff_type=case(_time>=relative_time(now(), "-24h@h"),"current", 1=1, "historical") | expandtoken rule_title | table _time,event_id,security_domain,urgency,rule_name,rule_title,src,dest,src_user,user,dvc,status,status_group,owner,timeDiff_type,governance,control | outputlookup es_notable_events | stats count


#####################
## Action History
#####################

[Dashboard Views - Action History]
action.email.sendresults            = 0
action.action_history               = 0
action.action_history.enabled       = 1
action.action_history.label         = Dashboard Viewed
action.action_history.content_type  = view
action.action_history.content       = content.view,content.app,content.uri
disabled                            = False
is_visible                          = false
search                              = | from datamodel:"Splunk_Audit"."View_Activity" | where 'user'!="-" | rename app as content.app, view as content.view, uri as content.uri
dispatchAs                          = owner

[Search Tracking - Action History]
action.email.sendresults            = 0
action.action_history               = 0
action.action_history.enabled       = 1
action.action_history.label         = Search Run
action.action_history.content_type  = search
action.action_history.content       = content.host,content.source,content.sourcetype,content.search,content.search_type,content.info,content.sid,content.earliest,content.latest
disabled                            = False
is_visible                          = false
search                              = | from datamodel:"Splunk_Audit"."Search_Activity" | where (search_type=="adhoc" OR search_type=="realtime") AND info=="granted" AND NOT user="splunk-system-user" AND NOT LIKE(search, "No search string available%") AND (savedsearch_name="quick-search-manager" OR isnull(savedsearch_name)) | `per_panel_filter("ppf_action_history_searches","search")` | rename host as content.host, source as content.source, sourcetype as content.sourcetype, search as content.search, search_type as content.search_type, info as content.info, search_lt as content.latest, search_et as content.earliest, search_id as content.sid 
dispatchAs                          = owner

[Per-Panel Filtering - Action History]
action.email.sendresults            = 0
action.action_history               = 0
action.action_history.enabled       = 1
action.action_history.label         = Panel Filtered
action.action_history.content_type  = ppf
action.action_history.content       = content.action,content.lookup_file,content.filter,content.namespace
disabled                            = False
is_visible                          = false
search                              = `ppf_updates` | `get_event_id` | rename action as content.action, lookup_file as content.lookup_file, filter as content.filter, namespace as content.namespace
dispatchAs                          = owner

[Notable Suppression - Action History]
action.email.sendresults            = 0
action.action_history               = 0
action.action_history.enabled       = 1
action.action_history.label         = Notable Event Suppression Updated
action.action_history.content_type  = notable_suppression
action.action_history.content       = content.action,content.signature,content.status,content.suppression
disabled                            = False
is_visible                          = false
search                              = `suppression_audit` | rename action as content.action, signature as content.signature, status as content.status, suppression as content.suppression
dispatchAs                          = owner

[Notable Status - Action History]
action.email.sendresults            = 0
action.action_history               = 0
action.action_history.enabled       = 1
action.action_history.label         = Notable Event Updated
action.action_history.content_type  = notable_status
action.action_history.content       = content.comment,content.owner,content.rule_id,content.rule_name,content.status,content.urgency
disabled                            = False
is_visible                          = false
search                              = index=_audit sourcetype=incident_review | `get_reviewstatuses` | rename comment as content.comment, owner as content.owner, rule_id as content.rule_id, rule_name as content.rule_name, status_label as content.status, urgency as content.urgency
dispatchAs                          = owner


#####################
## Telemetry
#####################
[Audit - Active Users - Telemetry Gen]
action.email.sendresults                   = 0
action.outputtelemetry                     = 1
action.outputtelemetry.param.anonymous     = 1
action.outputtelemetry.param.support       = 0
action.outputtelemetry.param.license       = 0
action.outputtelemetry.param.optinrequired = 3
action.outputtelemetry.param.component     = app.SplunkEnterpriseSecuritySuite.active_users
action.outputtelemetry.param.input         = event
action.outputtelemetry.param.type          = aggregate
alert.track                                = false
counttype                                  = number of events
relation                                   = greater than
quantity                                   = 0
cron_schedule                              = 0 1 * * *
description                                = Sends anonymous usage statistics pertaining to the unique number of active users.
disabled                                   = False
dispatch.earliest_time                     = -1d@d
dispatch.latest_time                       = @d
enableSched                                = 1
is_visible                                 = false
request.ui_dispatch_app                    = SplunkEnterpriseSecuritySuite
schedule_window                            = auto
search                                     = | tstats summariesonly=false allow_old_summaries=true count from datamodel=Splunk_Audit.View_Activity where (View_Activity.app="SplunkEnterpriseSecuritySuite" OR View_Activity.app="Splunk_DA-ESS*") by View_Activity.user | join user [| rest splunk_server=local count=0 /servicesNS/nobody/search/authentication/users | rename title as user | table title,roles] | stats count(eval(roles="admin" or roles="sc_admin" or roles="ess_admin")) as data.admin_count,count(eval(roles="ess_analyst")) as data.analyst_count,count(eval(roles="ess_user")) as data.user_count,count as data.count | addinfo | eval version="1.0",begin=floor(info_min_time),end=floor(info_max_time) | makejson version(string),begin(int),end(int),data.* output=event | table event

[Audit - Feature Usage - Telemetry Gen]
action.email.sendresults                   = 0
action.outputtelemetry                     = 1
action.outputtelemetry.param.anonymous     = 1
action.outputtelemetry.param.support       = 0
action.outputtelemetry.param.license       = 0
action.outputtelemetry.param.optinrequired = 3
action.outputtelemetry.param.component     = app.SplunkEnterpriseSecuritySuite.feature_usage
action.outputtelemetry.param.input         = event
action.outputtelemetry.param.type          = aggregate
alert.track                                = false
counttype                                  = number of events
relation                                   = greater than
quantity                                   = 0
cron_schedule                              = 0 2 * * *
description                                = Sends anonymous usage statistics pertaining to the number of view loads.
disabled                                   = False
dispatch.earliest_time                     = -1d@d
dispatch.latest_time                       = @d
enableSched                                = 1
is_visible                                 = false
request.ui_dispatch_app                    = SplunkEnterpriseSecuritySuite
schedule_window                            = auto
search                                     = | tstats summariesonly=false allow_old_summaries=true avg(View_Activity.spent) as data.avg_spent,count as data.count from datamodel=Splunk_Audit.View_Activity where (View_Activity.app="SplunkEnterpriseSecuritySuite" OR View_Activity.app="Splunk_DA-ESS*") by View_Activity.view | rename View_Activity.view as data.view | lookup update=true es_instrumentation_views view as data.view OUTPUT view as is_ok | eval is_custom=if(isnull(is_ok),1,0) | appendpipe [search is_custom=1 | eval weighted_avg='data.avg_spent'*'data.count' | stats sum(weighted_avg) as weighted_avg,sum(data.count) as data.count | eval "data.avg_spent"=weighted_avg/'data.count',"data.view"="other",is_ok="true"] | where isnotnull(is_ok) | addinfo | eval version="1.0",begin=floor(info_min_time),end=floor(info_max_time),"data.avg_spent"=floor('data.avg_spent') | makejson version(string),begin(int),end(int),data.* output=event | table event

[Audit - Search Execution - Telemetry Gen]
action.email.sendresults                   = 0
action.outputtelemetry                     = 1
action.outputtelemetry.param.anonymous     = 1
action.outputtelemetry.param.support       = 0
action.outputtelemetry.param.license       = 0
action.outputtelemetry.param.optinrequired = 3
action.outputtelemetry.param.component     = app.SplunkEnterpriseSecuritySuite.search_execution
action.outputtelemetry.param.input         = event
action.outputtelemetry.param.type          = aggregate
alert.track                                = false
counttype                                  = number of events
relation                                   = greater than
quantity                                   = 0
cron_schedule                              = 0 3 * * *
description                                = Sends anonymous usage statistics pertaining to the number of search executions.
disabled                                   = False
dispatch.earliest_time                     = -1d@d
dispatch.latest_time                       = @d
enableSched                                = 1
is_visible                                 = false
request.ui_dispatch_app                    = SplunkEnterpriseSecuritySuite
schedule_window                            = auto
search                                     = | tstats summariesonly=false allow_old_summaries=true values(nodename) as nodename,avg(Search_Activity.total_run_time) as data.avg_run_time,count as data.count from datamodel=Splunk_Audit.Search_Activity where Search_Activity.search_alias!="*Data Model Summary Director" by Search_Activity.search_alias | rename Search_Activity.search_alias as data.search_alias | where NOT match('data.search_alias', "search\d+") | lookup update=true es_instrumentation_searches search_alias as data.search_alias OUTPUT search_alias as is_ok | eval is_custom=if(isnull(is_ok),1,0) | appendpipe [search is_custom=1 | eval weighted_avg='data.avg_run_time'*'data.count' | stats sum(weighted_avg) as weighted_avg,sum(data.count) as data.count | eval "data.avg_run_time"=weighted_avg/'data.count',"data.search_alias"="other",is_ok="true"] | where isnotnull(is_ok) | addinfo | eval version="1.0",begin=floor(info_min_time),end=floor(info_max_time),"data.is_realtime"=if(nodename=="Search_Activity.Realtime_Jobs",1,0),"data.avg_run_time"=round('data.avg_run_time', 2) | makejson version(string),begin(int),end(int),data.* output=event | table event

[Audit - Search Actions - Telemetry Gen]
action.email.sendresults                   = 0
action.outputtelemetry                     = 1
action.outputtelemetry.param.anonymous     = 1
action.outputtelemetry.param.support       = 0
action.outputtelemetry.param.license       = 0
action.outputtelemetry.param.optinrequired = 3
action.outputtelemetry.param.component     = app.SplunkEnterpriseSecuritySuite.search_actions
action.outputtelemetry.param.input         = event
action.outputtelemetry.param.type          = event
alert.track                                = false
counttype                                  = number of events
relation                                   = greater than
quantity                                   = 0
cron_schedule                              = 0 4 * * *
description                                = Sends anonymous statistics pertaining to the usage of custom alert actions.
disabled                                   = False
dispatch.earliest_time                     = 0
dispatch.latest_time                       = +0s
enableSched                                = 1
is_visible                                 = false
request.ui_dispatch_app                    = SplunkEnterpriseSecuritySuite
schedule_window                            = auto
search                                     = | rest splunk_server=local count=0 /servicesNS/nobody/SplunkEnterpriseSecuritySuite/saved/searches | search disabled=0 is_scheduled=1 | eval "data.action"=split(actions, ",") | eventstats count as data.total_scheduled | stats first(data.total_scheduled) as data.total_scheduled,count as data.count by data.action | lookup update=true es_instrumentation_actions action as data.action OUTPUT action as is_ok | eval is_custom=if(isnull(is_ok),1,0) | appendpipe [search is_custom=1 | stats first(data.total_scheduled) as data.total_scheduled,sum(data.count) as data.count | eval "data.action"="other",is_ok="true"] | where isnotnull(is_ok) | join data.action type=left [| rest splunk_server=local count=0 /servicesNS/nobody/SplunkEnterpriseSecuritySuite/alerts/alert_actions | rename title as data.action | eval "data.is_adaptive_response"=if(isnotnull('param._cam'),1,0) | table data.action,data.is_adaptive_response] | eval version="1.0","data.is_adaptive_response"=if(isnull('data.is_adaptive_response'),0,1) | makejson version(string),data.* output=event | table event

[Audit - Datamodel Distribution - Telemetry Gen]
action.email.sendresults                   = 0
action.outputtelemetry                     = 1
action.outputtelemetry.param.anonymous     = 1
action.outputtelemetry.param.support       = 0
action.outputtelemetry.param.license       = 0
action.outputtelemetry.param.optinrequired = 3
action.outputtelemetry.param.component     = app.SplunkEnterpriseSecuritySuite.datamodel_distribution
action.outputtelemetry.param.input         = event
action.outputtelemetry.param.type          = event
alert.track                                = false
counttype                                  = number of events
relation                                   = greater than
quantity                                   = 0
cron_schedule                              = 0 5 * * *
description                                = Sends anonymous statistics pertaining to the usage of datamodels.
disabled                                   = False
dispatch.earliest_time                     = 0
dispatch.latest_time                       = +0s
enableSched                                = 1
is_visible                                 = false
request.ui_dispatch_app                    = SplunkEnterpriseSecuritySuite
schedule_window                            = auto
search                                     = | from datamodel:Splunk_Audit.Datamodel_Acceleration | rename datamodel as data.datamodel,size as data.size | lookup update=true es_instrumentation_datamodels datamodel as data.datamodel OUTPUT datamodel as is_ok | eval is_custom=if(isnull(is_ok),1,0) | appendpipe [search is_custom=1 | stats sum(data.size) as data.size | eval "data.datamodel"="other",is_ok="true"] | eventstats sum(data.size) as total_size | where isnotnull(is_ok) | eval version="1.0","data.perc"=round('data.size'/total_size*100, 2) | makejson version(string),data.* output=event | table event


[Event Sequencing Engine - Main]
cron_schedule            = * * * * *
disabled                 = 0
dispatch.earliest_time   = rt
dispatch.latest_time     = rt
dispatch.indexedRealtime = 1
enableSched              = 0
schedule_priority        = highest
is_visible               = 1
dispatch.rt_backfill     = 0
search                   = `event_seq_base_search` | esssequence create_seq_event="true"[Notable - Total Events By Network Domain]
action.keyindicator.group.0.order = 11

[Notable - Total Events By Access Domain]
action.keyindicator.group.0.order = 9

[Notable - Total Events By Endpoint Domain]
action.keyindicator.group.0.order = 10

[Notable - Total Events By Threat Domain]
action.keyindicator.group.0.order = 14

[Notable - Total Events By Identity Domain]
action.keyindicator.group.0.order = 12

[Notable - Total Events By Audit Domain]
action.keyindicator.group.0.order = 13
#   Version 7.2.5.1
[Errors in the last 24 hours]
search = error OR failed OR severe OR ( sourcetype=access_* ( 404 OR 500 OR 503 ) )
dispatch.earliest_time = -1d

[Errors in the last hour]
search = error OR failed OR severe OR ( sourcetype=access_* ( 404 OR 500 OR 503 ) )
dispatch.earliest_time = -1h

[Messages by minute last 3 hours]
search = index=_internal source="*metrics.log" eps "group=per_source_thruput" NOT filetracker | eval events=eps*kb/kbps | timechart fixedrange=t span=1m limit=5 sum(events) by series
dispatch.earliest_time = -3h
displayview = report_builder_display

[Splunk errors last 24 hours]
search = index=_internal " error " NOT debug source=*splunkd.log*
dispatch.earliest_time = -24h

[Orphaned scheduled searches]
search = | rest timeout=600 splunk_server=local /servicesNS/-/-/saved/searches add_orphan_field=yes count=0 \
| search orphan=1 disabled=0 is_scheduled=1 \
| eval status = if(disabled = 0, "enabled", "disabled") \
| fields title eai:acl.owner eai:acl.app eai:acl.sharing orphan status is_scheduled cron_schedule next_scheduled_time next_scheduled_time actions \
| rename title AS "search name" eai:acl.owner AS owner eai:acl.app AS app eai:acl.sharing AS sharing

# For license usage report dashboard
[License Usage Data Cube]
dispatch.earliest_time = -31d
dispatch.latest_time = -0d
auto_summarize = 0
auto_summarize.dispatch.earliest_time = -1mon@d
auto_summarize.cron_schedule = 3,13,23,33,43,53 * * * *
search = index=_internal source=*license_usage.log* type="Usage" | eval h=if(len(h)=0 OR isnull(h),"(SQUASHED)",h) | eval s=if(len(s)=0 OR isnull(s),"(SQUASHED)",s) | eval idx=if(len(idx)=0 OR isnull(idx),"(UNKNOWN)",idx) | bin _time span=1d | stats sum(b) as b by _time, pool, s, st, h, idx

[Threat - Testing Rule for app permission - Rule]
action.correlationsearch.enabled = 1
action.correlationsearch.label = Testing Rule for app permission
action.customsearchbuilder.enabled = false
action.customsearchbuilder.spec = {}
action.email = 1
action.email.to = cyrus_tam@macroview.com
action.notable.param.verbose = 0
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = */10 * * * *
description = Testing Testing
disabled = 1
dispatch.earliest_time = -1h
dispatch.latest_time = now
dispatch.rt_backfill = 1
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SplunkEnterpriseSecuritySuite
search = index=*

[Threat - Detect DNS Tunneling Activity by Entropy Score - Rule]
action.correlationsearch.enabled = 1
action.correlationsearch.label = Detect DNS Tunneling Activity by Entropy Score
action.customsearchbuilder.spec = {}
action.email = 1
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.message.alert = The alert condition for '$name$' was triggered.\
\
Time     : $result._time$\
Host     : $result.src$\
Query   : $result.query$\
Entropy Score : $result.Entropy_score$\
Severity : High\
\
Macroview SOC
action.email.subject = Detect DNS Tunneling Activity by Entropy Score by host : $result.src$
action.email.to = cyrus_tam@macroview.com,yul_fine@macroview.com
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
action.nbtstat.param.verbose = 0
action.notable = 1
action.notable.param.drilldown_name = Search DNS log by host $src$
action.notable.param.drilldown_search = | from datamodel:"Network_Resolution"."DNS"  | where src = "$src$"
action.notable.param.extract_assets = ["src","dest","dvc","orig_host"]
action.notable.param.extract_identities = ["src_user","user"]
action.notable.param.rule_description = Discovers DNS Tunneling Activity and there may be abnormal connection related to Ransomware /Malware Activity.
action.notable.param.rule_title = Detect DNS Tunneling Activity by Entropy Score by host : $src$
action.notable.param.security_domain = network
action.notable.param.severity = high
action.notable.param.verbose = 0
action.nslookup.param.verbose = 0
action.ping.param.verbose = 0
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 5
action.risk.param.verbose = 0
action.send2uba.param.verbose = 0
action.threat_add.param.verbose = 0
alert.suppress = 1
alert.suppress.fields = query,src,dest
alert.suppress.period = 3600s
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = Discovers DNS Tunneling Activity and there may be abnormal connection related to Ransomware /Malware Activity.
dispatch.earliest_time = -10m
dispatch.latest_time = now
dispatch.rt_backfill = 1
enableSched = 1
quantity = 1
relation = greater than
request.ui_dispatch_app = search
search = | from datamodel:"Network_Resolution"."DNS" \
| stats  values(query) as query by _time ,src \
| where query!="unknown" \
| `ut_shannon(query)` \
| rename ut_shannon as Entropy_score \
| where Entropy_score > 4.5 \
| dedup query \
| sort - _time \
| eval _time = strftime(_time,"%Y-%m-%d %H:%m:%S")
[Stage  1 - Reconnaissance, External Network Scan]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$, Source=$result.source$, Sourcetype=$result.sourcetype$, src_ip=$result.src_ip$, HostsScanned=$result.HostsScanned$, stage="$result.stage$", rule="$result.rule$"
action.logevent.param.index = apt-framework
action.logevent.param.source = apt-framework
action.logevent.param.sourcetype = apt-framework
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCAPTFrameworkBasic
request.ui_dispatch_view = search
search = index=* ( tag::eventtype="communicate" OR tag::eventtype="network")   NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv | rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_ip) AS HostsScanned by src_ip, _time |  where HostsScanned> 9 | dedup src_ip, HostsScanned | rename src_ip as clientip | lookup ipdomain clientip  OUTPUT class | fillnull class | where class=0 | eval rule="External Network Scan" | eval stage="Stage 1 - Reconnaissance" | rename clientip as src_ip |  table src_ip, HostsScanned, _time, stage, rule, source,sourcetype

[Stage 1 - Reconnaissance, External Port Scan]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$, Source=$result.source$, Sourcetype=$result.sourcetype$, src_ip=$result.src_ip$, PortsScanned=$result.PortsScanned$, stage="$result.stage$", rule="$result.rule$"
action.logevent.param.index = apt-framework
action.logevent.param.source = apt-framework
action.logevent.param.sourcetype = apt-framework
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCAPTFrameworkBasic
request.ui_dispatch_view = search
search = index=* ( tag::eventtype="communicate" OR tag::eventtype="network")   NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv | rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_port) AS PortsScanned by src_ip, _time |  where PortsScanned> 50 | dedup src_ip, PortsScanned | rename src_ip as clientip | lookup ipdomain clientip  OUTPUT class | fillnull class | where class=0 | eval rule="External Port Scan" | eval stage="Stage 1 - Reconnaissance" | rename clientip as src_ip |  table src_ip, PortsScanned, _time, stage, rule, source,sourcetype

[Stage 3 - Delivery, Outbound Connection to Attacker Host]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $trigger_time$, Source=$result.source$, Sourcetype=$result.sourcetype$, src_ip=$result.src_ip$, dest_ip=$result.dest_ip$, stage="$result.stage$", rule="$result.rule$",  count=$result.count$
action.logevent.param.index = apt-framework
action.logevent.param.source = apt-framework
action.logevent.param.sourcetype = apt-framework
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCAPTFrameworkBasic
request.ui_dispatch_view = search
search = index=* (tag::eventtype="web" OR tag::eventtype="proxy" OR tag::eventtype="communicate" OR tag::eventtype="network")  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rex field=dest "(?<IP_add>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(?<dest_port>\d+)" | rename src_ip as clientip | lookup ipdomain clientip  OUTPUT class | search class=internal | rename clientip as src_ip | join dest_ip [ search index=apt-framework earliest=-92d latest=now  stage="Stage 1 - Reconnaissance" | rename src_ip as dest_ip  | dedup  dest_ip ]  | eval stage="Stage 3 - Delivery" | eval rule="Outbound connection to Attacker Host"  | stats count by src_ip dest_ip rule stage source sourcetype | table _time src_ip dest_ip rule stage count, source,sourcetype

[Stage 4 - Exploitation, Service or Software Installed]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $trigger_time$, Source=$result.source$, Sourcetype=$result.sourcetype$, src_ip=$result.src_ip$, stage="$result.stage$", rule="$result.rule$", count=$result.count$, src_host=$result.ComputerName$
action.logevent.param.index = apt-framework
action.logevent.param.source = apt-framework
action.logevent.param.sourcetype = apt-framework
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCAPTFrameworkBasic
request.ui_dispatch_view = search
search = index=*  (EventCode=1022 SourceName=MsiInstaller) OR (EventCode=1033 SourceName=MsiInstaller) OR (EventCode=11707 SourceName=MsiInstaller) OR (EventCode=11728 SourceName=MsiInstaller) OR (EventCode=19 TaskCategory="Windows Update Agent") OR (SourceName="Microsoft-Windows-FilterManager" EventCode=6) OR (EventCode=4377 SourceName=NtServicePack) OR (LogName=Security EventCode=601) OR (EventCode=7045 SourceName="Microsoft-Windows-Service Control Manager") OR (SourceName="Microsoft-Windows-Security-Auditing" EventCode=4697) |  lookup dnsLookup  host as ComputerName | eval stage="Stage 4 - Exploitation" | eval rule="Service or Software Installed" | stats count by ip ComputerName stage rule source sourcetype | rename ip as src_ip

[Stage 5 - Installation, PsExec Service Installed]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$, Source=$result.source$, Sourcetype=$result.sourcetype$, src_ip=$result.src_ip$, stage="$result.stage$", rule="$result.rule$", src_host=$result.ComputerName$
action.logevent.param.index = apt-framework
action.logevent.param.source = apt-framework
action.logevent.param.sourcetype = apt-framework
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCAPTFrameworkBasic
request.ui_dispatch_view = search
search = index=*  EventCode=7045 SourceName="*Service Control Manager" | eval service_name_lower_case=lower(Service_Name) | eval service_file_name_lower_case=lower(Service_File_Name) | search (service_name_lower_case=*psexe* OR service_file_name_lower_case=*psexe*) | lookup dnsLookup  host as ComputerName | eval stage="Stage 5 - Installation" | eval rule="PsExec Service Installed" |  table _time ip ComputerName stage rule source sourcetype | rename ip as src_ip

[Stage 5 - Installation, PsExec Service Usage]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$, Source=$result.source$, Sourcetype=$result.sourcetype$, src_ip=$result.src_ip$, stage="$result.stage$", rule="$result.rule$", src_host=$result.ComputerName$
action.logevent.param.index = apt-framework
action.logevent.param.source = apt-framework
action.logevent.param.sourcetype = apt-framework
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCAPTFrameworkBasic
request.ui_dispatch_view = search
search = index=*  EventCode=7036 SourceName="*Service Control Manager"  | search *psexe*  | lookup dnsLookup  host as ComputerName | eval stage="Stage 5 - Installation" | eval rule="PsExec Service Usage" |  table _time ip ComputerName stage rule source sourcetype | rename ip as src_ip

[Stage 6 - C2, Outbound Connection to C2]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $trigger_time$, Source=$result.source$, Sourcetype=$result.sourcetype$, src_ip=$result.src_ip$, dest_ip=$result.dest_ip$, stage="$result.stage$", rule="$result.rule$",  count=$result.count$
action.logevent.param.index = apt-framework
action.logevent.param.source = apt-framework
action.logevent.param.sourcetype = apt-framework
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCAPTFrameworkBasic
request.ui_dispatch_view = search
search = index=* (tag::eventtype="web" OR tag::eventtype="proxy" ) earliest=-10m latest=now  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | lookup ipdomain clientip as dest_ip  OUTPUT class as cl  | rex mode=sed field=url "s/http:\/\///" | rex mode=sed field=url  "s/https:\/\///" | rex mode=sed field=url  "s/:443//" | rex mode=sed field=url  "s/\/$//" | rename url as Domain | join Domain [ | inputlookup c2domain.csv ] | append [ search earliest=-10m latest=now index=* (tag::eventtype="web" OR tag::eventtype="proxy" OR tag::eventtype="communicate" OR tag::eventtype="network")   | join dest_ip [ |inputlookup c2ip.csv | rename IPAddress as dest_ip ]] | eval stage="Stage 6 - C2" | eval rule="Outbound connection to C2"  | stats count by src_ip dest_ip rule stage source sourcetype | table src_ip dest_ip rule stage count source sourcetype

[Stage 7 - Actions on Objective, Internal Network Scan]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$, Source=$result.source$, Sourcetype=$result.sourcetype$, src_ip=$result.src_ip$, HostsScanned=$result.HostsScanned$, stage="$result.stage$", rule="$result.rule$"
action.logevent.param.index = apt-framework
action.logevent.param.source = apt-framework
action.logevent.param.sourcetype = apt-framework
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCAPTFrameworkBasic
request.ui_dispatch_view = search
search = index=* ( tag::eventtype="communicate" OR tag::eventtype="network")   NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv | rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_ip) AS HostsScanned by src_ip, _time |  where HostsScanned> 50 | dedup src_ip, HostsScanned | lookup ipdomain clientip as src_ip OUTPUT class as class1  | where class1="internal" |  lookup ipdomain clientip as dest_ip  OUTPUT class as class2 |  where class2="internal" | eval rule="Internal Network Scan" | eval stage="Stage 7 - Reconnaissance" |  table src_ip, HostsScanned, _time, stage, rule, source, sourcetype

[Stage 7 - Actions on Objective, Internal Port Scan]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$, Source=$result.source$, Sourcetype=$result.sourcetype$, src_ip=$result.src_ip$, PortsScanned=$result.PortsScanned$, stage="$result.stage$", rule="$result.rule$"
action.logevent.param.index = apt-framework
action.logevent.param.source = apt-framework
action.logevent.param.sourcetype = apt-framework
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCAPTFrameworkBasic
request.ui_dispatch_view = search
search = index=* ( tag::eventtype="communicate" OR tag::eventtype="network")   NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv | rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_port) AS PortsScanned by src_ip, _time |  where PortsScanned> 50 | dedup src_ip, PortsScanned | lookup ipdomain clientip as src_ip OUTPUT class as class1  | where class1="internal" |  lookup ipdomain clientip as dest_ip  OUTPUT class as class2 |  where class2="internal" | eval rule="Internal Port Scan" | eval stage="Stage 7 - Reconnaissance" |  table src_ip, PortsScanned, _time, stage, rule, source, sourcetype

[Stage 7 - Actions on Objective, Windows Audit Logs Cleared]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $trigger_time$, Source=$result.source$, Sourcetype=$result.sourcetype$, src_ip=$result.src_ip$, stage="$result.stage$", rule="$result.rule$" count=$result.count$, src_host=$result.ComputerName$
action.logevent.param.index = apt-framework
action.logevent.param.source = apt-framework
action.logevent.param.sourcetype = apt-framework
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCAPTFrameworkBasic
request.ui_dispatch_view = search
search = index=*  (EventCode=1102 SourceName="Microsoft-Windows-Eventlog") OR (EventCode=104 SourceName="Microsoft-Windows-Eventlog") OR (Security LogName=Security EventCode=517)  |  lookup dnsLookup  host as ComputerName | eval stage="Stage 7 - Actions on Objective" | eval rule="Windows Audit Logs Cleared" | stats count by ip ComputerName stage rule source sourcetype | rename ip as src_ip

[Stage 7 - Actions on Objective, Windows System Time Changed]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $trigger_time$, Source=$result.source$, Sourcetype=$result.sourcetype$, src_ip=$result.src_ip$, stage="$result.stage$", rule="$result.rule$", count=$result.count$, src_host=$result.ComputerName$
action.logevent.param.index = apt-framework
action.logevent.param.source = apt-framework
action.logevent.param.sourcetype = apt-framework
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */10 * * * *
dispatch.earliest_time = -10m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCAPTFrameworkBasic
request.ui_dispatch_view = search
search = index=*  (EventCode=4616 Windows SourceName="Microsoft Windows security auditing.") OR (LogName=Security EventCode=520)   |  lookup dnsLookup  host as ComputerName | eval stage="Stage 7 - Actions on Objective" | eval rule="Windows System Time Changed" | stats count by ip ComputerName stage rule source sourcetype | rename ip as src_ip
[SYSMON Integration Framework - 10 files or more creation per 1 min alert]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Huge count of new files" Image=$result.Image$ Computer=$result.Computer$ Count=$result.count$
action.logevent.param.index = sif
action.logevent.param.source = sif
action.logevent.param.sourcetype = sif
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeSYSMONIntegrationFrameworkBasic
request.ui_dispatch_view = search
search = index=*  sourcetype="xmlwineventlog:microsoft-windows-sysmon/operational" EventDescription="File Create Time" | streamstats time_window=1m count(EventDescription) AS "new_files" by Computer | search new_files>10 | fields + Image Computer | bin _time span=1m | stats count by _time Image Computer

[SYSMON Integration Framework - Long commands detection]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Long commands running"   Image="$result.Image$"  CommandLine="$result.CommandLine$" ParentImage="$result.ParentImage$" ParentCommandLine="$result.ParentCommandLine$" c_length=$result.c_length$ Computer="$result.Computer$"
action.logevent.param.index = sif
action.logevent.param.source = sif
action.logevent.param.sourcetype = sif
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
description = Detect long  commands that most probably will include obfuscated malicious code by length of command
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeSYSMONIntegrationFrameworkBasic
request.ui_dispatch_view = search
search = index =* sourcetype="xmlwineventlog:microsoft-windows-sysmon/operational" EventCode=1 (Image="*cmd.exe" OR Image="*powershell.exe") | eval   c_length=len(CommandLine) | where c_length>500 | table _time, Computer, User, Image, CommandLine, ParentImage, ParentCommandLine c_length

[SYSMON Ingegration Farmework - Suspicious child process running]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Suspicious child process running"   Image="$result.Image$" CommandLine="$result.CommandLine$" ParentImage="$result.ParentImage$" Computer="$result.Computer$"
action.logevent.param.index = sif
action.logevent.param.source = sif
action.logevent.param.sourcetype = sif
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeSYSMONIntegrationFrameworkBasic
request.ui_dispatch_view = search
search = index=* source="WinEventLog:Microsoft-Windows-Sysmon/Operational"  EventCode=1  ( ParentImage="*winword.exe" OR ParentImage="*outlook.exe" OR ParentImage="*excel.exe" OR ParentImage="*powerpnt.exe" OR ParentImage="*iexplore.exe" OR ParentImage="*firefox.exe" OR ParentImage="*chrome.exe") AND (Image="*powershell.exe" OR Image="*cmd.exe" OR Image="*cscript.exe" OR Image="*wscript.exe" OR Image="*rundll32.exe") | table _time ParentImage Image CommandLine Computer

[SYSMON Integration Framework - Non- browsers executables direct connections to Internet]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Non- browsers executables direct connections to Internet"   Image="$result.Image$"  SourceIp="$result.SourceIp$"  DestinationIp="$result.DestinationIp$" action=$result.action$ Computer=$result.Computer$
action.logevent.param.index = sif
action.logevent.param.source = sif
action.logevent.param.sourcetype = sif
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeSYSMONIntegrationFrameworkBasic
request.ui_dispatch_view = search
search = index=* source="WinEventLog:Microsoft-Windows-Sysmon/Operational"  EventCode=3  (Image!="*firefox.exe" OR Image!="*iexplore.exe" OR Image!="chrome.exe") | lookup ipdomain clientip as DestinationIp OUTPUT class | fillnull class | where class=0 |  table _time Image Computer SourceIp DestinationIp action

#####################
## Context Creation Searches
## To be enabled, modified, or scheduled by customer as needed.
## If "enableSched == 0" then typically the context is precreated and shipped 
## with the app.
#####################
[ESS - Percentile - Context Gen]
enableSched = 0
is_visible = false
search = | xsCreateUDContext scope=app container=default name=percentile terms="extreme,high,medium,low,minimal,low,medium,high,extreme" type=domain uom="percentage" min=-100 max=100 count=1 | stats count


#####################
## Users
#####################

###### Lookup Generating Searches ######
[Utils - User Realnames - Lookup Gen]
cron_schedule          = */10 * * * *
disabled               = False
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = true
search                 = | rest splunk_server=local count=0 /services/authentication/users | rename title as user | eval _key=user | eval realname=if(isnull(realname) or realname="", null(), realname) | table _key user realname | outputlookup user_realnames_lookup | stats count


#####################
## REST
#####################
[Utils - Top REST actions]
dispatch.earliest_time = rt-24h
dispatch.latest_time = rt
displayview = flashtimeline
request.ui_dispatch_view = flashtimeline
search = `rest_handler_transactions` | top action

[Utils - Top REST by duration]
dispatch.earliest_time = rt-24h
dispatch.latest_time = rt
displayview = flashtimeline
request.ui_dispatch_view = flashtimeline
search = `rest_handler_transactions` | stats sum(duration) by handler | sort 10 - sum(duration)

[Utils - Top REST actions by sourcetype]
dispatch.earliest_time = rt-24h
dispatch.latest_time = rt
displayview = flashtimeline
request.ui_dispatch_view = flashtimeline
search = `rest_handler_transactions` | search duration>0.05 | stats sparkline(sum(duration)) as sparkline,min(duration),avg(duration),max(duration),count by handler,action | sort - count


#####################
## Per-Panel Filtering
#####################

[Per-Panel Filtering - Activity By User Over Time] 
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
dispatchAs                                = user
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = column
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
search                                    = | search `ppf_updates` |  `get_realname(user)` | timechart useother=`useother` count by user_realname

[Per-Panel Filtering - Top Users]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = `ppf_updates` |  `get_realname(user)` | stats sparkline,count,min(_time) as firstTime,max(_time) as lastTime by user_realname | `uitime(firstTime)` | `uitime(lastTime)` | sort 100 - count

[Per-Panel Filtering - Recent Activity]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = `ppf_updates` |  `get_realname(user)` | sort 100 - _time | fillnull value="manual edit" action | table _time,user_realname,action,lookup_file


# health checks
[Audit - Default Admin Search Indexes]
action.output_message              = 1
action.output_message.param.name   = HEALTH_CHECK:DEFAULT_ADMIN_SEARCH_SUMMARY_INDEXES
action.output_message.param.msgid  = healthcheck_default_admin_search_summary_indexes
action.output_message.param.fields = splunk_server,srchIndexesDefault
action.output_message.param.purge  = 1
alert.digest_mode                  = true
alert.track                        = 0
counttype                          = number of events
cron_schedule                      = 0 3 * * *
dispatch.earliest_time             = 0
dispatch.latest_time               = +0s
enableSched                        = 1
quantity                           = 0
relation                           = greater than
schedule_window                    = auto
search                             = | rest /services/authorization/roles/admin splunk_server=* count=0 | where match(srchIndexesDefault, "^(.*summary[0-9]?|notable)$") | fields splunk_server, srchIndexesDefault | eval srchIndexesDefault=mvjoin(srchIndexesDefault, ",")

[Audit - Default Admin Search All Non-Internal]
action.output_message              = 1
action.output_message.param.name   = HEALTH_CHECK:DEFAULT_ADMIN_SEARCH_ALL_NON_INTERNAL
action.output_message.param.msgid  = healthcheck_default_admin_search_all_noninternal
action.output_message.param.fields = splunk_server
action.output_message.param.purge  = 1
alert.digest_mode                  = true
alert.track                        = 0
counttype                          = number of events
cron_schedule                      = 5 3 * * *
dispatch.earliest_time             = 0
dispatch.latest_time               = +0s
enableSched                        = 1
quantity                           = 0
relation                           = greater than
schedule_window                    = auto
search                             = | rest /services/authorization/roles/admin splunk_server=* count=0 | eval is_asterisk=if(srchIndexesDefault == "*", 1, 0) | where is_asterisk=1 | fields splunk_server, srchIndexesDefault

[Audit - Script Errors]
action.output_message              = 1
action.output_message.param.name   = HEALTH_CHECK:SCRIPT_ERRORS
action.output_message.param.msgid  = healthcheck_script_errors
action.output_message.param.fields = errmsg,script,stanza
action.output_message.param.purge  = 0
alert.digest_mode                  = true
alert.suppress                     = true
alert.suppress.fields              = script,stanza
alert.suppress.period              = 12h
alert.track                        = 0
counttype                          = number of events
cron_schedule                      = 0 * * * *
dispatch.earliest_time             = 0
dispatch.latest_time               = +0s
enableSched                        = 1
quantity                           = 0
relation                           = greater than
schedule_window                    = auto
search                             = | rest /services/admin/inputstatus/ModularInputs:modular%20input%20commands splunk_server=local count=0 | append [| rest /services/admin/inputstatus/ExecProcessor:exec%20commands splunk_server=local count=0] | fields inputs* | transpose | rex field=column "inputs(?<script>\S+)(?:\s\((?<stanza>[^\(]+)\))?\.(?<key>(exit status description)|(time closed)|(time opened))" | eval value=coalesce('row 1', 'row 2'), stanza=coalesce(stanza, "default"), started=if(key=="time opened", value, started), stopped=if(key=="time closed", value, stopped) | rex field=value "exited\s+with\s+code\s+(?<exit_status>\d+)" | stats first(started) as started, first(stopped) as stopped, first(exit_status) as exit_status by script, stanza | eval errmsg=case(exit_status=="0", null(), isnotnull(exit_status), "A script exited abnormally with exit status: "+exit_status, isnull(started) or isnotnull(stopped), "A script is in an unknown state"), ignore=if(`script_error_msg_ignore`, 1, 0) | where isnotnull(errmsg) AND ignore=0


[Audit - Savedsearch Statistics - Lookup Gen]
cron_schedule          = */30 * * * *
disabled               = 0
dispatch.earliest_time = -24h@h
dispatch.latest_time   = +0s
dispatchAs             = user
enableSched            = 1
is_visible             = false
run_on_startup         = true
schedule_window        = auto
search                 = index=_audit action=search savedsearch_name=* info=completed | stats avg(total_run_time) as avg_run_time, avg(event_count) as avg_event_count, avg(result_count) as avg_result_count, count as invocations by savedsearch_name | join type=outer savedsearch_name [search index=_internal sourcetype=scheduler search_type="scheduled" OR search_type="" | stats count(eval(status=="success")) as success, count(eval(status=="skipped")) as skipped by savedsearch_name] | where savedsearch_name != "" | eval update_time=now() | outputlookup key_field=savedsearch_name savedsearch_stats_lookup | stats count

[Audit - Sourcetype Readiness - Lookup Gen]
cron_schedule          = */30 * * * *
disabled               = 0
dispatch.earliest_time = 0
dispatch.latest_time   = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = true
schedule_window        = auto
search                 = | metadata type=sourcetypes splunk_server=* index=* index=_* | eval readiness=if(lastTime > now() - 86400, 1, 0), update_time=now() | fields sourcetype, readiness, update_time | outputlookup key_field=sourcetype sourcetype_readiness_lookup | stats count

[Audit - Dataset Relation]
cron_schedule          = */30 * * * *
disabled               = 0
dispatch.earliest_time = 0
dispatch.latest_time    = +0s
enableSched            = 1
is_visible             = false
run_on_startup         = true
schedule_window        = auto
search                 = | rest /servicesNS/nobody/SA-Utils/contentinfo/_cache timeout=600 splunk_server=local count=0 | stats count
[Utils - Top REST actions]
alert.track = 0
request.ui_dispatch_view = 

[Utils - Top REST actions by sourcetype]
alert.track = 0
request.ui_dispatch_view = 

[Utils - Top REST by duration]
alert.track = 0
request.ui_dispatch_view = 
[Nessus plugins]
disabled = 1
action.email.reportServerEnabled = 0
action.email.useNSSubject = 1
alert.track = 0
auto_summarize.dispatch.earliest_time = -30d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = 0
dispatch.latest_time = now
display.general.type = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = search
request.ui_dispatch_view = search
description = Saved search which populates Nessus plugins into lookup CSV
search = sourcetype=nessus:plugin | dedup id | table cvss,"cvss_base_score","cvss_vector",cwe,description,"exploit_available","exploit_framework_canvas","exploit_framework_core","exploit_framework_exploithub","exploit_framework_metasploit","exploitability_ease","exploited_by_malware","exploithub_sku","family_name",fname,id,"metasploit_name","patch_publication_date","plugin_modification_date","plugin_name","plugin_publication_date","plugin_type","risk_factor","script_version",signature,"signature_id",solution,synopsis | inputlookup append=t nessus_plugin_lookup | dedup id | outputlookup nessus_plugin_lookup

[Nessus plugins cve]
disabled = 1
action.email.reportServerEnabled = 0
action.email.useNSSubject = 1
alert.track = 0
auto_summarize.dispatch.earliest_time = -30d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = 0
dispatch.latest_time = now
display.general.type = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = search
request.ui_dispatch_view = search
description = Saved search which populates Nessus plugins into lookup CSV
search = sourcetype=nessus:plugin | dedup id | table id,cve | inputlookup append=t nessus_mv_cve_lookup | dedup id | mvexpand cve | outputlookup nessus_mv_cve_lookup

[Nessus plugins cpe]
disabled = 1
action.email.reportServerEnabled = 0
action.email.useNSSubject = 1
alert.track = 0
auto_summarize.dispatch.earliest_time = -30d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = 0
dispatch.latest_time = now
display.general.type = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = search
request.ui_dispatch_view = search
description = Saved search which populates Nessus plugins into lookup CSV
search = sourcetype=nessus:plugin | dedup id | table id,cpe | inputlookup append=t nessus_mv_cpe_lookup | dedup id | mvexpand cpe | outputlookup nessus_mv_cpe_lookup

[Nessus plugins bugtraq]
disabled = 1
action.email.reportServerEnabled = 0
action.email.useNSSubject = 1
alert.track = 0
auto_summarize.dispatch.earliest_time = -30d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = 0
dispatch.latest_time = now
display.general.type = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = search
request.ui_dispatch_view = search
description = Saved search which populates Nessus plugins into lookup CSV
search = sourcetype=nessus:plugin | dedup id | table id,bugtraq | inputlookup append=t nessus_mv_bugtraq_lookup | dedup id | mvexpand bugtraq | outputlookup nessus_mv_bugtraq_lookup

[Nessus plugins osvdb]
disabled = 1
action.email.reportServerEnabled = 0
action.email.useNSSubject = 1
alert.track = 0
auto_summarize.dispatch.earliest_time = -30d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = 0
dispatch.latest_time = now
display.general.type = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = search
request.ui_dispatch_view = search
description = Saved search which populates Nessus plugins into lookup CSV
search = sourcetype=nessus:plugin | dedup id | table id,osvdb | inputlookup append=t nessus_mv_osvdb_lookup | dedup id | mvexpand osvdb | outputlookup nessus_mv_osvdb_lookup

[Nessus plugins xref]
disabled = 1
action.email.reportServerEnabled = 0
action.email.useNSSubject = 1
alert.track = 0
auto_summarize.dispatch.earliest_time = -30d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = 0
dispatch.latest_time = now
display.general.type = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = search
request.ui_dispatch_view = search
description = Saved search which populates Nessus plugins into lookup CSV
search = sourcetype=nessus:plugin | dedup id | table id,xref | inputlookup append=t nessus_mv_xref_lookup | dedup id | mvexpand xref | outputlookup nessus_mv_xref_lookup

[Nessus plugins msft]
disabled = 1
action.email.reportServerEnabled = 0
action.email.useNSSubject = 1
alert.track = 0
auto_summarize.dispatch.earliest_time = -30d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = 0
dispatch.latest_time = now
display.general.type = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = search
request.ui_dispatch_view = search
description = Saved search which populates Nessus plugins into lookup CSV
search = sourcetype=nessus:plugin | dedup id | table id,msft | inputlookup append=t nessus_mv_msft_lookup | dedup id | mvexpand msft | outputlookup nessus_mv_msft_lookup

[Nessus plugins mskb]
disabled = 1
action.email.reportServerEnabled = 0
action.email.useNSSubject = 1
alert.track = 0
auto_summarize.dispatch.earliest_time = -30d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = 0
dispatch.latest_time = now
display.general.type = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = search
request.ui_dispatch_view = search
description = Saved search which populates Nessus plugins into lookup CSV
search = sourcetype=nessus:plugin | dedup id | table id,mskb | inputlookup append=t nessus_mv_mskb_lookup | dedup id | mvexpand mskb | outputlookup nessus_mv_mskb_lookup

[Nessus plugins cert]
disabled = 1
action.email.reportServerEnabled = 0
action.email.useNSSubject = 1
alert.track = 0
auto_summarize.dispatch.earliest_time = -30d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = 0
dispatch.latest_time = now
display.general.type = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = search
request.ui_dispatch_view = search
description = Saved search which populates Nessus plugins into lookup CSV
search = sourcetype=nessus:plugin | dedup id | table id,cert | inputlookup append=t nessus_mv_cert_lookup | dedup id | mvexpand cert | outputlookup nessus_mv_cert_lookup

[Nessus plugins see_also]
disabled = 1
action.email.reportServerEnabled = 0
action.email.useNSSubject = 1
alert.track = 0
auto_summarize.dispatch.earliest_time = -30d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = 0
dispatch.latest_time = now
display.general.type = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = search
request.ui_dispatch_view = search
description = Saved search which populates Nessus plugins into lookup CSV
search = sourcetype=nessus:plugin | dedup id | table id,see_also | inputlookup append=t nessus_mv_see_also_lookup | dedup id | mvexpand see_also | outputlookup nessus_mv_see_also_lookup[Nessus plugins]
request.ui_dispatch_view = 

[Nessus plugins bugtraq]
request.ui_dispatch_view = 

[Nessus plugins cert]
request.ui_dispatch_view = 

[Nessus plugins cpe]
request.ui_dispatch_view = 

[Nessus plugins cve]
request.ui_dispatch_view = 

[Nessus plugins msft]
request.ui_dispatch_view = 

[Nessus plugins mskb]
request.ui_dispatch_view = 

[Nessus plugins osvdb]
request.ui_dispatch_view = 

[Nessus plugins see_also]
request.ui_dispatch_view = 

[Nessus plugins xref]
request.ui_dispatch_view = 

###### Correlation Searches ######
## per SPL-98457 - moving "| table" in front of ppf lookup
[Threat - Threat List Activity - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Threat Activity Detected
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = threat
action.notable.param.severity         = low
action.notable.param.rule_title       = Threat Activity Detected ($threat_match_value$)
action.notable.param.rule_description = Threat activity ($threat_match_value$) was discovered in the "$threat_match_field$" field based on threat intelligence available in the $threat_collection$ collection
action.notable.param.nes_fields       = threat_match_field,threat_match_value
action.notable.param.drilldown_name   = View all threat activity involving $threat_match_field$="$threat_match_value$"
action.notable.param.drilldown_search = | from datamodel:"Threat_Intelligence"."Threat_Activity" | search threat_match_field="$threat_match_field$" threat_match_value="$threat_match_value$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
## risk_object_type, risk_object, and risk_score set via search language
## they are also set below for UI consistency
action.risk.param._risk_object        = src
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 40
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = threat_match_field,threat_match_value
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 10 * * * *
description                           = Alerts when any activity matching threat intelligence is detected.
disabled                              = True
dispatch.earliest_time                = -65m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | from datamodel:"Threat_Intelligence"."Threat_Activity" | dedup threat_match_field,threat_match_value | `get_event_id` | table _raw,event_id,source,src,dest,threat*,weight | rename weight as record_weight | `per_panel_filter("ppf_threat_activity","threat_match_field,threat_match_value")` | `get_threat_attribution(threat_key)` | rename source_* as threat_source_*,description as threat_description | eval risk_score=case(isnum(record_weight), record_weight, isnum(weight), weight, 1=1, null())  | fields - *time | eval risk_object_type=case(threat_match_field="query" OR threat_match_field=="src" OR threat_match_field=="dest","system",threat_match_field=="src_user" OR threat_match_field=="user","user",1=1,"other") | eval risk_object=threat_match_value

###### Key Indicator Searches ######
[Threat Activity - Unique Categories]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Threat Categories
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | from datamodel:"Threat_Intelligence"."Threat_Activity"
action.keyindicator.drilldown_uri             = search?earliest=-48h%40h&latest=now&q=%7C%20from%20datamodel%3A%22Threat_Intelligence%22.%22Threat_Activity%22
action.keyindicator.group.0.name              = threat_activity
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Threat Categories
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count from datamodel=Threat_Intelligence.Threat_Activity where earliest=-24h@h latest=+0s by Threat_Activity.threat_key | `drop_dm_object_name("Threat_Activity")` | `get_threat_attribution(threat_key)` | stats dc(threat_category) as current_count | appendcols [| tstats `summariesonly` count from datamodel=Threat_Intelligence.Threat_Activity where earliest=-48h@h latest=-24h@h by Threat_Activity.threat_key | `drop_dm_object_name("Threat_Activity")` | `get_threat_attribution(threat_key)` | stats dc(threat_category) as historical_count] | `get_delta`

[Threat Activity - Unique Collections]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Threat Collections
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | from datamodel:"Threat_Intelligence"."Threat_Activity"
action.keyindicator.drilldown_uri             = search?earliest=-48h%40h&latest=now&q=%7C%20from%20datamodel%3A%22Threat_Intelligence%22.%22Threat_Activity%22
action.keyindicator.group.0.name              = threat_activity
action.keyindicator.group.0.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Threat Collections
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Threat_Activity.threat_collection) as current_count from datamodel=Threat_Intelligence.Threat_Activity where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Threat_Activity.threat_collection) as historical_count from datamodel=Threat_Intelligence.Threat_Activity where earliest=-48h@h latest=-24h@h] | `get_delta`

[Threat Activity - Unique Matches]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Threat Matches
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | from datamodel:"Threat_Intelligence"."Threat_Activity"
action.keyindicator.drilldown_uri             = search?earliest=-48h%40h&latest=now&q=%7C%20from%20datamodel%3A%22Threat_Intelligence%22.%22Threat_Activity%22
action.keyindicator.group.0.name              = threat_activity
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Threat Matches
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count from datamodel=Threat_Intelligence.Threat_Activity where earliest=-24h@h latest=+0s by Threat_Activity.threat_match_field,Threat_Activity.threat_match_value | stats count as current_count | appendcols [| tstats `summariesonly` count from datamodel=Threat_Intelligence.Threat_Activity where earliest=-48h@h latest=-24h@h by Threat_Activity.threat_match_field,Threat_Activity.threat_match_value | stats count as historical_count] | `get_delta`

[Threat Activity - Unique Sources]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Threat Sources
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | from datamodel:"Threat_Intelligence"."Threat_Activity"
action.keyindicator.drilldown_uri             = search?earliest=-48h%40h&latest=now&q=%7C%20from%20datamodel%3A%22Threat_Intelligence%22.%22Threat_Activity%22
action.keyindicator.group.0.name              = threat_activity
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Threat Sources
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Threat_Activity.threat_key) as current_count from datamodel=Threat_Intelligence.Threat_Activity where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Threat_Activity.threat_key) as historical_count from datamodel=Threat_Intelligence.Threat_Activity where earliest=-48h@h latest=-24h@h] | `get_delta`

[Threat Activity - Total Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Threat Activity
action.keyindicator.subtitle                  = Total Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.group.0.name              = threat_activity
action.keyindicator.group.0.order             = 4
# | from datamodel:"Threat_Intelligence"."Threat_Activity"
action.keyindicator.drilldown_uri             = search?earliest=-48h%40h&latest=now&q=%7C%20from%20datamodel%3A%22Threat_Intelligence%22.%22Threat_Activity%22
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Threat Activity Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count as current_count from datamodel=Threat_Intelligence.Threat_Activity where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Threat_Intelligence.Threat_Activity where earliest=-48h@h latest=-24h@h] | `get_delta`

###### Lookup Generating Searches ######
[Threat - Threat Intelligence By Certificate Common Name - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel` |`exclude_disabled_entries` | rex field=certificate_issuer "CN\s*=(?<_certificate_issuer_common_name>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | rex field=certificate_subject "CN\s*=(?<_certificate_subject_common_name>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | eval certificate_common_name=if(isnull(certificate_issuer_common_name),_certificate_issuer_common_name,certificate_issuer_common_name) | eval certificate_subject_common_name=if(isnull(certificate_subject_common_name),_certificate_subject_common_name,certificate_subject_common_name) | `mvappend_field(certificate_common_name,certificate_subject_common_name)` | `threatintel_outputlookup(certificate_common_name)`

[Threat - Threat Intelligence By Certificate Common Name Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel` | `exclude_disabled_entries` | rex field=certificate_issuer "CN\s*=(?<_certificate_issuer_common_name>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | rex field=certificate_subject "CN\s*=(?<_certificate_subject_common_name>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | eval certificate_common_name=if(isnull(certificate_issuer_common_name),_certificate_issuer_common_name,certificate_issuer_common_name) | eval certificate_subject_common_name=if(isnull(certificate_subject_common_name),_certificate_subject_common_name,certificate_subject_common_name) | `mvappend_field(certificate_common_name,certificate_subject_common_name)` | `threatintel_outputlookup_wildcard(certificate_common_name)`

[Threat - Threat Intelligence By Certificate Organization - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel` | `exclude_disabled_entries` | rex field=certificate_issuer "O\s*=(?<_certificate_issuer_org>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | rex field=certificate_subject "O\s*=(?<_certificate_subject_org>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | eval certificate_organization=if(isnull(certificate_issuer_organization),_certificate_issuer_org,certificate_issuer_organization) | eval certificate_subject_organization=if(isnull(certificate_subject_organization),_certificate_subject_org,certificate_subject_organization) | `mvappend_field(certificate_organization,certificate_subject_organization)` | `threatintel_outputlookup(certificate_organization)`

[Threat - Threat Intelligence By Certificate Organization Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel` | `exclude_disabled_entries` | rex field=certificate_issuer "O\s*=(?<_certificate_issuer_org>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | rex field=certificate_subject "O\s*=(?<_certificate_subject_org>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | eval certificate_organization=if(isnull(certificate_issuer_organization),_certificate_issuer_org,certificate_issuer_organization) | eval certificate_subject_organization=if(isnull(certificate_subject_organization),_certificate_subject_org,certificate_subject_organization) | `mvappend_field(certificate_organization,certificate_subject_organization)` | `threatintel_outputlookup_wildcard(certificate_organization)`

[Threat - Threat Intelligence By Certificate Serial - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel`  | `exclude_disabled_entries` | `mvappend_field(certificate_serial_clean,certificate_serial_dec)` | rename certificate_serial_clean as certificate_serial | `threatintel_outputlookup(certificate_serial)`

[Threat - Threat Intelligence By Certificate Unit - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel`  | `exclude_disabled_entries` | rex field=certificate_issuer "OU\s*=(?<_certificate_issuer_unit>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | rex field=certificate_subject "OU\s*=(?<_certificate_subject_unit>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | eval certificate_unit=if(isnull(certificate_issuer_unit),_certificate_issuer_unit,certificate_issuer_unit) | eval certificate_subject_unit=if(isnull(certificate_subject_unit),_certificate_subject_unit,certificate_subject_unit) | `mvappend_field(certificate_unit,certificate_subject_unit)` | `threatintel_outputlookup(certificate_unit)`

[Threat - Threat Intelligence By Certificate Unit Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel` | `exclude_disabled_entries` | rex field=certificate_issuer "OU\s*=(?<_certificate_issuer_unit>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | rex field=certificate_subject "OU\s*=(?<_certificate_subject_unit>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | eval certificate_unit=if(isnull(certificate_issuer_unit),_certificate_issuer_unit,certificate_issuer_unit) | eval certificate_subject_unit=if(isnull(certificate_subject_unit),_certificate_subject_unit,certificate_subject_unit) | `mvappend_field(certificate_unit,certificate_subject_unit)` | `threatintel_outputlookup_wildcard(certificate_unit)`

[Threat - Threat Intelligence By CIDR - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel,email_intel,http_intel,ip_intel,process_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel` | `email_intel` | `http_intel` | `ip_intel` | `process_intel` | `exclude_disabled_entries` | `mvappend_field(ip,embedded_ip)` | `mvappend_field(ip,src)` | `mvappend_field(ip,dest)` | `get_threat_download_status` | `threatintel_outputlookup_exclusions` | mvexpand ip | rename ip as cidr,_key as threat_collection_key | dedup cidr,threat_collection_key,threat_key | where isnotnull(cidr) AND match(cidr,"\/[0-9]{1,2}") | fillnull value="X" weight | table cidr,threat_collection,threat_collection_key,threat_key,weight | outputlookup threatintel_by_cidr | stats count

[Threat - Threat Intelligence By Domain - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel,email_intel,http_intel,ip_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel` | `email_intel` | `http_intel` | `ip_intel` | `exclude_disabled_entries` | `mvappend_field(domain,embedded_domain)` | `threatintel_outputlookup(domain)`

[Threat - Threat Intelligence By Email - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel,email_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel` | `exclude_disabled_entries` | rex field=certificate_issuer "(?:E|emailAddress)\s*=(?<_certificate_issuer_email>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | rex field=certificate_subject "(?:E|emailAddress)\s*=(?<_certificate_subject_email>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | eval certificate_issuer_email=if(isnull(certificate_issuer_email),_certificate_issuer_email,certificate_issuer_email) | eval certificate_subject_email=if(isnull(certificate_subject_email),_certificate_subject_email,certificate_subject_email) | `email_intel` | `mvappend_field(src_user,certificate_issuer_email)` | `mvappend_field(src_user,certificate_subject_email)` | rename src_user as email | `threatintel_outputlookup(email)`

[Threat - Threat Intelligence By Email Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel,email_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel` | `exclude_disabled_entries` | rex field=certificate_issuer "(?:E|emailAddress)\s*=(?<_certificate_issuer_email>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | rex field=certificate_subject "(?:E|emailAddress)\s*=(?<_certificate_subject_email>.*?)(?=[,;/]\s*(?:[A-Z]+|emailAddress)\s*=|$)" | eval certificate_issuer_email=if(isnull(certificate_issuer_email),_certificate_issuer_email,certificate_issuer_email) | eval certificate_subject_email=if(isnull(certificate_subject_email),_certificate_subject_email,certificate_subject_email) | `email_intel` | `mvappend_field(src_user,certificate_issuer_email)` | `mvappend_field(src_user,certificate_subject_email)` | rename src_user as email | `threatintel_outputlookup_wildcard(email)`

[Threat - Threat Intelligence By Email Subject - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = email_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `email_intel` | `exclude_disabled_entries` | `threatintel_outputlookup("subject","threatintel_by_email_subject")`

[Threat - Threat Intelligence By Email Subject Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = email_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `email_intel` | `exclude_disabled_entries` | `threatintel_outputlookup_wildcard("subject","threatintel_by_email_subject_wildcard")`

[Threat - Threat Intelligence By File Hash - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel,email_intel,file_intel,service_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel` | `email_intel` | `file_intel` | `service_intel` | `exclude_disabled_entries` | `mvappend_field(file_hash,service_file_hash)` | `mvappend_field(file_hash,service_dll_file_hash)` | `threatintel_outputlookup(file_hash)`

[Threat - Threat Intelligence By File Name - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel,email_intel,file_intel,service_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `email_intel` | `file_intel` | `process_intel` | `exclude_disabled_entries` | `mvappend_field(file_name,process_file_name)` | `threatintel_outputlookup(file_name)`

[Threat - Threat Intelligence By File Name Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel,email_intel,file_intel,service_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `email_intel` | `file_intel` | `process_intel` | `exclude_disabled_entries` | `mvappend_field(file_name,process_file_name)` | `threatintel_outputlookup_wildcard(file_name)`

[Threat - Threat Intelligence By HTTP User Agent - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = http_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `http_intel` | `exclude_disabled_entries` | `threatintel_outputlookup(http_user_agent)`

[Threat - Threat Intelligence By HTTP User Agent Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = http_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `http_intel` | `exclude_disabled_entries` | `threatintel_outputlookup_wildcard(http_user_agent)`

[Threat - Threat Intelligence By Process - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = process_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `process_intel` | `exclude_disabled_entries` | `threatintel_outputlookup(process)`

[Threat - Threat Intelligence By Process Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = process_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `process_intel` | `exclude_disabled_entries` | `threatintel_outputlookup_wildcard(process)`

[Threat - Threat Intelligence By Registry Path - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = registry_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `registry_intel` | `exclude_disabled_entries` | `threatintel_outputlookup(registry_path)`

[Threat - Threat Intelligence By Registry Path Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = registry_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `registry_intel` | `exclude_disabled_entries` | `threatintel_outputlookup_wildcard(registry_path)`

[Threat - Threat Intelligence By Registry Value Name - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = registry_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `registry_intel` | `exclude_disabled_entries` | `threatintel_outputlookup(registry_value_name)`

[Threat - Threat Intelligence By Registry Value Name Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = registry_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `registry_intel` | `exclude_disabled_entries` | `threatintel_outputlookup_wildcard(registry_value_name)`

[Threat - Threat Intelligence By Registry Value Text - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = registry_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `registry_intel` | `exclude_disabled_entries` | `threatintel_outputlookup(registry_value_text)`

[Threat - Threat Intelligence By Registry Value Text Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = registry_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `registry_intel` | `exclude_disabled_entries` | `threatintel_outputlookup_wildcard(registry_value_text)`

[Threat - Threat Intelligence By Service - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = service_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `service_intel` | `exclude_disabled_entries` | `threatintel_outputlookup(service)`

[Threat - Threat Intelligence By Service Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = service_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `service_intel` | `exclude_disabled_entries` | `threatintel_outputlookup_wildcard(service)`

[Threat - Threat Intelligence By System - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = certificate_intel,email_intel,http_intel,ip_intel,process_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `certificate_intel` | `email_intel` | `http_intel` | `ip_intel` | `process_intel` | `exclude_disabled_entries` | `mvappend_field(ip,embedded_ip)` | `mvappend_field(ip,src)` | `mvappend_field(ip,dest)` | `get_threat_download_status` | `threatintel_outputlookup_exclusions` | mvexpand ip | rename ip as system,_key as threat_collection_key | dedup system,threat_collection_key,threat_key | where isnotnull(system) AND NOT match(system,"\/[0-9]{1,2}") | fillnull value="X" weight | table system,threat_collection,threat_collection_key,threat_key,weight | outputlookup threatintel_by_system | stats count

[Threat - Threat Intelligence By URL - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = http_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `http_intel` | `exclude_disabled_entries` | `mvappend_field(url,http_referrer)` | `threatintel_outputlookup(url)`

[Threat - Threat Intelligence By URL Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = http_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `http_intel` | `exclude_disabled_entries` | `mvappend_field(url,http_referrer)` | `threatintel_outputlookup_wildcard(url)`

[Threat - Threat Intelligence By User - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = registry_intel,user_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `registry_intel` | `user_intel` | `exclude_disabled_entries` | `threatintel_outputlookup(user)`

[Threat - Threat Intelligence By User Wildcard - Lookup Gen]
action.threat_outputlookup             = 1
action.threat_outputlookup.collections = registry_intel,user_intel
enableSched                            = 0
is_visible                             = false
request.ui_dispatch_app                = SplunkEnterpriseSecuritySuite
search                                 = | `registry_intel` | `user_intel` | `exclude_disabled_entries` | `threatintel_outputlookup_wildcard(user)`

###### Threat Intelligence Retention #####
[Threat - Certificate Threat Intelligence Retention - Lookup Gen]
cron_schedule                        = 0 3 * * *
disabled                             = true
dispatch.earliest_time               = 0
dispatch.latest_time                 = +0s
enableSched                          = true
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
schedule_window                      = 20
search                               = | `filter_threatintel_collection("certificate_intel")` | `set_threat_intel_meta_now("certificate_intel")`

[Threat - Email Threat Intelligence Retention - Lookup Gen]
cron_schedule                        = 5 3 * * *
disabled                             = true
dispatch.earliest_time               = 0
dispatch.latest_time                 = +0s
enableSched                          = true
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
schedule_window                      = 20
search                               = | `filter_threatintel_collection("email_intel")` | `set_threat_intel_meta_now("email_intel")`

[Threat - File Threat Intelligence Retention - Lookup Gen]
cron_schedule                        = 10 3 * * *
disabled                             = true
dispatch.earliest_time               = 0
dispatch.latest_time                 = +0s
enableSched                          = true
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
schedule_window                      = 20
search                               = | `filter_threatintel_collection("file_intel")` | `set_threat_intel_meta_now("file_intel")`

[Threat - HTTP Threat Intelligence Retention - Lookup Gen]
cron_schedule                        = 15 3 * * *
disabled                             = true
dispatch.earliest_time               = 0
dispatch.latest_time                 = +0s
enableSched                          = true
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
schedule_window                      = 20
search                               = | `filter_threatintel_collection("http_intel")` | `set_threat_intel_meta_now("http_intel")`

[Threat - IP Intelligence Retention - Lookup Gen]
cron_schedule                        = 20 3 * * *
disabled                             = true
dispatch.earliest_time               = 0
dispatch.latest_time                 = +0s
enableSched                          = true
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
schedule_window                      = 20
search                               = | `filter_threatintel_collection("ip_intel")` | `set_threat_intel_meta_now("ip_intel")`

[Threat - Process Threat Intelligence Retention - Lookup Gen]
cron_schedule                        = 25 3 * * *
disabled                             = true
dispatch.earliest_time               = 0
dispatch.latest_time                 = +0s
enableSched                          = true
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
schedule_window                      = 20
search                               = | `filter_threatintel_collection("process_intel")` | `set_threat_intel_meta_now("process_intel")`

[Threat - Registry Threat Intelligence Retention - Lookup Gen]
cron_schedule                        = 30 3 * * *
disabled                             = true
dispatch.earliest_time               = 0
dispatch.latest_time                 = +0s
enableSched                          = true
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
schedule_window                      = 20
search                               = | `filter_threatintel_collection("registry_intel")` | `set_threat_intel_meta_now("registry_intel")`

[Threat - Service Threat Intelligence Retention - Lookup Gen]
cron_schedule                        = 35 3 * * *
disabled                             = true
dispatch.earliest_time               = 0
dispatch.latest_time                 = +0s
enableSched                          = true
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
schedule_window                      = 20
search                               = | `filter_threatintel_collection("service_intel")` | `set_threat_intel_meta_now("service_intel")`

[Threat - User Threat Intelligence Retention - Lookup Gen]
cron_schedule                        = 40 3 * * *
disabled                             = true
dispatch.earliest_time               = 0
dispatch.latest_time                 = +0s
enableSched                          = true
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
schedule_window                      = 20
search                               = | `filter_threatintel_collection("user_intel")` | `set_threat_intel_meta_now("user_intel")`

###### Report Searches ######
[Audit - Failed Threatlist Downloads]
action.email.reportServerEnabled     = 0
action.output_message                = 1
action.output_message.param.name     = HEALTH_CHECK:FAILED_THREAT_DOWNLOAD
action.output_message.param.msgid    = healthcheck_failed_threat_download
action.output_message.param.fields   = info_sid,stanza,host,_time,status
action.output_message.param.purge    = 1
alert.digest_mode                    = true
alert.track                          = 0
counttype                            = number of events
cron_schedule                        = 0 */3 * * *
dispatch.earliest_time               = -3h@m
dispatch.latest_time                 = +0s
display.general.enablePreview        = 1
display.general.timeRangePicker.show = true
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
enableSched                          = 1
quantity                             = 0
relation                             = greater than
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
schedule_window                      = auto
search                               = index=_internal sourcetype=threatintel:download file="threatlist.py:download_*" NOT (status="*starting" OR status="retrying download" OR status="threat list downloaded" OR status="Retrieved document from TAXII feed" OR status="Retrieved documents from TAXII feed") | stats latest(status) as status, latest(_time) as _time by stanza, host, url

[Threat Activity - Most Active Threats Collections] 
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = true
display.general.type                      = statistics
display.statistics.drilldown              = row
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.show               = 0
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` values(source) as search,values(Threat_Activity.threat_collection_key) as threat_collection_key,count from datamodel=Threat_Intelligence.Threat_Activity where NOT [| `ppf_subsearch_dm("ppf_threat_activity","threat_match_field,threat_match_value",now(),"Threat_Activity")`] by _time,Threat_Activity.threat_collection span=1h | `drop_dm_object_name("Threat_Activity")` | stats values(search) as search,sparkline(sum(count),1h) as sparkline,dc(threat_collection_key) as dc(artifacts),sum(count) as count by threat_collection | rex max_match=10 field=search "Threat\s*-\s*(?<friendly_search>.*)(?:\s*-\s*Threat\s+Gen)" | rename friendly_search as search | sort - count

[Threat Activity - Most Active Threat Sources] 
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = true
display.general.type                      = statistics
display.statistics.drilldown              = row
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.show               = 0
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` count from datamodel=Threat_Intelligence.Threat_Activity where NOT [| `ppf_subsearch_dm("ppf_threat_activity","threat_match_field,threat_match_value",now(),"Threat_Activity")`] by Threat_Activity.threat_key | `drop_dm_object_name("Threat_Activity")` | `get_threat_attribution("threat_key")` | stats sum(count) as count by threat_key,source_id,source_path,source_type | sort 100 - count

[Threat Activity - Systems Impacted By Multiple Threats]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = true
display.general.type                      = statistics
display.statistics.drilldown              = row
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.show               = 0
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` values(Threat_Activity.src) as src,values(Threat_Activity.dest) as dest,count from datamodel=Threat_Intelligence.Threat_Activity where NOT [| `ppf_subsearch_dm("ppf_threat_activity","threat_match_field,threat_match_value",now(),"Threat_Activity")`] by Threat_Activity.threat_match_field,Threat_Activity.threat_match_value,Threat_Activity.threat_key | `drop_dm_object_name("Threat_Activity")` | eval src=if(threat_match_field=="src",null(),src) | eval dest=if(threat_match_field=="dest",null(),dest) | eval system=mvappend(src,NULL,dest) | stats dc(threat_key) as dc(threat) by system | search system!="...truncated..." system!="unknown" "dc(threat)">1 | sort 100 - dc(threat)

[Threat Activity - Threat Activity By Threat Category]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` count from datamodel=Threat_Intelligence.Threat_Activity where NOT [| `ppf_subsearch_dm("ppf_threat_activity","threat_match_field,threat_match_value",now(),"Threat_Activity")`] by Threat_Activity.threat_key | `drop_dm_object_name("Threat_Activity")` | `get_threat_attribution(threat_key)` | stats sum(count) as count by threat_category | sort 10 - count

[Threat Activity - Threat Activity By Threat Group]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` count from datamodel=Threat_Intelligence.Threat_Activity where NOT [| `ppf_subsearch_dm("ppf_threat_activity","threat_match_field,threat_match_value",now(),"Threat_Activity")`] by Threat_Activity.threat_key | `drop_dm_object_name("Threat_Activity")` | `get_threat_attribution(threat_key)` | stats sum(count) as count by threat_group | sort 10 - count

[Threat Activity - Threat Activity Details] 
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = true
display.general.timeRangePicker.show      = true
display.general.type                      = statistics
display.statistics.drilldown              = row
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.show               = 0
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` latest(_time) as _time,values(Threat_Activity.orig_sourcetype) as sourcetype,values(Threat_Activity.src) as src,values(Threat_Activity.dest) as dest from datamodel=Threat_Intelligence.Threat_Activity where NOT [| `ppf_subsearch_dm("ppf_threat_activity","threat_match_field,threat_match_value",now(),"Threat_Activity")`] by Threat_Activity.threat_collection,Threat_Activity.threat_match_field,Threat_Activity.threat_match_value,Threat_Activity.threat_key | `drop_dm_object_name("Threat_Activity")` | `get_threat_attribution("threat_key")` | `per_panel_filter("ppf_threat_activity","threat_match_field,threat_match_value")` | rename ppf_filter as filter | sort - filter,_time | table _time,threat_match_field,threat_match_value,filter,sourcetype,src,dest,threat_collection,threat_group,threat_category

[Threat Activity - Threat Activity Over Time] 
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
dispatchAs                                = user
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = true
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | `tstats` count from datamodel=Threat_Intelligence.Threat_Activity where NOT [| `ppf_subsearch_dm("ppf_threat_activity","threat_match_field,threat_match_value",now(),"Threat_Activity")`] by _time,Threat_Activity.threat_collection span=10m | timechart count by Threat_Activity.threat_collection | `drop_dm_object_name("Threat_Activity")`

[Threat Activity - Threats Impacting Multiple Systems]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = true
display.general.type                      = statistics
display.statistics.drilldown              = row
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.show               = 0
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` values(Threat_Activity.src) as src,values(Threat_Activity.dest) as dest,count from datamodel=Threat_Intelligence.Threat_Activity where NOT [| `ppf_subsearch_dm("ppf_threat_activity","threat_match_field,threat_match_value",now(),"Threat_Activity")`] by Threat_Activity.threat_match_field,Threat_Activity.threat_match_value,Threat_Activity.threat_key | `drop_dm_object_name("Threat_Activity")` | `get_threat_attribution(threat_key)` | eval src=if(threat_match_field=="src",null(),src) | eval dest=if(threat_match_field=="dest",null(),dest) | eval system=mvappend(src,NULL,dest) | stats dc(system) by source_path | search "dc(system)">1 | sort 100 - dc(system)

###### Threat (Match) Generating Searches ######
[Threat - Certificate Common Name Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = certificate_common_name,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = certificate_common_name
alert.track                          = false
cron_schedule                        = 0,30 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `tstats` values(sourcetype),values(All_Certificates.src),values(All_Certificates.dest) from datamodel=Certificates.All_Certificates by All_Certificates.SSL.ssl_issuer_common_name | eval certificate_common_name='All_Certificates.SSL.ssl_issuer_common_name' | eval threat_match_field="ssl_issuer_common_name" | `tstats` append=true values(sourcetype),values(All_Certificates.src),values(All_Certificates.dest) from datamodel=Certificates.All_Certificates by All_Certificates.SSL.ssl_subject_common_name | eval certificate_common_name=if(isnull(certificate_common_name),'All_Certificates.SSL.ssl_subject_common_name',certificate_common_name) | eval threat_match_field=if(isnull(threat_match_field),"ssl_subject_common_name",threat_match_field) | stats values(sourcetype) as sourcetype,values(All_Certificates.src) as src,values(All_Certificates.dest) as dest by certificate_common_name,threat_match_field | lookup update=true threatintel_by_certificate_common_name certificate_common_name OUTPUT | lookup update=true threatintel_by_certificate_common_name_wildcard certificate_common_name OUTPUTNEW | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - Certificate Organization Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = certificate_organization,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = certificate_organization
alert.track                          = false
cron_schedule                        = 5,35 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `tstats` values(sourcetype),values(All_Certificates.src),values(All_Certificates.dest) from datamodel=Certificates.All_Certificates by All_Certificates.SSL.ssl_issuer_organization | eval certificate_organization='All_Certificates.SSL.ssl_issuer_organization' | eval threat_match_field="ssl_issuer_organization" | `tstats` append=true values(sourcetype),values(All_Certificates.src),values(All_Certificates.dest) from datamodel=Certificates.All_Certificates by All_Certificates.SSL.ssl_subject_organization | eval certificate_organization=if(isnull(certificate_organization),'All_Certificates.SSL.ssl_subject_organization',certificate_organization) | eval threat_match_field=if(isnull(threat_match_field),"ssl_subject_organization",threat_match_field) | stats values(sourcetype) as sourcetype,values(All_Certificates.src) as src,values(All_Certificates.dest) as dest by certificate_organization,threat_match_field | lookup update=true threatintel_by_certificate_organization certificate_organization OUTPUT | lookup update=true threatintel_by_certificate_organization_wildcard certificate_organization OUTPUTNEW | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - Certificate Serial Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = certificate_serial,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = certificate_serial
alert.track                          = false
cron_schedule                        = 10,40 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | tstats `summariesonly` values(sourcetype) as sourcetype,values(All_Certificates.src) as src,values(All_Certificates.dest) as dest from datamodel=Certificates.All_Certificates where nodename="All_Certificates.SSL" by All_Certificates.SSL.ssl_serial | rename All_Certificates.SSL.ssl_serial as certificate_serial | eval threat_match_value=certificate_serial | `get_certificate_serial` | lookup update=true threatintel_by_certificate_serial certificate_serial as certificate_serial_clean OUTPUT | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - Certificate Unit Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = certificate_unit,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = certificate_unit
alert.track                          = false
cron_schedule                        = 15,45 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `tstats` values(sourcetype),values(All_Certificates.src),values(All_Certificates.dest) from datamodel=Certificates.All_Certificates by All_Certificates.SSL.ssl_issuer_unit | eval certificate_unit='All_Certificates.SSL.ssl_issuer_unit' | eval threat_match_field="ssl_issuer_unit" | `tstats` append=true values(sourcetype),values(All_Certificates.src),values(All_Certificates.dest) from datamodel=Certificates.All_Certificates by All_Certificates.SSL.ssl_subject_unit | eval certificate_unit=if(isnull(certificate_unit),'All_Certificates.SSL.ssl_subject_unit',certificate_unit) | eval threat_match_field=if(isnull(threat_match_field),"ssl_subject_unit",threat_match_field) | stats values(sourcetype) as sourcetype,values(All_Certificates.src) as src,values(All_Certificates.dest) as dest by certificate_unit,threat_match_field | lookup update=true threatintel_by_certificate_unit certificate_unit OUTPUT | lookup update=true threatintel_by_certificate_unit_wildcard certificate_unit OUTPUTNEW | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - Email Address Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = email,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = email
alert.track                          = false
cron_schedule                        = 20,50 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `tstats` values(sourcetype),values(All_Certificates.src),values(All_Certificates.dest) from datamodel=Certificates.All_Certificates by All_Certificates.SSL.ssl_issuer_email | eval email='All_Certificates.SSL.ssl_issuer_email' | eval threat_match_field="ssl_issuer_email" | `tstats` append=true values(sourcetype),values(All_Certificates.src),values(All_Certificates.dest) from datamodel=Certificates.All_Certificates by All_Certificates.SSL.ssl_subject_email | eval email=if(isnull(email),'All_Certificates.SSL.ssl_subject_email',email) | eval threat_match_field=if(isnull(threat_match_field),"ssl_subject_email",threat_match_field) | `sistats_values_rename(All_Certificates.src,src)` | `sistats_values_rename(All_Certificates.dest,dest)` | `tstats` append=true values(sourcetype),values(All_Email.src),values(All_Email.dest) from datamodel=Email.All_Email by All_Email.src_user | eval email=if(isnull(email),'All_Email.src_user',email) | eval threat_match_field=if(isnull(threat_match_field),"src_user",threat_match_field) | `tstats` append=true values(sourcetype),values(All_Email.src),values(All_Email.dest) from datamodel=Email.All_Email by All_Email.recipient | eval email=if(isnull(email),'All_Email.recipient',email) | eval threat_match_field=if(isnull(threat_match_field),"recipient",threat_match_field) | `sistats_values_rename(All_Email.src,src)` | `sistats_values_rename(All_Email.dest,dest)` | stats values(sourcetype) as sourcetype,values(src) as src,values(dest) as dest by email,threat_match_field | extract cim_email_domain | `truncate_domain_dedup(email_domain,truncated_email_domain)` | lookup update=true threatintel_by_email email OUTPUT | lookup update=true threatintel_by_email_wildcard email OUTPUTNEW | lookup update=true threatintel_by_domain domain as email_domain OUTPUTNEW | lookup update=true threatintel_by_domain domain as truncated_email_domain OUTPUTNEW | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches` | table sourcetype,src,dest,email,threat*,weight

[Threat - Email Subject Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = subject,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = subject
alert.track                          = false
cron_schedule                        = 25,55 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | tstats `summariesonly` values(sourcetype) as sourcetype,values(All_Email.src) as src,values(All_Email.dest) as dest from datamodel=Email.All_Email by All_Email.subject | `drop_dm_object_name("All_Email")` | lookup update=true threatintel_by_email_subject subject OUTPUT | lookup update=true threatintel_by_email_subject_wildcard subject OUTPUTNEW | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - File Hash Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = file_hash,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = file_hash
alert.track                          = false
cron_schedule                        = 0,30 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `tstats` values(sourcetype),values(All_Certificates.src),values(All_Certificates.dest) from datamodel=Certificates.All_Certificates by All_Certificates.SSL.ssl_hash | eval file_hash='All_Certificates.SSL.ssl_hash' | eval threat_match_field="ssl_hash" | `sistats_values_rename(All_Certificates.src,src)` | `sistats_values_rename(All_Certificates.dest,dest)` | `tstats` append=true values(sourcetype),values(Filesystem.dest) from datamodel=Endpoint.Filesystem by Filesystem.file_hash | eval file_hash=if(isnull(file_hash),'Filesystem.file_hash',file_hash) | `sistats_values_rename(Filesystem.dest,dest)` | `tstats` append=true values(sourcetype),values(All_Email.src),values(All_Email.dest) from datamodel=Email.All_Email by All_Email.file_hash | eval file_hash=if(isnull(file_hash),'All_Email.file_hash',file_hash) | `sistats_values_rename(All_Email.src,src)` | `sistats_values_rename(All_Email.dest,dest)` | `tstats` append=true values(sourcetype),values(Malware_Attacks.src),values(Malware_Attacks.dest) from datamodel=Malware.Malware_Attacks by Malware_Attacks.file_hash | eval file_hash=if(isnull(file_hash),'Malware_Attacks.file_hash',file_hash) | `sistats_values_rename(Malware_Attacks.src,src)` | `sistats_values_rename(Malware_Attacks.dest,dest)` | `tstats` append=true values(sourcetype),values(Updates.src),values(Updates.dest) from datamodel=Updates.Updates by Updates.file_hash | eval file_hash=if(isnull(file_hash),'Updates.file_hash',file_hash) | eval threat_match_field=if(isnull(threat_match_field),"file_hash",threat_match_field) | `sistats_values_rename(Updates.src,src)` | `sistats_values_rename(Updates.dest,dest)` | stats values(sourcetype) as sourcetype,values(src) as src,values(dest) as dest by file_hash,threat_match_field | lookup update=true threatintel_by_file_hash file_hash OUTPUT | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - File Name Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = file_name,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = file_name
alert.track                          = false
cron_schedule                        = 5,35 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `tstats` values(sourcetype),values(Filesystem.dest) from datamodel=Endpoint.Filesystem by Filesystem.file_name | eval file_name=if(isnull(file_name),'Filesystem.file_name',file_name) | `sistats_values_rename(Filesystem.dest,dest)` | `tstats` append=true values(sourcetype),values(All_Email.src),values(All_Email.dest) from datamodel=Email.All_Email by All_Email.file_name | eval file_name=if(isnull(file_name),'All_Email.file_name',file_name) | `sistats_values_rename(All_Email.src,src)` | `sistats_values_rename(All_Email.dest,dest)` | `tstats` append=true values(sourcetype),values(Malware_Attacks.src),values(Malware_Attacks.dest) from datamodel=Malware.Malware_Attacks by Malware_Attacks.file_name | eval file_name=if(isnull(file_name),'Malware_Attacks.file_name',file_name) | `sistats_values_rename(Malware_Attacks.src,src)` | `sistats_values_rename(Malware_Attacks.dest,dest)` | `tstats` append=true values(sourcetype),values(Updates.src),values(Updates.dest) from datamodel=Updates.Updates by Updates.file_name | eval file_name=if(isnull(file_name),'Updates.file_name',file_name) | eval threat_match_field=if(isnull(threat_match_field),"file_name",threat_match_field) | `sistats_values_rename(Updates.src,src)` | `sistats_values_rename(Updates.dest,dest)` | stats values(sourcetype) as sourcetype,values(src) as src,values(dest) as dest by file_name,threat_match_field | lookup update=true threatintel_by_file_name file_name OUTPUT | lookup update=true threatintel_by_file_name_wildcard file_name OUTPUTNEW | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - HTTP User Agent Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = http_user_agent,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = http_user_agent
alert.track                          = false
cron_schedule                        = 10,40 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | tstats `summariesonly` values(sourcetype) as sourcetype,values(Web.src) as src,values(Web.dest) as dest from datamodel=Web.Web by Web.http_user_agent | `drop_dm_object_name("Web")` | lookup update=true threatintel_by_http_user_agent http_user_agent OUTPUT | lookup update=true threatintel_by_http_user_agent_wildcard http_user_agent OUTPUTNEW | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - Network Resolution Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = query,answer,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
## threat_match_field and threat_match_value set via eval
#action.threat_activity._threat_match =
alert.track                          = false
cron_schedule                        = 15,45 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `tstats` values(sourcetype),values(DNS.src),values(DNS.dest) from datamodel=Network_Resolution.DNS by DNS.query,DNS.answer | eval query='DNS.query' | eval answer='DNS.answer' | `tstats` append=true values(sourcetype) from datamodel=Domain_Analysis.All_Domains by All_Domains.domain,All_Domains.resolved_domain | eval query=if(isnull(query),'All_Domains.domain',query) | eval answer=if(isnull(answer),'All_Domains.resolved_domain',answer) | stats values(sourcetype) as sourcetype,values(DNS.src) as src,values(DNS.dest) as dest by query,answer | `threatintel_multilookup(query)` | `threatintel_multilookup(answer)` | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches` | table sourcetype,src,dest,query,answer,threat*,weight

[Threat - Process Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = process,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = process
alert.track                          = false
cron_schedule                        = 20,50 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | tstats `summariesonly` values(sourcetype) as sourcetype,values(Processes.dest) as dest from datamodel=Endpoint.Processes by Processes.process_name | rename Processes.process_name as process | lookup update=true threatintel_by_process process OUTPUT | lookup update=true threatintel_by_process_wildcard process OUTPUTNEW | lookup update=true threatintel_by_file_name file_name as process OUTPUTNEW | lookup update=true threatintel_by_file_name_wildcard file_name as process OUTPUTNEW | search threat_collection_key=* | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - Registry Path Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = registry_path,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = registry_path
alert.track                          = false
cron_schedule                        = 25,55 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = sourcetype=WinRegistry | stats values(sourcetype) as sourcetype,values(dest) as dest by registry_path | lookup update=true threatintel_by_registry_path registry_path OUTPUT | lookup update=true threatintel_by_registry_path_wildcard registry_path OUTPUTNEW | search threat_collection_key=* | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - Registry Value Name Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = registry_value_name,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = registry_value_name
alert.track                          = false
cron_schedule                        = 0,30 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = sourcetype=WinRegistry | stats values(sourcetype) as sourcetype,values(dest) as dest by registry_value_data | lookup update=true threatintel_by_registry_value_name registry_value_name OUTPUT | lookup update=true threatintel_by_registry_value_name_wildcard registry_value_name OUTPUTNEW | search threat_collection_key=* | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - Registry Value Text Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = registry_value_text,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = registry_value_text
alert.track                          = false
cron_schedule                        = 5,35 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = sourcetype=WinRegistry | stats values(sourcetype) as sourcetype,values(dest) as dest by registry_value_data | rename registry_value_data as registry_value_text | lookup update=true threatintel_by_registry_value_text registry_value_text OUTPUT | lookup update=true threatintel_by_registry_value_text_wildcard registry_value_text OUTPUTNEW | search threat_collection_key=* | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - Service Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = service,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = service
alert.track                          = false
cron_schedule                        = 10,40 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | tstats `summariesonly` values(sourcetype) as sourcetype,values(Services.dest) as dest from datamodel=Endpoint.Services by Services.service | rename Services.service as service | lookup update=true threatintel_by_service service OUTPUT | lookup update=true threatintel_by_service_wildcard service OUTPUTNEW | search threat_collection_key=* | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - Source And Destination Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = src,dest,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
## threat_match_field and threat_match_value set via eval
#action.threat_activity._threat_match =
alert.track                          = false
cron_schedule                        = 15,45 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `src_dest_tstats("allowed")` | `threatintel_multilookup(src)` | `threatintel_multilookup(dest)` | search threat_collection_key=* | fields - count | `zipexpand_threat_matches` | fields sourcetype,src,dest,threat*,weight

[Threat - URL Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = url,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = url
alert.track                          = false
cron_schedule                        = 20,50 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `tstats` values(sourcetype) as sourcetype,values(Web.src),values(Web.dest) from datamodel=Web.Web by Web.http_referrer | eval url='Web.http_referrer' | eval threat_match_field="http_referrer" | `tstats` append=true values(sourcetype) as sourcetype,values(Web.src),values(Web.dest) from datamodel=Web.Web by Web.url | eval url=if(isnull(url),'Web.url',url) | eval threat_match_field=if(isnull(threat_match_field),"url",threat_match_field) | stats values(sourcetype) as sourcetype,values(Web.src) as src,values(Web.dest) as dest by url,threat_match_field | extract domain_from_url | `threatintel_url_lookup(url)` | `threatintel_domain_lookup(url_domain)` | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches`

[Threat - User Matches - Threat Gen]
action.email.sendresults             = 0
alert.digest_mode                    = 1
alert.suppress                       = 1
alert.suppress.fields                = user,threat_collection_key
alert.suppress.period                = 86300s
action.threat_activity               = 1
action.threat_activity._threat_match = user
alert.track                          = false
cron_schedule                        = 25,55 * * * *
disabled                             = False
dispatch.earliest_time               = -45m@m
dispatch.latest_time                 = +0s
enableSched                          = True
is_visible                           = false
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `tstats` values(sourcetype),values(Authentication.src),values(Authentication.dest) from datamodel=Authentication.Authentication by Authentication.src_user | eval user='Authentication.src_user' | eval threat_match_field="src_user" | `tstats` append=true values(sourcetype),values(Authentication.src),values(Authentication.dest) from datamodel=Authentication.Authentication by Authentication.user | eval user=if(isnull(user),'Authentication.user',user) | `sistats_values_rename(Authentication.src,src)` | `sistats_values_rename(Authentication.dest,dest)` | `tstats` append=true values(sourcetype),values(All_Inventory.src),values(All_Inventory.dest) from datamodel=Compute_Inventory.All_Inventory by All_Inventory.User.user | eval user=if(isnull(user),'All_Inventory.User.user',user) | eval threat_match_field=if(isnull(threat_match_field),"user",threat_match_field) | `sistats_values_rename(All_Inventory.src,src)` | `sistats_values_rename(All_Inventory.dest,dest)` | `tstats` append=true values(sourcetype),values(Web.src),values(Web.dest) from datamodel=Web.Web by Web.user | eval user=if(isnull(user),'Web.user',user) | `sistats_values_rename(Web.src,src)` | `sistats_values_rename(Web.dest,dest)` | stats values(sourcetype) as sourcetype,values(src) as src,values(dest) as dest by user,threat_match_field | lookup update=true threatintel_by_user user OUTPUT | lookup update=true threatintel_by_user_wildcard user OUTPUTNEW | search threat_collection_key=* | `mvtruncate(src)` | `mvtruncate(dest)` | `zipexpand_threat_matches`
[Threat Activity - Total Count]
action.keyindicator.group.1.name = security_posture
action.keyindicator.group.1.order = 7

[Threat - Threat List Activity - Rule]
action.customsearchbuilder.spec = {}
action.notable.param.extract_assets = ["src","dest","dvc","orig_host"]
action.notable.param.extract_identities = ["src_user","user"]
cron_schedule = */3 * * * *
disabled = 0

#####################
## Global
#####################

[Network - Unroutable Host Activity - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Unroutable Activity Detected
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = high
action.notable.param.rule_title       = Unroutable Activity Detected ($bogon_ip$)
action.notable.param.rule_description = $orig_sourcetype$ network communication was discovered to a host that is unroutable ($bogon_ip$). This activity may be indicative of malicious activity (such as IP spoofing) since address ($bogon_ip$) should not be used for legitimate network traffic.
action.notable.param.nes_fields       = src,dest
action.notable.param.drilldown_name   = View all $orig_sourcetype$ activity involving $src$ to $dest$
action.notable.param.drilldown_search = sourcetype="$orig_sourcetype$" "$src$" "$dest$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = src
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = sourcetype,src,dest
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 40 * * * *
description                           = Alerts when activity to or from a host that is unroutable is detected.
disabled                              = True
dispatch.earliest_time                = -70m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | `src_dest_tstats("allowed")` | `bogonlist_lookup` | search (dest_is_bogon=true dest_is_internal!=true) OR (src_is_bogon=true src_is_internal!=true) | eval bogon_ip=if(dest_is_bogon=="true" AND dest_is_internal!="true",dest,bogon_ip) | eval bogon_ip=if(src_is_bogon=="true" AND src_is_internal!="true",src,bogon_ip) | fields + sourcetype,src,dest,bogon_ip

[Network - High Volume of Traffic from High or Critical Host - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = High Volume of Web Activity from Critical System
action.email.sendresults              = 0
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Web",\
         "object":        "Web",\
         "earliest":      "-70m@m",\
         "latest":        "+0s",\
         "eventFilter":   "'Web.bytes_out'>0 AND ('Web.src_priority'=\"high\" OR 'Web.src_priority'=\"critical\")",\
         "aggregates":    [{"function": "sum", "attribute": "Web.bytes_out", "alias": "bytes_out"}],\
         "splitby":       [\
                           {"attribute": "Web.src", "alias": "src"},\
                           {"attribute": "Web.dest", "alias": "dest"}\
                          ],\
         "resultFilter":  {"field": "bytes_out", "comparator": ">", "value": "10485760"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest","src"]\
}
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = high
action.notable.param.rule_title       = High Volume of Web Activity from $src$ to $dest$
action.notable.param.rule_description = A large volume of web activity was observed from $src$ to $dest$.
action.notable.param.nes_fields       = src,dest
action.notable.param.drilldown_name   = View web activity involving $src$ to $dest$
action.notable.param.drilldown_search = | from datamodel:"Web"."Web" | where 'bytes_out'>0 AND ('src_priority'="high" OR 'src_priority'="critical") AND 'src'="$src$" AND 'dest'="$dest$"
action.notable.param.default_status   =
action.notable.param.default_owner    =
action.risk                           = 1
action.risk.param._risk_object        = src
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest,src
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 5,20,35,50 * * * *
description                           = Alerts when a system of high or critical severity generates a high volume of outbound web activity. This may indicate that the system has been compromised.
disabled                              = True
dispatch.earliest_time                = -70m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
search                                = | tstats summariesonly=true allow_old_summaries=true sum(Web.bytes_out) as "bytes_out" from datamodel="Web"."Web" where    "Web.bytes_out">0 AND ("Web.src_priority"="high" OR "Web.src_priority"="critical") by "Web.src","Web.dest" | rename "Web.src" as "src","Web.dest" as "dest" | where 'bytes_out'>10485760

[Network - Unusual Volume of Network Activity - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Unusual Volume of Network Activity
action.correlationsearch.related_searches = [\
    "Network - Traffic Volume Per 30m - Context Gen",\
    "Network - Traffic Source Count Per 30m - Context Gen"\
]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = network
action.notable.param.severity             = high
action.notable.param.rule_title           = Unusual Volume of Network Activity
action.notable.param.rule_description     = An unusual volume of network activity was detected. $src_count$ unique sources have generated network traffic in the past 15 minutes and $count$ network events have been observed in the same time period.
action.notable.param.nes_fields           = 
action.notable.param.drilldown_name       = 
action.notable.param.drilldown_search     = 
action.notable.param.default_status       =
action.notable.param.default_owner        = 
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = const_dedup_id
alert.suppress.period                     = 14300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = */30 * * * *
description                               = Detects unusual network traffic that may be indicative of a DoS attack as indicated by a high number of unique sources or a high volume of firewall packets
disabled                                  = True
dispatch.earliest_time                    = -40m@m
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(All_Traffic.src) as src_count,count from datamodel=Network_Traffic.All_Traffic | localop | xswhere count from count_30m in network_traffic is extreme or src_count from src_count_30m in network_traffic is extreme | eval const_dedup_id="Network - Unusual Volume of Network Activity - Rule"


#####################
## DNS
#####################

###### Correlation Searches ######
[Network - Excessive DNS Failures - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Excessive DNS Failures
action.email.sendresults              = 0
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Network_Resolution",\
         "object":        "DNS",\
         "earliest":      "-70m@m",\
         "latest":        "+0s",\
         "eventFilter":   "'DNS.reply_code'!=\"No error\" AND 'DNS.reply_code'!=\"NoError\"",\
         "aggregates":    [{"function": "count"}],\
         "splitby":       [{"attribute": "DNS.src", "alias": "src"}],\
         "resultFilter":  {"field": "count", "comparator": ">", "value": "100"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["src"]\
}
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = high
action.notable.param.rule_description = A host ($src$) was detected receiving a high number of DNS failure responses ($count$).
action.notable.param.rule_title       = Excessive DNS Failures ($src$)
action.notable.param.nes_fields       = src
action.notable.param.drilldown_name   = View DNS Activity on $src$
action.notable.param.drilldown_search = | from datamodel:"Network_Resolution"."DNS" | search src="$src$"
action.notable.param.default_owner    = 
action.notable.param.default_status   = 
action.risk                           = 1
action.risk.param._risk_object        = src
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 40
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = src
alert.suppress.period                 = 86300s
alert.track                           = 0
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 10 * * * *
description                           = Alerts when a host receives many DNS failures in a short span
disabled                              = True
dispatch.earliest_time                = -70m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | tstats summariesonly=true allow_old_summaries=true count from datamodel="Network_Resolution"."DNS" where "DNS.reply_code"!="No error" AND "DNS.reply_code"!="NoError" by "DNS.src"  | rename "DNS.src" as "src" | where 'count'>100

[Network - Excessive DNS Queries - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Excessive DNS Queries
action.email.sendresults              = 0
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Network_Resolution",\
         "object":        "DNS",\
         "earliest":      "-70m@m",\
         "latest":        "+0s",\
         "eventFilter":   "'DNS.message_type'=\"QUERY\"",\
         "aggregates":    [{"function":"count"}],\
         "splitby":       [{"attribute": "DNS.src", "alias":"src"}],\
         "resultFilter":  {"field": "count", "comparator": ">", "value": "100"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["src"]\
}
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = high
action.notable.param.rule_title       = Excessive DNS Queries ($src$)
action.notable.param.rule_description = A host ($src$) was detected sending a high number of DNS queries ($count$).
action.notable.param.nes_fields       = src
action.notable.param.drilldown_name   = View DNS Activity on $src$
action.notable.param.drilldown_search = | from datamodel:"Network_Resolution"."DNS" | search src="$src$"
action.notable.param.default_owner    = 
action.notable.param.default_status   = 
action.risk                           = 1
action.risk.param._risk_object        = src
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 40
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = src
alert.suppress.period                 = 86300s
alert.track                           = 0
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 20 * * * *
description                           = Alerts when a host starts sending excessive DNS queries
disabled                      	      = True
dispatch.earliest_time                = -70m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | tstats summariesonly=true allow_old_summaries=true count from datamodel="Network_Resolution"."DNS" where    "DNS.message_type"="QUERY" by "DNS.src" | rename "DNS.src" as "src" | where 'count'>100

###### Key Indicator Searches ######
[DNS - Messages]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Total DNS messages
action.keyindicator.subtitle                    = Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Network_Resolution.DNS where earliest=-24h@h latest=+0s
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DNetwork_Resolution.DNS%20where%20earliest%3D-24h%40h%20latest%3D%2B0s
action.keyindicator.group.0.name                = net_dns_activity
action.keyindicator.group.0.order               = 0
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Total DNS messages
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count as current_count from datamodel=Network_Resolution.DNS where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Network_Resolution.DNS where earliest=-48h@h latest=-24h@h] | `get_delta`

[DNS - Errors]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Total DNS Errors
action.keyindicator.subtitle                    = Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   =
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Network_Resolution.DNS where earliest=-24h@h latest=+0s (DNS.reply_code!="No error" AND DNS.reply_code!="NoError")
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DNetwork_Resolution.DNS%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20(DNS.reply_code!%3D%22No%20error%22%20AND%20DNS.reply_code!%3D%22NoError%22)
action.keyindicator.group.0.name                = net_dns_activity
action.keyindicator.group.0.order               = 1
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Total DNS Errors
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count as current_count from datamodel=Network_Resolution.DNS where earliest=-24h@h latest=+0s (DNS.reply_code!="No error" AND DNS.reply_code!="NoError") | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Network_Resolution.DNS where earliest=-48h@h latest=-24h@h (DNS.reply_code!="No error" AND DNS.reply_code!="NoError") ] | `get_delta`

[DNS - Unique Queries]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Unique Queries 
action.keyindicator.subtitle                    = Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Network_Resolution.DNS where earliest=-24h@h latest=+0s by DNS.query
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DNetwork_Resolution.DNS%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20DNS.query
action.keyindicator.group.0.name                = net_dns_activity
action.keyindicator.group.0.order               = 2
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Unique Query Count
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` estdc(DNS.query) as current_count from datamodel=Network_Resolution.DNS where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(DNS.query) as historical_count from datamodel=Network_Resolution.DNS where earliest=-48h@h latest=-24h@h] | `get_delta`

[DNS - Query Sources]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title 			            = Unique Sources
action.keyindicator.subtitle                    = Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Network_Resolution.DNS where earliest=-24h@h latest=+0s by DNS.src
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DNetwork_Resolution.DNS%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20DNS.src
action.keyindicator.group.0.name                = net_dns_activity
action.keyindicator.group.0.order               = 3
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Unique Query Sources 
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` estdc(DNS.src) as current_count from datamodel=Network_Resolution.DNS where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(DNS.src) as historical_count from datamodel=Network_Resolution.DNS where earliest=-48h@h latest=-24h@h] | `get_delta`

###### Swim Lane Searches ######
[DNS - Errors - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = DNS Errors
action.swimlane.color                             = red
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = DNS.src,DNS.dest,src,dest
action.swimlane.drilldown_search                  = | from datamodel:"Network_Resolution"."DNS" | search $constraints$
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Protocol Intelligence
display.page.asset_investigator.0.order           = 0
is_visible                                        = false
request.ui_dispatch_app                           = SplunkEnterpriseSecuritySuite
search                                            = | tstats `summariesonly` count, values(DNS.src) as src, values(DNS.query) as query, values(DNS.reply_code) as reply_code from datamodel=Network_Resolution.DNS where (DNS.reply_code!="No error" AND DNS.reply_code!="NoError") $constraints$ by _time span=$span$


###########
## Email
###########

###### Key Indicator Searches ######
[Email - Unique Senders]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Unique Senders
action.keyindicator.subtitle                    = Sender Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats  `summariesonly` count from datamodel=Email.All_Email where earliest=-24h@h latest=+0s by All_Email.src_user
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%20%60summariesonly%60%20count%20from%20datamodel%3DEmail.All_Email%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20All_Email.src_user
action.keyindicator.group.0.name                = net_email_activity
action.keyindicator.group.0.order               = 0
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Unique Senders
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats  `summariesonly` estdc(All_Email.src_user) as current_count from datamodel=Email.All_Email where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(All_Email.src_user) as historical_count from datamodel=Email.All_Email where earliest=-48h@h latest=-24h@h ] | `get_delta`

[Email - Unique Receivers]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Unique Receivers
action.keyindicator.subtitle                    = Receiver Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   =
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats  `summariesonly` count from datamodel=Email.All_Email where earliest=-24h@h latest=+0s by All_Email.recipient
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%20%60summariesonly%60%20count%20from%20datamodel%3DEmail.All_Email%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20All_Email.recipient
action.keyindicator.group.0.name                = net_email_activity
action.keyindicator.group.0.order               = 1
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Unique Receivers
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats  `summariesonly` estdc(All_Email.recipient) as current_count from datamodel=Email.All_Email where earliest=-24h@h latest=+0s | appendcols [| tstats  `summariesonly` estdc(All_Email.recipient) as historical_count from datamodel=Email.All_Email where earliest=-48h@h latest=-24h@h ] | `get_delta`

[Email - Cloud Activity]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Cloud Activity
action.keyindicator.subtitle                    = Email Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   =
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Email.All_Email where earliest=-24h@h latest=+0s (`cloud_email_search("All_Email.src_user")` OR `cloud_email_search("All_Email.recipient")`) by All_Email.src_user All_Email.recipient
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DEmail.All_Email%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20(%60cloud_email_search(%22All_Email.src_user%22)%60%20OR%20%60cloud_email_search(%22All_Email.recipient%22)%60)%20by%20All_Email.src_user%20All_Email.recipient
action.keyindicator.group.0.name                = net_email_activity
action.keyindicator.group.0.order               = 2
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Cloud Activity
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count as current_count from datamodel=Email.All_Email where earliest=-24h@h latest=+0s (`cloud_email_search("All_Email.src_user")` OR `cloud_email_search("All_Email.recipient")`) | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Email.All_Email where earliest=-48h@h latest=-24h@h (`cloud_email_search("All_Email.src_user")` OR `cloud_email_search("All_Email.recipient")`) ] | `get_delta`

###### Swim Lane Searches ######
[Email - Cloud Activity - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = Cloud Emails
action.swimlane.color                             = green
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = All_Email.src,All_Email.dest,src,dest
action.swimlane.drilldown_search                  = | from datamodel:"Email"."All_Email" | search $constraints$
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Protocol Intelligence
display.page.asset_investigator.0.order           = 1
is_visible                                        = false
request.ui_dispatch_app                           = SplunkEnterpriseSecuritySuite
search                                            = | tstats `summariesonly` count, values(All_Email.src) as src, values(All_Email.src_user) as sender, values(All_Email.recipient) as recipient from datamodel=Email.All_Email where $constraints$ (`cloud_email_search("All_Email.src_user")` OR `cloud_email_search("All_Email.recipient")`) by _time span=$span$ 


#####################
## Traffic
#####################

###### Correlation Searches ######
[Network - Unapproved Port Activity Detected - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Prohibited Port Activity Detected
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = low
action.notable.param.rule_title       = Prohibited Port Activity Detected ($transport$/$dest_port$ on $dvc$ )
action.notable.param.rule_description = The device $dvc$ has allowed communication via prohibited port $dest_port$ and $transport$ protocol. Please verify this activity is authorized and modify the prohibited_traffic lookup table if necessary.
action.notable.param.nes_fields       = transport,dest_port
action.notable.param.drilldown_name   = View prohibited port usage for device $dvc$ and $transport$/$dest_port$
action.notable.param.drilldown_search = | from datamodel:"Network_Traffic"."Allowed_Traffic" | search dvc="$dvc$" transport="$transport$" dest_port=$dest_port$
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest_port
action.risk.param._risk_object_type   = other
action.risk.param._risk_score         = 40
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dvc,transport,dest_port
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects the use of ports that are prohibited. Useful for detecting the installation of new software or a successful compromise of a host (such as the presence of a backdoor or a system communicating with a botnet).
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
search                                = | from datamodel:"Network_Traffic"."Allowed_Traffic" | `is_traffic_prohibited(dest_port)` | search dest_port>0 NOT is_prohibited=false | stats count by dvc,transport,dest_port,is_prohibited | `get_asset(dvc)` | `get_identity4events(dvc_owner)`

###### Generating Searches ######
[Network - Traffic Bytes Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 30 0,4,8,12,16,20 * * *
description              = Maintains Traffic byte statistics
dispatch.earliest_time   = -90d
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
request.ui_dispatch_app  = SplunkEnterpriseSecuritySuite
schedule_window      	 = 10
search                   = | tstats `summariesonly` min(All_Traffic.bytes) as min_bytes,avg(All_Traffic.bytes) as mean_bytes,max(All_Traffic.bytes) as max_bytes,stdev(All_Traffic.bytes) as stdev,count as total_count from datamodel=Network_Traffic.All_Traffic where All_Traffic.bytes>0 | appendcols [| from inputlookup:standard_deviations | rename stdev as standard_deviation] | filldown | fillnull value=0 min_bytes,mean_bytes,max_bytes,stdev,total_count | `stdev_desired_result(standard_deviation,mean_bytes,"gt_bytes")` | `stdev_desired_result(-standard_deviation,mean_bytes,"lt_bytes")` | eval search=case(gt_bytes>0 AND lt_bytes>0, "(All_Traffic.bytes>".floor(gt_bytes)." OR All_Traffic.bytes<".ceil(lt_bytes).")",gt_bytes>0 AND lt_bytes<=0,"All_Traffic.bytes>".floor(gt_bytes),gt_bytes<=0 AND lt_bytes>0,"All_Traffic.bytes<".ceil(lt_bytes),gt_bytes<=0 AND lt_bytes<=0,"All_Traffic.bytes=-1") | rename standard_deviation as Z | rename total as total_count | fields min_bytes,mean_bytes,max_bytes,stdev,total_count,Z,search | `round(mean_bytes)` | `round(stdev)` | outputlookup traffic_bytes_tracker | stats count

###### Key Indicator Searches ######
[Network - Long Lived Connections]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Long Lived Connections
action.keyindicator.subtitle                    = Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s All_Traffic.duration>300000000 by All_Traffic.src All_Traffic.dest
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DNetwork_Traffic.All_Traffic%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Traffic.duration%3E300000000%20by%20All_Traffic.src%20All_Traffic.dest
action.keyindicator.group.0.name                = net_unique_sources
action.keyindicator.group.0.order               = 1
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Long Lived Connections
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count as current_count from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s All_Traffic.duration>300000000 | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Network_Traffic.All_Traffic where earliest=-48h@h latest=-24h@h All_Traffic.duration>300000000] | `get_delta`

[Traffic - Maximum Bytes]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Maximum Bytes
action.keyindicator.subtitle                  = Bytes
action.keyindicator.value                     = current_max
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` max(All_Traffic.bytes) as maximum_bytes from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s All_Traffic.bytes>0 by All_Traffic.src All_Traffic.dest | sort -maximum_bytes
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20max(All_Traffic.bytes)%20as%20maximum_bytes%20from%20datamodel%3DNetwork_Traffic.All_Traffic%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Traffic.bytes%3E0%20by%20All_Traffic.src%20All_Traffic.dest%20%7C%20sort%20-maximum_bytes
action.keyindicator.group.0.name              = traffic_size
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Maximum Bytes
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` max(All_Traffic.bytes) as current_max from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s All_Traffic.bytes>0 | appendcols [| tstats `summariesonly` max(All_Traffic.bytes) as historical_max from datamodel=Network_Traffic.All_Traffic where earliest=-48h@h latest=-24h@h All_Traffic.bytes>0] | `get_delta(current_max,historical_max)`

[Traffic - Mean Bytes]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Mean Bytes
action.keyindicator.subtitle                  = Bytes
action.keyindicator.value                     = current_mean
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Traffic.bytes) as bytes from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s All_Traffic.bytes>0 by All_Traffic.src All_Traffic.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Traffic.bytes)%20as%20bytes%20from%20datamodel%3DNetwork_Traffic.All_Traffic%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Traffic.bytes%3E0%20by%20All_Traffic.src%20All_Traffic.dest
action.keyindicator.group.0.name              = traffic_size
action.keyindicator.group.0.order             = 1
action.keyindicator.group.1.name              = traffic_center
action.keyindicator.group.1.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Mean Bytes
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` avg(All_Traffic.bytes) as current_mean from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s All_Traffic.bytes>0 | appendcols [| tstats `summariesonly` avg(All_Traffic.bytes) as historical_mean from datamodel=Network_Traffic.All_Traffic where earliest=-48h@h latest=-24h@h All_Traffic.bytes>0] | `get_delta(current_mean,historical_mean)`

[Traffic - Minimum Bytes]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Minimum Bytes
action.keyindicator.subtitle                  = Bytes
action.keyindicator.value                     = current_min
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Traffic.bytes) as bytes from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s All_Traffic.bytes>0 by All_Traffic.src All_Traffic.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Traffic.bytes)%20as%20bytes%20from%20datamodel%3DNetwork_Traffic.All_Traffic%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Traffic.bytes%3E0%20by%20All_Traffic.src%20All_Traffic.dest
action.keyindicator.group.0.name              = traffic_size
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Minimum Bytes
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` min(All_Traffic.bytes) as current_min from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s All_Traffic.bytes>0 | appendcols [| tstats `summariesonly` min(All_Traffic.bytes) as historical_min from datamodel=Network_Traffic.All_Traffic where earliest=-48h@h latest=-24h@h All_Traffic.bytes>0] | `get_delta(current_min,historical_min)`

[Traffic - Standard Deviation Bytes]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Stdev Bytes
action.keyindicator.subtitle                  = Bytes
action.keyindicator.value                     = current_stdev
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Traffic.bytes) as bytes from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s All_Traffic.bytes>0 by All_Traffic.src All_Traffic.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Traffic.bytes)%20as%20bytes%20from%20datamodel%3DNetwork_Traffic.All_Traffic%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20All_Traffic.bytes%3E0%20by%20All_Traffic.src%20All_Traffic.dest
action.keyindicator.group.0.name              = traffic_size
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Standard Deviation Bytes
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` stdev(All_Traffic.bytes) as current_stdev from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s All_Traffic.bytes>0 | appendcols [| tstats `summariesonly` stdev(All_Traffic.bytes) as historical_stdev from datamodel=Network_Traffic.All_Traffic where earliest=-48h@h latest=-24h@h All_Traffic.bytes>0] | `get_delta(current_stdev,historical_stdev)`

[Traffic - Stream Connections]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Stream Connections
action.keyindicator.subtitle                    = Total Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic where All_Traffic.transport=tcp `src_stream` earliest=-24h@h latest=+0s by All_Traffic.src All_Traffic.dest
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DNetwork_Traffic.All_Traffic%20where%20All_Traffic.transport%3Dtcp%20%60src_stream%60%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20All_Traffic.src%20All_Traffic.dest
action.keyindicator.group.0.name                = net_unique_sources
action.keyindicator.group.0.order               = 2
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Stream Connections
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count as current_count from datamodel=Network_Traffic.All_Traffic where All_Traffic.transport=tcp `src_stream` earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Network_Traffic.All_Traffic where All_Traffic.transport=tcp `src_stream` earliest=-48h@h latest=-24h@h] | `get_delta`

[Traffic - Network Threat Activity]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Network Threat Activity
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | from datamodel:"Threat_Intelligence"."Threat_Activity" | search source="Threat - Source And Destination Matches - Threat Gen"
action.keyindicator.drilldown_uri             = search?q=%7C%20from%20datamodel%3A%22Threat_Intelligence%22.%22Threat_Activity%22%20%7C%20search%20source%3D%22Threat%20-%20Source%20And%20Destination%20Matches%20-%20Threat%20Gen%22&earliest=-24h%40h&latest=now
action.keyindicator.group.0.name              = traffic_center
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Network Threat Activity
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count as current_count from datamodel=Threat_Intelligence.Threat_Activity where source="Threat - Source And Destination Matches - Threat Gen" earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Threat_Intelligence.Threat_Activity where source="Threat - Source And Destination Matches - Threat Gen" earliest=-48h@h latest=-24h@h] | `get_delta`

[Traffic - Total Bytes]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Total Bytes
action.keyindicator.subtitle                    = Bytes
action.keyindicator.value                       = current_bytes
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic where All_Traffic.transport=tcp `src_stream` earliest=-24h@h latest=+0s by All_Traffic.src All_Traffic.dest
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DNetwork_Traffic.All_Traffic%20where%20All_Traffic.transport%3Dtcp%20%60src_stream%60%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20All_Traffic.src%20All_Traffic.dest
action.keyindicator.group.0.name                = net_unique_sources
action.keyindicator.group.0.order               = 4
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Total Bytes
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` sum(All_Traffic.bytes) as current_bytes from datamodel=Network_Traffic.All_Traffic where All_Traffic.bytes>0 earliest=-24h@h latest=+0s | appendcols [ | tstats `summariesonly` sum(All_Traffic.bytes) as historical_bytes from datamodel=Network_Traffic.All_Traffic where All_Traffic.bytes>0 earliest=-48h@h latest=-24h@h] | `get_delta(current_bytes, historical_bytes)`

[Traffic - Total Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Total Count
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic where All_Traffic.transport=tcp `src_stream` earliest=-24h@h latest=+0s by All_Traffic.src All_Traffic.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DNetwork_Traffic.All_Traffic%20where%20All_Traffic.transport%3Dtcp%20%60src_stream%60%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20All_Traffic.src%20All_Traffic.dest
action.keyindicator.group.0.name              = traffic_size
action.keyindicator.group.0.order             = 4
action.keyindicator.group.1.name              = traffic_center
action.keyindicator.group.1.order             = 4
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Traffic Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count as current_count from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Network_Traffic.All_Traffic where earliest=-48h@h latest=-24h@h] | `get_delta`

[Traffic - Total Encrypted Connections]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Encrypted Connections
action.keyindicator.subtitle                    = SSL/TLS Connection Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Certificates.All_Certificates where nodename="All_Certificates.SSL" All_Certificates.tag="network" All_Certificates.tag="communicate" earliest=-24h@h latest=+0s by All_Certificates.src All_Certificates.dest
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DCertificates.All_Certificates%20where%20nodename%3D%22All_Certificates.SSL%22%20All_Certificates.tag%3D%22network%22%20All_Certificates.tag%3D%22communicate%22%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20All_Certificates.src%20All_Certificates.dest
action.keyindicator.group.0.name                = net_unique_sources
action.keyindicator.group.0.order               = 3
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Total Encrypted Connections
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count as current_count from datamodel=Certificates.All_Certificates where nodename="All_Certificates.SSL" All_Certificates.tag="network" All_Certificates.tag="communicate" earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Certificates.All_Certificates where nodename="All_Certificates.SSL" All_Certificates.tag="network" All_Certificates.tag="communicate" earliest=-24h@h latest=+0s earliest=-48h@h latest=-24h@h] | `get_delta`

[Traffic - Unique Sources]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Traffic Sources
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s by All_Traffic.src
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DNetwork_Traffic.All_Traffic%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20All_Traffic.src
action.keyindicator.group.0.name              = traffic_center
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Traffic Sources
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(All_Traffic.src) as current_count from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(All_Traffic.src) as historical_count from datamodel=Network_Traffic.All_Traffic where earliest=-48h@h latest=-24h@h] | `get_delta`

[Traffic - Unique Network Protocols]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Protocol Activity
action.keyindicator.subtitle                    = Unique Protocols
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s `cim_filter_unknown_values(All_Traffic.app)` by All_Traffic.app
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DNetwork_Traffic.All_Traffic%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20%60cim_filter_unknown_values(All_Traffic.app)%60%20by%20All_Traffic.app
action.keyindicator.group.0.name                = net_unique_sources
action.keyindicator.group.0.order               = 0
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Unique Protocols
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` estdc(all_traffic.app) as current_count from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s `cim_filter_unknown_values(All_Traffic.app)` | appendcols [|tstats `summariesonly` estdc(all_traffic.app) as historical_count from datamodel=Network_Traffic.All_Traffic where earliest=-48h@h latest=-24h@h `cim_filter_unknown_values(All_Traffic.app)`] | `get_delta`

[Traffic - Unique Destinations]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Traffic Destinations
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s by All_Traffic.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DNetwork_Traffic.All_Traffic%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20All_Traffic.dest
action.keyindicator.group.0.name              = traffic_center
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Traffic Destinations
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(All_Traffic.dest) as current_count from datamodel=Network_Traffic.All_Traffic where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(All_Traffic.dest) as historical_count from datamodel=Network_Traffic.All_Traffic where earliest=-48h@h latest=-24h@h] | `get_delta`


###### Report Searches ######
[Traffic - New Port Activity]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `port_protocol_tracker` | `dayDiff(firstTime)` | search dayDiff<7 | eval _firstTime=firstTime,firstTime=strftime(firstTime, "%m/%d/%Y %H:%M:%S"),_lastTime=lastTime,lastTime=strftime(lastTime,"%m/%d/%Y %H:%M:%S") | fields firstTime,lastTime,transport,dest_port,app

[Traffic - Prohibited Or Insecure Traffic Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | tstats `summariesonly` values(All_Traffic.src_category) as src_category,values(All_Traffic.dest_category) as dest_category,count from datamodel=Network_Traffic.All_Traffic by _time,All_Traffic.src,All_Traffic.dest,All_Traffic.transport,All_Traffic.dest_port span=10m | `drop_dm_object_name("All_Traffic")` | `is_traffic_prohibited(dest_port)` | search (is_prohibited!="false" OR is_secure!="unknown") | `get_transport_dest_port` | timechart minspan=10m sum(count) as count by transport_dest_port

[Traffic - Prohibited Traffic Details]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | tstats `summariesonly` max(_time) as _time,values(All_Traffic.src_category) as src_category,values(All_Traffic.dest_category) as dest_category,count from datamodel=Network_Traffic.All_Traffic by All_Traffic.src,All_Traffic.dest,All_Traffic.transport,All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | `is_traffic_prohibited(dest_port)` | search (is_prohibited!="false" OR is_secure!="unknown") | fields _time,src,src_category,dest,dest_category,transport,dest_port,is_prohibited,is_secure

[Traffic - Scan Activity By Destination Ports]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` dc(All_Traffic.dest_port) as dest_port_count from datamodel=Network_Traffic.All_Traffic by All_Traffic.src | `drop_dm_object_name("All_Traffic")` | sort 10 - dest_port_count

[Traffic - Scan Activity By Destinations]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` dc(All_Traffic.dest) as dest_count from datamodel=Network_Traffic.All_Traffic by All_Traffic.src | `drop_dm_object_name("All_Traffic")` | sort 10 - dest_count

[Traffic - Top Traffic By Destination]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic by _time,All_Traffic.dest span=1h | `drop_dm_object_name("All_Traffic")` | stats sparkline(sum(count),1h) as sparkline,sum(count) as count by dest | sort 100 - count

[Traffic - Top Traffic By Destination Port]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.chart.stackMode = stacked
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | `tstats` count from datamodel=Network_Traffic.All_Traffic by All_Traffic.action,All_Traffic.dest_port | chart count over All_Traffic.dest_port by All_Traffic.action | `drop_dm_object_name("All_Traffic")` | `sort_chart`

[Traffic - Top Traffic By Device]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.chart.stackMode = stacked
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | `tstats` count from datamodel=Network_Traffic.All_Traffic by All_Traffic.action,All_Traffic.dvc | chart count over All_Traffic.dvc by All_Traffic.action | `drop_dm_object_name("All_Traffic")` | `sort_chart`

[Traffic - Top Traffic By Source]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic by _time,All_Traffic.src span=1h | `drop_dm_object_name("All_Traffic")` | stats sparkline(sum(count),1h) as sparkline,sum(count) as count by src | sort 100 - count

[Traffic - Top Traffic By Source Port]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.chart.stackMode = stacked
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | `tstats` count from datamodel=Network_Traffic.All_Traffic by All_Traffic.action,All_Traffic.src_port | chart count over All_Traffic.src_port by All_Traffic.action | `drop_dm_object_name("All_Traffic")` | `sort_chart`

[Traffic - Top Traffic By Transport]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.chart.stackMode = stacked
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | `tstats` count from datamodel=Network_Traffic.All_Traffic by All_Traffic.action,All_Traffic.transport | chart count over All_Traffic.transport by All_Traffic.action | `drop_dm_object_name("All_Traffic")` | `sort_chart`

[Traffic - Traffic Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Network_Traffic.All_Traffic by _time span=10m | timechart minspan=10m count

[Traffic - Traffic Over Time By Action]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Network_Traffic.All_Traffic by _time,All_Traffic.action span=10m | timechart minspan=10m count by All_Traffic.action | `drop_dm_object_name("All_Traffic")`

[Traffic - Traffic Over Time By Bytes]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -7d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` min(All_Traffic.bytes),avg(All_Traffic.bytes),max(All_Traffic.bytes) from datamodel=Network_Traffic.All_Traffic where All_Traffic.bytes>0 by _time span=10m  | timechart minspan=10m min(All_Traffic.bytes) as min(bytes),avg(All_Traffic.bytes) as avg(bytes),max(All_Traffic.bytes) as max(bytes) | eval min(bytes)=round('min(bytes)') | eval max(bytes)=round('max(bytes)') | eval avg(bytes)=round('avg(bytes)')

[Traffic - Traffic Over Time By Mega-Bytes]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -7d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` min(All_Traffic.bytes),avg(All_Traffic.bytes),max(All_Traffic.bytes) from datamodel=Network_Traffic.All_Traffic where All_Traffic.bytes>0 by _time span=10m  | timechart minspan=10m min(All_Traffic.bytes) as min(bytes),avg(All_Traffic.bytes) as avg(bytes),max(All_Traffic.bytes) as max(bytes) | eval min(megabytes)=round('min(bytes)'/1024/1024), max(megabytes)=round('max(bytes)'/1024/1024), avg(megabytes)=round('avg(bytes)'/1024/1024) | fields - min(bytes) max(bytes) avg(bytes)


[Traffic - Traffic Over Time By Destination]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Network_Traffic.All_Traffic by _time,All_Traffic.dest span=10m | timechart minspan=10m useother=`useother` count by All_Traffic.dest | `drop_dm_object_name("All_Traffic")`

[Traffic - Traffic Over Time By Destination Port]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Network_Traffic.All_Traffic by _time,All_Traffic.dest_port span=10m | timechart minspan=10m useother=`useother` count by All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")`

[Traffic - Traffic Over Time By Device]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Network_Traffic.All_Traffic by _time,All_Traffic.dvc span=10m | timechart minspan=10m useother=`useother` count by All_Traffic.dvc | `drop_dm_object_name("All_Traffic")`

[Traffic - Traffic Over Time By Source]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Network_Traffic.All_Traffic by _time,All_Traffic.src span=10m | timechart minspan=10m useother=`useother` count by All_Traffic.src | `drop_dm_object_name("All_Traffic")`

[Traffic - Traffic Over Time By Source Port]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Network_Traffic.All_Traffic by _time,All_Traffic.src_port span=10m | timechart minspan=10m useother=`useother` count by All_Traffic.src_port | `drop_dm_object_name("All_Traffic")`

[Traffic - Traffic Over Time By Transport Protocol]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Network_Traffic.All_Traffic by _time,All_Traffic.transport span=10m | timechart minspan=10m useother=`useother` count by All_Traffic.transport | `drop_dm_object_name("All_Traffic")`

## Traffic Size Analysis

[Traffic - Traffic Size Anomalies Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -7d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | tstats `summariesonly` count from datamodel=Network_Traffic.All_Traffic where [| from inputlookup:traffic_bytes_tracker | search Z=2 | fields search] by _time,All_Traffic.src,All_Traffic.transport span=10m | `drop_dm_object_name("All_Traffic")` | `per_panel_filter("ppf_traffic_size","src")` | timechart minspan=10m sum(count) by All_Traffic

[Traffic - Traffic Size Anomalies]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` max(_time) as lastTime,min(All_Traffic.bytes) as min_bytes,avg(All_Traffic.bytes) as mean_bytes,max(All_Traffic.bytes) as max_bytes,dc(All_Traffic.dest) as dc(dest),count from datamodel=Network_Traffic.All_Traffic where [| from inputlookup:traffic_bytes_tracker | search Z=2 | fields search] by All_Traffic.src | `drop_dm_object_name("All_Traffic")` | appendcols [inputlookup append=T start=0 max=1 traffic_bytes_tracker | rename mean_bytes as tracker_mean | fields tracker_mean,stdev] | filldown tracker_mean,stdev | eval Z=round(((mean_bytes-tracker_mean)/stdev),2) | `per_panel_filter("ppf_traffic_size","src")` | rename ppf_filter as filter | eval bytes=if(min_bytes==mean_bytes AND mean_bytes==max_bytes,floor(min_bytes),"min: ".floor(min_bytes)."|avg: ".floor(mean_bytes)."|max: ".floor(max_bytes)) | `makemv(bytes)` | sort - filter,Z | `uitime(lastTime)` | table src,filter,bytes,dc(dest),count,Z,lastTime

###### Swim Lane Searches ######
[Traffic - Threat List Activity By Asset - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = Threat List Activity
action.swimlane.color                             = orange
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = Threat_Activity.src,Threat_Activity.dest,Threat_Activity.threat_match_value,src,dest,threat_match_value
action.swimlane.drilldown_search                  = | from datamodel:"Threat_Intelligence"."Threat_Activity" | search $constraints$
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 2
is_visible                                        = false
request.ui_dispatch_app                           = SplunkEnterpriseSecuritySuite
search                                            = | tstats `summariesonly` values(Threat_Activity.threat_match_field) as threat_match_field,values(Threat_Activity.threat_match_value) as threat_match_value,values(Threat_Activity.threat_collection) as threat_collection,count from datamodel=Threat_Intelligence.Threat_Activity where $constraints$ by _time span=$span$

[Traffic - Threat List Activity By Identity - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = Threat List Activity
action.swimlane.color                                = orange
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = Threat_Activity.src_user,Threat_Activity.user,Threat_Activity.threat_match_value,src_user,user,threat_match_value
action.swimlane.drilldown_search                     = | from datamodel:"Threat_Intelligence"."Threat_Activity" | search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 2
is_visible                                           = false
request.ui_dispatch_app                              = SplunkEnterpriseSecuritySuite
search                                               = | tstats `summariesonly` values(Threat_Activity.threat_match_field) as threat_match_field,values(Threat_Activity.threat_match_value) as threat_match_value,values(Threat_Activity.threat_collection) as threat_collection,count from datamodel=Threat_Intelligence.Threat_Activity where $constraints$ by _time span=$span$


#####################
## IDS
#####################

###### Key Indicator Searches ######
[IDS - High Severity Attacks]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = High Sev. Attacks
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-24h@h latest=+0s (IDS_Attacks.severity="critical" OR IDS_Attacks.severity="high") by IDS_Attacks.src
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DIntrusion_Detection.IDS_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20(IDS_Attacks.severity%3D%22critical%22%20OR%20IDS_Attacks.severity%3D%22high%22)%20by%20IDS_Attacks.src
action.keyindicator.group.0.name              = ids_center
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = High Severity Attacks
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count as current_count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-24h@h latest=+0s (IDS_Attacks.severity="critical" OR IDS_Attacks.severity="high") | appendcols [| tstats `summariesonly` count as historical_count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-48h@h latest=-24h@h (IDS_Attacks.severity="critical" OR IDS_Attacks.severity="high")] | `get_delta`

[IDS - Unique Categories]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Attack Categories
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-24h@h latest=+0s by IDS_Attacks.category
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DIntrusion_Detection.IDS_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20IDS_Attacks.category
action.keyindicator.group.0.name              = ids_center
action.keyindicator.group.0.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Attack Categories
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` dc(IDS_Attacks.category) as current_count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` dc(IDS_Attacks.category) as historical_count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-48h@h latest=-24h@h] | `get_delta`

[IDS - Unique Signature Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Attack Signatures
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-24h@h latest=+0s by IDS_Attacks.signature
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DIntrusion_Detection.IDS_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20IDS_Attacks.signature
action.keyindicator.group.0.name              = ids_center
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Attack Signatures
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(IDS_Attacks.signature) as current_count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(IDS_Attacks.signature) as historical_count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-48h@h latest=-24h@h] | `get_delta`

[IDS - Unique Sources]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Attack Sources
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-24h@h latest=+0s by IDS_Attacks.src
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DIntrusion_Detection.IDS_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20IDS_Attacks.src
action.keyindicator.group.0.name              = ids_center
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Attack Sources
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(IDS_Attacks.src) as current_count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(IDS_Attacks.src) as historical_count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-48h@h latest=-24h@h] | `get_delta`

[IDS - Unique Destinations]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Attack Destinations
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-24h@h latest=+0s by IDS_Attacks.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DIntrusion_Detection.IDS_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20IDS_Attacks.dest
action.keyindicator.group.0.name              = ids_center
action.keyindicator.group.0.order             = 4
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Attack Destinations
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(IDS_Attacks.dest) as current_count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(IDS_Attacks.dest) as historical_count from datamodel=Intrusion_Detection.IDS_Attacks where earliest=-48h@h latest=-24h@h] | `get_delta`

###### Report Searches ######
[IDS - Activity By IDS Type]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` count from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.ids_type | `drop_dm_object_name("IDS_Attacks")`

[IDS - Activity By Category]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` count from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.category | `drop_dm_object_name("IDS_Attacks")`

[IDS - Activity By Severity]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` count from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.severity | `drop_dm_object_name("IDS_Attacks")` | sort - count

[IDS - Top Attacks By Device]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` dc(IDS_Attacks.signature) as attack_count,dc(IDS_Attacks.src) as src_count,dc(IDS_Attacks.dest) as dest_count,count from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.dvc | `drop_dm_object_name("IDS_Attacks")` | sort - count

[IDS - Top Attacks By Category]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` dc(IDS_Attacks.signature) as attack_count,dc(IDS_Attacks.src) as src_count,dc(IDS_Attacks.dest) as dest_count,count from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.category | `drop_dm_object_name("IDS_Attacks")` | sort - count

[IDS - Top Attacks By Severity]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` dc(IDS_Attacks.signature) as attack_count,dc(IDS_Attacks.src) as src_count,dc(IDS_Attacks.dest) as dest_count,count from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.severity | `drop_dm_object_name("IDS_Attacks")`  | sort - count

[IDS - Top Attacks By Attack]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` dc(IDS_Attacks.src) as src_count,dc(IDS_Attacks.dest) as dest_count,count from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.signature | `drop_dm_object_name("IDS_Attacks")` | sort - count

[IDS - Top Attacks By Source]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` dc(IDS_Attacks.signature) as attack_count,dc(IDS_Attacks.dest) as dest_count,count from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.src | `drop_dm_object_name("IDS_Attacks")` | sort - count

[IDS - Top Attacks By Destination]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` dc(IDS_Attacks.signature) as attack_count,dc(IDS_Attacks.src) as src_count,count from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.dest | `drop_dm_object_name("IDS_Attacks")` | sort - count

[IDS - Activity Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Intrusion_Detection.IDS_Attacks by _time span=10m | timechart minspan=10m useother=`useother` count

[IDS - Activity Over Time By Device]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Intrusion_Detection.IDS_Attacks by _time,IDS_Attacks.dvc span=10m | timechart minspan=10m useother=`useother` count by IDS_Attacks.dvc | `drop_dm_object_name("IDS_Attacks")`

[IDS - Activity Over Time By Category]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Intrusion_Detection.IDS_Attacks by _time,IDS_Attacks.category span=10m | timechart minspan=10m useother=`useother` count by IDS_Attacks.category | `drop_dm_object_name("IDS_Attacks")`

[IDS - Activity Over Time By Severity]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Intrusion_Detection.IDS_Attacks by _time,IDS_Attacks.severity span=10m | timechart minspan=10m useother=`useother` count by IDS_Attacks.severity | `drop_dm_object_name("IDS_Attacks")`

[IDS - Activity Over Time By Attack]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Intrusion_Detection.IDS_Attacks by _time,IDS_Attacks.signature span=10m | timechart minspan=10m useother=`useother` count by IDS_Attacks.signature | `drop_dm_object_name("IDS_Attacks")`

[IDS - Activity Over Time By Source]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Intrusion_Detection.IDS_Attacks by _time,IDS_Attacks.src span=10m | timechart minspan=10m useother=`useother` count by IDS_Attacks.src | `drop_dm_object_name("IDS_Attacks")`

[IDS - Activity Over Time By Destination]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Intrusion_Detection.IDS_Attacks by _time,IDS_Attacks.dest span=10m | timechart minspan=10m useother=`useother` count by IDS_Attacks.dest | `drop_dm_object_name("IDS_Attacks")`

[IDS - Scanning Activity (Many Attacks)]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(IDS_Attacks.signature) as attack_count from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.src | `drop_dm_object_name("IDS_Attacks")` | sort 10 - attack_count

[IDS - Scanning Activity (Many Systems)]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(IDS_Attacks.dest) as dest_count from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.src | `drop_dm_object_name("IDS_Attacks")` | sort 10 - dest_count

[IDS - New Attacks]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -30d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `ids_attack_tracker(firstTime)` | `uitime(firstTime)` | sort 100 - firstTime | fields firstTime,ids_type,signature,vendor_product

###### Swim Lane Searches ######
[IDS - All IDS Attacks By Asset - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = IDS Attacks
action.swimlane.color                             = purple
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = IDS_Attacks.src,IDS_Attacks.dest,src,dest
action.swimlane.drilldown_search                  = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | search $constraints$
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 4
is_visible                                        = false
request.ui_dispatch_app                           = SplunkEnterpriseSecuritySuite
search                                            = | tstats `summariesonly` values(IDS_Attacks.severity) as severity,values(IDS_Attacks.signature) as signature,values(IDS_Attacks.src) as src,values(IDS_Attacks.dest) as dest,count from datamodel=Intrusion_Detection.IDS_Attacks where $constraints$ by _time span=$span$

[IDS - All IDS Attacks By Identity - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = IDS Attacks
action.swimlane.color                                = purple
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = IDS_Attacks.user,user
action.swimlane.drilldown_search                     = | from datamodel:"Intrusion_Detection"."IDS_Attacks" | search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 4
is_visible                                           = false
request.ui_dispatch_app                              = SplunkEnterpriseSecuritySuite
search                                               = | tstats `summariesonly` values(IDS_Attacks.severity) as severity,values(IDS_Attacks.signature) as signature,values(IDS_Attacks.src) as src,values(IDS_Attacks.dest) as dest,count from datamodel=Intrusion_Detection.IDS_Attacks where $constraints$ by _time span=$span$


###################
## Network Changes
###################

###### Report Searches ######
[Change - Network Changes By Action]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
dispatchAs                                      = user
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.chart           = column
display.visualizations.charting.drilldown       = all
display.visualizations.charting.chart.stackMode = stacked
display.visualizations.show                     = 1
display.visualizations.type                     = charting
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | `tstats` count from datamodel=Change.All_Changes where nodename=All_Changes.Network_Changes by _time,All_Changes.action span=10m | timechart minspan=10m useother=`useother` count by All_Changes.action | `drop_dm_object_name("All_Changes")`

[Change - Network Changes By Device]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = line
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` count from datamodel=Change.All_Changes where nodename=All_Changes.Network_Changes by All_Changes.dvc | `drop_dm_object_name("All_Changes")`

[Change - Recent Network Changes]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.events.fields            = ["dvc", "action", "command"]
display.events.list.wrap         = true
display.events.rowNumbers        = false
display.events.type              = list
display.general.enablePreview    = true
display.general.type             = events
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | from datamodel:"Change"."Network_Changes" | head 100


############################
## SSL
############################

###### Key Indicator Searches ######
[SSL - Cloud Sessions]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Cloud Sessions
action.keyindicator.subtitle                    = Session Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Certificates.All_Certificates where earliest=-24h@h latest=+0s nodename=All_Certificates.SSL `cloud_domain_search("All_Certificates.SSL.ssl_subject_common_name")` by All_Certificates.SSL.ssl_subject_common_name
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DCertificates.All_Certificates%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20nodename%3DAll_Certificates.SSL%20%60cloud_domain_search(%22All_Certificates.SSL.ssl_subject_common_name%22)%60%20by%20All_Certificates.SSL.ssl_subject_common_name
action.keyindicator.group.0.name                = net_ssl_activity
action.keyindicator.group.0.order               = 0
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Cloud Sessions
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count as current_count from datamodel=Certificates.All_Certificates where earliest=-24h@h latest=+0s nodename=All_Certificates.SSL `cloud_domain_search("All_Certificates.SSL.ssl_subject_common_name")` | appendcols [tstats `summariesonly` count as historical_count from datamodel=Certificates.All_Certificates where earliest=-48h@h latest=-24h@h nodename=All_Certificates.SSL `cloud_domain_search("All_Certificates.SSL.ssl_subject_common_name")`] | `get_delta`

[SSL - Short Duration Certificates]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Short Validity Certs
action.keyindicator.subtitle                    = Session Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Certificates.All_Certificates where earliest=-24h@h latest=+0s nodename=All_Certificates.SSL All_Certificates.SSL.ssl_validity_window<7776000 by All_Certificates.SSL.ssl_subject_common_name
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DCertificates.All_Certificates%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20nodename%3DAll_Certificates.SSL%20All_Certificates.SSL.ssl_validity_window%3C7776000%20by%20All_Certificates.SSL.ssl_subject_common_name
action.keyindicator.group.0.name                = net_ssl_activity
action.keyindicator.group.0.order               = 1
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Short Validity Certs 
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count as current_count from datamodel=Certificates.All_Certificates where earliest=-24h@h latest=+0s nodename=All_Certificates.SSL All_Certificates.SSL.ssl_validity_window<7776000 | appendcols [tstats `summariesonly` count as historical_count from datamodel=Certificates.All_Certificates where earliest=-48h@h latest=-24h@h nodename=All_Certificates.SSL All_Certificates.SSL.ssl_validity_window<7776000 ] | `get_delta`

[SSL - Expired Certificates]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Expired Certs
action.keyindicator.subtitle                    = Session Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   =
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Certificates.All_Certificates where nodename=All_Certificates.SSL All_Certificates.SSL.ssl_is_valid=0 earliest=-24h@h latest=+0s by All_Certificates.SSL.ssl_subject_common_name
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DCertificates.All_Certificates%20where%20nodename%3DAll_Certificates.SSL%20All_Certificates.SSL.ssl_is_valid%3D0%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20All_Certificates.SSL.ssl_subject_common_name
action.keyindicator.group.0.name                = net_ssl_activity
action.keyindicator.group.0.order               = 3
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Expired Certs
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count as current_count from datamodel=Certificates.All_Certificates where nodename=All_Certificates.SSL All_Certificates.SSL.ssl_is_valid=0 earliest=-24h@h latest=+0s  | appendcols [ | tstats `summariesonly` count as historical_count from datamodel=Certificates.All_Certificates where nodename=All_Certificates.SSL All_Certificates.SSL.ssl_is_valid=0 earliest=-48h@h latest=-24h@h] | `get_delta`

[SSL - Total SSL Sessions]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
action.keyindicator                             = 1
action.keyindicator.title                       = Total SSL Sessions 
action.keyindicator.subtitle                    = Session Count
action.keyindicator.value                       = current_count
action.keyindicator.threshold                   = 
action.keyindicator.delta                       = delta
action.keyindicator.invert                      = false
# | tstats `summariesonly` count from datamodel=Certificates.All_Certificates where earliest=-24h@h latest=+0s nodename=All_Certificates.SSL by All_Certificates.SSL.ssl_subject_common_name
action.keyindicator.drilldown_uri               = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DCertificates.All_Certificates%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20nodename%3DAll_Certificates.SSL%20by%20All_Certificates.SSL.ssl_subject_common_name
action.keyindicator.group.0.name                = net_ssl_activity
action.keyindicator.group.0.order               = 4
dispatch.earliest_time                          = -48h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.timeRangePicker.show            = false
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.visualizations.charting.drilldown       = all
display.visualizations.singlevalue.underLabel   = Total SSL Sessions
display.visualizations.show                     = 1
display.visualizations.type                     = singlevalue
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count as current_count from datamodel=Certificates.All_Certificates where earliest=-24h@h latest=+0s nodename=All_Certificates.SSL | appendcols [ | tstats `summariesonly` count as historical_count from datamodel=Certificates.All_Certificates where earliest=-48h@h latest=-24h@h nodename=All_Certificates.SSL] | `get_delta`

###### Swim Lane Searches ######
[SSL - Expired Certs - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = SSL Expired Certs
action.swimlane.color                             = orange 
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = All_Certificates.src,All_Certificates.dest,src,dest
action.swimlane.drilldown_search                  = | from datamodel:"Certificates"."All_Certificates" | search $constraints$
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Protocol Intelligence
display.page.asset_investigator.0.order           = 3
is_visible                                        = false
request.ui_dispatch_app                           = SplunkEnterpriseSecuritySuite
search                                            = | tstats `summariesonly` count, values(All_Certificates.src) as src, values(All_Certificates.SSL.ssl_subject_common_name) as subject_common_name from datamodel=Certificates.All_Certificates where $constraints$ nodename=All_Certificates.SSL All_Certificates.SSL.ssl_is_valid=0 by _time span=$span$


#####################
## Vulnerabilities
#####################

###### Key Indicator Searches ######
[Vuln - Total Vulnerabilities]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Total Vulns
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Vulnerabilities.Vulnerabilities where earliest=-30d@d latest=+0s `cim_filter_vuln_severity("Vulnerabilities")` by Vulnerabilities.signature,Vulnerabilities.dest  
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DVulnerabilities.Vulnerabilities%20where%20earliest%3D-30d%40d%20latest%3D%2B0s%20%60cim_filter_vuln_severity(%22Vulnerabilities%22)%60%20by%20Vulnerabilities.signature%2CVulnerabilities.dest%20%20
action.keyindicator.group.0.name              = vuln_center
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -60d@d
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Total Vulns
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count from datamodel=Vulnerabilities.Vulnerabilities where earliest=-30d@d latest=+0s `cim_filter_vuln_severity("Vulnerabilities")` by Vulnerabilities.signature,Vulnerabilities.dest | stats count as current_count | appendcols [| tstats `summariesonly` count from datamodel=Vulnerabilities.Vulnerabilities where earliest=-60d@d latest=-30d@d `cim_filter_vuln_severity("Vulnerabilities")` by Vulnerabilities.signature,Vulnerabilities.dest | stats count as historical_count] | `get_delta`

[Vuln - Vulnerable System Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Vulnerable Systems
action.keyindicator.subtitle                  = System Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Vulnerabilities.Vulnerabilities where earliest=-30d@d latest=+0s `cim_filter_vuln_severity("Vulnerabilities")` by Vulnerabilities.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DVulnerabilities.Vulnerabilities%20where%20earliest%3D-30d%40d%20latest%3D%2B0s%20%60cim_filter_vuln_severity(%22Vulnerabilities%22)%60%20by%20Vulnerabilities.signature%2CVulnerabilities.dest%20%20
action.keyindicator.group.0.name              = vuln_center
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -60d@d
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Vulnerable Systems
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Vulnerabilities.dest) as current_count from datamodel=Vulnerabilities.Vulnerabilities where earliest=-30d@d latest=+0s `cim_filter_vuln_severity("Vulnerabilities")` | appendcols [| tstats `summariesonly` estdc(Vulnerabilities.dest) as historical_count from datamodel=Vulnerabilities.Vulnerabilities where earliest=-60d@d latest=-30d@d `cim_filter_vuln_severity("Vulnerabilities")`] | `get_delta`

[Vuln - Average Vulns Per System]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Vulns Per System
action.keyindicator.subtitle                  = Average Count
action.keyindicator.value                     = current_avg
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` dc(Vulnerabilities.signature) as signature_count from datamodel=Vulnerabilities.Vulnerabilities where earliest=-30d@d latest=+0s `cim_filter_vuln_severity("Vulnerabilities")` by Vulnerabilities.dest | `drop_dm_object_name("Vulnerabilities")` 
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20dc(Vulnerabilities.signature)%20as%20signature_count%20from%20datamodel%3DVulnerabilities.Vulnerabilities%20where%20earliest%3D-30d%40d%20latest%3D%2B0s%20%60cim_filter_vuln_severity(%22Vulnerabilities%22)%60%20by%20Vulnerabilities.dest%20%7C%20%60drop_dm_object_name(%22Vulnerabilities%22)%60%20
action.keyindicator.group.0.name              = vuln_center
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -60d@d
dispatch.latest_time                          = now
display.general.enablePreview                 = 0
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Average Vulns Per System
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` dc(Vulnerabilities.signature) as signature_count from datamodel=Vulnerabilities.Vulnerabilities where earliest=-30d@d latest=+0s `cim_filter_vuln_severity("Vulnerabilities")` by Vulnerabilities.dest | `drop_dm_object_name("Vulnerabilities")` | stats avg(signature_count) as current_avg | appendcols [| tstats `summariesonly` dc(Vulnerabilities.signature) as signature_count from datamodel=Vulnerabilities.Vulnerabilities where earliest=-60d@d latest=-30d@d `cim_filter_vuln_severity("Vulnerabilities")` by Vulnerabilities.dest | `drop_dm_object_name("Vulnerabilities")` | stats avg(signature_count) as historical_avg] | `get_delta(current_avg,historical_avg)`

[Vuln - Percentage Of Vulnerable Systems]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Vulnerable Systems
action.keyindicator.subtitle                  = Percent Vulnerable
action.keyindicator.value                     = current_percent
action.keyindicator.value_suffix              = %
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = 
# | tstats `summariesonly` values(Vulnerabilities.severity) as severity from datamodel=Vulnerabilities.Vulnerabilities by Vulnerabilities.dest | `drop_dm_object_name("Vulnerabilities")` 
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20values(Vulnerabilities.severity)%20as%20severity%20from%20datamodel%3DVulnerabilities.Vulnerabilities%20by%20Vulnerabilities.dest%20%7C%20%60drop_dm_object_name(%22Vulnerabilities%22)%60%20
action.keyindicator.invert                    = false
action.keyindicator.group.0.name              = vuln_center
action.keyindicator.group.0.order             = 1
dispatch.earliest_time                        = -30d@d
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Percent Of Systems Vulnerable
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` values(Vulnerabilities.severity) as severity from datamodel=Vulnerabilities.Vulnerabilities by Vulnerabilities.dest | `drop_dm_object_name("Vulnerabilities")` | eval filtered_severity=mvfilter((severity!="informational" AND severity!="low")) | stats count(eval(isnotnull(severity))) as total_systems,count(eval(isnotnull(filtered_severity))) as vulnerable_systems | eval current_percent=round((vulnerable_systems*100)/total_systems,1) | fillnull value="?" current_percent

[Vuln - Average Vulnerability Age]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Vulnerability Age
action.keyindicator.subtitle                  = Average days
action.keyindicator.value                     = current_avg
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = 
action.keyindicator.invert                    = false
# | tstats `summariesonly` min(_time) as firstTime,max(_time) as lastTime,count from datamodel=Vulnerabilities.Vulnerabilities by Vulnerabilities.signature,Vulnerabilities.dest | `drop_dm_object_name("Vulnerabilities")` | where firstTime!=lastTime AND (now()-lastTime)<2592000
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20min(_time)%20as%20firstTime%2Cmax(_time)%20as%20lastTime%2Ccount%20from%20datamodel%3DVulnerabilities.Vulnerabilities%20by%20Vulnerabilities.signature%2CVulnerabilities.dest%20%7C%20%60drop_dm_object_name(%22Vulnerabilities%22)%60%20%7C%20where%20firstTime!%3DlastTime%20AND%20(now()-lastTime)%3C2592000
action.keyindicator.group.0.name              = vuln_center
action.keyindicator.group.0.order             = 4
dispatch.earliest_time                        = -90d@d
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Average Vulnerability Age
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | `vulnerability_tracker(lastTime)` | where firstTime!=lastTime | eval dayDiff=(lastTime-firstTime)/86400 | stats avg(dayDiff) as current_avg

###### Generating Searches ######
[Network - Vulnerability Tracker - Lookup Gen]
action.customsearchbuilder.enabled = 1
action.customsearchbuilder.routine = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec    = {\
    "version":      "1.0", \
    "search": {\
        "datamodel":     "Vulnerabilities",\
        "object":        "Vulnerabilities",\
        "earliest":      "-70m@m",\
        "latest":        "+0s",\
        "eventFilter":   "'Vulnerabilities.severity' != \"informational\" AND 'Vulnerabilities.severity' != \"low\"",\
        "aggregates":    [{"function":"min","attribute":"_time","alias":"firstTime"},\
                          {"function":"max","attribute":"_time","alias":"lastTime"}],\
        "splitby":       [{"attribute":"Vulnerabilities.signature","alias":"signature"},\
                          {"attribute":"Vulnerabilities.dest","alias":"dest"}],\
        "summariesonly": true,\
        "outputlookup":  "vulnerability_tracker",\
        "retention":     {\
            "earliestTime":"-5y",\
            "timeField":"lastTime",\
            "timeFormat":"%s"\
        }\
    }\
}
cron_schedule                      = 50 * * * *
description                        = Maintains a list of Vulnerabilities by signature, destination and the first and last time they were seen.
dispatch.earliest_time             = -70m@m
dispatch.latest_time               = +0s
enableSched                        = true
is_visible                         = false
request.ui_dispatch_app            = SplunkEnterpriseSecuritySuite
schedule_window                    = 5
search                             = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Vulnerabilities"."Vulnerabilities" where    "Vulnerabilities.severity" != "informational" AND "Vulnerabilities.severity" != "low" by "Vulnerabilities.signature","Vulnerabilities.dest"  | rename "Vulnerabilities.signature" as "signature","Vulnerabilities.dest" as "dest" | inputlookup append=T "vulnerability_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "signature","dest" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "vulnerability_tracker" | stats count

###### Report Searches ######
[Vuln - Top Vulnerabilities]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -30d@d
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(Vulnerabilities.dest) as dest_count from datamodel=Vulnerabilities.Vulnerabilities where * `cim_filter_vuln_severity("Vulnerabilities")` by Vulnerabilities.signature | `drop_dm_object_name("Vulnerabilities")` | sort 10 - dest_count

[Vuln - Most Vulnerable Hosts]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -30d@d
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.chart.stackMode = stacked
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` dc(Vulnerabilities.signature) as vuln_count from datamodel=Vulnerabilities.Vulnerabilities by Vulnerabilities.severity,Vulnerabilities.dest | chart useother=`useother` first(vuln_count) over Vulnerabilities.dest by Vulnerabilities.severity | `drop_dm_object_name("Vulnerabilities")` | eval total=case(critical>0 AND high>0,critical+high,critical>0,critical,high>0,high,1==1,0) | eval subTotal=case(medium>0 AND low>0,medium+low,medium>0,medium,low>0,low,1==1,0) | eval subSubTotal=case(informational>0 AND unknown>0,informational+unknown,informational>0,informational,unknown>0,unknown,1==1,0) | sort 10 - total,subTotal,subSubTotal | fields - total,subTotal,subSubTotal

[Vuln - Vulnerabilities By Category]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -30d@d
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(Vulnerabilities.signature) as vuln_count from datamodel=Vulnerabilities.Vulnerabilities by Vulnerabilities.category,Vulnerabilities.dest | `drop_dm_object_name("Vulnerabilities")` | stats sum(vuln_count) as count by category

[Vuln - Vulnerabilities By Severity]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(Vulnerabilities.signature) as vuln_count from datamodel=Vulnerabilities.Vulnerabilities by Vulnerabilities.severity,Vulnerabilities.dest | `drop_dm_object_name("Vulnerabilities")` | stats sum(vuln_count) as count by severity

[Vuln - New Vulnerabilities]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -30d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | `vuln_signature_reference(firstTime)` | `uitime(firstTime)` | sort 100 - firstTime | `makemv(cve)` | fields firstTime,signature,cve,vendor_product

[Vuln - Scan Activity Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -365d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` dc(Vulnerabilities.dest) from datamodel=Vulnerabilities.Vulnerabilities by _time span=1d | timechart minspan=1d dc(Vulnerabilities.dest) as "dc(dest)"

[Vuln - Vulnerabilities By Age]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -90d@d
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | `vulnerability_tracker(lastTime)` | where firstTime!=lastTime | eval timeDiff=lastTime-firstTime | sort 100 - timeDiff,lastTime | eval "Age (days)"=round(timeDiff/86400,1) | `uitime(firstTime)` | `uitime(lastTime)` | fields firstTime,lastTime,signature,dest,"Age (days)"

[Vuln - Delinquent Scanning]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -365d@d
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` min(_time) as firstTime,max(_time) as lastTime from datamodel=Vulnerabilities.Vulnerabilities by Vulnerabilities.dest | `drop_dm_object_name("Vulnerabilities")` | `dayDiff(lastTime)` | eval dayDiff=round(dayDiff,1) | `uitime(firstTime)` | `uitime(lastTime)` | sort 100 + lastTime


###################
## Web
###################

###### Correlation Searches ######
[Web - Abnormally High Number of HTTP Method Events By Src - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Abnormally High Number of HTTP Method Events By Src
action.correlationsearch.related_searches = ["Web - Web Event Count By Src By HTTP Method Per 1d - Context Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = network
action.notable.param.severity             = medium
action.notable.param.rule_title           = Abnormally High Number of HTTP $http_method$ Request Events By $src$
action.notable.param.rule_description     = A system ($src$) was detected as generating an abnormally high number of $http_method$ request events.
action.notable.param.nes_fields           = src,http_method
action.notable.param.drilldown_name       = View Web Activity on $src$
action.notable.param.drilldown_search     = | from datamodel:"Web"."Web" | search src="$src$"
action.notable.param.default_owner        = 
action.notable.param.default_status       = 
action.risk                               = 1
action.risk.param._risk_object            = src
action.risk.param._risk_object_type       = system
action.risk.param._risk_score             = 60
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = src, http_method
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 50 * * * *
description                               = Alerts when a host has an abnormally high number of HTTP requests by http method.
disabled                                  = True
dispatch.earliest_time                    = -1450m@m
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
schedule_window                           = 5
search                                    = | tstats `summariesonly` count as web_event_count from datamodel=Web.Web by Web.src, Web.http_method | `drop_dm_object_name("Web")` | xswhere web_event_count FROM count_by_http_method_by_src_1d in web by http_method is above high

[Network - Excessive HTTP Failure Responses - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Excessive HTTP Failure Responses
action.email.sendresults              = 0
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Web",\
         "object":        "Web",\
         "earliest":      "-70m@m",\
         "latest":        "+0s",\
         "eventFilter":   "('Web.status'=400 OR 'Web.status'=403 OR 'Web.status'=404 OR 'Web.status'=411 OR 'Web.status'=500 OR 'Web.status'=501)",\
         "aggregates":    [{"function": "count"}],\
         "splitby":       [{"attribute": "Web.dest", "alias": "dest"}],\
         "resultFilter":  {"field": "count", "comparator": ">", "value": "50"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest"]\
}
action.notable                        = 1
action.notable.param.security_domain  = network
action.notable.param.severity         = high
action.notable.param.rule_title       = Excessive HTTP Failure Responses ($dest$)
action.notable.param.rule_description = A system ($dest$) was detected sending a high number of HTTP failure responses ($count$).
action.notable.param.nes_fields       = dest
action.notable.param.drilldown_name   = View Web Activity on $dest$
action.notable.param.drilldown_search = | from datamodel:"Web"."Web" | search dest="$dest$"
action.notable.param.default_owner    = 
action.notable.param.default_status   = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest
alert.suppress.period                 = 86300s
alert.track                           = 0
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 40 * * * *
description                           = Alerts when a host generates a lot of HTTP failures in a short span of time
disabled                              = True
dispatch.earliest_time                = -70m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | tstats summariesonly=true allow_old_summaries=true count from datamodel="Web"."Web" where    ("Web.status"=400 OR "Web.status"=403 OR "Web.status"=404 OR "Web.status"=411 OR "Web.status"=500 OR "Web.status"=501) by "Web.dest" | rename "Web.dest" as "dest" | where 'count'>50

###### Generating Searches ######
[Network - User Agent Length Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 10 0,4,8,12,16,20 * * *
description              = Maintains Web user agent length statistics
dispatch.earliest_time   = -90d
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
request.ui_dispatch_app  = SplunkEnterpriseSecuritySuite
schedule_window     	 = 10
search                   = | tstats `summariesonly` min(Web.http_user_agent_length) as min_length,avg(Web.http_user_agent_length) as mean_length,max(Web.http_user_agent_length) as max_length,stdev(Web.http_user_agent_length) as stdev,count as total_count from datamodel=Web.Web where Web.http_user_agent!="unknown" | appendcols [| from inputlookup:standard_deviations | rename stdev as standard_deviation] | filldown | fillnull value=0 min_length,mean_length,max_length,stdev,total_count | `stdev_desired_result(standard_deviation,mean_length,"gt_length")` | `stdev_desired_result(-standard_deviation,mean_length,"lt_length")` | eval search=case(gt_length>0 AND lt_length>0, "(Web.http_user_agent_length>".floor(gt_length)." OR Web.http_user_agent_length<".ceil(lt_length).")",gt_length>0 AND lt_length<=0,"Web.http_user_agent_length>".floor(gt_length),gt_length<=0 AND lt_length>0,"Web.http_user_agent_length<".ceil(lt_length),gt_length<=0 AND lt_length<=0,"Web.http_user_agent_length=-1") | rename standard_deviation as Z | rename total as total_count | fields min_length,mean_length,max_length,stdev,total_count,Z,search | `round(mean_length)` | `round(stdev)` | outputlookup user_agent_length_tracker | stats count

[Network - URL Length Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 30 0,4,8,12,16,20 * * *
description              = Maintains Web url length statistics
dispatch.earliest_time   = -90d
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
request.ui_dispatch_app  = SplunkEnterpriseSecuritySuite
schedule_window     	 = 10
search                   = | tstats `summariesonly` min(Web.url_length) as min_length,avg(Web.url_length) as mean_length,max(Web.url_length) as max_length,stdev(Web.url_length) as stdev,count as total_count from datamodel=Web.Web where Web.url!="unknown" | appendcols [| from inputlookup:standard_deviations | rename stdev as standard_deviation] | filldown | fillnull value=0 min_length,mean_length,max_length,stdev,total_count | `stdev_desired_result(standard_deviation,mean_length,"gt_length")` | `stdev_desired_result(-standard_deviation,mean_length,"lt_length")` | eval search=case(gt_length>0 AND lt_length>0,"(Web.url_length>" .floor(gt_length)." OR Web.url_length<".ceil(lt_length)." OR url_length>".floor(gt_length)." OR url_length<".ceil(lt_length).")",gt_length>0 AND lt_length<=0,"(Web.url_length>".floor(gt_length)." OR url_length>".floor(gt_length).")",gt_length<=0 AND lt_length>0,"(Web.url_length<".ceil(lt_length)." OR url_length<".ceil(lt_length).")",gt_length<=0 AND lt_length<=0,"(Web.url_length=-1 OR url_length=-1)") | rename standard_deviation as Z | rename total as total_count | fields min_length,mean_length,max_length,stdev,total_count,Z,search | `round(mean_length)` | `round(stdev)` | outputlookup url_length_tracker | stats count

###### Key Indicator Searches ######

## HTTP Category Analysis

[Web - HTTP Category Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Unique Categories
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s by Web.category
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Web.category
action.keyindicator.group.0.name              = http_category
action.keyindicator.group.0.order             = 4
action.keyindicator.group.1.name              = web_center
action.keyindicator.group.1.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique HTTP Category Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Web.category) as current_count from datamodel=Web.Web where earliest=-24h@h latest=+0s | appendcols [| tstats `summariesonly` estdc(Web.category) as historical_count from datamodel=Web.Web where earliest=-48h@h latest=-24h@h] | `get_delta`

[Web - HTTP Category Maximum Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Maximum Count
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_max
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s by Web.category | `drop_dm_object_name("Web")`
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Web.category%20%7C%20%60drop_dm_object_name(%22Web%22)%60
action.keyindicator.group.0.name              = http_category
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Maximum Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count as current_max from datamodel=Web.Web where earliest=-24h@h latest=+0s by Web.category | sort 1 - current_max | `drop_dm_object_name("Web")` | eval label=current_max." event(s) for HTTP category: ".category | appendcols [| tstats `summariesonly` count as historical_max from datamodel=Web.Web where earliest=-48h@h latest=-24h@h by Web.category | sort 1 - historical_max | `drop_dm_object_name("Web")`] | fields label,current_max,historical_max | `get_delta(current_max,historical_max)`

[Web - HTTP Category Mean Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Mean Count
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_mean
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
#  | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s by Web.category 
action.keyindicator.drilldown_uri             = search?q=%20%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Web.category%20
action.keyindicator.group.0.name              = http_category
action.keyindicator.group.0.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Mean Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s by Web.category | stats avg(count) as current_mean | appendcols [| tstats `summariesonly` count from datamodel=Web.Web where earliest=-48h@h latest=-24h@h by Web.category | stats avg(count) as historical_mean] | `get_delta(current_mean,historical_mean)`

[Web - HTTP Category Minimum Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Minimum Count
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_min
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
#  | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s by Web.category 
action.keyindicator.drilldown_uri             = search?q=%20%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Web.category%20
action.keyindicator.group.0.name              = http_category
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Minimum Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count as current_min from datamodel=Web.Web where earliest=-24h@h latest=+0s by Web.category | sort 1 + current_min | `drop_dm_object_name("Web")` | eval label=current_min." event(s) for HTTP category: ".category | appendcols [| tstats `summariesonly` count as historical_min from datamodel=Web.Web where earliest=-48h@h latest=-24h@h by Web.category | sort 1 + historical_min | `drop_dm_object_name("Web")`] | fields label,current_min,historical_min | `get_delta(current_min,historical_min)`

[Web - HTTP Category Standard Deviation Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Stdev Count
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_stdev
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
#  | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s by Web.category 
action.keyindicator.drilldown_uri             = search?q=%20%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Web.category%20
action.keyindicator.group.0.name              = http_category
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Standard Deviation Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s by Web.category | stats stdev(count) as current_stdev | appendcols [| tstats `summariesonly` count from datamodel=Web.Web where earliest=-48h@h latest=-24h@h by Web.category | stats stdev(count) as historical_stdev] | `get_delta(current_stdev,historical_stdev)`

## URL Length Analysis

[Web - URL Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Unique URLs
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.url!=unknown by Web.url
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.url!%3Dunknown%20by%20Web.url
action.keyindicator.group.0.name              = url_length
action.keyindicator.group.0.order             = 4
action.keyindicator.group.1.name              = web_center
action.keyindicator.group.1.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique URL Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Web.url) as current_count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.url!=unknown | appendcols [| tstats `summariesonly` estdc(Web.url) as historical_count from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.url!=unknown] | `get_delta`

[Web - URL Maximum Length]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Maximum URL Length
action.keyindicator.subtitle                  = Max Length
action.keyindicator.value                     = current_length
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.url!=unknown by Web.url Web.url_length | sort -Web.url_length
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.url!%3Dunknown%20by%20Web.url%20Web.url_length%20%7C%20sort%20-Web.url_length
action.keyindicator.group.0.name              = url_length
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Maximum URL Length
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` max(Web.url_length) as current_length from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.url!=unknown | appendcols [| tstats `summariesonly` max(Web.url_length) as historical_length from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.url!=unknown] | `get_delta(current_length,historical_length)`

[Web - URL Mean Length]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Mean URL Length
action.keyindicator.subtitle                  = Mean Length
action.keyindicator.value                     = current_length
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.url!=unknown by Web.url Web.url_length | sort -Web.url_length
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.url!%3Dunknown%20by%20Web.url%20Web.url_length%20%7C%20sort%20-Web.url_length
action.keyindicator.group.0.name              = url_length
action.keyindicator.group.0.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Mean URL Length
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` avg(Web.url_length) as current_length from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.url!=unknown | appendcols [| tstats `summariesonly` avg(Web.url_length) as historical_length from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.url!=unknown] | `get_delta(current_length,historical_length)`

[Web - URL Minimum Length]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Minimum URL Length
action.keyindicator.subtitle                  = Min Length
action.keyindicator.value                     = current_length
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.url!=unknown by Web.url Web.url_length | sort -Web.url_length
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.url!%3Dunknown%20by%20Web.url%20Web.url_length%20%7C%20sort%20-Web.url_length
action.keyindicator.group.0.name              = url_length
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Minimum URL Length
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` min(Web.url_length) as current_length from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.url!=unknown | appendcols [| tstats `summariesonly` min(Web.url_length) as historical_length from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.url!=unknown] | `get_delta(current_length,historical_length)`

[Web - URL Length Standard Deviation]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Stdev URL Length
action.keyindicator.subtitle                  = Stdev Length
action.keyindicator.value                     = current_length
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.url!=unknown by Web.url Web.url_length | sort -Web.url_length
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.url!%3Dunknown%20by%20Web.url%20Web.url_length%20%7C%20sort%20-Web.url_length
action.keyindicator.group.0.name              = url_length
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = URL Length Standard Deviation
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` stdev(Web.url_length) as current_length from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.url!=unknown | appendcols [| tstats `summariesonly` stdev(Web.url_length) as historical_length from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.url!=unknown] | `get_delta(current_length,historical_length)`

## HTTP User Agent Analysis

[Web - User Agent Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Unique User Agents
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.http_user_agent!=unknown by Web.http_user_agent
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.http_user_agent!%3Dunknown%20by%20Web.http_user_agent
action.keyindicator.group.0.name              = http_user_agent
action.keyindicator.group.0.order             = 4
action.keyindicator.group.1.name              = web_center
action.keyindicator.group.1.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique User Agents
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Web.http_user_agent) as current_count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.http_user_agent!=unknown | appendcols [| tstats `summariesonly` estdc(Web.http_user_agent) as historical_count from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.http_user_agent!=unknown] | `get_delta`

[Web - User Agent Maximum Length]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Maximum UA Length
action.keyindicator.subtitle                  = Max Length
action.keyindicator.value                     = current_length
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.http_user_agent!=unknown by Web.http_user_agent
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.http_user_agent!%3Dunknown%20by%20Web.http_user_agent
action.keyindicator.group.0.name              = http_user_agent
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Maximum User Agent Length
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` max(Web.http_user_agent_length) as current_length from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.http_user_agent!=unknown | appendcols [| tstats `summariesonly` max(Web.http_user_agent_length) as historical_length from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.http_user_agent!=unknown] | `get_delta(current_length,historical_length)`

[Web - User Agent Mean Length]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Mean UA Length
action.keyindicator.subtitle                  = Mean Length
action.keyindicator.value                     = current_length
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.http_user_agent!=unknown by Web.http_user_agent
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.http_user_agent!%3Dunknown%20by%20Web.http_user_agent
action.keyindicator.group.0.name              = http_user_agent
action.keyindicator.group.0.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Mean User Agent Length
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` avg(Web.http_user_agent_length) as current_length from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.http_user_agent!=unknown | appendcols [| tstats `summariesonly` avg(Web.http_user_agent_length) as historical_length from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.http_user_agent!=unknown] | `get_delta(current_length,historical_length)`

[Web - User Agent Minimum Length]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Minimum UA Length
action.keyindicator.subtitle                  = Min Length
action.keyindicator.value                     = current_length
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.http_user_agent!=unknown by Web.http_user_agent
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.http_user_agent!%3Dunknown%20by%20Web.http_user_agent
action.keyindicator.group.0.name              = http_user_agent
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Minimum User Agent Length
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` min(Web.http_user_agent_length) as current_length from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.http_user_agent!=unknown | appendcols [| tstats `summariesonly` min(Web.http_user_agent_length) as historical_length from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.http_user_agent!=unknown] | `get_delta(current_length,historical_length)`

[Web - User Agent Length Standard Deviation]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Stdev UA Length
action.keyindicator.subtitle                  = Stdev Length
action.keyindicator.value                     = current_length
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.http_user_agent!=unknown by Web.http_user_agent
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.http_user_agent!%3Dunknown%20by%20Web.http_user_agent
action.keyindicator.group.0.name              = http_user_agent
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = User Agent Length Standard Deviation
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` stdev(Web.http_user_agent_length) as current_length from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.http_user_agent!=unknown | appendcols [| tstats `summariesonly` stdev(Web.http_user_agent_length) as historical_length from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.http_user_agent!=unknown] | `get_delta(current_length,historical_length)`

## Web Center
[Web - Destination Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Unique Destinations
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.dest!=unknown by Web.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.http_user_agent!%3Dunknown%20by%20Web.http_user_agent
action.keyindicator.group.0.name              = web_center
action.keyindicator.group.0.order             = 4
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Destinations
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Web.dest) as current_count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.dest!=unknown | appendcols [| tstats `summariesonly` estdc(Web.dest) as historical_count from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.dest!=unknown] | `get_delta`

[Web - Source Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Unique Sources
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.dest!=unknown by Web.src
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Web.dest!%3Dunknown%20by%20Web.src
action.keyindicator.group.0.name              = web_center
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Sources
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Web.src) as current_count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.src!=unknown | appendcols [| tstats `summariesonly` estdc(Web.src) as historical_count from datamodel=Web.Web where earliest=-48h@h latest=-24h@h Web.src!=unknown] | `get_delta`


###### Report Searches ######
[Web - Events Over Time By Action]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
dispatchAs                                      = user
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.chart           = column
display.visualizations.charting.drilldown       = all
display.visualizations.charting.chart.stackMode = stacked
display.visualizations.show                     = 1
display.visualizations.type                     = charting
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | `tstats` count from datamodel=Web.Web by _time,Web.action span=10m | timechart minspan=10m useother=`useother` count by Web.action | `drop_dm_object_name("Web")`

[Web - Events Over Time By Content Type]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
dispatchAs                                      = user
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.chart           = column
display.visualizations.charting.drilldown       = all
display.visualizations.charting.chart.stackMode = stacked
display.visualizations.show                     = 1
display.visualizations.type                     = charting
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | `tstats` count from datamodel=Web.Web by _time,Web.http_content_type span=10m | timechart minspan=10m useother=`useother` count by Web.http_content_type | `drop_dm_object_name("Web")`

[Web - Events Over Time By Method]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
dispatchAs                                      = user
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.chart           = column
display.visualizations.charting.drilldown       = all
display.visualizations.charting.chart.stackMode = stacked
display.visualizations.show                     = 1
display.visualizations.type                     = charting
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | `tstats` count from datamodel=Web.Web by _time,Web.http_method span=10m | timechart minspan=10m useother=`useother` count by Web.http_method | `drop_dm_object_name("Web")`

[Web - Events Over Time By Status]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
dispatchAs                                      = user
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.chart           = column
display.visualizations.charting.drilldown       = all
display.visualizations.charting.chart.stackMode = stacked
display.visualizations.show                     = 1
display.visualizations.type                     = charting
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | `tstats` count from datamodel=Web.Web by _time,Web.status span=10m | timechart minspan=10m useother=`useother` count by Web.status | `drop_dm_object_name("Web")`

[Web - Events Over Time By User Agent]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
dispatchAs                                      = user
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.chart           = column
display.visualizations.charting.drilldown       = all
display.visualizations.charting.chart.stackMode = stacked
display.visualizations.show                     = 1
display.visualizations.type                     = charting
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | `tstats` count from datamodel=Web.Web by _time,Web.http_user_agent span=10m | timechart minspan=10m useother=`useother` count by Web.http_user_agent | `drop_dm_object_name("Web")`

[Web - Total Events By Action]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count from datamodel=Web.Web by Web.action | `drop_dm_object_name("Web")` | sort 10 - count

[Web - Total Events By Content Type]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count from datamodel=Web.Web by Web.http_content_type | `drop_dm_object_name("Web")` | sort 10 - count

[Web - Total Events By Method]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count from datamodel=Web.Web by Web.http_method | `drop_dm_object_name("Web")` | sort 10 - count

[Web - Total Events By Status]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count from datamodel=Web.Web by Web.status | `drop_dm_object_name("Web")` | sort 10 - count

[Web - Total Events By User Agent]
action.email.reportServerEnabled                = 0
alert.track                                     = 0
dispatch.earliest_time                          = -24h@h
dispatch.latest_time                            = now
display.general.enablePreview                   = 1
display.general.type                            = visualizations
display.statistics.rowNumbers                   = 0
display.statistics.wrap                         = 0
display.visualizations.charting.axisTitleY.text = count
display.visualizations.charting.chart           = bar
display.visualizations.charting.drilldown       = all
display.visualizations.chartHeight              = 350
display.visualizations.show                     = 1
request.ui_dispatch_app                         = SplunkEnterpriseSecuritySuite
search                                          = | tstats `summariesonly` count from datamodel=Web.Web by Web.http_user_agent | `drop_dm_object_name("Web")` | sort 10 - count

[Web - Top Sources]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` dc(Web.dest) as dc(dest),dc(Web.url) as dc(url),count,sum(Web.bytes) as bytes from datamodel=Web.Web by Web.src | `drop_dm_object_name("Web")` | sort 100 - bytes

[Web - Top Destinations]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` dc(Web.src) as dc(src),dc(Web.url) as dc(url),count,sum(Web.bytes) as bytes from datamodel=Web.Web by Web.dest | `drop_dm_object_name("Web")` | sort 100 - bytes

[Web - URL Length Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = connect
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` min(Web.url_length),avg(Web.url_length),max(Web.url_length) from datamodel=Web.Web by _time span=10m | timechart minspan=10m min(Web.url_length) as min(length),avg(Web.url_length) as avg(length),max(Web.url_length) as max(length)

## HTTP Category Analysis

[Web - HTTP Category Details]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` max(_time) as lastTime,dc(Web.src) as dc(src),dc(Web.dest) as dc(dest),count from datamodel=Web.Web by Web.category | `drop_dm_object_name("Web")` | join type=outer category [| tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s by _time,Web.category span=`http_category_sparkline_span` | stats sparkline(sum(count),`http_category_sparkline_span`) as sparkline by Web.category | `drop_dm_object_name("Web")`] | `makemv(sparkline,",")` | eventstats avg(count) as mean_count,stdev(count) as stdev | `get_stdev_index(count)` | `round(Z)` | `per_panel_filter("ppf_http_category","category")` | rename ppf_filter as filter | sort -filter,+count | `uitime(lastTime)` | table category,filter,sparkline,dc(src),dc(dest),count,Z,lastTime

[Web - HTTP Category Distribution]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = scatter
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(Web.src) as dc(src),count from datamodel=Web.Web by Web.category | eval category='Web.category' | `per_panel_filter("ppf_http_category","category")` | table category,count,dc(src)

## URL Length Analysis

[Web - URL Length Anomalies]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 1
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` max(_time) as lastTime,latest(Web.url_length) as length,dc(Web.src) as dc(src),dc(Web.dest) as dc(dest),count from datamodel=Web.Web where Web.url!="unknown" [| from inputlookup:url_length_tracker | search Z=2 | fields search] by Web.url | `drop_dm_object_name("Web")` | appendcols[| inputlookup append=T start=0 max=1 url_length_tracker | fields mean_length,stdev] | filldown mean_length,stdev | `get_stdev_index(length)` | `round(Z)`| `per_panel_filter("ppf_url_length","url")` | rename ppf_filter as filter | sort - filter,Z | `uitime(lastTime)` | table url,filter,length,dc(src),dc(dest),count,Z,lastTime

[Web - URL Length Anomalies Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = connect
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | tstats `summariesonly` latest(Web.http_method) as http_method,count from datamodel=Web.Web where Web.url!="unknown" [| from inputlookup:url_length_tracker | search Z=2 | fields search] by _time,Web.url span=10m | `drop_dm_object_name("Web")` | `per_panel_filter("ppf_url_length","url")` | timechart minspan=10m sum(count) as count by http_method

## HTTP User Agent Analysis

[Web - User Agent Details]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 1
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` max(_time) as lastTime,dc(Web.src) as dc(src),dc(Web.dest) as dc(dest),latest(Web.http_user_agent_length) as length,count from datamodel=Web.Web where Web.http_user_agent!=unknown by Web.http_user_agent | `drop_dm_object_name("Web")` | join type=outer http_user_agent [| tstats `summariesonly` count from datamodel=Web.Web where earliest=-24h@h latest=+0s Web.http_user_agent!=unknown by _time,Web.http_user_agent span=`http_user_agent_sparkline_span` | stats sparkline(sum(count),`http_user_agent_sparkline_span`) as sparkline by Web.http_user_agent | `drop_dm_object_name("Web")`] | `makemv(sparkline,",")` | appendcols[| inputlookup append=T start=0 max=1 user_agent_length_tracker | fields mean_length,stdev] | filldown mean_length,stdev | `get_stdev_index(length)` | `round(Z)` | `per_panel_filter("ppf_http_user_agent","http_user_agent")` | rename ppf_filter as filter | sort - filter,Z | `uitime(lastTime)` | table http_user_agent,filter,sparkline,length,dc(src),dc(dest),count,Z,lastTime

[Web - User Agent Distribution]
action.email.reportServerEnabled                 = 0
alert.track                                      = 0
dispatch.earliest_time                           = -24h@h
dispatch.latest_time                             = now
display.general.enablePreview                    = 1
display.general.type                             = visualizations
display.statistics.rowNumbers                    = 0
display.statistics.wrap                          = 0
display.visualizations.charting.chart            = scatter
display.visualizations.charting.drilldown        = all
display.visualizations.charting.legend.placement = none
display.visualizations.show                      = 1
display.visualizations.type                      = charting
request.ui_dispatch_app                          = SplunkEnterpriseSecuritySuite
search                                           = | tstats `summariesonly` latest(Web.http_user_agent_length) as length,count from datamodel=Web.Web where Web.http_user_agent!=unknown by Web.http_user_agent | eval http_user_agent='Web.http_user_agent' | `per_panel_filter("ppf_http_user_agent","http_user_agent")` | table http_user_agent,length,count

###### Swim Lane Searches ######
[Web - Errors - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = HTTP Errors
action.swimlane.color                             = blue
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = Web.src,Web.dest,src,dest
action.swimlane.drilldown_search                  = | from datamodel:"Web"."Web" | search $constraints$
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Protocol Intelligence
display.page.asset_investigator.0.order           = 2
is_visible                                        = false
request.ui_dispatch_app                           = SplunkEnterpriseSecuritySuite
search                                            = | tstats `summariesonly` count,values(Web.src) as src, values(Web.dest) as dest, values(Web.status) as status from datamodel=Web.Web where $constraints$ Web.status!=200 by _time span=$span$


###########
## WHOIS
###########

###### Generating Searches ######

## Network - Whois Tracker - Checkpoint Gen Breakdown
## 1  - get the most recent occurance of all dest values in the web data model
## 2  - rename Web.dest as domain
## 3  - set keep_count=0 for most recent proxy event data
## 4  - input whois_tracker
## 6  - set keep_count=1 for whois_tracker data
## 7  - calculate discard as "sum(keep_count)" by domain
## 8  - discard events w/ discard=0
## 9  - persist _time,domain
## 10 - sort ascending based on time
## 11 - update whois_tracker
## 12 - `outputcheckpoint_whois` == outputcheckpoint or noop
## 13 - empty result set (| stats count)
[Network - Whois Tracker - Checkpoint Gen]
action.email.sendresults = 0
cron_schedule            = 30 * * * *
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
request.ui_dispatch_app  = SplunkEnterpriseSecuritySuite
schedule_window          = 5
search                   = | tstats `summariesonly` max(_time) as _time from datamodel=Web.Web by Web.dest | rename Web.dest as domain | `truncate_domain(domain)` | eval keep_count=0 | inputlookup append=T whois_tracker | eval keep_count=if(isnull(keep_count),1,keep_count) | eventstats sum(keep_count) as discard by domain | where discard==0 | stats min(_time) as _time by domain | sort 0 + _time | outputlookup override_if_empty=false append=T whois_tracker | `outputcheckpoint_whois` | stats count

## Network - Whois Tracker - Lookup Gen Breakdown
## 1 - get the most recent whois data
## 2 - rename fields
## 3 - input whois_tracker
## 4 - Truncate the domain field, to clean up any bad data.
## 5 - consolidate recent whois data and tracker data
## 6 - output whois_tracker
## 7 - empty result set (| stats count)
[Network - Whois Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 15 * * * *
description              = Maintains a list of whois scan data including the resolved_domain (if domain was an IP) and the date the domain was created
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
request.ui_dispatch_app  = SplunkEnterpriseSecuritySuite
schedule_window          = 5
search                   = | tstats `summariesonly` max(_time) as _time,latest(All_Domains.resolved_domain) as resolved_domain,latest(All_Domains.created) as created from datamodel=Domain_Analysis.All_Domains by All_Domains.domain | `drop_dm_object_name("All_Domains")` | inputlookup append=T whois_tracker | `truncate_domain(domain)` | stats max(_time) as _time,latest(resolved_domain) as resolved_domain,latest(created) as created by domain | outputlookup override_if_empty=false whois_tracker | stats count

###### Report Searches ######
[Whois - New Domain Activity]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 1
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` max(_time) as _time,count from datamodel=Web.Web by Web.dest | `drop_dm_object_name("Web")` | `get_whois` | search (created=* NOT created="unknown") | eval "Age (days)"=ceil((now()-created)/86400) | where 'Age (days)'<=30 | eval domain=if(isnull(domain), dest, domain) | `swap_resolved_domain(domain)` | `per_panel_filter("ppf_new_domains","domain")` | rename ppf_filter as filter | eval resolved_domain=if(isnull(resolved_domain) OR resolved_domain=="unknown",null(),resolved_domain) | sort - filter,_time | `uitime(created)` | fields _time,dest,resolved_domain,filter,created,"Age (days)",count

[Whois - New Domain Activity By Age]
action.email.reportServerEnabled                 = 0
alert.track                                      = 0
dispatch.earliest_time                           = -24h@h
dispatch.latest_time                             = now
display.general.enablePreview                    = 1
display.general.type                             = visualizations
display.statistics.rowNumbers                    = 0
display.statistics.wrap                          = 0
display.visualizations.charting.chart            = scatter
display.visualizations.charting.drilldown        = all
display.visualizations.charting.legend.placement = none
display.visualizations.show                      = 1
display.visualizations.type                      = charting
request.ui_dispatch_app                          = SplunkEnterpriseSecuritySuite
search                                           = | tstats `summariesonly` count from datamodel=Web.Web by Web.dest | `drop_dm_object_name("Web")` | `get_whois` | search (created=* NOT created="unknown") | eval age=ceil((now()-created)/86400) | where age<=30 | eval domain=if(isnull(domain), dest, domain) | `swap_resolved_domain(domain)` | `per_panel_filter("ppf_new_domains","domain")` | stats sum(count) as count by age | eval "Age (days)"=age | table "Age (days)",count

[Whois - New Domain Activity By TLD]
action.email.reportServerEnabled                 = 0
alert.track                                      = 0
dispatch.earliest_time                           = -24h@h
dispatch.latest_time                             = now
display.general.enablePreview                    = 1
display.general.type                             = visualizations
display.statistics.rowNumbers                    = 0
display.statistics.wrap                          = 0
display.visualizations.charting.chart            = bar
display.visualizations.charting.drilldown        = all
display.visualizations.charting.legend.placement = none
display.visualizations.show                      = 1
display.visualizations.type                      = charting
request.ui_dispatch_app                          = SplunkEnterpriseSecuritySuite
search                                           = | tstats `summariesonly` count from datamodel=Web.Web by Web.dest | `drop_dm_object_name("Web")` | `get_whois` | search (created=* NOT created="unknown") | eval age=ceil((now()-created)/86400) | where age<=30 | eval domain=if(isnull(domain), dest, domain) | `swap_resolved_domain(domain)` | `per_panel_filter("ppf_new_domains","domain")` | `get_tld(domain)` | stats sum(count) as count by tld | sort 10 - count

[Whois - Registration Details]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 1
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | from datamodel:"Domain_Analysis"."All_Domains" | head 1000 | eval orig_domain=domain,age=ceil(((now() - created) / 86400)) | `swap_resolved_domain(domain)` | `per_panel_filter("ppf_new_domains","domain")` | rename ppf_filter as filter | eval domain=orig_domain | eval resolved_domain=if(isnull(resolved_domain) OR resolved_domain=="unknown",null(),resolved_domain) | sort - filter,_time | `uitime(created)` | `uitime(expires)` | table _time domain resolved_domain filter created age expires nameservers registrant registrar[Network - Excessive DNS Failures - Rule]
disabled = 0

[Vuln - Vulnerable System Count]
action.keyindicator.group.1.name = security_posture
action.keyindicator.group.1.order = 8

[Network - Excessive DNS Queries - Rule]
action.customsearchbuilder.enabled = false
action.customsearchbuilder.spec = {"version":"1.0","searches":[{"datamodel":"Network_Resolution","object":"DNS","earliest":"-70m@m","latest":"+0s","eventFilter":"'DNS.message_type'=\"QUERY\"","aggregates":[{"function":"count"}],"splitby":[{"attribute":"DNS.src","alias":"src"}],"resultFilter":{"field":"count","comparator":">","value":"100"},"summariesonly":"1"}],"alert.suppress":"1","alert.suppress.fields":["src"]}
action.email = 1
action.email.to = cyrus_tam@macroview.com
action.notable.param.extract_assets = ["src","dest","dvc","orig_host"]
action.notable.param.extract_identities = ["src_user","user"]
cron_schedule = */20 * * * *
disabled = 0
dispatch.earliest_time = -20m@m
[Bucket Copy Trigger]
description = Triggers bucket copying
cron_schedule = 17 * * * *
enableSched = 1
search = | archivebuckets

[default]
disabled = 0

[Certificate Expired]
cron_schedule = 00 9 * * *
action.email.reportServerEnabled = 0
request.ui_dispatch_view = search
request.ui_dispatch_app = MTLSOCSSLFramework
action.keyindicator.invert = 0
action.email = 1
display.general.type = statistics
alert.digest_mode = 0
action.email.inline = 1
enableSched = 1
action.email.message.alert = Certificate for $result.Domain$ has expired (was valid until $result.Valid Until$)!\
\
Please contact "$result.Issuer$" to renew certificate.\
\
View Full Report on ssllabs.com: https://www.ssllabs.com/ssltest/analyze.html?d=$result.Domain$&hideResults=on\
\
Impressive? Want some more? https://socprime.com
action.email.subject.alert = Certificate Expired
alert.track = 1
action.email.to = youremail@yourdomain.com
counttype = number of events
quantity = 0
action.email.sendresults = 1
display.page.search.tab = statistics
alert.suppress = 0
description = Additional information on SSL Framework dashboard in "Expired or Revoked Certificates" panel
dispatch.latest_time = now
action.email.useNSSubject = 1
alert.severity = 1
relation = greater than
dispatch.earliest_time = -2d
search = index=ssl_framework product="SSL Framework" | stats count dc(src) as "HostCount" by domainName,certIssuer,validUntil | eval left=round((((strptime(validUntil,"%b %d %Y %H:%M:%S"))-time())/86400), 0) | where left=0 | table domainName "HostCount" certIssuer validUntil left | table domainName HostCount certIssuer validUntil left email | rename domainName as "Domain", certIssuer as "Issuer", validUntil as "Valid Until", left as "Days left", HostCount as "Host Count"

[Certificate Revoked]
cron_schedule = 00 9 * * *
action.email.reportServerEnabled = 0
request.ui_dispatch_view = search
request.ui_dispatch_app = MTLSOCSSLFramework
action.keyindicator.invert = 0
action.email = 1
display.general.type = statistics
alert.digest_mode = 0
action.email.inline = 1
enableSched = 1
action.email.message.alert = Certificate for $result.Domain$ has been revoked (Status = $result.Status$)!\
\
Please contact "$result.Issuer$" to renew certificate.\
\
View Full Report on ssllabs.com: https://www.ssllabs.com/ssltest/analyze.html?d=$result.Domain$&hideResults=on\
\
Impressive? Want some more? https://socprime.com
action.email.subject.alert = Certificate Revoked!
alert.track = 1
action.email.to = youremail@yourdomain.com
counttype = number of events
quantity = 0
action.email.sendresults = 1
display.page.search.tab = statistics
alert.suppress = 0
description = Additional information on SSL Framework dashboard in "Expired or Revoked Certificates" panel
dispatch.latest_time = now
action.email.useNSSubject = 1
alert.severity = 4
relation = greater than
dispatch.earliest_time = -2d
search = index=ssl_framework product="SSL Framework" | where revocStatus=="Bad (revoked)" OR revocStatus="Bad (no revocation information)" | stats count dc(src) as "HostCount" by domainName,certIssuer,validUntil,revocStatus | table domainName HostCount revocStatus certIssuer validUntil | table domainName HostCount revocStatus  certIssuer validUntil | rename domainName as "Domain", certIssuer as "Issuer", validUntil as "Valid Until", HostCount as "Host Count", revocStatus as Status

[Overall Rating Changed]
cron_schedule = 00 9 * * *
action.email.reportServerEnabled = 0
request.ui_dispatch_view = search
request.ui_dispatch_app = MTLSOCSLFramework
action.keyindicator.invert = 0
action.email = 1
action.email.inline = 1
alert.digest_mode = 0
display.general.type = statistics
enableSched = 1
action.email.message.alert = Overall Rating for $result.Domain$ ($result.IP Address$) has changed from $result.Previous Rating$ to $result.Current Rating$.\
\
Please review Full Report on SSL Labs: https://www.ssllabs.com/ssltest/analyze.html?d=$result.Domain$&hideResults=on&latest\
\
\
Impressive? Want some more? https://socprime.com
action.email.subject.alert = Overall Rating of Host Changed!
alert.track = 1
counttype = number of events
quantity = 0
action.email.sendresults = 1
display.page.search.tab = statistics
alert.suppress = 0
description = Additional information on SSL Framework dashboard in "Overall Rating Changed" panel
dispatch.latest_time = now
action.email.useNSSubject = 1
relation = greater than
dispatch.earliest_time = -2d
search = index=ssl_framework product="SSL Framework" | transaction maxevents=2 fields domainName,src | eval "Previous Scan Date"=mvindex(devTime,0) | eval "Last Scan Date"=mvindex(devTime,1) | eval rating_0=mvindex(rating,0) | eval rating_1=mvindex(rating,1) | where rating_0!=rating_1 | table domainName src "Previous Scan Date" rating_0 "Last Scan Date" rating_1 | table domainName src "Previous Scan Date" rating_0 "Last Scan Date" rating_1 | rename domainName as "Domain" src as "IP Address" rating_0 as "Previous Rating" rating_1 as "Current Rating"

[Soon to Expire Certificates]
cron_schedule = 00 9 * * *
action.email.reportServerEnabled = 0
request.ui_dispatch_view = search
request.ui_dispatch_app = MTLSOCSSLFramework
action.keyindicator.invert = 0
action.email = 1
display.general.type = statistics
alert.digest_mode = 0
action.email.inline = 1
enableSched = 1
action.email.message.alert = Certificate for $result.Domain$ expires in $result.Days left$ days ($result.Valid Until$).\
\
Please contact "$result.Issuer$" to renew certificate.\
\
View Full Report on ssllabs.com: https://www.ssllabs.com/ssltest/analyze.html?d=$result.Domain$&hideResults=on\
\
Impressive? Want some more? https://socprime.com
action.email.subject.alert = Certificate Expires in $result.Days left$ days
alert.track = 1
action.email.to = youremail@yourdomain.com
counttype = number of events
quantity = 0
action.email.sendresults = 1
display.page.search.tab = statistics
alert.suppress = 0
description = Additional information on SSL Framework dashboard
dispatch.latest_time = now
action.email.useNSSubject = 1
alert.severity = 1
relation = greater than
dispatch.earliest_time = -2d
search = index=ssl_framework product="SSL Framework" | stats count dc(src) as "HostCount" by domainName certIssuer validUntil | eval left=round((((strptime(validUntil,"%b %d %Y %H:%M:%S"))-time())/86400), 0) | where left=30 OR left=7 OR left=60 OR left=1 | table domainName "HostCount" certIssuer validUntil left | table domainName HostCount certIssuer validUntil left | rename domainName as "Domain", certIssuer as "Issuer", validUntil as "Valid Until", left as "Days left", HostCount as "Host Count"

[Web Server was not scanned for 2 days]
action.email = 1
action.email.inline = 1
action.email.message.alert = Web Server was not scanned by Qualys SSL Labs for 2 days!\
\
Domain Name: $result.Domain Name$\
IP Address: $result.IP Address$\
Last Seen: $result.Last Seen$\
\
\
Impressive? Want some more? https://socprime.com
action.email.reportServerEnabled = 0
action.email.sendresults = 1
action.email.subject.alert = Web Server $result.Domain Name$ ($result.IP Address$) was not scanned for 2 days!
action.email.to = youremail@yourdomain.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
alert.digest_mode = 0
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 00 9 * * *
dispatch.earliest_time = -2d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCSSLFramework
request.ui_dispatch_view = search
search = index=ssl_framework product="SSL Framework" earliest=-3d@d  latest=-2d@d [search index=ssl_framework product="SSL Framework" earliest=-3d@d  latest=-2d@d| dedup  domainName, src | table domainName, src | append [ search index=ssl_framework product="SSL Framework" earliest=-2d@d  latest=now | dedup  domainName, src | table domainName, src] | stats dc(src) AS COUNT by domainName | where COUNT>0 | fields- COUNT] | dedup domainName, src | table domainName, src, devTime | rename domainName AS "Domain Name", src AS "IP Address", devTime AS "Last Seen"

[New Domain or IP Address]
action.email = 1
action.email.inline = 1
action.email.message.alert = New Domain added to SSL Framework or new IP Address in Domain.\
\
Domain Name: $result.Domain Name$\
Valid from: $result.Valid from$\
Valid until: $result.Valid until$\
Issuer: $result.Issuer$\
Overall Rating (by Qualys SSL Labs): $result.Overall Rating$\
Trusted: $result.Trusted$\
Revocation Status: $result.Revocation Status$\
Alternative Names: $result.Alternative Names$\
\
IP Address: $result.IP Address$\
Host Name: $result.Host Name$\
Vulnerabilities: $result.Vulnerabilities$\
\
Qualys SSL Labs Full Report: $result.Qualys SSL Labs Full Report$\
\
\
Impressive? Want some more? https://socprime.com
action.email.reportServerEnabled = 0
action.email.sendresults = 1
action.email.subject.alert = New Domain or IP Address. $result.Domain Name$ ($result.IP Address$)
action.email.to = youremail@yourdomain.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
alert.digest_mode = 0
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 00 9 * * *
description = New Domain added to SSL Framework or new IP Address in Domain.
dispatch.earliest_time = -2d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = MTLSOCSSLFramework
request.ui_dispatch_view = search
search = index=ssl_framework product="SSL Framework" earliest=-1d@d  latest=now [search index=ssl_framework product="SSL Framework" earliest=-1d@d  latest=now| dedup  domainName, src | table domainName, src | append [ search index=ssl_framework product="SSL Framework" earliest=-2d@d  latest=-1d@d | dedup  domainName, src | table domainName, src] | stats dc(src) AS COUNT by domainName | where COUNT=1 | fields- COUNT] | dedup domainName, src | table domainName, validFrom, validUntil, certIssuer, rating, trustStatus, revocStatus, altNames, src, serverHost vulnerabilitiesDomain, fullReportUrl | rename domainName AS "Domain Name", validFrom AS "Valid from", validUntil AS "Valid until", certIssuer AS Issuer, rating AS "Overall Rating", trustStatus AS Trusted, revocStatus AS "Revocation Status", altNames AS "Alternative Names", src AS "IP Address", serverHost AS "Host Name", vulnerabilitiesDomain AS  Vulnerabilities, fullReportUrl AS "Qualys SSL Labs Full Report"
[DMC Alert - Total License Usage Near Daily Quota]
alert.digest_mode = 1 
alert.expires = 7d
counttype = number of events
alert.suppress = 1
alert.suppress.period = 4h
alert.track = 1
action.email.sendresults = 1
action.email.inline = 1
cron_schedule = 3,33 * * * *
description = You have used 90% of your total daily license quota.
dispatch.ttl = 14400
disabled = 1
enableSched = 1
quantity = 0
relation = greater than
search = | rest splunk_server_group=dmc_group_license_master /services/licenser/pools \
| join type=outer stack_id splunk_server [rest splunk_server_group=dmc_group_license_master /services/licenser/groups | search is_active=1 | eval stack_id=stack_ids | fields splunk_server stack_id is_active] \
| search is_active=1 \
| fields splunk_server, stack_id, used_bytes \
| join type=outer stack_id splunk_server [rest splunk_server_group=dmc_group_license_master /services/licenser/stacks | eval stack_id=title | eval stack_quota=quota | fields splunk_server stack_id stack_quota] \
| stats sum(used_bytes) as used_bytes max(stack_quota) as stack_quota by splunk_server \
| eval usedGB=round(used_bytes/1024/1024/1024,3) \
| eval totalGB=round(stack_quota/1024/1024/1024,3) \
| eval percentage=round(usedGB / totalGB, 3)*100 \
| fields splunk_server, percentage, usedGB, totalGB \
| where percentage > 90 \
| rename splunk_server AS Instance, percentage AS "License quota used (%)", usedGB AS "License quota used (GB)", totalGB as "Total license quota (GB)"

[DMC Alert - Missing forwarders]
disabled = 1
alert.suppress = 0
alert.track = 1
auto_summarize.dispatch.earliest_time = -1d@h
counttype = number of events
cron_schedule = */15 * * * *
description = One or more forwarders are missing.
enableSched = 1
quantity = 0
relation = greater than
search = | inputlookup dmc_forwarder_assets\
| search status="missing" \
| rename hostname as Instance

[DMC Alert - Expired and Soon To Expire Licenses]
alert.suppress = 0
alert.digest_mode = 1 
alert.expires = 7d
counttype = number of events
alert.track = 1
action.email.sendresults = 1
action.email.inline = 1
cron_schedule = 3 0 * * *
description = You have licenses that expired or will expire within 2 weeks.
dispatch.ttl = 14400
disabled = 1
enableSched = 1
quantity = 0
relation = greater than
search = | rest splunk_server_group=dmc_group_license_master /services/licenser/licenses \
| join type=outer group_id splunk_server [ \
    rest splunk_server_group=dmc_group_license_master /services/licenser/groups \
    | where is_active = 1 \
    | rename title AS group_id \
    | fields is_active group_id splunk_server] \
| where is_active = 1 \
| eval days_left = floor((expiration_time - now()) / 86400)  \
| where (status == "EXPIRED" OR days_left < 15) AND NOT (quota = 1048576 OR label == "Splunk Enterprise Reset Warnings" OR label == "Splunk Lite Reset Warnings") \
| eval expiration_status = case(days_left >= 14, days_left." days left", days_left < 14 AND days_left >= 0, "Expires soon: ".days_left." days left", days_left < 0, "Expired") \
| eval total_gb=round(quota/1024/1024/1024,3) \
| fields splunk_server label license_hash type group_id total_gb expiration_time expiration_status \
| convert ctime(expiration_time) \
| rename splunk_server AS Instance label AS "Label" license_hash AS "License Hash" type AS Type group_id AS Group total_gb AS Size expiration_time AS "Expires On" expiration_status AS Status

[DMC Alert - Saturated Event-Processing Queues]
alert.digest_mode = 1 
alert.expires = 7d
counttype = number of events
alert.suppress = 1
alert.suppress.period = 1h
alert.track = 1
action.email.sendresults = 1
action.email.inline = 1
cron_schedule = 3,13,23,33,43,53 * * * *
description = One or more of your indexer queues is reporting a fill percentage, averaged over the last 15 minutes, of 90% or more.
disabled = 1
dispatch.ttl = 14400
enableSched = 1 
quantity = 0
relation = greater than
search = | rest splunk_server_group=dmc_group_indexer /services/server/introspection/queues \
| search title=tcpin_queue OR title=parsingQueue OR title=aggQueue OR title=typingQueue OR title=indexQueue \
| eval fifteen_min_fill_perc = round(value_cntr3_size_bytes_lookback / max_size_bytes * 100,2) \
| fields title fifteen_min_fill_perc splunk_server \
| where fifteen_min_fill_perc > 90 \
| rename splunk_server as Instance, title AS "Queue name", fifteen_min_fill_perc AS "Average queue fill percentage (last 15min)"

[DMC Alert - Abnormal State of Indexer Processor]
alert.digest_mode = 1 
alert.expires = 7d
alert.suppress = 1
alert.suppress.period = 30m
alert.track = 1
action.email.sendresults = 1
action.email.inline = 1
counttype = number of events
cron_schedule = 3,8,13,18,23,28,33,38,43,48,53,58 * * * *
description = One or more of your indexers is reporting an abnormal state. 
disabled = 1
dispatch.ttl = 14400
enableSched = 1 
quantity = 0
relation = greater than
search = | rest splunk_server_group=dmc_group_indexer /services/server/introspection/indexer \
| fields splunk_server, average_KBps, status, reason \
| where status != "normal" \
| eval average_KBps = round(average_KBps, 0) \
| eval status= if(status=="normal", status, status." - ".reason) \
| fields - reason \
| rename splunk_server as Instance, average_KBps as "Average KB/s (last 30s)", status as Status 

[DMC Alert - Search Peer Not Responding]
alert.digest_mode = 1
alert.expires = 7d
alert.suppress = 1
alert.suppress.period = 30m
alert.track = 1
action.email.sendresults = 1
action.email.inline = 1
counttype = number of events
cron_schedule = 3,8,13,18,23,28,33,38,43,48,53,58 * * * *
description = One or more of your search peers is currently down.
disabled = 1
dispatch.ttl = 14400
enableSched = 1 
quantity = 0
relation = greater than
search = | rest splunk_server=local /services/search/distributed/peers/ \
| where status!="Up" AND disabled=0 \
| fields peerName, status \
| rename peerName as Instance, status as Status 

[DMC Alert - Critical System Physical Memory Usage]
alert.digest_mode = 1
alert.expires = 7d
alert.suppress = 1
alert.suppress.period = 30m
alert.track = 1
action.email.sendresults = 1
action.email.inline = 1
counttype = number of events
cron_schedule = 3,8,13,18,23,28,33,38,43,48,53,58 * * * *
description = One or more instances has exceeded 90% memory usage.
disabled = 1
dispatch.ttl = 14400
enableSched = 1
quantity = 0
relation = greater than
search = | rest splunk_server_group=dmc_group_* /services/server/status/resource-usage/hostwide \
| eval percentage=round(mem_used/mem,3)*100 \
| where percentage > 90 \
| fields splunk_server, percentage, mem_used, mem \
| rename splunk_server AS Instance, mem AS "Physical memory installed (MB)", percentage AS "Memory used (%)", mem_used AS "Memory used (MB)" 

[DMC Alert - Near Critical Disk Usage]
alert.digest_mode = 1
alert.expires = 7d
counttype = number of events
alert.suppress = 1
alert.suppress.period = 4h
alert.track = 1
action.email.sendresults = 1
action.email.inline = 1
cron_schedule = 3,33 * * * *
description = You have used 80% of your disk capacity.
disabled = 1
enableSched = 1 
quantity = 0
relation = greater than
search = | rest splunk_server_group=dmc_group_* /services/server/status/partitions-space \
| eval free = if(isnotnull(available), available, free) \
| eval usage = capacity - free \
| eval pct_usage = floor(usage / capacity * 100) \
| where pct_usage > 80 \
| stats first(fs_type) as fs_type first(capacity) AS capacity first(usage) AS usage first(pct_usage) AS pct_usage by splunk_server, mount_point \
| eval usage = round(usage / 1024, 2) \
| eval capacity = round(capacity / 1024, 2) \
| rename splunk_server AS Instance mount_point as "Mount Point", fs_type as "File System Type", usage as "Usage (GB)", capacity as "Capacity (GB)", pct_usage as "Usage (%)"

[DMC Asset - Build Standalone Asset Table]
action.populate_lookup = 1
action.populate_lookup.dest = dmc_assets
run_on_startup = 1
cron_schedule = */1 * * * *
run_n_times = 1
disabled = 0
description = This search establishes an updated cache of metadata necessary for the localhost to be included in DMC dashboards. This search will be disabled when user go throught the setup process. and will be re-enabled when user resets to factory mode.
enableSched = 1
dispatchAs = user
search = | `dmc_get_local_instance_asset` \
| rename search_groups AS search_group \
| inputlookup append=true dmc_assets \
| stats last(*) AS * by peerURI, search_group \
| fields peerURI serverName host machine search_group

[DMC Asset - Build Standalone Computed Groups Only]
action.populate_lookup = 1
action.populate_lookup.dest = dmc_assets
disabled = 0
dispatchAs = user
search = | `dmc_get_local_instance_asset` \
| rename search_groups AS search_group \
| fields peerURI serverName host machine search_group

[DMC Asset - Build Full]
action.populate_lookup = 1
action.populate_lookup.dest = dmc_assets
disabled = 0
dispatchAs = user
search = | rest splunk_server=local /services/search/distributed/peers \
| search status=Up disabled=0 \
| eval os = os_name \
| fields guid title peerName host host_fqdn server_roles search_groups cpu_arch os numberOfCores physicalMemoryMB version \
| rename title AS peerURI peerName AS serverName host_fqdn AS machine numberOfCores AS cpu_count physicalMemoryMB AS mem version AS splunk_version server_roles AS inherited_server_roles \
| where isnotnull(mvfind(search_groups,"dmc_group_")) \
| join type=outer peerURI [ \
    | rest splunk_server=local /servicesNS/nobody/splunk_monitoring_console/configs/conf-splunk_monitoring_console_assets \
    | fields title host host_fqdn \
    | rename title AS peerURI host_fqdn AS machine] \
| mvexpand search_groups \
| append [ | `dmc_get_local_instance_asset_in_distributed_mode` ] \
| fields peerURI serverName host machine search_groups \
| rename search_groups AS search_group

[DMC Forwarder - Build Asset Table]
disabled = 1
enableSched = 1
cron_schedule = 3,18,33,48 * * * *
run_on_startup = false
dispatch.earliest_time = -16m@m
dispatch.latest_time = -1m@m
dispatchAs = user
search = `dmc_build_forwarder_assets(1m)` \
| inputlookup append=true dmc_forwarder_assets \
| stats values(forwarder_type) as forwarder_type, max(version) as version, values(arch) as arch, values(os) as os, max(last_connected) as last_connected, values(new_sum_kb) as sum_kb, values(new_avg_tcp_kbps_sparkline) as avg_tcp_kbps_sparkline, values(new_avg_tcp_kbps) as avg_tcp_kbps, values(new_avg_tcp_eps) as avg_tcp_eps by guid, hostname \
| addinfo \
| eval status = if(isnull(sum_kb) or (sum_kb <= 0) or (last_connected < (info_max_time - 900)), "missing", "active") \
| eval sum_kb = round(sum_kb, 2) \
| eval avg_tcp_kbps = round(avg_tcp_kbps, 2) \
| eval avg_tcp_eps = round(avg_tcp_eps, 2) \
| fields guid, hostname, forwarder_type, version, arch, os, status, last_connected, sum_kb, avg_tcp_kbps_sparkline, avg_tcp_kbps, avg_tcp_eps \
| outputlookup dmc_forwarder_assets

# For license usage report dashboard
[DMC License Usage Data Cube]
dispatch.earliest_time = -31d
dispatch.latest_time = -0d
auto_summarize = 0
auto_summarize.dispatch.earliest_time = -1mon@d
auto_summarize.cron_schedule = 3,13,23,33,43,53 * * * *
search = index=_internal source=*license_usage.log* type="Usage" | eval h=if(len(h)=0 OR isnull(h),"(SQUASHED)",h) | eval s=if(len(s)=0 OR isnull(s),"(SQUASHED)",s) | eval idx=if(len(idx)=0 OR isnull(idx),"(UNKNOWN)",idx) | bin _time span=1d | stats sum(b) as b by _time, host, pool, s, st, h, idx

# For DMC Heatmap
[default]
display.visualizations.custom.splunk_monitoring_console.heatmap.showTooltip = true
display.visualizations.custom.splunk_monitoring_console.heatmap.baseColor = #284774
display.visualizations.custom.splunk_monitoring_console.heatmap.showLegend = true
display.visualizations.custom.splunk_monitoring_console.heatmap.showXAxis = true
display.visualizations.custom.splunk_monitoring_console.heatmap.showYAxis = true
display.visualizations.custom.splunk_monitoring_console.heatmap.legendTitle = Instance count
display.visualizations.custom.splunk_monitoring_console.heatmap.xAxis = Time
display.visualizations.custom.splunk_monitoring_console.heatmap.yAxis =
[WannaCry Ransomware Worm Detector - Connection to WannaCry Distribution IP]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to WannaCry Distribution IP" Severity="8" src_ip="$result.src_ip$"  dest_ip=$result.IPAddress$, dest_port="$result.dest_port$"
action.logevent.param.index = wannacry
action.logevent.param.source = wannacry
action.logevent.param.sourcetype = wannacry
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeWannaCryRansomwareWormDetector
request.ui_dispatch_view = search
search = index=* (tag::eventtype="web" OR tag::eventtype="proxy" OR tag::eventtype="communicate" OR tag::eventtype="network") NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rex field=dest "(?<IP_add>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(?<dest_port>\d+)" | rename dest_ip as clientip  | lookup ipdomain clientip  OUTPUT class | search NOT class=*  | rename clientip as IPAddress | join IPAddress [| inputlookup wanna_cry_distribution_ip.csv ] | table  _time,src_ip, IPAddress, dest_port

[WannaCry Ransomware Worm Detector - Connection to WannaCry IP_only ip]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to WannaCry IP" Severity="6" src_ip="$result.src_ip$"  dest_ip=$result.IPAddress$, dest_port="$result.dest_port$"
action.logevent.param.index = wannacry
action.logevent.param.source = wannacry
action.logevent.param.sourcetype = wannacry
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeWannaCryRansomwareWormDetector
request.ui_dispatch_view = search
search = index=* (tag::eventtype="web" OR tag::eventtype="proxy" OR tag::eventtype="communicate" OR tag::eventtype="network") NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rex field=dest "(?<IP_add>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(?<dest_port>\d+)" | rename dest_ip as clientip  | lookup ipdomain clientip  OUTPUT class | search NOT class=*  | rename clientip as IPAddress | join IPAddress  [|inputlookup wanna_cry_ip.csv ] | table src_ip, IPAddress, dest_port

[WannaCry Ransomware Worm Detector - Network Scan on 445 137-139 Port (by WannaCry)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Network Scan on 445 137-139 Port" Severity="8" src_ip="$result.src_ip$" HostsScanned=$result.HostsScanned$
action.logevent.param.index = wannacry
action.logevent.param.source = wannacry
action.logevent.param.sourcetype = wannacry
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeWannaCryRansomwareWormDetector
request.ui_dispatch_view = search
search = index=* ( tag::eventtype="communicate" OR tag::eventtype="network") (dest_port=445 OR dest_port=137 OR dest_port=138 OR dest_port=139 OR dest_port=3389)  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_ip) AS HostsScanned by src_ip, _time |  where HostsScanned >= 30 | dedup src_ip, HostsScanned | table src_ip, HostsScanned, _time

[WannaCry Ransomware Worm Detector - Activity on Windows Hosts by File Names (Sysmon)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by File Names" Severity="8"\
src_ip="$result.ip$" FileName=$result.FileName$
action.logevent.param.index = wannacry
action.logevent.param.source = wannacry
action.logevent.param.sourcetype = wannacry
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeWannaCryRansomwareWormDetector
request.ui_dispatch_view = search
search = index=*  sourcetype="xmlwineventlog:microsoft-windows-sysmon/operational"  (EventDescription="Process Create" OR EventDescription="File Create" ) |rename process as FileName |  join FileName [| inputlookup wanna_cry_hashes.csv | table FileName ] | search FileName!=cmd.exe |  rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip FileName

[WannaCry Ransomware Worm Detector - Activity on Windows Hosts by File Hashes (Sysmon)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by File Hashes" Severity="8"\
src_ip="$result.ip$" Hashes=$result.Hashes$
action.logevent.param.index = wannacry
action.logevent.param.source = wannacry
action.logevent.param.sourcetype = wannacry
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeWannaCryRansomwareWormDetector
request.ui_dispatch_view = search
search = index=*  sourcetype="xmlwineventlog:microsoft-windows-sysmon/operational"  (EventDescription="Process Create" OR EventDescription="File Create" ) | rex field=Hashes mode=sed "s/SHA256=//g" | rex field=Hashes mode=sed "s/SHA1=//g" | rex field=Hashes mode=sed "s/MD5=//g"| join Hashes [| inputlookup wanna_cry_hashes.csv | table HashMD5 | rename HashMD5 as Hashes] | rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip Hashes

[WannaCry Ransomware Worm Detector - Activity on Windows Hosts by Process (Sysmon)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by Process" Severity="8"\
src_ip="$result.ip$" CommandLine="$result.CommandLine$"
action.logevent.param.index = wannacry
action.logevent.param.source = wannacry
action.logevent.param.sourcetype = wannacry
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeWannaCryRansomwareWormDetector
request.ui_dispatch_view = search
search = index=*  sourcetype="xmlwineventlog:microsoft-windows-sysmon/operational"  (EventDescription="Process Create" OR EventDescription="File Create" ) tasksche.exe OR mssecsvc.exe OR taskdl.exe OR WanaDecryptor OR taskhsvc.exe OR taskse.exe OR\
    (DISABLED vdsldr.exe OR wbengine.exe) OR \
    "@Please_Read_Me@.txt" OR "@WanaDecryptor@.exe" OR \
    ".WNCRYT" OR ".WNCRY" OR ".wnry" OR ".wcry" OR \
    (wbadmin delete catalog) OR \
    (vssadmin delete shadows all quiet) OR \
    (cscript.exe nologo m.vbs) OR \
    (icacls grant "Everyone:F /T /C /Q") OR (icacls . /grant Everyone:F /T /C /Q) OR (C:\mssecsvc.exe) OR (C:\WINDOWS\tasksche.exe /i) OR (C:\mssecsvc.exe -m security) OR (cmd.exe /c 'C:\ProgramData\helgycvyviihxp363\tasksche.exe') OR (C:\ProgramData\helgycvyviihxp363\tasksche.exe) OR (attrib +h .) OR (icacls . /grant Everyone:F /T /C /Q) OR taskdl.exe OR (C:\Windows\system32\cmd.exe /c 297451494605691.bat) OR (cscript.exe //nologo m.vbs) OR (@WanaDecryptor@.exe co) OR (TaskData\Tor\taskhsvc.exe) OR (cmd.exe /c start /b @WanaDecryptor@.exe vs) OR (@WanaDecryptor@.exe vs) OR (cmd.exe /c vssadmin delete shadows /all /quiet & wmic shadowcopy delete & bcdedit /set {default} bootstatuspolicy ignoreallfailures & bcdedit /set {default} recoveryenabled no & wbadmin delete catalog -quiet) OR (vssadmin delete shadows /all /quiet) OR (wmic shadowcopy delete) OR (bcdedit /set {default} bootstatuspolicy ignoreallfailures) OR (bcdedit /set {default} recoveryenabled no) OR (wbadmin delete catalog -quiet) OR taskdl.exe OR (taskse.exe C:\ProgramData\helgycvyviihxp363\@WanaDecryptor@.exe) OR (C:\ProgramData\helgycvyviihxp363\@WanaDecryptor@.exe) OR (cmd.exe /c reg add HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\Run /v 'helgycvyviihxp363' /t REG_SZ /d '\'C:\ProgramData\helgycvyviihxp363\tasksche.exe\'' /f) OR (reg add HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\Run /v 'helgycvyviihxp363' /t REG_SZ /d '\'C:\ProgramData\helgycvyviihxp363\tasksche.exe\'' /f) OR taskdl.exe OR (taskse.exe C:\ProgramData\helgycvyviihxp363\@WanaDecryptor@.exe) OR (C:\ProgramData\helgycvyviihxp363\@WanaDecryptor@.exe) OR (C:\Windows\system32\wbengine.exe) | rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip CommandLine

[WannaCry Ransomware Worm Detector - Connection to TORPROJECT.ORG]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to TORPROJECT.ORG" Severity="7" src_ip="$result.src_ip$"  domain=$result.domain$
action.logevent.param.index = wannacry
action.logevent.param.source = wannacry
action.logevent.param.sourcetype = wannacry
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeWannaCryRansomwareWormDetector
request.ui_dispatch_view = search
search = index=* tag=proxy url=*torproject.org* NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rex field=url "((?:http(?:s)?:\/\/)?(?<domain>[\w\-\.]+)(?:\:|\/)?(?: \d+)?[^$]*)" | table _time src_ip domain

[WannaCry Ransomware Worm Detector - Connections to External Multiple Hosts (by WannaCry)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connections to External Multiple Hosts (by WannaCry)" Severity="5" src_ip="$result.src_ip$" HostsScanned=$result.HostsScanned$
action.logevent.param.index = wannacry
action.logevent.param.source = wannacry
action.logevent.param.sourcetype = wannacry
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
disabled = 1
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeWannaCryRansomwareWormDetector
request.ui_dispatch_view = search
search = index=* ( tag::eventtype="communicate" OR tag::eventtype="network")   NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rename dest_ip as clientip  | lookup ipdomain clientip  OUTPUT class | search NOT class=*  | rename clientip as dest_ip | bucket _time span=60 | eventstats dc(dest_ip) AS HostsScanned by src_ip, _time |  where HostsScanned >= 14 | dedup src_ip, HostsScanned | table src_ip, HostsScanned, _time

[WannaCry Ransomware Worm Detector - Connection to WannaCry hosts]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to WannaCry hosts" Severity="8" src_ip="$result.src_ip$"  domain=$result.domain$
action.logevent.param.index = wannacry
action.logevent.param.source = wannacry
action.logevent.param.sourcetype = wannacry
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimeWannaCryRansomwareWormDetector
request.ui_dispatch_view = search
search = index=* tag=proxy NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rex field=url "((?:http(?:s)?:\/\/)?(?<domain>[\w\-\.]+)(?:\:|\/)?(?: \d+)?[^$]*)" |join domain [|inputlookup wanna_cry_hosts.csv | rename HostName as domain]| table _time src_ip domain

###### Lookup Generating Searches ######

## CIM - Vendor Product Tracker - Lookup Gen Breakdown
##  1 - get vendor_product values from Malware data model
##  2 - field renaming
##  3 - set model="Malware"
##  4 - get vendor_product values from Network_Traffic data model
##  5 - field renaming
##  6 - set model="Network_Traffic"
##  7 - get vendor_product values from Intrusion_Detection data model
##  8 - field renaming
##  9 - set model="Intrusion_Detection"
## 10 - get vendor_product values from Vulnerability namespace
## 11 - field renaming
## 12 - set model="Vulnerabilities"
## 13 - consolidate vendor_product values
## 14 - input existing values
## 15 - consolidate vendor_product values for the second time
## 16 - write lookup
## 17 - purge results
[CIM - Vendor Product Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule = 5,20,35,50 * * * *
description = Maintains a list of vendor_product values and the first and list time they have been seen
dispatch.earliest_time = -30m@m
dispatch.latest_time = +0s
enableSched = 0
is_visible = false
search = | tstats prestats=true summariesonly=true min(_time),max(_time) from datamodel=Malware.Malware_Attacks by Malware_Attacks.vendor_product | `drop_dm_object_name("Malware_Attacks")` | eval model="Malware" | tstats prestats=true summariesonly=true append=true min(_time),max(_time) from datamodel=Network_Traffic.All_Traffic by All_Traffic.vendor_product | `drop_dm_object_name("All_Traffic")` | eval model=if(isnull(model),"Network_Traffic",model) | tstats prestats=true summariesonly=true append=true min(_time),max(_time) from datamodel=Intrusion_Detection.IDS_Attacks by IDS_Attacks.vendor_product | `drop_dm_object_name("IDS_Attacks")` | eval model=if(isnull(model),"Intrusion_Detection",model) | tstats prestats=true summariesonly=true append=true min(_time),max(_time) from datamodel=Vulnerabilities.Vulnerabilities by Vulnerabilities.vendor_product | `drop_dm_object_name("Vulnerabilities")` | eval model=if(isnull(model),"Vulnerabilities",model) | stats min(_time) as firstTime,max(_time) as lastTime by vendor_product,model | inputlookup append=true cim_vendor_product_tracker | stats min(firstTime) as firstTime,max(lastTime) as lastTime by vendor_product,model | outputlookup cim_vendor_product_tracker | stats count


###### Report Searches ######
[CIM - Top Data Model Accelerations]
description            = Maintains a data cube of DMA statistics for use in Datamodel Audit view
dispatchAs             = user
dispatch.latest_time   = now
is_visible             = false
search                 = | `datamodel("Splunk_Audit", "Datamodel_Acceleration")` | `drop_dm_object_name("Datamodel_Acceleration")` | join type=outer last_sid [| rest splunk_server=local count=0 /services/search/jobs reportSearch=summarize* | rename sid as last_sid | fields last_sid,runDuration] | eval "size(MB)"=round(size/1048576,1), "retention(days)"=if(retention==0,"unlimited",round(retention/86400,1)), "complete(%)"=round(complete*100,1), "runDuration(s)"=round(runDuration,1)

[CIM - Top Data Model Accelerations By Size]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
search                                    = | `datamodel("Splunk_Audit", "Datamodel_Acceleration")` | `drop_dm_object_name("Datamodel_Acceleration")` | eval size(MB)=size/1048576 | sort 100 - size | table datamodel,size(MB)

[CIM - Top Data Model Accelerations By Run Duration]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
search                                    = | `datamodel("Splunk_Audit", "Datamodel_Acceleration")` | `drop_dm_object_name("Datamodel_Acceleration")` | join type=outer last_sid [| rest splunk_server=local count=0 /services/search/jobs reportSearch=summarize* | rename sid as last_sid | fields last_sid,runDuration] | sort 100 - runDuration | table datamodel,runDuration

[CIM - Data Model Acceleration Details]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `datamodel("Splunk_Audit", "Datamodel_Acceleration")` | `drop_dm_object_name("Datamodel_Acceleration")` | eval size(MB)=round(size/1048576,1) | eval retention(days)=retention/86400 | eval complete(%)=round(complete*100,1) | sort 100 + datamodel | fieldformat earliest=strftime(earliest, "%m/%d/%Y %H:%M:%S") | fieldformat latest=strftime(latest, "%m/%d/%Y %H:%M:%S") | fields datamodel,app,cron,retention(days),earliest,latest,is_inprogress,complete(%),size(MB),last_error

###### Correlation Searches ######
[Audit - Anomalous Audit Trail Activity Detected - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Anomalous Audit Trail Activity Detected
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Change",\
         "object":        "Auditing_Changes",\
         "earliest":      "rt-5m@m",\
         "latest":        "rt+5m@m",\
         "eventFilter":   "('All_Changes.action'=\"cleared\" OR 'All_Changes.action'=\"stopped\")",\
         "aggregates":    [{"function": "max", "attribute": "_time", "alias": "lastTime"},\
                           {"function": "latest", "attribute": "_raw", "alias": "orig_raw"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "All_Changes.dest", "alias": "dest"},\
                           {"attribute": "All_Changes.result", "alias": "signature"}\
                          ],\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest","signature"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = audit
action.notable.param.severity         = low
action.notable.param.rule_title       = Anomalous Audit Trail Activity Detected On $dest$
action.notable.param.rule_description = Anomalous audit trail activity (such as clearing or deletion of log entries) was noted on the device $dest$
action.notable.param.nes_fields       = dest,signature
action.notable.param.drilldown_name   = View anomalous audit trail activity on device $dest$
action.notable.param.drilldown_search = tag=audit (tag=stop OR tag=delete) dest="$dest$"
action.notable.param.default_status   =
action.notable.param.default_owner    =
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 40
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest,signature
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Discovers anomalous activity such as the deletion of or clearing of log files. Attackers oftentimes clear the log files in order to hide their actions, therefore, this may indicate that the system has been compromised.
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Change"."Auditing_Changes" | where ('action'="cleared" OR 'action'="stopped") | stats max(_time) as "lastTime",latest(_raw) as "orig_raw",count by "dest","result" | rename "result" as "signature"

[Audit - Expected Host Not Reporting - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Expected Host Not Reporting
action.email.sendresults              = 0
action.risk                           = 1
action.risk.param._risk_object        = host
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
action.notable                        = 1
action.notable.param.security_domain  = audit
action.notable.param.severity         = medium
action.notable.param.rule_title       = Expected Host Not Reporting ($orig_host$)
action.notable.param.rule_description = The Splunk device $orig_host$ is expected to be forwarding data to Splunk and has not in the last $dayDiff$ days.
action.notable.param.nes_fields       = orig_host
action.notable.param.drilldown_name   = View events from $orig_host$
action.notable.param.drilldown_search = host="$orig_host$"
action.notable.param.default_status   =
action.notable.param.default_owner    =
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = host
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 0,15,30,45 * * * *
description                           = Discovers hosts that are longer reporting events but should be submitting log events. This rule is used to monitor hosts that you know should be providing a constant stream of logs in order to determine why the host has failed to provide log data.
disabled                              = True
dispatch.earliest_time                = 0
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
search                                = | `host_eventcount(30,2)` | search is_expected=true | `ctime(lastTime)` | fields + host,lastTime,is_expected,dayDiff

[Audit - Personally Identifiable Information Detection - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Personally Identifiable Information Detected
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = audit
action.notable.param.severity         = high
action.notable.param.rule_title       = Personally Identifiable Information Detected
action.notable.param.rule_description = Splunk has detected potentially sensitive information ($pii$ issued by $iin_issuer$) in the following event.
action.notable.param.nes_fields       = pii
action.notable.param.drilldown_name   = View detected PII for $pii$
action.notable.param.drilldown_search = NOT sourcetype=stash | `get_integer_seq` | lookup luhn_lite_lookup integer_seq OUTPUTNEW pii,pii_clean | search pii="$pii$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = host
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = pii_hash
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects personally identifiable information (PII) in log files. Some software will inadvertently provide sensitive information in log files and thus causing the information to be exposed unnecessarily to those reviewing the log files.
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = NOT sourcetype=stash | `get_integer_seq` | lookup luhn_lite_lookup integer_seq OUTPUTNEW pii,pii_clean | eval pii_length=len(pii_clean) | lookup iin_lookup iin as pii_clean,length as pii_length OUTPUTNEW iin_issuer | search iin_issuer=* | `get_event_id` | fields + event_id,_raw,host,pii,iin_issuer | eval pii_hash=sha1(pii)

[Audit - Potential Gap in Data - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Potential Gap in Data
action.email.sendresults              = 0
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Splunk_Audit",\
         "object":        "Scheduler_Activity",\
         "earliest":      "-10m",\
         "latest":        "-5m",\
         "eventFilter":   "'Scheduler_Activity.status'=\"success\" AND ('Scheduler_Activity.app' LIKE \"Splunk_%\" OR 'Scheduler_Activity.app' LIKE \"SA-%\" OR 'Scheduler_Activity.app' LIKE \"DA-%\" OR 'Scheduler_Activity.app'=\"SplunkEnterpriseSecuritySuite\" OR 'Scheduler_Activity.app'=\"SplunkPCIComplianceSuite\")",\
         "aggregates":    [{"function": "count"}],\
         "resultFilter":  {"field": "count", "comparator": "=", "value": "0"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["const_dedup_id"]\
}
action.notable                        = 1
action.notable.param.security_domain  = audit
action.notable.param.severity         = medium
action.notable.param.rule_title       = No Saved Searches Executed Recently
action.notable.param.rule_description = No saved searches were recently executed over a five minute period. If saved searches do not execute then there may be gaps in summary data.
action.notable.param.nes_fields       = 
action.notable.param.drilldown_name   = View search scheduler log
action.notable.param.drilldown_search = | from datamodel:"Splunk_Audit"."Scheduler_Activity" | where 'status'="success" AND ('app'="Splunk_*" OR 'app'="SA-*" OR 'app'="DA-*" OR 'app'="SplunkEnterpriseSecuritySuite" OR 'app'="SplunkPCIComplianceSuite")
action.notable.param.default_status   =
action.notable.param.default_owner    =
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = const_dedup_id
alert.suppress.period                 = 14400s
alert.track                           = 0
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */2 * * * *
description                           = Detects gaps caused by the failure of the search head. If saved searches do not execute then there may be gaps in summary data.
disabled                              = True
dispatch.earliest_time                = -10m
dispatch.latest_time                  = -5m
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Splunk_Audit"."Scheduler_Activity" | where 'status'="success" AND ('app' LIKE "Splunk_%" OR 'app' LIKE "SA-%" OR 'app' LIKE "DA-%" OR 'app'="SplunkEnterpriseSecuritySuite" OR 'app'="SplunkPCIComplianceSuite") | stats count | where 'count'=0 | eval const_dedup_id="const_dedup_id"

###### Key Indicator Searches ######
[Licensing - Minimum Events Per Day]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Minimum EPD
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = min_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = 
action.keyindicator.invert                    = false
# | `licensing_epd`
action.keyindicator.drilldown_uri             = search?q=%7C%20%60licensing_epd%60
action.keyindicator.group.0.name              = index_auditing
action.keyindicator.group.0.order             = 0
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Minimum EPD
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `licensing_epd` | stats sum(count) as count by _time | stats min(count) as min_count

[Licensing - Average Events Per Day]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Average EPD
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = avg_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = 
action.keyindicator.invert                    = false
# | `licensing_epd`
action.keyindicator.drilldown_uri             = search?q=%7C%20%60licensing_epd%60
action.keyindicator.group.0.name              = index_auditing
action.keyindicator.group.0.order             = 1
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Average EPD
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `licensing_epd` | stats sum(count) as count by _time | stats avg(count) as avg_count

[Licensing - Maximum Events Per Day]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Maximum EPD
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = max_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = 
action.keyindicator.invert                    = false
# | `licensing_epd`
action.keyindicator.drilldown_uri             = search?q=%7C%20%60licensing_epd%60
action.keyindicator.group.0.name              = index_auditing
action.keyindicator.group.0.order             = 2
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Maximum EPD
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `licensing_epd` | stats sum(count) as count by _time | stats max(count) as max_count

[Licensing - Recent Events Per Day]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Recent EPD
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | `licensing_epd`
action.keyindicator.drilldown_uri             = search?q=%7C%20%60licensing_epd%60
action.keyindicator.group.0.name              = index_auditing
action.keyindicator.group.0.order             = 3
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Recent EPD
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `licensing_epd` | stats sum(count) as count by _time | sort 0 -_time | head 2 | table count | transpose | rename "row 1" as current_count,"row 2" as historical_count | `get_delta` | fields delta,*

[Performance - Number Of Systems Not Reporting]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Not Reporting
action.keyindicator.subtitle                  = System Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = 
action.keyindicator.invert                    = false
# | `host_eventcount(30,2)`
action.keyindicator.drilldown_uri             = search?q=%7C%20%60host_eventcount(30%2C2)%60%20%7C%20search%20is_expected%3Dtrue
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Expected Hosts Not Reporting
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | `host_eventcount(30,2)` | search is_expected=true | stats count as current_count

[Performance - Average Run Duration]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Avg Run Duration (s)
action.keyindicator.subtitle                  = 
action.keyindicator.value                     = avg_run_duration
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = 
action.keyindicator.invert                    = false
action.keyindicator.drilldown_uri             = datamodel_audit
dispatch.latest_time                          = now
dispatch.earliest_time                        = -1h@h
dispatchAs                                    = owner
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Avg Run Duration (s)
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
search                                        = | rest splunk_server=local count=0 /services/search/jobs reportSearch=summarize* | fields runDuration | eval runDuration=round(runDuration,2) | stats avg(runDuration) as avg_run_duration


###### Lookup Generating Searches ######
## Audit - Events Per Day - Lookup Gen Breakdown
## 1  - Retrieve idxSummary events
## 1a - Execute at 00:01 for the previous day
## 2  - Bucket events into one day spans
## 3  - Compute event count stats
## 4  - Rename "series" as "index"
## 5  - Set "key" as _time|index for upsert
## 6  - Upsert to licensing_epd
## 7  - Consolidating stats
[Audit - Events Per Day - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 1 0 * * *
description              = Maintains a list of event counts per day per index
disabled                 = False
dispatch.earliest_time   = -1d@d
dispatch.latest_time     = @d
enableSched              = 1
is_visible               = false
schedule_window          = 20
search                   = index=_internal source=*metrics.log* group=thruput name=idxSummary | bin _time span=1d | stats sum(ev) as count by _time,series | rename series as index | eval key=_time."|".index | outputlookup key_field=key licensing_epd | stats count


###### Report Searches ######
[Audit - Event Count Over Time By Top 10 Hosts]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -30d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = area
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = | `tstats` count where index=* [| metadata type=hosts | `lower(host)` | sort 10 - totalCount | fields host | format] by _time,host | timechart useother=`useother` count by host

[Audit - Hosts By Last Report Time]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `host_eventcount` | rename totalCount as count | `uitime(firstTime)` | `uitime(lastTime)` | table host is_expected firstTime lastTime count dayDiff

[Audit - Searches Over Time By Type]
action.email.reportServerEnabled                 = 0
alert.track                                      = 0
dispatch.earliest_time                           = -24h@h
dispatch.latest_time                             = now
dispatchAs                                       = user
display.general.enablePreview                    = 1
display.general.type                             = visualizations
display.statistics.rowNumbers                    = 0
display.statistics.wrap                          = 0
display.visualizations.charting.chart            = column
display.visualizations.charting.chart.stackMode  = stacked
display.visualizations.charting.drilldown        = all
display.visualizations.show                      = 1
display.visualizations.type                      = charting
search                                           = | `tstats` count from datamodel=Splunk_Audit.Search_Activity where (Search_Activity.info="granted" OR (Search_Activity.info="completed" Search_Activity.search_type="subsearch")) by _time,Search_Activity.search_type span=10m | timechart minspan=10m count by Search_Activity.search_type

[Audit - Searches Over Time By User]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
search                                              = | tstats `summariesonly` count from datamodel=Splunk_Audit.Search_Activity where (Search_Activity.info="granted" OR (Search_Activity.info="completed" Search_Activity.search_type="subsearch")) by Search_Activity.user | rename Search_Activity.* as * | sort 10 - count

[Audit - Splunkd Process Utilization]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats `summariesonly` avg(Processes.cpu_load_percent) as avg_cpu_load,avg(Processes.mem_used) as avg_mem_used from datamodel=Endpoint.Processes where Processes.process=*splunkd* by Processes.dest | `drop_dm_object_name("Processes")` | eval "avg_cpu_load (%)"=floor(avg_cpu_load) | eval "avg_mem_used (MB)"=floor(avg_mem_used/1048576) | fields - avg_cpu_load,avg_mem_used | sort 100 - "avg_cpu_load (%)"

[Audit - Splunk Service Start Mode Anomalies]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | tstats `summariesonly` max(_time) as _time,latest(Services.start_mode) as start_mode,latest(Services.status) as status from datamodel=Endpoint.Services where (Services.service=splunkd OR Services.service=splunk) by Services.dest | `drop_dm_object_name("Services")` | search start_mode!=auto | sort 100 + start_mode | fields _time,dest,start_mode,status

[Audit - Top Searches By Run Time]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
search                           = | tstats `summariesonly` first(Search_Activity.search_alias) as search_alias,first(Search_Activity.search) as search,first(Search_Activity.total_run_time) as run_time,first(Search_Activity.user) as user from datamodel=Splunk_Audit.Search_Activity by Search_Activity.search_id | stats first(search_alias) as "search alias",min(run_time),avg(run_time),max(run_time),values(user) as user,count by search | eval "min(run_time)"=round('min(run_time)', 1),"avg(run_time)"=round('avg(run_time)', 1),"max(run_time)"=round('max(run_time)', 1) | sort 500 - "avg(run_time)"

[Audit - Web Service Errors]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.events.fields            = ["source", "sourcetype", "host"]
display.events.list.wrap         = true
display.events.rowNumbers        = false
display.events.type              = list
display.general.enablePreview    = true
display.general.type             = events
search                           = | from datamodel:"Splunk_Audit"."Web_Service_Errors" | head 1000

[Data Protection - Data Integrity Control By Index]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatchAs                       = owner
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
search                           = | rest splunk_server=* count=0 /services/data/indexes search="enableDataIntegrityControl=1" | stats values(splunk_server) as splunk_server by title,enableDataIntegrityControl | rename title as index | fields index,splunk_server,enableDataIntegrityControl

[Licensing - Events Per Day]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `licensing_epd` | stats sum(count) as count by _time | eval avg_eps=round(count/86400,1) | sort 0 -_time

[Licensing - Events Per Day Over Time]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
dispatchAs                                = user
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = column
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
search                                    = | `licensing_epd` | timechart span=1d sum(count) as count

[Licensing - Events Per Index (Last Day)]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
search                               = | `licensing_epd` | eventstats max(_time) | where _time='max(_time)' | table _time,index,count | sort 0 - count
[Audit - Anomalous Audit Trail Activity Detected - Rule]
disabled = 0

#####################
## Identity
#####################

###### Correlation Searches ######
[Identity - High Volume Email Activity with Non-corporate Domains - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = High Volume Email Activity to Non-corporate Domains by User
action.correlationsearch.related_searches = ["Identity - Email Activity to Non-corporate Domains by Users Per 1d - Context Gen"]
action.email.sendresults                  = 0
action.notable.param.security_domain      = identity
action.notable.param.severity             = high
action.notable.param.rule_title           = Emails to Non-corporate Domains from User ($src_user$)
action.notable.param.rule_description     = High volume email activity from a user to non-corporate domains was detected. This could be indicative of data exfiltration attempts. 
action.notable.param.nes_fields           = user
action.notable.param.drilldown_name       = View email activity from $src_user$
action.notable.param.drilldown_search     = | from datamodel:"Email"."All_Email" | search src_user=$src_user$
action.notable.param.default_status       =
action.notable.param.default_owner        =
action.risk                               = 1
action.risk.param._risk_object            = src_user
action.risk.param._risk_object_type       = user
action.risk.param._risk_score             = 50
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = src_user
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 25 * * * *
description                               = Alerts on high volume email activity by a user to non-corporate domains.
disabled                                  = True
dispatch.earliest_time                    = -70m@m
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
schedule_window                           = 5
search                                    = | tstats `summariesonly` sum(All_Email.size) as bytes, values(All_Email.recipient) as recipient from datamodel=Email.All_Email where NOT `cim_corporate_email_domain_search("All_Email.recipient")` by All_Email.src_user | `drop_dm_object_name("All_Email")` | xsfindbestconcept bytes from email_volume_1h_noncorp | eval risk_score=case(BestConcept="extreme",80,BestConcept="high",50,BestConcept="medium",20, 1==1, 0) | search risk_score>0

[Identity - Web Uploads to Non-corporate Domains - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Web Uploads to Non-corporate Sites by Users
action.correlationsearch.related_searches = ["Identity - Web Uploads to Non-corporate Domains by Users Per 1d - Context Gen"]
action.email.sendresults                  = 0
action.notable.param.security_domain      = identity
action.notable.param.severity             = high
action.notable.param.rule_title           = Web Uploads to Non-corporate Domains from User ($user$)
action.notable.param.rule_description     = Web Uploads by a user to non-corporate domains was detected. This could be indicative of data exfiltration attempts. 
action.notable.param.nes_fields           = user
action.notable.param.drilldown_name       = View web uploads by $user$
action.notable.param.drilldown_search     = | from datamodel:"Web"."Web" | search user=$user$
action.notable.param.default_status       =
action.notable.param.default_owner        =
action.risk                               = 1
action.risk.param._risk_object            = user
action.risk.param._risk_object_type       = user
action.risk.param._risk_score             = 50
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = user
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 35 * * * *
description                               = Alerts on high volume web uploads by a user to non-corporate domains.
disabled                                  = True
dispatch.earliest_time                    = -70m@m
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
schedule_window                           = 5
search                                    = | tstats `summariesonly` sum(Web.bytes) as bytes from datamodel=Web.Web where (Web.http_method="POST" OR Web.http_method="PUT")  NOT (`cim_corporate_web_domain_search("Web.url")`) by Web.user | `drop_dm_object_name("Web")` | xsfindbestconcept bytes from web_volume_1h_noncorp | eval risk_score=case(BestConcept="extreme",80,BestConcept="high",50,BestConcept="medium",20, 1==1, 0) | search risk_score>0


###### Key Indicator Searches ######

[Identity - High Risk Users]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Total High Risk Users
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 =
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.group.0.name              = user_activity
action.keyindicator.group.0.order             = 0
# | from datamodel:"Risk"."All_Risk" | search risk_object_type="user"
action.keyindicator.drilldown_uri             = search?q=%7C%20from%20datamodel%3A%22Risk%22.%22All_Risk%22%20%7C%20search%20risk_object_type%3D%22user%22&earliest=-48h%40h&latest=now
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Total High Risk Users
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc("All_Risk.risk_object") as current_count from datamodel=Risk.All_Risk where All_Risk.risk_object_type="user" earliest=-24h@h latest=+0s | appendcols [|tstats `summariesonly` estdc("All_Risk.risk_object") as historical_count from datamodel=Risk.All_Risk where All_Risk.risk_object_type="user" earliest=-48h@h latest=-24h@h] | `get_delta`

[Identity - High Risk User Events]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Total High Risk User Events
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 =
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
action.keyindicator.group.0.name              = user_activity
action.keyindicator.group.0.order             = 1
# | from datamodel:"Risk"."All_Risk" | search risk_object_type="user"
action.keyindicator.drilldown_uri             = search?q=%7C%20from%20datamodel%3A%22Risk%22.%22All_Risk%22%20%7C%20search%20risk_object_type%3D%22user%22&earliest=-48h%40h&latest=now
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Total High Risk User Events
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count as current_count from datamodel=Risk.All_Risk where All_Risk.risk_object_type="user" All_Risk.risk_score>60 earliest=-24h@h latest=+0s  | appendcols [|tstats `summariesonly` count as historical_count from datamodel=Risk.All_Risk where All_Risk.risk_object_type="user" All_Risk.risk_score>60 earliest=-48h@h latest=-24h@h ]| `get_delta`

[Identity - Noncorporate Web Activity]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Noncorp Web Volume
action.keyindicator.subtitle                  = Bytes
action.keyindicator.value                     = current_size
action.keyindicator.threshold                 =
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(Web.bytes) as current_size from datamodel=Web.Web where  earliest=-24h@h latest=+0s NOT(`cim_corporate_web_domain_search("Web.url")`) (Web.http_method="POST" OR Web.http_method="PUT") by Web.url
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(Web.bytes)%20as%20current_size%20from%20datamodel%3DWeb.Web%20where%20%20earliest%3D-24h%40h%20latest%3D%2B0s%20NOT(%60cim_corporate_web_domain_search(%22Web.url%22)%60)%20(Web.http_method%3D%22POST%22%20OR%20Web.http_method%3D%22PUT%22)%20by%20Web.url&earliest=-48h%40h&latest=now
action.keyindicator.group.0.name              = user_activity
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Noncorp Web Volume
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` sum(Web.bytes) as current_size from datamodel=Web.Web where  earliest=-24h@h latest=+0s NOT(`cim_corporate_web_domain_search("Web.url")`) (Web.http_method="POST" OR Web.http_method="PUT") | appendcols[|tstats `summariesonly` sum(Web.bytes) as historical_size from datamodel=Web.Web where earliest=-48h@h latest=-24h@h NOT(`cim_corporate_web_domain_search("Web.url")`) (Web.http_method="POST" OR Web.http_method="PUT")] |  `get_delta(current_size, historical_size)`

[Identity - Noncorporate Email Activity]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Noncorp Email Volume
action.keyindicator.subtitle                  = Bytes
action.keyindicator.value                     = current_size
action.keyindicator.threshold                 =
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` sum(All_Email.size) as current_size from datamodel=Email.All_Email where earliest=-24h@h latest=+0s NOT `cim_corporate_email_domain_search("All_Email.recipient")` by All_Email.recipient
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20sum(All_Email.size)%20as%20current_size%20from%20datamodel%3DEmail.All_Email%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20NOT%20%60cim_corporate_email_domain_search(%22All_Email.recipient%22)%60%20by%20All_Email.recipient
action.keyindicator.group.0.name              = user_activity
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Noncorp Web Volume
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` sum(All_Email.size) as current_size from datamodel=Email.All_Email where earliest=-24h@h latest=+0s NOT `cim_corporate_email_domain_search("All_Email.recipient")` | appendcols[| tstats `summariesonly` sum(All_Email.size) as historical_size from datamodel=Email.All_Email where earliest=-48h@h latest=-24h@h NOT `cim_corporate_email_domain_search("All_Email.recipient")`] | `get_delta(current_size, historical_size)`

[Identity - Watchlisted Website Activity]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Watchlisted Websites
action.keyindicator.subtitle                  = Access Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 =
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Web.Web where Web.tag="web_watchlist" by Web.url
action.keyindicator.drilldown_uri             = search?earliest=-48h%40h&latest=now&q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DWeb.Web%20where%20Web.tag%3D%22web_watchlist%22%20by%20Web.url
action.keyindicator.group.0.name              = user_activity
action.keyindicator.group.0.order             = 4
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Watchlisted Websites
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` count as current_count from datamodel=Web.Web where  Web.tag="web_watchlist" earliest=-24h@h latest=+0s | appendcols[ | tstats `summariesonly` count as historical_count from datamodel=Web.Web where  Web.tag="web_watchlist" earliest=-48h@h latest=-24h@h  ] | `get_delta`
       

###### Swim Lane Searches ######
[Identity - Emails to Noncorporate Domains - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = Non-corporate Emails
action.swimlane.color                                = orange
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = All_Email.src_user,src_user
action.swimlane.drilldown_search                     = | from datamodel:"Email"."All_Email" | search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = User Activity
display.page.identity_investigator.0.order           = 0 
is_visible                                           = false
request.ui_dispatch_app                              = SplunkEnterpriseSecuritySuite
search                                               = | tstats `summariesonly` sum(All_Email.size) as bytes, values(All_Email.src_user) as src_user, values(All_Email.recipient) as recipient, values(All_Email.subject) as subject, count from datamodel=Email.All_Email where $constraints$ NOT `cim_corporate_email_domain_search("All_Email.recipient")` by _time span=$span$

[Identity - Noncorporate Web Uploads - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = Non-corporate Web Uploads
action.swimlane.color                                = yellow
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = Web.user,user
action.swimlane.drilldown_search                     = | from datamodel:"Web"."Web" | search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = User Activity
display.page.identity_investigator.0.order           = 1
is_visible                                           = false
request.ui_dispatch_app                              = SplunkEnterpriseSecuritySuite
search                                               = | tstats `summariesonly` sum(Web.bytes) as bytes, values(Web.user) as user, values(Web.url) as url, values(Web.http_method) as http_method, values(Web.http_content_type) as http_content_type, count from datamodel=Web.Web where $constraints$  NOT(`cim_corporate_web_domain_search("Web.url")`) (Web.http_method="POST" OR Web.http_method="PUT") by _time span=$span$ | `drop_dm_object_name("Web")`

[Identity - Watchlisted Sites - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = Watchlisted Sites
action.swimlane.color                                = red
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = Web.user,user
action.swimlane.drilldown_search                     = | from datamodel:"Web"."Web" |  search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = User Activity
display.page.identity_investigator.0.order           = 2
is_visible                                           = false
request.ui_dispatch_app                              = SplunkEnterpriseSecuritySuite
search                                               = | tstats `summariesonly` count, values(Web.user) as user, values(Web.url) as url, values(Web.src) as src  from datamodel=Web.Web where $constraints$ Web.tag="web_watchlist" by _time span=$span$ | `drop_dm_object_name("Web")`

[Identity - Remote Access - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = Remote Access
action.swimlane.color                                = blue
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = Authentication.user,user
action.swimlane.drilldown_search                     = | from datamodel:"Authentication"."Authentication" |  search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = User Activity
display.page.identity_investigator.0.order           = 3
is_visible                                           = false
request.ui_dispatch_app                              = SplunkEnterpriseSecuritySuite
search                                               = | tstats `summariesonly` count, values(Authentication.user) as user, values(Authentication.user_bunit) as user_bunit from datamodel=Authentication.Authentication where $constraints$ by Authentication.src, _time span=$span$ | `drop_dm_object_name("Authentication")` | `get_identity4events(user)` | `get_asset(src)` | iplocation src | eval src_city=if(isnull(src_city), City,src_city) | eval src_country=if(isnull(src_country), Country,src_country) | where isnotnull(src_city) AND isnotnull(user_work_city) AND (lower(user_work_city)!=lower(src_city) OR lower(user_work_country)!=lower(src_country)) | stats sum(count) as count, values(user) as user, values(src) as src, values(user_bunit) as user_bunit, values(user_work_city) as user_work_city, values(src_city) as src_city, values(user_work_country) as user_work_country, values(src_country) as src_country by _time | fields count, user, user_bunit, src, user_work_city, user_work_country, src_city, src_country

[Identity - Tickets by User - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = Ticket Activity 
action.swimlane.color                                = green 
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = All_Ticket_Management.src_user,src_user
action.swimlane.drilldown_search                     = | from datamodel:"Ticket_Management"."All_Ticket_Management" |  search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = User Activity
display.page.identity_investigator.0.order           = 4
is_visible                                           = false
request.ui_dispatch_app                              = SplunkEnterpriseSecuritySuite
search                                               = | tstats `summariesonly` count, values(All_Ticket_Management.src_user) as src_user, values(All_Ticket_Management.description) as description, values(All_Ticket_Management.priority) as priority, values(All_Ticket_Management.severity) as severity from datamodel=Ticket_Management.All_Ticket_Management where $constraints$ by _time span=$span$ | `drop_dm_object_name("All_Ticket_Management")`

#####################
## Authentication
#####################

##### Context-updating searches #####
[Access - Authentication Failures By Source - Context Gen]
action.email.sendresults = 0
cron_schedule            = 0 3 * * *
dispatch.earliest_time   = -25h@h
dispatch.latest_time     = -1h@h
enableSched              = 1
is_visible               = false
schedule_window          = 20
search                   = | tstats `summariesonly` count as failures from datamodel=Authentication.Authentication where Authentication.action="failure" by Authentication.src,_time span=1h | stats median(failures) as median, min(failures) as min, count as count | eval max = median*2 | xsUpdateDDContext app="SA-AccessProtection" name=failures_by_src_count_1h container=authentication scope=app | stats count

[Access - Authentication Failures By Source Per Day - Context Gen]
action.email.sendresults = 0
cron_schedule            = 0 5 * * *
dispatch.earliest_time   = -31d@d
dispatch.latest_time     = -1d@d
enableSched              = 1
is_visible               = false
schedule_window          = 20
search                   = | tstats `summariesonly` count as failures from datamodel=Authentication.Authentication where Authentication.action="failure" by Authentication.src,_time span=1d | stats median(failures) as median, min(failures) as min, count as count | eval max = median*2 | xsCreateDDContext app="SA-AccessProtection" name=failures_by_src_count_1d container=authentication scope=app type=domain terms=`xs_default_magnitude_concepts` | stats count

[Access - Authentication Volume Per Day - Context Gen]
action.email.sendresults = 0
cron_schedule            = 0 4 * * *
dispatch.earliest_time   = -61d@d
dispatch.latest_time     = -1d@d
enableSched              = 1
is_visible               = false
schedule_window          = 20
search                   = | tstats `summariesonly` count as count_1d from datamodel=Authentication.Authentication by _time span=1d | stats count, median(count_1d) as median, stdev(count_1d) as size | search size>0 | xsCreateDDContext name=count_1d container=authentication type=median_centered scope=app app=SA-AccessProtection terms=`xs_default_magnitude_concepts` | stats count

###### Correlation Searches ######
[Access - Account Deleted - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Account Deleted
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":	  "Change",\
         "object":		  "Account_Management",\
         "earliest":      "rt-5m@m",\
         "latest":        "rt+5m@m",\
         "eventFilter":   "'All_Changes.tag'=\"delete\"",\
         "aggregates":    [{"function": "max", "attribute": "_time", "alias": "lastTime"},\
                           {"function": "latest", "attribute": "_raw", "alias": "orig_raw"},\
                           {"function": "values", "attribute": "All_Changes.result", "alias": "signature"},\
                           {"function": "values", "attribute": "All_Changes.src", "alias": "src"},\
                           {"function": "values", "attribute": "All_Changes.dest", "alias": "dest"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [{"attribute": "All_Changes.Account_Management.src_user", "alias": "src_user"},\
                           {"attribute": "All_Changes.user", "alias": "user"}\
                          ],\
         "resultFilter":  {"field": "count", "comparator": ">", "value": "0"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["user"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = access 
action.notable.param.severity         = medium
action.notable.param.rule_title       = Account Deleted
action.notable.param.rule_description = User ($src_user$) deleted account ($user$) on system ($dest$)
action.notable.param.nes_fields       = user
action.notable.param.drilldown_name   = View all account deletions by user ($src_user$)
action.notable.param.drilldown_search = | from datamodel:"Change"."Account_Management" | where 'tag'="delete" AND 'src_user'="$src_user$"
action.notable.param.default_status   =
action.notable.param.default_owner    =
action.risk                           = 1
action.risk.param._risk_object        = user
action.risk.param._risk_object_type   = user
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = user
alert.suppress.period                 = 86300s
alert.track                           = 0
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects user and computer account deletion
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
search                                = | from datamodel:"Change"."Account_Management" | where 'tag'="delete" | stats max(_time) as "lastTime",latest(_raw) as "orig_raw",values(result) as "signature",values(src) as "src",values(dest) as "dest",count by "src_user","user" | where 'count'>0

[Access - Brute Force Access Behavior Detected - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Brute Force Access Behavior Detected
action.correlationsearch.related_searches = ["Access - Authentication Failures By Source - Context Gen"]
## commenting guided mode for now, as this implementation does not allow for RT
#action.customsearchbuilder               = 0
#action.customsearchbuilder.enabled       = 1
#action.customsearchbuilder.routine       = make_correlation_search:makeCorrelationSearch
#action.customsearchbuilder.spec          = {\
#    "version":  "1.0",\
#    "searches": [\
#        {"key":          "src",\
#         "datamodel":    "Authentication",\
#         "object":       "Failed_Authentication",\
#         "earliest":     "-70m@m",\
#         "latest":       "+0s",\
#         "aggregates":   [{"function": "values", "attribute": "Authentication.tag", "alias": "tag"},\
#                          {"function": "count", "alias": "failed_count"}\
#                         ],\
#         "splitby":      [{"attribute": "Authentication.src", "alias": "src"}],\
#         "resultFilter": {"field": "failed_count", "comparator": ">", "value": "6"}\
#        },\
#        {"key":          "src",\
#         "datamodel":    "Authentication",\
#         "earliest":     "-70m@m",\
#         "latest":       "+0s",\
#         "object":       "Successful_Authentication",\
#         "aggregates":   [{"function": "count", "alias": "successful_count"}],\
#         "splitby":      [{"attribute": "Authentication.src", "alias": "src"}]\
#        }\
#    ],\
#    "alert.suppress":         "1",\
#    "alert.suppress.fields":  ["src"]\
#}
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = access
action.notable.param.severity             = high
action.notable.param.rule_title           = Brute Force Access Behavior Detected From $src$
action.notable.param.rule_description     = The system $src$ has failed authentication $failure$ times and successfully authenticated $success$ times in the last hour
action.notable.param.nes_fields           = src
action.notable.param.drilldown_name       = View all login attempts by system $src$
action.notable.param.drilldown_search     = | from datamodel:"Authentication"."Authentication" | search src="$src$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = src
action.risk.param._risk_object_type       = system
action.risk.param._risk_score             = 80
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = src
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = */5 * * * *
description                               = Detects excessive number of failed login attempts along with a successful attempt (this could indicate a successful brute force attack)
disabled                                  = True
dispatch.rt_backfill                      = 1
dispatch.earliest_time                    = rt-65m@m
dispatch.latest_time                      = rt+5m@m
enableSched                               = 1
is_visible                                = false
search                                    = | from datamodel:"Authentication"."Authentication" | stats values(tag) as tag,values(app) as app,count(eval('action'=="failure")) as failure,count(eval('action'=="success")) as success by src | search success>0 | xswhere failure from failures_by_src_count_1h in authentication is above medium

[Access - Brute Force Access Behavior Detected Over 1d - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Brute Force Access Behavior Detected Over One Day
action.correlationsearch.related_searches = ["Access - Authentication Failures By Source Per Day - Context Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = access
action.notable.param.severity             = high
action.notable.param.rule_title           = Brute Force Access Behavior Detected Over 1d From $src$
action.notable.param.rule_description     = The system $src$ has failed authentication $failure$ times and successfully authenticated $success$ times in the last day.
action.notable.param.nes_fields           = src
action.notable.param.drilldown_name       = View all login attempts by system $src$
action.notable.param.drilldown_search     = | from datamodel:"Authentication"."Authentication" | search src="$src$"
action.notable.param.default_status       =
action.notable.param.default_owner        =
action.risk                               = 1
action.risk.param._risk_object            = src
action.risk.param._risk_object_type       = system
action.risk.param._risk_score             = 80
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = src
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 0 1 * * *
description                               = Detects an excessive number of failed login attempts, along with a successful attempt, over a one day period (this could indicate a successful brute force attack)
disabled                                  = True
dispatch.rt_backfill                      = 1
dispatch.earliest_time                    = -25h@h
dispatch.latest_time                      = -1h@h
enableSched                               = 1
is_visible                                = false
schedule_window                           = 20
search                                    = | tstats `summariesonly` values(Authentication.app) as app,count from datamodel=Authentication.Authentication by Authentication.action,Authentication.src | `drop_dm_object_name("Authentication")` | eval success=if(action="success",count,0),failure=if(action="failure",count,0) | stats values(app) as app,sum(failure) as failure,sum(success) as success by src | where success > 0 | xswhere failure from failures_by_src_count_1d in authentication is above medium

[Access - Cleartext Password At Rest - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Cleartext Password At Rest Detected
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Compute_Inventory",\
         "object":        "Cleartext_Passwords",\
         "earliest":      "rt-5m@m",\
         "latest":        "rt+5m@m",\
         "aggregates":    [{"function": "max", "attribute": "_time", "alias": "lastTime"},\
                           {"function": "latest", "attribute": "_raw", "alias": "orig_raw"},\
                           {"function": "values", "attribute": "All_Inventory.tag", "alias": "tag"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "All_Inventory.dest", "alias": "dest"},\
                           {"attribute": "All_Inventory.User.user", "alias": "user"},\
                           {"attribute": "All_Inventory.User.password", "alias": "password"}\
                          ],\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest","user","password"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = access
action.notable.param.severity         = high
action.notable.param.rule_title       = Cleartext Password At Rest Detected
action.notable.param.rule_description = The system $dest$ is storing the password for user $user$ in the clear
action.notable.param.nes_fields       = dest,user,password
action.notable.param.drilldown_name   = View cleartext passwords for user $user$ on device $dest$
action.notable.param.drilldown_search = | from datamodel:"Compute_Inventory"."Cleartext_Passwords" | search dest="$dest$" user="$user$" password="$password$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest,user,password
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects cleartext passwords being stored at rest (such as in the Unix passwd file)
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Compute_Inventory"."Cleartext_Passwords" | stats max(_time) as "lastTime",latest(_raw) as "orig_raw",values(tag) as "tag",count by "dest","user","password"

[Access - Completely Inactive Account - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Completely Inactive Account
action.correlationsearch.related_searches = ["Access - Authentication Tracker - Lookup Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = access
action.notable.param.severity             = informational
action.notable.param.rule_title           = Completely Inactive Account For $user$
action.notable.param.rule_description     = User account $user$ has not successfully authenticated in 90 days.  Please verify this account is still needed.
action.notable.param.nes_fields           = user
action.notable.param.drilldown_name       = View inactive $user$ accounts
action.notable.param.drilldown_search     = | `inactive_accounts(90)` | `uitime(firstTime)` | `uitime(second2lastTime)` | `uitime(lastTime)` | search user="$user$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = user
action.risk.param._risk_object_type       = user
action.risk.param._risk_score             = 20
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = user
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 55 * * * *
description                               = Discovers accounts that are no longer used. Unused accounts should be disabled and are oftentimes used by attackers to gain unauthorized access.
disabled                                  = True
dispatch.earliest_time                    = 0
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
schedule_window                           = 5
search                                    = | from inputlookup:access_tracker | stats min(firstTime) as firstTime,max(lastTime) as lastTime by user | where ((now()-'lastTime')/86400)>90

[Access - Default Account Usage - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Default Account Activity Detected
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Authentication",\
         "object":        "Successful_Default_Authentication",\
         "earliest":      "rt-5m@m",\
         "latest":        "rt+5m@m",\
         "aggregates":    [{"function": "max", "attribute": "_time", "alias": "lastTime"},\
                           {"function": "values", "attribute": "Authentication.tag", "alias": "tag"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "Authentication.dest", "alias": "dest"},\
                           {"attribute": "Authentication.user", "alias": "user"},\
                           {"attribute": "Authentication.app", "alias": "app"}\
                          ],\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest","user","app"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = access
action.notable.param.severity         = low
action.notable.param.rule_title       = Default Account Activity Detected
action.notable.param.rule_description = User account $user$ is a default account that successfully authenticated to $dest$ at $lastTime$.  Please verify this activity conforms with your information security policy.
action.notable.param.nes_fields       = user,dest
action.notable.param.drilldown_name   = View usage of default account $user$ on device $dest$
action.notable.param.drilldown_search = | from datamodel:"Authentication"."Successful_Default_Authentication" | search dest="$dest$" user="$user$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 40
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = user,dest,app
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Discovers use of default accounts (such as admin, administrator, etc.). Default accounts have default passwords and are therefore commonly targeted by attackers using brute force attack tools.
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Authentication"."Successful_Default_Authentication" | stats max(_time) as "lastTime",values(tag) as "tag",count by "dest","user","app"

[Access - Default Accounts At Rest - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Default Account At Rest Detected
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Compute_Inventory",\
         "object":        "Default_Accounts",\
         "earliest":      "rt-5m@m",\
         "latest":        "rt+5m@m",\
         "eventFilter":   "NOT match('All_Inventory.enabled', \"0|[Ff]|[Ff][Aa][Ll][Ss][Ee]\") AND NOT 'All_Inventory.status'==\"Degraded\" AND NOT like('All_Inventory.User.shell',\"%nologin\") AND NOT like('All_Inventory.User.shell',\"%false\") AND 'All_Inventory.User.user'!=\"root\"",\
         "aggregates":    [{"function": "max", "attribute": "_time", "alias": "lastTime"},\
                           {"function": "latest", "attribute": "_raw", "alias": "orig_raw"},\
                           {"function": "values", "attribute": "All_Inventory.tag", "alias": "tag"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "All_Inventory.dest", "alias": "dest"},\
                           {"attribute": "All_Inventory.User.user", "alias": "user"}\
                          ],\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest","user"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = access
action.notable.param.severity         = low
action.notable.param.rule_title       = Default Account At Rest Detected
action.notable.param.rule_description = The device $dest$ currently allows authentication for the default account $user$.  Please verify your information security policy allows authentication for this account.
action.notable.param.nes_fields       = user,dest
action.notable.param.drilldown_name   = View default account $user$ at rest on device $dest$
action.notable.param.drilldown_search = | from datamodel:"Compute_Inventory"."Default_Accounts" | search dest="$dest$" user="$user$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 40
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = user,dest
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Discovers the presence of default accounts even if they are not being used. Default accounts should be disabled in order to prevent an attacker from using them to gain unauthorized access to remote hosts.
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Compute_Inventory"."Default_Accounts" | where NOT match('enabled', "0|[Ff]|[Ff][Aa][Ll][Ss][Ee]") AND NOT 'status'=="Degraded" AND NOT like('shell',"%nologin") AND NOT like('shell',"%false") AND 'user'!="root" | stats max(_time) as "lastTime",latest(_raw) as "orig_raw",values(tag) as "tag",count by "dest","user"

## Setting Threshold @ 6 per 8.5.13
[Access - Excessive Failed Logins - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Excessive Failed Logins
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Authentication",\
         "object":        "Failed_Authentication",\
         "earliest":      "rt-65m@m",\
         "latest":        "rt-5m@m",\
         "aggregates":    [{"function": "values", "attribute": "Authentication.tag", "alias": "tag"},\
                           {"function": "dc", "attribute": "Authentication.user", "alias": "user_count"},\
                           {"function": "dc", "attribute": "Authentication.dest", "alias": "dest_count"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "Authentication.app", "alias": "app"},\
                           {"attribute": "Authentication.src", "alias": "src"}\
                          ],\
         "resultFilter":  {"field": "count", "comparator": ">=", "value": "6"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["app","src"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = access
action.notable.param.severity         = medium
action.notable.param.rule_title       = Excessive Failed Logins
action.notable.param.rule_description = The system $src$ has failed $app$ authentication $count$ times using $user_count$ username(s) against $dest_count$ target(s) in the last hour
action.notable.param.nes_fields       = src
action.notable.param.drilldown_name   = View all login failures by system $src$ for the application $app$
action.notable.param.drilldown_search = | from datamodel:"Authentication"."Failed_Authentication" | search src="$src$" app="$app$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = src
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = app,src
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects excessive number of failed login attempts (this is likely a brute force attack)
disabled                              = True
dispatch.earliest_time                = rt-65m@m
dispatch.latest_time                  = rt-5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Authentication"."Failed_Authentication" | stats values(tag) as "tag",dc(user) as "user_count",dc(dest) as "dest_count",count by "app","src" | where 'count'>=6

[Access - Inactive Account Usage - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Inactive Account Activity Detected
action.correlationsearch.related_searches = ["Access - Authentication Tracker - Lookup Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = access
action.notable.param.severity             = low
action.notable.param.rule_title           = Inactive Account Activity Detected For $user$
action.notable.param.rule_description     = User account $user$ was inactive for $inactiveDays$ days but logged in at $lastTime$.  Please verify this account is still needed.
action.notable.param.nes_fields           = user
action.notable.param.drilldown_name       = View usage of previously inactive account $user$
action.notable.param.drilldown_search     = | `access_tracker` | search user="$user$" | `uitime(firstTime)` | `uitime(second2lastTime)` | `uitime(lastTime)`
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = user
action.risk.param._risk_object_type       = user
action.risk.param._risk_score             = 40
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = user
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 55 * * * *
description                               = Discovers previously inactive accounts that are now being used. This may be due to an attacker that successfully gained access to an account that was no longer being used.
disabled                                  = True
dispatch.earliest_time                    = 0
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
schedule_window                           = 5
search                                    = | `inactive_account_usage("90","2")` | `ctime(lastTime)` | fields + user,tag,inactiveDays,lastTime

[Access - Insecure Or Cleartext Authentication - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Insecure Or Cleartext Authentication Detected
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Authentication",\
         "object":        "Insecure_Authentication",\
         "earliest":      "rt-5m@m",\
         "latest":        "rt+5m@m",\
         "aggregates":    [{"function": "max", "attribute": "_time", "alias": "lastTime"},\
                           {"function": "latest", "attribute": "_raw", "alias": "orig_raw"},\
                           {"function": "values", "attribute": "Authentication.tag", "alias": "tag"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "Authentication.app", "alias": "app"},\
                           {"attribute": "Authentication.dest", "alias": "dest"}\
                          ],\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["app","dest"]\
}
action.email.sendresults              = 0
action.notable.param.security_domain  = access
action.notable.param.severity         = high
action.notable.param.rule_title       = Insecure Or Cleartext Authentication Detected
action.notable.param.rule_description = The device $dest$ is accepting insecure or cleartext $app$ authentication
action.notable.param.nes_fields       = dest,app
action.notable.param.drilldown_name   = View insecure or cleartext authentication requests for $app$ on device $dest$
action.notable.param.drilldown_search = | from datamodel:"Authentication"."Insecure_Authentication" | search app="$app$" dest="$dest$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
action.notable                        = 1
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = app,dest
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Detects authentication requests that transmit the password over the network as cleartext (unencrypted)
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
search                                = | from datamodel:"Authentication"."Insecure_Authentication" | stats max(_time) as "lastTime",latest(_raw) as "orig_raw",values(tag) as "tag",count by "app","dest"


###### Lookup Generating Searches ######

## Access - Authentication Tracker - Lookup Gen Breakdown
## 1-2 - tstats query for successful authentication data
##   3 - renaming fields
##   4 - consolidation into min(_time), values(_time), and max(_time) by dest,user
##   5 - input access_tracker
##   6 - convert "dest" to lowercase and "user" to lowercase
##   7 - consolidation into min(firstTime), values(second2lastTime), values(lastTime), and max(lastTime) by dest,user
##   8 - compute second2lastTime
##   9 - compute firstTime_user and lastTime_user
##  10 - remove lastTime_vals
##  11 - write lookup
##  12 - purge results
[Access - Authentication Tracker - Lookup Gen]
action.email.sendresults = 0
cron_schedule            = 5 * * * *
description              = Maintains a list of users that have authenticated to each system and the first, second to last, and last time they have been seen
dispatch.earliest_time   = -70m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
schedule_window          = 5
search                   = | tstats `summariesonly` count from datamodel=Authentication.Authentication where Authentication.action=success Authentication.dest!=unknown Authentication.user!=unknown by _time,Authentication.dest,Authentication.user span=1s | `drop_dm_object_name("Authentication")` | stats min(_time) as firstTime,values(_time) as second2lastTime,max(_time) as lastTime by dest,user | inputlookup append=T access_tracker | eval dest=lower(dest),user=lower(user) | stats min(firstTime) as firstTime,values(second2lastTime) as second2lastTime,values(lastTime) as lastTime_vals,max(lastTime) as lastTime by dest,user | eval `get_second2lastTime_meval(second2lastTime,lastTime_vals,lastTime)` | eventstats min(firstTime) as firstTime_user,max(lastTime) as lastTime_user by user | fields - lastTime_vals | outputlookup override_if_empty=false access_tracker | stats count

## Access - Access App Tracker - Lookup Gen Breakdown
## 1-2 - tstats query for distinct apps
##   3 - input access_tracker
##   4 - consolidation of tstats and access_tracker
##   5 - write lookup
##   6 - purge results
[Access - Access App Tracker - Lookup Gen]
action.customsearchbuilder          = 0
action.customsearchbuilder.enabled  = 1
action.customsearchbuilder.routine  = make_lookup_generating_search:makeLookupGeneratingSearch
action.customsearchbuilder.spec     = {\
    "version":      "1.0",\
    "search":       {\
	    "datamodel":     "Authentication",\
	    "object":        "Authentication",\
        "earliest":      "-30m@m",\
        "latest":        "+0s",\
        "eventFilter":   "'Authentication.app'!=\"unknown\"",\
		"aggregates":    [{"function": "min", "attribute": "_time", "alias": "firstTime"},\
	                      {"function": "max", "attribute": "_time", "alias": "lastTime"}\
	                     ],\
	    "splitby":       [{"attribute": "Authentication.app", "alias": "app"}],\
        "summariesonly": "1",\
        "outputlookup":  "access_app_tracker",\
        "retention":     {\
            "earliestTime":  "-5y",\
            "timeField":     "lastTime",\
            "timeFormat":    "%s"\
        }\
    }\
}
action.email.sendresults = 0
cron_schedule            = */15 * * * *
description              = Maintains a list of Authentication app values and the first and last time they have been seen
dispatch.earliest_time   = -30m@m
dispatch.latest_time     = +0s
enableSched              = 1
is_visible               = false
search                   = | tstats summariesonly=true allow_old_summaries=true min(_time) as "firstTime",max(_time) as "lastTime" from datamodel="Authentication"."Authentication" where    "Authentication.app"!="unknown" by "Authentication.app"  | rename "Authentication.app" as "app" | inputlookup append=T "access_app_tracker" | stats min(firstTime) as "firstTime",max(lastTime) as "lastTime" by "app" | where strptime('lastTime', "%s")>=relative_time(now(), "-5y") | outputlookup override_if_empty=false "access_app_tracker" | stats count
[Access - Authentication Failures By Source - Context Gen]

[Access - Excessive Failed Logins - Rule]
disabled = 0

[Access - Brute Force Access Behavior Detected - Rule]
action.customsearchbuilder.spec = {}
action.email = 1
action.email.to = cyrus_tam@macroview.com
action.notable.param.extract_assets = ["src","dest","dvc","orig_host"]
action.notable.param.extract_identities = ["src_user","user"]
disabled = 0
request.ui_dispatch_app = search

###### Correlation Searches ######
[Endpoint - Host Sending Excessive Email - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Host Sending Excessive Email
action.correlationsearch.related_searches = [\
    "Endpoint - Emails By Source - Context Gen",\
    "Endpoint - Emails By Destination Count - Context Gen"\
]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = endpoint
action.notable.param.severity             = high
action.notable.param.rule_title           = Host Sending Excessive Email ($src$)
action.notable.param.rule_description     = The device $src$ was detected making $count$ SMTP connections to $dest_count$ destinations.
action.notable.param.nes_fields           = src
action.notable.param.drilldown_name       = View email-related traffic for source $src$ for this event
action.notable.param.drilldown_search     = | from datamodel:"Email"."All_Email" | where 'src'="$src$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = src
action.risk.param._risk_object_type       = system
action.risk.param._risk_score             = 80
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = src
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 55 * * * *
description                               = Alerts when an host not designated as an e-mail server sends excessive e-mail to one or more target hosts.
disabled                                  = True
dispatch.earliest_time                    = -70m@m
dispatch.latest_time                      = +0s
enableSched                               = True
is_visible                                = false
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
schedule_window                           = 5
search                                    = | tstats `summariesonly` sum(All_Email.recipient_count) as count,dc(All_Email.dest) as dest_count from datamodel=Email.All_Email where NOT All_Email.src_category="email_servers" by "All_Email.src",_time span=1h | `drop_dm_object_name("All_Email")` | xswhere count from recipients_by_src_1h in email is above medium OR dest_count from destinations_by_src_1h in email is above medium

###### Report Searches ######
[Endpoint - SSHD Configurations By System]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -48h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = `sshdconfig` | stats max(_time) as _time,latest(sshd_protocol) as sshd_protocol by dest | fields _time,dest,sshd_protocol

[Endpoint - SELinux Configurations By System]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -48h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = `selinuxconfig` | stats max(_time) as _time,latest(selinux) as selinux by dest | fields _time,dest,selinux


#####################
## Endpoint
#####################

###### Correlation Searches ######
[Endpoint - Anomalous New Listening Port - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Anomalous New Listening Port
action.correlationsearch.related_searches = ["Endpoint - Listening Ports Tracker - Lookup Gen"]
action.customsearchbuilder                = 0
action.customsearchbuilder.enabled        = 1
action.customsearchbuilder.routine        = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec           = {\
    "version":  "1.0",\
    "searches": [\
        {"inputlookup":  {"lookupName": "listeningports_tracker", "timeField":  "firstTime"},\
         "earliest":     "-24h@h",\
         "latest":       "+0s",\
         "aggregates":   [{"function": "dc", "attribute": "dest", "alias": "dest_count"}],\
         "splitby":      [\
                          {"attribute": "transport"},\
                          {"attribute": "dest_port"}\
                         ],\
         "resultFilter": {"field": "dest_count", "comparator": ">", "value": "10"}\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["transport","dest_port"]\
}
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = endpoint
action.notable.param.severity             = low
action.notable.param.rule_title           = Anomalous New Listening Port ($transport$/$dest_port$)
action.notable.param.rule_description     = $dest_count$ hosts were found to begin listening on port $transport$/$dest_port$ within the last 24 hours. This may indicate that software was recently installed on the hosts; this software may be associated with malware which oftentimes opens a backdoor using a network port.
action.notable.param.nes_fields           = dest_port,transport
action.notable.param.drilldown_name       = View systems listening on $transport$/$dest_port$
action.notable.param.drilldown_search     = | from datamodel:"Endpoint"."Ports" | search dest_port="$dest_port$" transport="$transport$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = dest_port
action.risk.param._risk_object_type       = other
action.risk.param._risk_score             = 40
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = transport,dest_port
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 25 * * * *
description                               = Alerts a series of hosts begin listening on a new port within 24 hours. This may be an indication that the devices have been compromised or have had new (and potentially vulnerable) software installed.
disabled                                  = True
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
## This remains implemented using the listeningports_tracker which will maintain true firstTime for us
schedule_window                           = 5
search                                    = | from inputlookup:"listeningports_tracker" | eval earliestQual=case(match("-24h@h", "^\d"), tostring("-24h@h"),  match("-24h@h", "^([@\+-]){1}"), relative_time(time(), "-24h@h"),  true(), time()) | eval latestQual=case(match("+0s", "^\d"), tostring("+0s"),  match("+0s", "^([@\+-]){1}"), relative_time(time(), "+0s"),  true(), time()) | where ('firstTime'>=earliestQual AND 'firstTime'<=latestQual) | fields - earliestQual, latestQual | stats dc(dest) as "dest_count" by "transport","dest_port" | where 'dest_count'>10

[Endpoint - Host With Excessive Number Of Listening Ports - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Host With High Number Of Listening ports
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":	  "Endpoint",\
         "object":		  "Ports",\
         "earliest":      "-1450m@m",\
         "latest":        "+0s",\
         "aggregates":    [{"function": "dc", "attribute": "Ports.transport_dest_port", "alias": "port_count"}],\
         "splitby":       [{"attribute": "Ports.dest", "alias": "dest"}],\
         "resultFilter":  {"field": "port_count", "comparator": ">", "value": "20"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = medium
action.notable.param.rule_title       = Host With High Number Of Listening Ports ($dest$)
action.notable.param.rule_description = A host ($dest$) was detected with a high number of listening ports ($port_count$).
action.notable.param.nes_fields       = dest
action.notable.param.drilldown_name   = View listening ports on $dest$
action.notable.param.drilldown_search = | from datamodel:"Endpoint"."Ports" | search dest="$dest$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 10 * * * *
description                           = Alerts when host has a high number of listening services. This may be an indication that the device is running services that are not necessary (such as a default installation of a server) or is not running a firewall.
disabled                              = True
dispatch.earliest_time                = -1450m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | tstats summariesonly=true allow_old_summaries=true dc(Ports.transport_dest_port) as "port_count" from datamodel="Endpoint"."Ports"  by "Ports.dest" | rename "Ports.dest" as "dest" | where 'port_count'>20

[Endpoint - Host With Excessive Number Of Processes - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = High Process Count
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = medium
action.notable.param.rule_title       = Host With High Process Count ($dest$)
action.notable.param.rule_description = A host ($dest$) was detected with a high number of processes ($process_count$).
action.notable.param.nes_fields       = dest
action.notable.param.drilldown_name   = View processes on $dest$
action.notable.param.drilldown_search = | from datamodel:"Endpoint"."Processes" | search dest="$dest$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 30 * * * *
description                           = Alerts when host has a high number of processes. This may be due to an infection or a runaway process.
disabled                              = True
dispatch.earliest_time                = -1450m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
## Based on the amount of variability in process names we compute only the most recent processes detected by a system
## This requires that all processes detected are logged with the same _time value per iteration
## NOTE:  This was also the default behavior prior to the tstats implementation of this correlation search
schedule_window                       = 5
search                                = | tstats `summariesonly` max(_time) as _time from datamodel=Endpoint.Processes by Processes.dest,Processes.process | `drop_dm_object_name("Processes")` | eventstats max(_time) as lastReportTime by dest | where _time==lastReportTime | stats dc(process) as process_count by dest | search process_count>200

[Endpoint - Host With Excessive Number Of Services - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Host With High Number Of Services
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":	  "Endpoint",\
         "object":		  "Services",\
         "earliest":      "-1450m@m",\
         "latest":        "+0s",\
         "aggregates":    [{"function": "dc", "attribute": "Services.service", "alias": "service_count"}],\
         "splitby":       [{"attribute": "Services.dest", "alias": "dest"}],\
         "resultFilter":  {"field": "service_count", "comparator": ">", "value": "100"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = medium
action.notable.param.rule_title       = Host With High Number Of Services ($dest$)
action.notable.param.rule_description = A host ($dest$) was detected with a high number of services ($service_count$).
action.notable.param.nes_fields       = dest
action.notable.param.drilldown_name   = View services on $dest$
action.notable.param.drilldown_search = | from datamodel:"Endpoint"."Services" | search dest="$dest$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 60
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 55 * * * *
description                           = Alerts when host has a high number of services. This may be an indication that the device is running services that are not necessary (such as a default installation of a server).
disabled                              = True
dispatch.earliest_time                = -1450m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | tstats summariesonly=true allow_old_summaries=true dc(Services.service) as "service_count" from datamodel="Endpoint"."Services"  by "Services.dest" | rename "Services.dest" as "dest" | where 'service_count'>100

###### Report Searches ######
[App State - Ports By System Count]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` dc(Ports.dest) as dest_count from datamodel=Endpoint.Ports by Ports.transport,Ports.dest_port | `drop_dm_object_name("Ports")` | sort 100 - dest_count

[App State - Systems By Port Count]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(Ports.transport_dest_port) as port_count from datamodel=Endpoint.Ports by Ports.dest | `drop_dm_object_name("Ports")` | sort 10 - port_count

[App State - Processes By System Count]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` max(_time) as _time from datamodel=Endpoint.Processes by Processes.dest,Processes.process_name | `drop_dm_object_name("Processes")` | eventstats max(_time) as lastReportTime by dest | where _time==lastReportTime | stats dc(dest) as dest_count by process_name | sort 100 - dest_count

[App State - Systems By Process Count]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` max(_time) as _time from datamodel=Endpoint.Processes by Processes.dest,Processes.process | `drop_dm_object_name("Processes")` | eventstats max(_time) as lastReportTime by dest | where _time==lastReportTime | stats dc(process) as process_count by dest | sort 10 - process_count

[App State - Services By System Count]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` dc(Services.dest) as dest_count from datamodel=Endpoint.Services by Services.service | `drop_dm_object_name("Services")` | sort 100 - dest_count

[App State - Systems By Service Count]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(Services.service) as service_count from datamodel=Endpoint.Services by Services.dest | `drop_dm_object_name("Services")` | sort 10 - service_count


#####################
## Endpoint Changes
#####################

###### Correlation Searches #######
[Change - Abnormally High Number of Endpoint Changes By User - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Abnormally High Number of Endpoint Changes By User
action.correlationsearch.related_searches = ["Change - Total Change Count By User By Change Type Per Day - Context Gen"]
action.email.sendresults                  = 0
action.notable.param.rule_title           = Abnormally High Number of Endpoint Changes By User
action.risk                               = 1
action.risk.param._risk_object            = user
action.risk.param._risk_object_type       = user
action.risk.param._risk_score             = 40
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = user, change_type
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 5 * * * *
description                               = Detects an abnormally high number of endpoint changes by user account, as they relate to restarts, audits, filesystem, user, and registry modifications.
disabled                                  = True
dispatch.earliest_time                    = -1450m@m
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
schedule_window                           = 5
search                                    = | `tstats` count from datamodel=Endpoint.Filesystem where Filesystem.tag="change" by Filesystem.user | eval change_type="filesystem",user='Filesystem.user' | `tstats` append=T count from datamodel=Endpoint.Registry where Registry.tag="change" by Registry.user | eval change_type=if(isnull(change_type),"registry",change_type),user=if(isnull(user),'Registry.user',user) | `tstats` append=T count from datamodel=Change.All_Changes where nodename="All_Changes.Endpoint_Changes" by All_Changes.change_type,All_Changes.user | eval change_type=if(isnull(change_type),'All_Changes.change_type',change_type),user=if(isnull(user),'All_Changes.user',user) | stats count as change_count by change_type,user | xswhere change_count from change_count_by_user_by_change_type_1d in change_analysis by change_type is above high

###### Report Searches ######
[Change - Endpoint Changes By Action]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Endpoint.Filesystem where Filesystem.tag="change" by Filesystem.action | eval action='Filesystem.action' | `tstats` append=T count from datamodel=Endpoint.Registry where Registry.tag="change" by Registry.action | eval action=if(isnull(action),'Registry.action',action) | `tstats` append=T count from datamodel=Change.All_Changes where nodename="All_Changes.Endpoint_Changes" by All_Changes.action | eval action=if(isnull(action),'All_Changes.action',action) | timechart minspan=10m useother=`useother` count by action

[Change - Endpoint Changes By Type]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | `tstats` count from datamodel=Endpoint.Filesystem where Filesystem.tag="change" | eval object_category="file" | `tstats` append=T count from datamodel=Endpoint.Registry where Registry.tag="change" | eval object_category=if(isnull(object_category),"registry",object_category) | `tstats` append=T count from datamodel=Change.All_Changes where nodename="All_Changes.Endpoint_Changes" by All_Changes.object_category | eval object_category=if(isnull(object_category),'All_Changes.object_category',object_category) | stats count by object_category | sort 10 - count

[Change - Recent Endpoint Changes]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.events.fields            = ["object_category", "action", "object_path", "dest"]
display.events.list.wrap         = true
display.events.rowNumbers        = false
display.events.type              = list
display.general.enablePreview    = true
display.general.type             = events
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | multisearch [| from datamodel:Endpoint.Filesystem | search tag="change"] [| from datamodel:Endpoint.Registry | search tag="change"] [| from datamodel:Change.Endpoint_Changes | search tag="change"] | head 1000

[Change - Endpoint Changes By System]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | `tstats` count from datamodel=Endpoint.Filesystem where Filesystem.tag="change" by _time,Filesystem.dest | eval object_category="file",dest='Filesystem.dest' | `tstats` append=T count from datamodel=Endpoint.Registry where Registry.tag="change" by _time,Registry.dest | eval object_category=if(isnull(object_category),"registry",object_category),dest=if(isnull(dest),'Registry.dest',dest) | `tstats` append=T count from datamodel=Change.All_Changes where nodename="All_Changes.Endpoint_Changes" by _time,All_Changes.object_category,All_Changes.dest | eval object_category=if(isnull(object_category),'All_Changes.object_category',object_category),dest=if(isnull(dest),'All_Changes.dest',dest) | stats count by _time,object_category,dest | stats sparkline(sum(count)) as sparkline,values(object_category) as object_category,sum(count) as count by dest | sort 100 - count

###### Swim Lane Searches ######
[Change - All Changes By Asset - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = All Changes
action.swimlane.color                             = green
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = Filesystem.src,Filesystem.dest,Registry.src,Registry.dest,All_Changes.src,All_Changes.dest,src,dest
action.swimlane.drilldown_search                  = | multisearch [| from datamodel:Endpoint.Filesystem | search tag="change" ($constraints$)] [| from datamodel:Endpoint.Registry | search tag="change" ($constraints$)] [| from datamodel:Change.All_Changes | search $constraints$]
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 1
is_visible                                        = false
request.ui_dispatch_app                           = SplunkEnterpriseSecuritySuite
search                                            = | `tstats` values(Filesystem.action),values(Filesystem.file_path),values(Filesystem.dest),values(Filesystem.user),count from datamodel=Endpoint.Filesystem where Filesystem.tag=change ($constraints$) by _time span=$span$ | `sistats_values_rename(Filesystem.action,action)` | `sistats_values_rename(Filesystem.file_path,object)` | `sistats_values_rename(Filesystem.dest,dest)` | `sistats_values_rename(Filesystem.user,user)` | eval object_category="file" | `tstats` append=T values(Registry.action),values(Registry.registry_key_name),values(Registry.dest),values(Registry.user),count from datamodel=Endpoint.Registry where Registry.tag=change ($constraints$) by _time span=$span$ | `sistats_values_rename(Registry.action,action)` | `sistats_values_rename(Registry.registry_key_name,object)` | `sistats_values_rename(Registry.dest,dest)` | `sistats_values_rename(Registry.user,user)` | eval object_category=if(isnull(object_category),"registry",object_category) | `tstats` append=T values(All_Changes.action) as action,values(All_Changes.object) as object,values(All_Changes.src) as src,values(All_Changes.dest) as dest,values(All_Changes.user) as user,count from datamodel=Change.All_Changes where $constraints$ by _time,All_Changes.object_category span=$span$ | `sistats_values_rename(All_Changes.action,action)` | `sistats_values_rename(All_Changes.object,object)` | `sistats_values_rename(All_Changes.src,src)` | `sistats_values_rename(All_Changes.dest,dest)` | `sistats_values_rename(All_Changes.user,user)` | eval object_category=if(isnull(object_category),'All_Changes.object_category',object_category) | stats values(action) as action,values(object) as object,values(src) as src,values(dest) as dest,values(user) as user,count by _time,object_category | stats values(action) as action,values(object_category) as object_category,values(object) as object,values(src) as src,values(dest) as dest,values(user) as user,sum(count) as count by _time

[Change - All Changes By Identity - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = All Changes
action.swimlane.color                                = green
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = Filesystem.user,Registry.user,All_Changes.Account_Management.src_user,All_Changes.user,user,src_user
action.swimlane.drilldown_search                     = | multisearch [| from datamodel:Endpoint.Filesystem | search tag="change" ($constraints$)] [| from datamodel:Endpoint.Registry | search tag="change" ($constraints$)] [| from datamodel:Change.All_Changes | search $constraints$]
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 1
is_visible                                           = false
request.ui_dispatch_app                              = SplunkEnterpriseSecuritySuite
search                                               = | `tstats` values(Filesystem.action),values(Filesystem.file_path),values(Filesystem.dest),values(Filesystem.user),count from datamodel=Endpoint.Filesystem where Filesystem.tag=change ($constraints$) by _time span=$span$ | `sistats_values_rename(Filesystem.action,action)` | `sistats_values_rename(Filesystem.file_path,object)` | `sistats_values_rename(Filesystem.dest,dest)` | `sistats_values_rename(Filesystem.user,user)` | eval object_category="file" | `tstats` append=T values(Registry.action),values(Registry.registry_key_name),values(Registry.dest),values(Registry.user),count from datamodel=Endpoint.Registry where Registry.tag=change ($constraints$) by _time span=$span$ | `sistats_values_rename(Registry.action,action)` | `sistats_values_rename(Registry.registry_key_name,object)` | `sistats_values_rename(Registry.dest,dest)` | `sistats_values_rename(Registry.user,user)` | eval object_category=if(isnull(object_category),"registry",object_category) | `tstats` append=T values(All_Changes.action) as action,values(All_Changes.object) as object,values(All_Changes.src) as src,values(All_Changes.dest) as dest,values(All_Changes.user) as user,count from datamodel=Change.All_Changes where $constraints$ by _time,All_Changes.object_category span=$span$ | `sistats_values_rename(All_Changes.action,action)` | `sistats_values_rename(All_Changes.object,object)` | `sistats_values_rename(All_Changes.src,src)` | `sistats_values_rename(All_Changes.dest,dest)` | `sistats_values_rename(All_Changes.user,user)` | eval object_category=if(isnull(object_category),'All_Changes.object_category',object_category) | stats values(action) as action,values(object) as object,values(src) as src,values(dest) as dest,values(user) as user,count by _time,object_category | stats values(action) as action,values(object_category) as object_category,values(object) as object,values(src) as src,values(dest) as dest,values(user) as user,sum(count) as count by _time


#####################
## Compute Inventory
#####################

###### Report Searches ######
[Inventory - Operating Systems By System Count]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | from inputlookup:system_version_tracker | stats count by os

[Inventory - Users By System Count]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | from inputlookup:useraccounts_tracker | stats dc(dest) as dc(dest) by user | sort 10 - dc(dest)

[Inventory - Systems By User Count]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.timeRangePicker.show      = false
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | from inputlookup:useraccounts_tracker | stats dc(user) as dc(user) by dest | sort 10 - dc(user)


#####################
## Malware
#####################

###### Correlation Searches #######
[Endpoint - High Number of Hosts Not Updating Malware Signatures - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = High Number of Hosts Not Updating Malware Signatures
action.correlationsearch.related_searches = ["Endpoint - Malware Operations Tracker - Lookup Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = endpoint
action.notable.param.severity             = high
action.notable.param.rule_title           = High Number of Hosts Not Updating Malware Signatures
action.notable.param.rule_description     = A high number of hosts not updating malware signatures have been discovered.  $count$ hosts have not updated malware signatures in the last week. These hosts should be evaluated to determine why they are not updating their malware signatures.
action.notable.param.nes_fields           = 
action.notable.param.drilldown_name       = View systems not updating malware signatures
action.notable.param.drilldown_search     = | `malware_operations_tracker` | rename _time_signature_version as _time | `dayDiff(_time)` | search dayDiff>7 | sort - dayDiff | table _time,dest,dest_nt_domain,product_version,signature_version,vendor_product,dayDiff
action.notable.param.default_status       =
action.notable.param.default_owner        = 
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = const_dedup_id
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 40 * * * *
description                               = Alerts when a high number of hosts not updating malware signatures have been discovered.  These hosts should be evaluated to determine why they are not updating their malware signatures.
disabled                                  = True
dispatch.earliest_time                    = 0
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
schedule_window                           = 5
search                                    = | `malware_operations_tracker` | rename time_signature_version as _time | `dayDiff(_time)` | search dayDiff>7 | stats count | search count>10 | eval const_dedup_id="Endpoint - High Number of Hosts Not Updating Malware Signatures - Rule"

[Endpoint - High Number Of Infected Hosts - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = High Number Of Infected Hosts
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":	  "Malware",\
         "object":		  "Malware_Attacks",\
         "earliest":      "-15d",\
         "latest":        "+0s",\
         "aggregates":    [{"function": "estdc", "attribute": "Malware_Attacks.dest", "alias": "infected_hosts"}],\
         "resultFilter":  {"field": "infected_hosts", "comparator": ">", "value": "100"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["const_dedup_id"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = high
action.notable.param.rule_title       = High Number Of Infected Hosts ($infected_hosts$)
action.notable.param.rule_description = A high number of total infected systems was discovered. $infected_hosts$ hosts currently have an infection that was active in the last 15 days.
action.notable.param.drilldown_name   = View all malware infections
action.notable.param.drilldown_search = | from datamodel:"Malware"."Malware_Attacks"
action.notable.param.default_status   =
action.notable.param.default_owner    =
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = const_dedup_id
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 0 * * * *
description                           = Alerts when a high total number of infected hosts is discovered.
disabled                              = True
dispatch.earliest_time                = -15d
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
schedule_window                       = 5
search                                = | tstats summariesonly=true allow_old_summaries=true estdc(Malware_Attacks.dest) as "infected_hosts" from datamodel="Malware"."Malware_Attacks"    | where 'infected_hosts'>100 | eval const_dedup_id="const_dedup_id"

[Endpoint - High Or Critical Priority Host With Malware - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = High Or Critical Priority Host With Malware Detected
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":	  "Malware",\
         "object":		  "Malware_Attacks",\
         "earliest":      "rt-5m@m",\
         "latest":        "rt+5m@m",\
         "eventFilter":   "('Malware_Attacks.dest_priority'=\"high\" OR 'Malware_Attacks.dest_priority'=\"critical\")",\
         "aggregates":    [{"function": "max", "attribute": "_time", "alias": "lastTime"},\
                           {"function": "latest", "attribute": "_raw", "alias": "orig_raw"},\
                           {"function": "values", "attribute": "Malware_Attacks.dest_priority", "alias": "dest_priority"},\
                           {"function": "count"}\
                          ],\
         "splitby":       [\
                           {"attribute": "Malware_Attacks.dest", "alias": "dest"},\
                           {"attribute": "Malware_Attacks.signature", "alias": "signature"}\
                          ],\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest","signature"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = high
action.notable.param.rule_title       = High Or Critical Priority Host With Malware Detected
action.notable.param.rule_description = A high or critical priority host ($dest$) was detected with malware.
action.notable.param.nes_fields       = dest
action.notable.param.drilldown_name   = View infections on $dest$
action.notable.param.drilldown_search = | from datamodel:"Malware"."Malware_Attacks" | search dest="$dest$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest,signature
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = */5 * * * *
description                           = Alerts when an infection is noted on a host with high or critical priority.
disabled                              = True
dispatch.earliest_time                = rt-5m@m
dispatch.latest_time                  = rt+5m@m
dispatch.rt_backfill                  = 1
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
search                                = | from datamodel:"Malware"."Malware_Attacks" | where ('dest_priority'="high" OR 'dest_priority'="critical") | stats max(_time) as "lastTime",latest(_raw) as "orig_raw",values(dest_priority) as "dest_priority",count by "dest","signature"

[Endpoint - Host With Multiple Infections - Rule]
action.correlationsearch              = 0
action.correlationsearch.enabled      = 1
action.correlationsearch.label        = Host With Multiple Infections
action.customsearchbuilder            = 0
action.customsearchbuilder.enabled    = 1
action.customsearchbuilder.routine    = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec       = {\
    "version":  "1.0",\
    "searches": [\
        {"datamodel":     "Malware",\
         "object":        "Malware_Attacks",\
         "earliest":      "-1450m@m",\
         "latest":        "+0s",\
         "aggregates":    [{"function": "dc", "attribute": "Malware_Attacks.signature", "alias": "infection_count"}],\
         "splitby":       [{"attribute": "Malware_Attacks.dest", "alias": "dest"}],\
         "resultFilter":  {"field": "infection_count", "comparator": ">", "value": "1"},\
         "summariesonly": "1"\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["dest"]\
}
action.email.sendresults              = 0
action.notable                        = 1
action.notable.param.security_domain  = endpoint
action.notable.param.severity         = high
action.notable.param.rule_title       = Host With Multiple Infections ($dest$)
action.notable.param.rule_description = The device $dest$ was detected with multiple ($infection_count$) infections.
action.notable.param.nes_fields       = dest
action.notable.param.drilldown_name   = View all infection events associated with device $dest$
action.notable.param.drilldown_search = | from datamodel:"Malware"."Malware_Attacks" | search dest="$dest$"
action.notable.param.default_status   =
action.notable.param.default_owner    = 
action.risk                           = 1
action.risk.param._risk_object        = dest
action.risk.param._risk_object_type   = system
action.risk.param._risk_score         = 80
## action.summary_index._name present for migration purposes
action.summary_index._name            = notable
alert.digest_mode                     = 1
alert.suppress                        = 1
alert.suppress.fields                 = dest
alert.suppress.period                 = 86300s
alert.track                           = false
counttype                             = number of events
relation                              = greater than
quantity                              = 0
cron_schedule                         = 5,20,35,50 * * * *
description                           = Alerts when a host with multiple infections is discovered.
disabled                              = True
dispatch.earliest_time                = -1450m@m
dispatch.latest_time                  = +0s
enableSched                           = 1
is_visible                            = false
request.ui_dispatch_app               = SplunkEnterpriseSecuritySuite
search                                = | tstats summariesonly=true allow_old_summaries=true dc(Malware_Attacks.signature) as "infection_count" from datamodel="Malware"."Malware_Attacks"   by "Malware_Attacks.dest" | rename "Malware_Attacks.dest" as "dest" | where 'infection_count'>1

## per SOLNESS-6094:  There should be a much easier technique that we can employ here.  Basically the search language should:
## 1.  Look for new malware events in a non-overlapping fashion
## 2.  Perform a lookup to determine the firstTime we have seen that notable event
## 3.  If the difference between the _time and firstTime is >30days trigger
[Endpoint - Old Malware Infection - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = Host With Old Infection Or Potential Re-Infection
action.correlationsearch.related_searches = ["Endpoint - Malware Tracker - Lookup Gen"]
action.email.sendresults                  = 0
action.notable                            = 1
action.notable.param.security_domain      = endpoint
action.notable.param.severity             = high
action.notable.param.rule_title           = Host With Old Infection Or Potential Re-Infection ($signature$ On $dest$)
action.notable.param.rule_description     = The device $dest$ was detected with malware '$signature$' that was present $dayDiff$ days ago. This is either an old infection or a re-infection.
action.notable.param.nes_fields           = dest,signature
action.notable.param.drilldown_name       = View all $signature$ events for $dest$
action.notable.param.drilldown_search     = | from datamodel:"Malware"."Malware_Attacks" | search dest="$dest$" signature="$signature$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = dest
action.risk.param._risk_object_type       = system
action.risk.param._risk_score             = 80
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = dest,signature
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 45 * * * *
description                               = Alerts when a host with an old infection is discovered (likely a re-infection).
disabled                                  = True
dispatch.earliest_time                    = -70m@m
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
schedule_window                           = 5
search                                    = | tstats `summariesonly` max(_time) as lastTime from datamodel=Malware.Malware_Attacks by Malware_Attacks.signature,Malware_Attacks.dest | `drop_dm_object_name("Malware_Attacks")` | lookup local=true malware_tracker dest,signature OUTPUT firstTime | eval dayDiff=round((lastTime-firstTime)/86400,1) | search dayDiff>30

###### Key Indicator Searches ######

## Malware Center

[Malware - Infected System Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Infected Systems
action.keyindicator.subtitle                  = System Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s Malware_Attacks.action=allowed by Malware_Attacks.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DMalware.Malware_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Malware_Attacks.action%3Dallowed%20by%20Malware_Attacks.dest
action.keyindicator.group.0.name              = malware_center
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Infected System Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Malware_Attacks.dest) as current_count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s Malware_Attacks.action=allowed | appendcols [| tstats `summariesonly` estdc(Malware_Attacks.dest) as historical_count from datamodel=Malware.Malware_Attacks where earliest=-48h@h latest=-24h@h Malware_Attacks.action=allowed] | `get_delta`

[Malware - Multiple Infections]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Multiple Infections
action.keyindicator.subtitle                  = System Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` dc(Malware_Attacks.signature) as infection_count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s Malware_Attacks.action=allowed by Malware_Attacks.dest | search infection_count>1 
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20dc(Malware_Attacks.signature)%20as%20infection_count%20from%20datamodel%3DMalware.Malware_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Malware_Attacks.action%3Dallowed%20by%20Malware_Attacks.dest%20%7C%20search%20infection_count%3E1%20
action.keyindicator.group.0.name              = malware_center
action.keyindicator.group.0.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Infected System Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` dc(Malware_Attacks.signature) as infection_count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s Malware_Attacks.action=allowed by Malware_Attacks.dest | search infection_count>1 | stats count as current_count | appendcols [| tstats `summariesonly` dc(Malware_Attacks.signature) as infection_count from datamodel=Malware.Malware_Attacks where earliest=-48h@h latest=-24h@h Malware_Attacks.action=allowed by Malware_Attacks.dest | search infection_count>1 | stats count as historical_count] | `get_delta`

[Malware - New Infections]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = New Infections
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | from inputlookup:malware_tracker | `dayDiff(firstTime)` 
action.keyindicator.drilldown_uri             = search?q=%7C%20from%20inputlookup%3Amalware_tracker%20%7C%20%60dayDiff(firstTime)%60%20
action.keyindicator.group.0.name              = malware_center
action.keyindicator.group.0.order             = 0
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = New Infections
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | from inputlookup:malware_tracker | `dayDiff(firstTime)` | eval current_count=if(dayDiff<=1,1,0) | eval historical_count=if(dayDiff>1 AND dayDiff<=2,1,0) | stats sum(current_count) as current_count,sum(historical_count) as historical_count | `get_delta`

[Malware - Total Infection Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Total Infections
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` dc(Malware_Attacks.signature) as infection_count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s Malware_Attacks.action=allowed by Malware_Attacks.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20dc(Malware_Attacks.signature)%20as%20infection_count%20from%20datamodel%3DMalware.Malware_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Malware_Attacks.action%3Dallowed%20by%20Malware_Attacks.dest
action.keyindicator.group.0.name              = malware_center
action.keyindicator.group.0.order             = 4
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Total Infections
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` dc(Malware_Attacks.signature) as infection_count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s Malware_Attacks.action=allowed by Malware_Attacks.dest | stats sum(infection_count) as current_count | appendcols [| tstats `summariesonly` dc(Malware_Attacks.signature) as infection_count from datamodel=Malware.Malware_Attacks where earliest=-48h@h latest=-24h@h Malware_Attacks.action=allowed by Malware_Attacks.dest | stats sum(infection_count) as historical_count] | `get_ksi_fields(current_count,historical_count)` | xsFindBestConcept current_count from count_1d in malware as current_count_qual | xsfindbestconcept delta from percentile in default as delta_qual

[Malware - Unique Malware Count]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Unique Malware
action.keyindicator.subtitle                  = Unique Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s Malware_Attacks.action=allowed by Malware_Attacks.signature
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DMalware.Malware_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Malware_Attacks.action%3Dallowed%20by%20Malware_Attacks.signature
action.keyindicator.group.0.name              = malware_center
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Malware Count
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Malware_Attacks.signature) as current_count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s Malware_Attacks.action=allowed | appendcols [| tstats `summariesonly` estdc(Malware_Attacks.signature) as historical_count from datamodel=Malware.Malware_Attacks where earliest=-48h@h latest=-24h@h Malware_Attacks.action=allowed] | `get_delta`

## Malware Operations

[Malware - Average Infection Length]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Avg Infection Length
action.keyindicator.subtitle                  = Days
action.keyindicator.value                     = current_avg
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | from inputlookup:malware_tracker | `dayDiff(lastTime)` 
action.keyindicator.drilldown_uri             = search?q=%7C%20from%20inputlookup%3Amalware_tracker%20%7C%20%60dayDiff(lastTime)%60
action.keyindicator.group.0.name              = malware_operations
action.keyindicator.group.0.order             = 3
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Average Infection Length
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | from inputlookup:malware_tracker | `dayDiff(lastTime)` | eval current_diff=if(dayDiff<=7,(lastTime-firstTime)/86400,null()) | eval historical_diff=if(dayDiff>1 AND dayDiff<=8,(lastTime-firstTime)/86400,null()) | stats avg(current_diff) as current_avg,avg(historical_diff) as historical_avg | `round(current_avg,1)` | `round(historical_avg,1)` | `get_delta(current_avg,historical_avg)`

[Malware - Old Malware Defintions]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Old Malware Defs
action.keyindicator.subtitle                  = Client Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | from inputlookup:malware_operations_tracker | rename time_signature_version as _time | `dayDiff` 
action.keyindicator.drilldown_uri             = search?q=%7C%20from%20inputlookup%3Amalware_operations_tracker%20%7C%20rename%20time_signature_version%20as%20_time%20%7C%20%60dayDiff%60%20
action.keyindicator.group.0.name              = malware_operations
action.keyindicator.group.0.order             = 1
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Systems With Old Malware Definitions
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | from inputlookup:malware_operations_tracker | rename time_signature_version as _time | `dayDiff` | eval current_count=if(dayDiff>=7,1,0) | eval historical_count=if(dayDiff>=8,1,0) | stats sum(current_count) as current_count,sum(historical_count) as historical_count | `get_delta`

[Malware - Oldest Infection]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Oldest Infection
action.keyindicator.subtitle                  = Days
action.keyindicator.value                     = current_max
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | from inputlookup:malware_tracker | `dayDiff(lastTime)` 
action.keyindicator.drilldown_uri             = search?q=%7C%20from%20inputlookup%3Amalware_tracker%20%7C%20%60dayDiff(lastTime)%60%20
action.keyindicator.group.0.name              = malware_operations
action.keyindicator.group.0.order             = 4
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Oldest Infection
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | from inputlookup:malware_tracker | `dayDiff(lastTime)` | eval current_diff=if(dayDiff<=7,(lastTime-firstTime)/86400,null()) | eval historical_diff=if(dayDiff>1 AND dayDiff<=8,(lastTime-firstTime)/86400,null()) | stats max(current_diff) as current_max,max(historical_diff) as historical_max | `round(current_max,1)` | `round(historical_max,1)` | `get_delta(current_max,historical_max)`

[Malware - Percent Of Systems Infected]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Infected Systems
action.keyindicator.subtitle                  = Percent
action.keyindicator.value                     = current_percent
action.keyindicator.value_suffix              = % 
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s Malware_Attacks.action=allowed by Malware_Attacks.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20count%20from%20datamodel%3DMalware.Malware_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Malware_Attacks.action%3Dallowed%20by%20Malware_Attacks.dest
action.keyindicator.group.0.name              = malware_operations
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Percent Of Infected Systems
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Malware_Attacks.dest) as current_count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s Malware_Attacks.action=allowed | appendcols [| tstats `summariesonly` estdc(Malware_Attacks.dest) as historical_count from datamodel=Malware.Malware_Attacks where earliest=-48h@h latest=-24h@h Malware_Attacks.action=allowed] | appendcols [| from inputlookup:malware_operations_tracker | `daysago(30)` | stats count as total_count] | eval current_percent=round(current_count*100/total_count,1) | eval historical_percent=round(historical_count*100/total_count,1) | fields current_percent,historical_percent | `get_delta(current_percent,historical_percent)`

[Malware - Systems With Anti-Malware]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Malware Clients
action.keyindicator.subtitle                  = Client Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = true
# | from inputlookup:malware_operations_tracker | `dayDiff` 
action.keyindicator.drilldown_uri             = search?q=%7C%20from%20inputlookup%3Amalware_operations_tracker%20%7C%20%60dayDiff%60%20
action.keyindicator.group.0.name              = malware_operations
action.keyindicator.group.0.order             = 0
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Systems With Anti-Malware
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | from inputlookup:malware_operations_tracker | `dayDiff` | eval current_count=if(dayDiff<=7,1,0) | eval historical_count=if(dayDiff>1 AND dayDiff<=8,1,0) | stats sum(current_count) as current_count,sum(historical_count) as historical_count | `get_delta`

[Malware - Top Infection]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Top Infection
action.keyindicator.subtitle                  = $signature$
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` dc(Malware_Attacks.dest) as count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s by Malware_Attacks.signature
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20dc(Malware_Attacks.dest)%20as%20count%20from%20datamodel%3DMalware.Malware_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Malware_Attacks.signature
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Top Infection
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` dc(Malware_Attacks.dest) as current_count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s by Malware_Attacks.signature | join type=outer Malware_Attacks.signature [| tstats `summariesonly` dc(Malware_Attacks.dest) as historical_count from datamodel=Malware.Malware_Attacks where earliest=-48h@h latest=-24@h by Malware_Attacks.signature] | `drop_dm_object_name("Malware_Attacks")` | sort 1 - current_count | eval label=signature." was detected on ".current_count." systems" | eval label=if(current_count==1,replace(label,"systems","system"),label) | `get_delta` | fields label,signature,current_count,historical_count,delta

[Malware - Top Infected Domain]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Top Infected Domain
action.keyindicator.subtitle                  = $dest_nt_domain$
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` dc(Malware_Attacks.dest) as count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s by Malware_Attacks.dest_nt_domain 
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20dc(Malware_Attacks.dest)%20as%20count%20from%20datamodel%3DMalware.Malware_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Malware_Attacks.dest_nt_domain%20
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Top Infected Domain
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` dc(Malware_Attacks.dest) as current_count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s by Malware_Attacks.dest_nt_domain | join type=outer Malware_Attacks.dest_nt_domain [| tstats `summariesonly` dc(Malware_Attacks.dest) as historical_count from datamodel=Malware.Malware_Attacks where earliest=-48h@h latest=-24@h by Malware_Attacks.dest_nt_domain] | `drop_dm_object_name("Malware_Attacks")` | sort 1 - current_count | eval label=dest_nt_domain." has ".current_count." infected systems" | eval label=if(current_count==1,replace(label,"systems","system"),label) | `get_delta` | fields label,dest_nt_domain,current_count,historical_count,delta

[Malware - Top Infected System]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Top Infected System
action.keyindicator.subtitle                  =	$dest$
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` dc(Malware_Attacks.signature) as count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s by Malware_Attacks.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20dc(Malware_Attacks.signature)%20as%20count%20from%20datamodel%3DMalware.Malware_Attacks%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20by%20Malware_Attacks.dest
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Top Infected System
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` dc(Malware_Attacks.signature) as current_count from datamodel=Malware.Malware_Attacks where earliest=-24h@h latest=+0s by Malware_Attacks.dest | join type=outer Malware_Attacks.dest [| tstats `summariesonly` dc(Malware_Attacks.signature) as historical_count from datamodel=Malware.Malware_Attacks where earliest=-48h@h latest=-24@h by Malware_Attacks.dest] | `drop_dm_object_name("Malware_Attacks")` | sort 1 - current_count | eval label=dest." has ".current_count." unique infections" | eval label=if(current_count==1,replace(label,"infections","infection"),label) | `get_delta` | fields label,dest,current_count,historical_count,delta

###### Report Searches ######
[Endpoint - Application Errors]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.events.fields            = ["source", "sourcetype", "host", "event_id"] 
display.events.list.wrap         = true
display.events.rowNumbers        = false
display.events.type              = list
display.general.enablePreview    = true
display.general.type             = events
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = tag=endpoint tag=application tag=error | `get_event_id` | `parse_event_id(event_id)` | head 1000

[Malware - Average Infection Length Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -7d@d
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = connect
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = index=endpoint_summary source="Endpoint - Average Infection Length - Summary Gen" | timechart minspan=1h avg(avg_dayDiff) as avg_dayDiff

[Malware - Activity Over Time]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = zero
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Malware.Malware_Attacks by _time span=10m | timechart minspan=10m useother=`useother` count

[Malware - Activity Over Time By Action]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = connect
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` count from datamodel=Malware.Malware_Attacks by _time,Malware_Attacks.action span=10m | timechart minspan=10m useother=`useother` count by Malware_Attacks.action | `drop_dm_object_name("Malware_Attacks")`

[Malware - Activity Over Time By Infection]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
dispatchAs                                = user
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = column
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
display.visualizations.type               = charting
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | `tstats` count from datamodel=Malware.Malware_Attacks by _time,Malware_Attacks.signature span=10m | timechart minspan=10m useother=`useother` count by Malware_Attacks.signature | `drop_dm_object_name("Malware_Attacks")`

[Malware - Clients By Product Version]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | from inputlookup:malware_operations_tracker | stats count by product_version,vendor_product | sort 100 - count

[Malware - Clients By Signature Version]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | from inputlookup:malware_operations_tracker | stats count by signature_version,vendor_product | sort 100 - count

[Malware - Clients Not Updating Signatures]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | from inputlookup:malware_operations_tracker | rename time_signature_version as _time | eval dayDiff=round((now()-_time)/86400,2) | sort 100 + _time | table _time,dest,dest_nt_domain,product_version,signature_version,vendor_product,dayDiff

[Malware - Repeat Infections]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -30d@d
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` values(Malware_Attacks.action) as action,count from datamodel=Malware.Malware_Attacks where Malware_Attacks.action!=allowed by _time,Malware_Attacks.signature,Malware_Attacks.dest span=1d | `drop_dm_object_name("Malware_Attacks")` | stats values(action) as action,count as day_count by signature,dest | sort 100 - day_count

[Malware - New Malware]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | from inputlookup:malware_tracker | stats min(firstTime) as firstTime,dc(dest) by signature | eval _time=firstTime | `daysago(30)` | sort 100 - firstTime | `uitime(firstTime)` | fields firstTime,signature,dc(dest)

[Malware - Oldest Infections]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -30d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.timeRangePicker.show = false
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | inputlookup append=T malware_tracker where `tracker_trp(lastTime,lastTime)` | eval days_active=floor((lastTime-firstTime)/86400 + 1) | `uitime(firstTime)` | `uitime(lastTime)` | sort 100 - days_active | fields firstTime,lastTime,signature,dest,days_active

[Malware - Top 10 Infected Domains]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(Malware_Attacks.dest) as dest_count from datamodel=Malware.Malware_Attacks by Malware_Attacks.dest_nt_domain | `drop_dm_object_name("Malware_Attacks")` | sort 10 - dest_count

[Malware - Top 10 Infected Systems]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(Malware_Attacks.signature) as signature_count from datamodel=Malware.Malware_Attacks by Malware_Attacks.dest | `drop_dm_object_name("Malware_Attacks")` | sort 10 - signature_count

[Malware - Top 10 Infections]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` dc(Malware_Attacks.dest) as dest_count from datamodel=Malware.Malware_Attacks by Malware_Attacks.signature | `drop_dm_object_name("Malware_Attacks")` | sort 10 - dest_count

[Malware - Unique Infected Systems]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
dispatch.earliest_time                        = -24h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Infected Systems
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Malware_Attacks.dest) as estdc(dest) from datamodel=Malware.Malware_Attacks where Malware_Attacks.action="allowed"

[Malware - Unique Infections]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
dispatch.earliest_time                        = -24h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Unique Infections
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` estdc(Malware_Attacks.signature) as estdc(signature) from datamodel=Malware.Malware_Attacks where Malware_Attacks.action="allowed"

###### Swim Lane Searches ######
[Malware - All Malware Attacks By Asset - Swimlane]
action.email.reportServerEnabled                  = 0
action.swimlane                                   = 1
action.swimlane.title                             = Malware Attacks
action.swimlane.color                             = red
action.swimlane.constraint_method                 = reverse_asset_lookup
action.swimlane.constraint_fields                 = Malware_Attacks.dest,dest
action.swimlane.drilldown_search                  = | from datamodel:"Malware"."Malware_Attacks" | search $constraints$
alert.track                                       = 0
dispatch.latest_time                              = now
display.page.asset_investigator.0.collection_name = Default
display.page.asset_investigator.0.order           = 3
is_visible                                        = false
request.ui_dispatch_app                           = SplunkEnterpriseSecuritySuite
search                                            = | tstats `summariesonly` values(Malware_Attacks.action) as action,values(Malware_Attacks.signature) as signature,values(Malware_Attacks.dest) as dest,values(Malware_Attacks.user) as user,count from datamodel=Malware.Malware_Attacks where $constraints$ by _time span=$span$

[Malware - All Malware Attacks By Identity - Swimlane]
action.email.reportServerEnabled                     = 0
action.swimlane                                      = 1
action.swimlane.title                                = Malware Attacks
action.swimlane.color                                = red
action.swimlane.constraint_method                    = reverse_identity_lookup
action.swimlane.constraint_fields                    = Malware_Attacks.user,user
action.swimlane.drilldown_search                     = | from datamodel:"Malware"."Malware_Attacks" | search $constraints$
alert.track                                          = 0
dispatch.latest_time                                 = now
display.page.identity_investigator.0.collection_name = Default
display.page.identity_investigator.0.order           = 3
is_visible                                           = false
request.ui_dispatch_app                              = SplunkEnterpriseSecuritySuite
search                                               = | tstats `summariesonly` values(Malware_Attacks.action) as action,values(Malware_Attacks.signature) as signature,values(Malware_Attacks.dest) as dest,values(Malware_Attacks.user) as user,count from datamodel=Malware.Malware_Attacks where $constraints$ by _time span=$span$


#####################
## Peformance
#####################

###### Key Indicator Searches ######

## Timesync
[Performance - Number Of Systems Not Time Synchronizing]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Timesync Anomalies
action.keyindicator.subtitle                  = System Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = 
action.keyindicator.invert                    = false
# | tstats `summariesonly` max(_time) as lastTime from datamodel=Performance.All_Performance where nodename=All_Performance.OS.Timesync All_Performance.OS.Timesync.action=success by All_Performance.dest
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20max(_time)%20as%20lastTime%20from%20datamodel%3DPerformance.All_Performance%20where%20nodename%3DAll_Performance.OS.Timesync%20All_Performance.OS.Timesync.action%3Dsuccess%20by%20All_Performance.dest&earliest=-24h%40h&latest=now
## All time intentional here
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Timesync Anomalies
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` max(_time) as lastTime from datamodel=Performance.All_Performance where nodename=All_Performance.OS.Timesync All_Performance.OS.Timesync.action=success by All_Performance.dest | `drop_dm_object_name("All_Performance")` | `timeDiff(lastTime)` | search timeDiff>86400 | stats count as current_count

## Uptime
[Performance - Number Of Systems With Uptime Anomalies]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Uptime Anomalies
action.keyindicator.subtitle                  = System Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` latest(All_Performance.OS.Uptime.uptime) as uptime from datamodel=Performance.All_Performance where earliest=-48h@h latest=+0s nodename=All_Performance.OS.Uptime by All_Performance.dest | `drop_dm_object_name("All_Performance")` | where (uptime/86400)>30
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20latest(All_Performance.OS.Uptime.uptime)%20as%20uptime%20from%20datamodel%3DPerformance.All_Performance%20where%20earliest%3D-48h%40h%20latest%3D%2B0s%20nodename%3DAll_Performance.OS.Uptime%20by%20All_Performance.dest%20%7C%20%60drop_dm_object_name(%22All_Performance%22)%60%20%7C%20where%20(uptime%2F86400)%3E30
action.keyindicator.group.0.name              = update_center
action.keyindicator.group.0.order             = 2
dispatch.earliest_time                        = -96h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Uptime Anomalies
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` latest(All_Performance.OS.Uptime.uptime) as uptime from datamodel=Performance.All_Performance where earliest=-48h@h latest=+0s nodename=All_Performance.OS.Uptime by All_Performance.dest | `drop_dm_object_name("All_Performance")` | where (uptime/86400)>30 | stats count as current_count | appendcols [| tstats `summariesonly` latest(All_Performance.OS.Uptime.uptime) as uptime from datamodel=Performance.All_Performance where earliest=-96h@h latest=-48h@h nodename=All_Performance.OS.Uptime by All_Performance.dest | `drop_dm_object_name("All_Performance")` | where (uptime/86400)>30 | stats count as historical_count] | `get_delta`

###### Report Searches ######

## CPU
[Performance - Top-Average CPU Load Over Time By System]
action.email.reportServerEnabled                    = 0
alert.track                                         = 0
dispatch.earliest_time                              = -24h@h
dispatch.latest_time                                = now
dispatchAs                                          = user
display.general.enablePreview                       = 1
display.general.type                                = visualizations
display.statistics.rowNumbers                       = 0
display.statistics.wrap                             = 0
display.visualizations.charting.chart               = line
display.visualizations.charting.chart.nullValueMode = connect
display.visualizations.charting.drilldown           = all
display.visualizations.show                         = 1
display.visualizations.type                         = charting
request.ui_dispatch_app                             = SplunkEnterpriseSecuritySuite
search                                              = | `tstats` avg(All_Performance.CPU.cpu_load_percent) from datamodel=Performance.All_Performance where nodename=All_Performance.CPU [| `tstats` avg(All_Performance.CPU.cpu_load_percent) from datamodel=Performance.All_Performance where nodename=All_Performance.CPU by All_Performance.dest | stats avg(All_Performance.CPU.cpu_load_percent) as "avg" by All_Performance.dest | sort 10 - "avg" | fields All_Performance.dest | format] by _time,All_Performance.dest span=10m | timechart minspan=10m avg(All_Performance.CPU.cpu_load_percent) as "avg_cpu_load(%)" by All_Performance.dest | `drop_dm_object_name("All_Performance")`

## Memory
[Performance - Memory Utilization By System]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` latest(All_Performance.Memory.mem) as mem,latest(All_Performance.Memory.mem_used) as mem_used,latest(All_Performance.Memory.mem_free) as mem_free from datamodel=Performance.All_Performance where nodename=All_Performance.Memory by All_Performance.dest | `drop_dm_object_name("All_Performance")` | eval mem_used=if(isnotnull(mem) AND isnotnull(mem_free),mem-mem_free,null()) | eval mem_used_percent=if(isnotnull(mem) AND mem>0,round(mem_used*100/mem,1),null()) | sort 100 - mem_used_percent | eval "mem(GB)"=round(mem/1024,1) | eval "mem_used(GB)"=round(mem_used/1024,1) | eval "mem_free(GB)"=round(mem_free/1024,1) | fields dest,*(GB),mem_used_percent

## Storage
[Performance - Storage Utilization By System]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -48h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` latest(All_Performance.Storage.storage) as storage, latest(All_Performance.Storage.storage_free) as storage_free, latest(All_Performance.Storage.storage_free_percent) as storage_free_percent, latest(All_Performance.Storage.storage_used) as storage_used, latest(All_Performance.Storage.storage_used_percent) as storage_used_percent from datamodel=Performance.All_Performance where nodename=All_Performance.Storage by All_Performance.dest,All_Performance.Storage.mount | sort 100 + storage_free_percent | `drop_dm_object_name("All_Performance")` | `drop_dm_object_name("Storage")` | eval storage=if(isnull(storage) AND isnotnull(storage_free) AND isnotnull(storage_free_percent),(storage_free)*(1-(storage_free_percent/100)),storage) | eval storage_used=if(isnotnull(storage) AND isnotnull(storage_free),storage-storage_free,storage_used) | eval "storage(GB)"=round(storage/1073741824,1) | eval "storage_free(GB)"=round(storage_free/1073741824,1) | eval storage_free_percent=round(storage_free_percent,1) | eval "storage_used(GB)"=round(storage_used/1073741824,1) | fields dest,mount,*(GB),storage_free_percent

## Time Synchronization
[Performance - Time Synchronization Failures]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` max(_time) as _time,latest(All_Performance.dest_should_timesync) as dest_should_timesync,count from datamodel=Performance.All_Performance where nodename=All_Performance.OS.Timesync All_Performance.OS.Timesync.action=failure by All_Performance.dest | eval action="failure" | `drop_dm_object_name("All_Performance")` | fields _time,action,dest,dest_should_timesync,count

[Performance - Systems Not Time Synching]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -30d@d
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` min(_time) as firstTime,max(_time) as lastTime,latest(All_Performance.dest_should_timesync) as dest_should_timesync from datamodel=Performance.All_Performance where nodename=All_Performance.OS.Timesync All_Performance.OS.Timesync.action=success by All_Performance.dest | `drop_dm_object_name("All_Performance")` | `timeDiff(lastTime)` | search timeDiff>86400 | sort 100 + lastTime | `uitime(firstTime)` | `uitime(lastTime)` | fields firstTime,lastTime,dest,dest_should_timesync

[Performance - Indexing Time Delay By Host]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -7d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = `index_time_delta` | stats min(min_timeDiff) as min_timeDiff,max(max_timeDiff) as max_timeDiff,sum(sum_timeDiff) as sum_timeDiff,sum(count) as count by host | `get_asset(host)` | eval "min_diff(minutes)"=round(min_timeDiff/60,1) | eval "max_diff(minutes)"=round(max_timeDiff/60,1) | eval "avg_diff(minutes)"=round(sum_timeDiff/(count*60),1) | sort 100 + avg_diff(minutes) | fields host,host_should_timesync,min_diff(minutes),avg_diff(minutes),max_diff(minutes)

[Performance - Indexing Time Delay By Sourcetype]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -7d@d
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = `index_time_delta` | stats min(min_timeDiff) as min_timeDiff,max(max_timeDiff) as max_timeDiff,sum(sum_timeDiff) as sum_timeDiff,sum(count) as count by sourcetype | eval "min_diff(minutes)"=round(min_timeDiff/60,1) | eval "max_diff(minutes)"=round(max_timeDiff/60,1) | eval "avg_diff(minutes)"=round(sum_timeDiff/(count*60),1) | sort 100 + avg_diff(minutes) | fields sourcetype,min_diff(minutes),avg_diff(minutes),max_diff(minutes)

[Performance - Time Service Start Mode Anomalies]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | tstats `summariesonly` max(_time) as _time,latest(Services.start_mode) as start_mode,latest(Services.status) as status,latest(Services.dest_should_timesync) as dest_should_timesync from datamodel=Endpoint.Services where (Services.tag=time Services.tag=synchronize) by Services.dest,Services.service | `drop_dm_object_name("Services")` | search start_mode!=auto | sort 100 + start_mode | fields _time,dest,dest_should_timesync,service,start_mode,status

## Uptime
[Performance - Minimum System Uptime]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Minimum System Uptime
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` latest(All_Performance.OS.Uptime.uptime) as uptime from datamodel=Performance.All_Performance where nodename=All_Performance.OS.Uptime All_Performance.OS.Uptime.uptime!=unknown All_Performance.OS.Uptime.uptime>=0 by All_Performance.dest | sort 1 + uptime | `drop_dm_object_name("All_Performance")` | `uptime2string(uptime,uptime)` | eval label=dest." has been up for ".uptime | fields label,dest,uptime

[Performance - Average System Uptime]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Average System Uptime
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` avg(All_Performance.OS.Uptime.uptime) as avg_uptime from datamodel=Performance.All_Performance where nodename=All_Performance.OS.Uptime All_Performance.OS.Uptime.uptime!=unknown All_Performance.OS.Uptime.uptime>=0 | `uptime2string(avg_uptime,avg_uptime)` | rename avg_uptime as "avg(uptime)" | fields avg(uptime)

[Performance - Maximum System Uptime]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Maximum System Uptime
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` latest(All_Performance.OS.Uptime.uptime) as uptime from datamodel=Performance.All_Performance where nodename=All_Performance.OS.Uptime All_Performance.OS.Uptime.uptime!=unknown All_Performance.OS.Uptime.uptime>=0 by All_Performance.dest | sort 1 - uptime | `drop_dm_object_name("All_Performance")` | `uptime2string(uptime,uptime)` | eval label=dest." has been up for ".uptime | fields label,dest,uptime

[Performance - Uptime By System]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -48h@h
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` latest(All_Performance.OS.Uptime.uptime) as uptime from datamodel=Performance.All_Performance where nodename=All_Performance.OS.Uptime by All_Performance.dest | `drop_dm_object_name("All_Performance")` | sort 100 - uptime | `uptime2string(uptime,uptime)` | fields dest,uptime


#####################
## Updates
#####################

###### Key Indicator Searches ######
[Updates - Available Updates]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Available Updates
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = false
# | tstats `summariesonly` latest(Updates.status) as status from datamodel=Updates.Updates where earliest=-30d@d latest=+0s by Updates.dest,Updates.signature_id,Updates.vendor_product
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20latest(Updates.status)%20as%20status%20from%20datamodel%3DUpdates.Updates%20where%20earliest%3D-30d%40d%20latest%3D%2B0s%20by%20Updates.dest%2CUpdates.signature_id%2CUpdates.vendor_product
action.keyindicator.group.0.name              = update_center
action.keyindicator.group.0.order             = 3
dispatch.earliest_time                        = -37d@d
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Available Updates
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` latest(Updates.status) as status from datamodel=Updates.Updates where earliest=-30d@d latest=+0s by Updates.dest,Updates.signature_id,Updates.vendor_product | search status=available | stats count as current_count | appendcols [| tstats `summariesonly` latest(Updates.status) as status from datamodel=Updates.Updates where earliest=-37d@d latest=-7d@d by Updates.dest,Updates.signature_id,Updates.vendor_product | search status=available | stats count as historical_count] | `get_delta`

[Updates - Installed Updates]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Installed Updates
action.keyindicator.subtitle                  = Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = true
# | tstats `summariesonly` latest(Updates.status) as status from datamodel=Updates.Updates where earliest=-30d@d latest=+0s by Updates.dest,Updates.signature_id,Updates.vendor_product | search status=installed
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20latest(Updates.status)%20as%20status%20from%20datamodel%3DUpdates.Updates%20where%20earliest%3D-30d%40d%20latest%3D%2B0s%20by%20Updates.dest%2CUpdates.signature_id%2CUpdates.vendor_product%20%7C%20search%20status%3Dinstalled
action.keyindicator.group.0.name              = update_center
action.keyindicator.group.0.order             = 4
dispatch.earliest_time                        = -37d@d
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Installed Updates
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` latest(Updates.status) as status from datamodel=Updates.Updates where earliest=-30d@d latest=+0s by Updates.dest,Updates.signature_id,Updates.vendor_product | search status=installed | stats count as current_count | appendcols [| tstats `summariesonly` latest(Updates.status) as status from datamodel=Updates.Updates where earliest=-37d@d latest=-7d@d by Updates.dest,Updates.signature_id,Updates.vendor_product | search status=installed | stats count as historical_count] | `get_delta`

[Updates - Number Of Systems Not Updating]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Not Updating
action.keyindicator.subtitle                  = System Count
action.keyindicator.value                     = count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = 
action.keyindicator.invert                    = 
# | tstats `summariesonly` min(_time) as firstTime from datamodel=Updates.Updates where Updates.status=installed by Updates.dest,Updates.signature_id,Updates.vendor_product | `drop_dm_object_name("Updates")` | stats max(firstTime) as lastTime by dest | `dayDiff(lastTime)` | search dayDiff>30 
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20min(_time)%20as%20firstTime%20from%20datamodel%3DUpdates.Updates%20where%20Updates.status%3Dinstalled%20by%20Updates.dest%2CUpdates.signature_id%2CUpdates.vendor_product%20%7C%20%60drop_dm_object_name(%22Updates%22)%60%20%7C%20stats%20max(firstTime)%20as%20lastTime%20by%20dest%20%7C%20%60dayDiff(lastTime)%60%20%7C%20search%20dayDiff%3E30%20
action.keyindicator.group.0.name              = update_center
action.keyindicator.group.0.order             = 0
dispatch.earliest_time                        = -1y@d
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Systems Not Updating
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` min(_time) as firstTime from datamodel=Updates.Updates where Updates.status=installed by Updates.dest,Updates.signature_id,Updates.vendor_product | `drop_dm_object_name("Updates")` | stats max(firstTime) as lastTime by dest | `dayDiff(lastTime)` | search dayDiff>30 | stats count

[Updates - Number Of Systems With Start Mode Anomalies]
action.email.reportServerEnabled              = 0
alert.track                                   = 0
action.keyindicator                           = 1
action.keyindicator.title                     = Update Service Anomalies
action.keyindicator.subtitle                  = System Count
action.keyindicator.value                     = current_count
action.keyindicator.threshold                 = 
action.keyindicator.delta                     = delta
action.keyindicator.invert                    = 
# | tstats `summariesonly` latest(Services.start_mode) as start_mode,latest(Services.status) as status from datamodel=Endpoint.Services where earliest=-24h@h latest=+0s Services.tag=update by Services.dest | `drop_dm_object_name("Services")` | search start_mode!=auto
action.keyindicator.drilldown_uri             = search?q=%7C%20tstats%20%60summariesonly%60%20latest(Services.start_mode)%20as%20start_mode%2Clatest(Services.status)%20as%20status%20from%20datamodel%3DEndpoint.Services%20where%20earliest%3D-24h%40h%20latest%3D%2B0s%20Services.tag%3Dupdate%20by%20Services.dest%20%7C%20%60drop_dm_object_name(%22Services%22)%60%20%7C%20search%20start_mode!%3Dauto
action.keyindicator.group.0.name              = update_center
action.keyindicator.group.0.order             = 1
dispatch.earliest_time                        = -48h@h
dispatch.latest_time                          = now
display.general.enablePreview                 = 1
display.general.timeRangePicker.show          = false
display.general.type                          = visualizations
display.statistics.rowNumbers                 = 0
display.statistics.wrap                       = 0
display.visualizations.charting.drilldown     = all
display.visualizations.singlevalue.underLabel = Update Service Anomalies
display.visualizations.show                   = 1
display.visualizations.type                   = singlevalue
request.ui_dispatch_app                       = SplunkEnterpriseSecuritySuite
search                                        = | tstats `summariesonly` latest(Services.start_mode) as start_mode,latest(Services.status) as status from datamodel=Endpoint.Services where earliest=-24h@h latest=+0s Services.tag=update by Services.dest | `drop_dm_object_name("Services")` | search start_mode!=auto | stats count as current_count | appendcols [| tstats `summariesonly` latest(Services.start_mode) as start_mode,latest(Services.status) as status from datamodel=Endpoint.Services where earliest=-48h@h latest=-24h@h Services.tag=update by Services.dest | `drop_dm_object_name("Services")` | search start_mode!=auto | stats count as historical_count] | `get_delta`

###### Report Searches ######
[Updates - Available Updates By System]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -30d@d
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` latest(Updates.status) as status from datamodel=Updates.Updates by Updates.dest,Updates.signature_id,Updates.vendor_product | `drop_dm_object_name("Updates")` | search status=available | stats count by dest | `get_asset(dest)` | sort 100 - count | fields dest,dest_should_update,count

[Updates - Systems By Last Update Time]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -1y@d
dispatch.latest_time             = now
display.general.enablePreview    = 1
display.general.type             = statistics
display.statistics.drilldown     = row
display.statistics.rowNumbers    = 0
display.statistics.wrap          = 0
display.visualizations.show      = 0
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | tstats `summariesonly` min(_time) as _time,latest(Updates.dest_should_update) as dest_should_update from datamodel=Updates.Updates where Updates.status=installed by Updates.dest,Updates.signature_id,Updates.vendor_product | `drop_dm_object_name("Updates")` | stats max(_time) as lastTime,latest(dest_should_update) as dest_should_update by dest | eval dayDiff=round((now()-lastTime)/86400,1) | sort + lastTime | `uitime(lastTime)`

[Updates - Top Systems Needing Updates]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -30d@d
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` latest(Updates.status) as status from datamodel=Updates.Updates by Updates.dest,Updates.signature_id,Updates.vendor_product | `drop_dm_object_name("Updates")` | search status=available | stats count by dest | sort 10 - count

[Updates - Top Updates Needed]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -30d@d
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = bar
display.visualizations.charting.drilldown = all
display.visualizations.chartHeight        = 350
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` latest(Updates.status) as status from datamodel=Updates.Updates by Updates.dest,Updates.signature_id,Updates.vendor_product | `drop_dm_object_name("Updates")` | search status=available | stats count by signature_id | sort 10 - count

[Updates - Update Errors]
action.email.reportServerEnabled = 0
alert.track                      = 0
dispatch.earliest_time           = -24h@h
dispatch.latest_time             = now
display.events.fields            = ["source", "sourcetype", "host"] 
display.events.list.wrap         = true
display.events.rowNumbers        = false
display.events.type              = list
display.general.enablePreview    = true
display.general.type             = events
request.ui_dispatch_app          = SplunkEnterpriseSecuritySuite
search                           = | from datamodel:"Updates"."Update_Errors" | head 1000

[Updates - Update Service Start Mode Anomalies]
action.email.reportServerEnabled     = 0
alert.track                          = 0
dispatch.earliest_time               = -24h@h
dispatch.latest_time                 = now
display.general.enablePreview        = 1
display.general.type                 = statistics
display.statistics.drilldown         = row
display.statistics.rowNumbers        = 0
display.statistics.wrap              = 0
display.visualizations.show          = 0
request.ui_dispatch_app              = SplunkEnterpriseSecuritySuite
search                               = | tstats `summariesonly` latest(Services.start_mode) as start_mode,latest(Services.status) as status from datamodel=Endpoint.Services where Services.tag=update by Services.dest,Services.service | `drop_dm_object_name("Services")` | search start_mode!=auto | sort 100 + start_mode | fields dest,service,start_mode,status

[Updates - Updates By Status]
action.email.reportServerEnabled          = 0
alert.track                               = 0
dispatch.earliest_time                    = -30d@d
dispatch.latest_time                      = now
display.general.enablePreview             = 1
display.general.type                      = visualizations
display.statistics.rowNumbers             = 0
display.statistics.wrap                   = 0
display.visualizations.charting.chart     = pie
display.visualizations.charting.drilldown = all
display.visualizations.show               = 1
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
search                                    = | tstats `summariesonly` latest(Updates.status) as status from datamodel=Updates.Updates by Updates.dest,Updates.signature_id,Updates.vendor_product | `drop_dm_object_name("Updates")` | stats count by status | sort - count


#####################
## User Accounts
#####################

[Endpoint - Anomalous User Account Creation - Rule]
action.correlationsearch                  = 0
action.correlationsearch.enabled          = 1
action.correlationsearch.label            = New User Account Created On Multiple Hosts
action.correlationsearch.related_searches = ["Endpoint - User Account Tracker - Lookup Gen"]
action.email.sendresults                  = 0
action.customsearchbuilder                = 0
action.customsearchbuilder.enabled        = 1
action.customsearchbuilder.routine        = make_correlation_search:makeCorrelationSearch
action.customsearchbuilder.spec           = {\
    "version":  "1.0",\
    "searches": [\
        {"inputlookup":  {"lookupName": "useraccounts_tracker", "timeField":  "firstTime"},\
         "earliest":     "-24h@h",\
         "latest":       "+0s",\
         "aggregates":   [{"function": "dc", "attribute": "dest", "alias": "dest_count"}],\
         "splitby":      [{"attribute": "user"}],\
         "resultFilter": {"field": "dest_count", "comparator": ">", "value": "3"}\
        }\
    ],\
    "alert.suppress":        "1",\
    "alert.suppress.fields": ["user"]\
}
action.notable                            = 1
action.notable.param.security_domain      = endpoint
action.notable.param.severity             = medium
action.notable.param.rule_title           = User Account ($user$) Created On $dest_count$ Hosts
action.notable.param.rule_description     = A user account ($user$) was created on several $dest_count$ hosts in the last 24 hours.
action.notable.param.nes_fields           = user
action.notable.param.drilldown_name       = View activity for account $user$
action.notable.param.drilldown_search     = | from datamodel:"Compute_Inventory"."User" | search user="$user$"
action.notable.param.default_status       =
action.notable.param.default_owner        = 
action.risk                               = 1
action.risk.param._risk_object            = user
action.risk.param._risk_object_type       = user
action.risk.param._risk_score             = 60
## action.summary_index._name present for migration purposes
action.summary_index._name                = notable
alert.digest_mode                         = 1
alert.suppress                            = 1
alert.suppress.fields                     = user
alert.suppress.period                     = 86300s
alert.track                               = false
counttype                                 = number of events
relation                                  = greater than
quantity                                  = 0
cron_schedule                             = 40 * * * *
description                               = Alerts when a previously unseen account is created on multiple hosts.
disabled                                  = True
dispatch.earliest_time                    = -24h@h
dispatch.latest_time                      = +0s
enableSched                               = 1
is_visible                                = false
request.ui_dispatch_app                   = SplunkEnterpriseSecuritySuite
schedule_window                           = 5
search                                    = | from inputlookup:"useraccounts_tracker" | eval earliestQual=case(match("-24h@h", "^\d"), tostring("-24h@h"),  match("-24h@h", "^([@\+-]){1}"), relative_time(time(), "-24h@h"),  true(), time()) | eval latestQual=case(match("+0s", "^\d"), tostring("+0s"),  match("+0s", "^([@\+-]){1}"), relative_time(time(), "+0s"),  true(), time()) | where ('firstTime'>=earliestQual AND 'firstTime'<=latestQual) | fields - earliestQual, latestQual | stats dc(dest) as "dest_count" by "user" | where 'dest_count'>3
[Endpoint - High Number Of Infected Hosts - Rule]
action.customsearchbuilder.spec = {"version":"1.0","searches":[{"datamodel":"Malware","object":"Malware_Attacks","earliest":"-15d","latest":"+0s","aggregates":[{"function":"estdc","attribute":"Malware_Attacks.dest","alias":"infected_hosts"}],"resultFilter":{"field":"infected_hosts","comparator":">","value":"100"},"summariesonly":"1"}],"alert.suppress":"1","alert.suppress.fields":["const_dedup_id"]}
action.notable.param.extract_assets = ["src","dest","dvc","orig_host"]
action.notable.param.extract_identities = ["src_user","user"]
action.notable.param.severity = critical
disabled = 0

[Malware - Infected System Count]
action.keyindicator.group.1.name = security_posture
action.keyindicator.group.1.order = 6

[Malware - Total Infection Count]
action.keyindicator.group.1.name = security_posture
action.keyindicator.group.1.order = 15

[Change - Abnormally High Number of Endpoint Changes By User - Rule]
action.customsearchbuilder.spec = {}
action.email = 1
action.email.to = cyrus_tam@macroview.com
[Petya Ransomware Detector - Activity on Windows Hosts by File Hashes (Sysmon)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by File Hashes" Severity="8"\
src_ip="$result.ip$" Hashes=$result.Hashes$
action.logevent.param.index = petya_ransomware_detector
action.logevent.param.source = petya_ransomware_detector
action.logevent.param.sourcetype = petya_ransomware_detector
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimePetyaRansomwareDetector
request.ui_dispatch_view = search
search = index=*  source="WinEventLog:Microsoft-Windows-Sysmon/Operational"  (EventDescription="Process Create" OR EventDescription="File Create" ) | rex field=Hashes mode=sed "s/SHA256=//g" | rex field=Hashes mode=sed "s/SHA1=//g" | rex field=Hashes mode=sed "s/MD5=//g"| join Hashes [| inputlookup petya_hashes.csv | table Hash | rename Hash as Hashes] | rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip Hashes

[Petya Ransomware Detector - Activity on Windows Hosts by File Names (Sysmon)]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by File Names" Severity="8"\
src_ip="$result.ip$" FileName=$result.FileName$
action.logevent.param.index = petya_ransomware_detector
action.logevent.param.source = petya_ransomware_detector
action.logevent.param.sourcetype = petya_ransomware_detector
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimePetyaRansomwareDetector
request.ui_dispatch_view = search
search = index=*  source="WinEventLog:Microsoft-Windows-Sysmon/Operational"  (EventDescription="Process Create" OR EventDescription="File Create" ) |rename process as FileName |  join FileName [| inputlookup petya_files.csv | table FileName ]  |  rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip FileName

[Petya Ransomware Detector - Connection to Petya Distributions Sites]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to Petya Distributions Sites" Severity="7" src_ip="$result.src_ip$"  domain=$result.domain$
action.logevent.param.index = petya_ransomware_detector
action.logevent.param.source = petya_ransomware_detector
action.logevent.param.sourcetype = petya_ransomware_detector
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimePetyaRansomwareDetector
request.ui_dispatch_view = search
search = index=* tag=proxy (url=*french-cooking.com* OR url=*coffeinoffice.xyz* OR url="*185.165.29.78/~alex/svchost.exe" OR url="*84.200.16.242/myguy.xls" OR url="*french-cooking.com/myguy.exe&amp#39" OR url=*sundanders.online* OR url=*1000kiosks.com* or url=*acb-porte-et-fenetre.com* OR url=*acb-portes-et-fenetres.com* OR url=*acb-portesetfenetres.com* OR url=*acovel.com*  OR url=*afrochicparis.com* OR url=*albon.fr* OR url=*albonweb.com* OR url=*allia-france.com* OR url=*ambianceinformatique.fr* OR url=*angers-loire-aeroport.fr* OR url=*angersnautique.org* OR url=*anjou-sieges.com* OR url=*anjouloireterritoire.com* OR url=*antoinebeaumont.com* OR url=*arbres-de-memoire.com* OR url=*arbres-de-memoire.fr* OR url=*asso-ball.com* OR url=*avenir-meca.com* OR url=*axode-france.com* OR url=*axode-france.net* OR url=*axode-france.org* OR url=*axode.cn* OR url=*axode.com* OR url=*axode.eu* OR url=*axode.fr* OR url=*axode.org* OR url=*axodefrance.com* OR url=*axodefrance.net* OR url=*axodefrance.org* OR url=*bearn-loisirs.com* OR url=*bearn-loisirs.fr* OR url=*beaupreau-en-mauges.com* OR url=*beaupreau-en-mauges.org* OR url=*beaupreauenmauges.com* OR url=*beaute-femme-noire.com* OR url=*beaute-peau-noire.com* OR url=*bertranlotth.com* OR url=*bhrvegetal.com* OR url=*biogenix.fr* OR url=*bioparc-zoo.com* OR url=*bioparc-zoo.mobi* OR url=*biovac-autovaccins.fr* OR url=*biovac-reactifs.fr* OR url=*biovac-reagents.com* OR url=*biovac.fr* OR url=*blackcosmeticsparis.com* OR url=*bois-beton.com* OR url=*bois-beton.fr* OR url=*branly-lacaze.com* OR url=*bruno-pele-energie-renouvelable.com* OR url=*bureaux-locaux49.com* OR url=*campinglayole.mobi* OR url=*cao-concept.com* OR url=*caoconcept.com* OR url=*carre-installateur.com* OR url=*cash-to-card.com* OR url=*centrale-gge.com* OR url=*centredeformationdestaxis49.com* OR url=*chaillou.biz* OR url=*chalonnes-sur-loire.com* OR url=*chalonnes-sur-loire.info* OR url=*chalonnes-sur-loire.net* OR url=*chalonnes-sur-loire.org* OR url=*chemille-en-anjou.com* OR url=*chemilleenanjou.com* OR url=*cheveu-crepu.com* OR url=*chrono-laser.com* OR url=*chyporus.online* OR url=*clawap.fr* OR url=*colaissiere.com* OR url=*cornillelescaves.fr* OR url=*cppinvestissements.com* OR url=*c OR url=s-europe.com* OR url=*c OR url=s-hairs.com* OR url=*c OR url=s-products.com* OR url=*cvl-contract.com* OR url=*cvl-manufacture.com* OR url=*diouda-online.com* OR url=*diouda.biz* OR url=*drugrd.com* OR url=*dupire.com* OR url=*easyweeks.com* OR url=*ece-environnement.com* OR url=*echodesanes.com* OR url=*editionstequi.com* OR url=*effluservice.com* OR url=*emploi-saisonnier49.com* OR url=*esternayauto.com* OR url=*femme-beaute.fr* OR url=*filling-equipment.com* OR url=*formations-entreprises49.com* OR url=*foyerdarwin.com* OR url=*foyerormieres.fr* OR url=*fransal.com* OR url=*ftmeca.com* OR url=*gite-domaine-aux-moines.com* OR url=*groupe-deroure.com* OR url=*groupe-jenny.com* OR url=*imancosmetics.fr* OR url=*infoshow.fr* OR url=*institutdumanagementdigital.com* OR url=*iprim.fr* OR url=*laboiteajoujoux-cndc.com* OR url=*ladyblackparis.com* OR url=*lamaisoncreole.com* OR url=*leader-loisirs.fr* OR url=*lecouteux-branly.com* OR url=*lesvisitesvertes.com* OR url=*lesvisitesvertes.fr* OR url=*ligerim.fr* OR url=*logermonbusiness.com* OR url=*m-tourisme.com* OR url=*maepi.com* OR url=*maison-jamet.com* OR url=*maquillage-des-peaux-noires.com* OR url=*mauges-communaute.com* OR url=*maugescommunaute.com* OR url=*mecschaumiere.fr* OR url=*meublesinstinct.com* OR url=*meublesneova.com* OR url=*meublesneova.net* OR url=*mfam.fr* OR url=*mh-formation.com* OR url=*mieletgourmandises.fr* OR url=*mobilier-mousse-collectivites.com* OR url=*mobilier-mousse-direct.com* OR url=*mobilier-mousse.com* OR url=*modedirecte.com* OR url=*no-stress.org* OR url=*noireinparis.com* OR url=*nostress.net* OR url=*optilogistic.com* OR url=*optilogistic.eu* OR url=*optilogistic.fr* OR url=*optilogistic.net* OR url=*ouest-overseas.org* OR url=*outilleurs-angevins.fr* OR url=*packrasia.com* OR url=*panelia.fr* OR url=*patrimonia-bs.com* OR url=*physipro.fr* OR url=*pjcourtin.com* OR url=*plandanjou.com* OR url=*pomevasion.fr* OR url=*probalu.com* OR url=*probalu.fr* OR url=*profiltech.net* OR url=*prostyl.net* OR url=*prostyl.org* OR url=*ps-algerie.com* OR url=*rb2creations.com* OR url=*rougan-art.com* OR url=*salon-artisans-croisic.com* OR url=*sdmsodimat.com* OR url=*sieges-billes.com* OR url=*sieges-coussins-plein-air-direct.com* OR url=*sifom.com* OR url=*sigpizarras.com* OR url=*softec.fr* OR url=*spin-off.biz* OR url=*sportmaniac.co.in* OR url=*strategie-aims.com* OR url=*swissknot.com* OR url=*tarosani.com* OR url=*technicotheque.com* OR url=*unit-logistique.com* OR url=*viedenoir.com* OR url=*viedenoire.com* OR url=*viedenoire.fr* OR url=*visioptronic.com* OR url=*vita-consult.fr* OR url=*vitaconsult.fr* OR url=*vive-les-cheveux-crepus.com* OR url=*xn--chemill-en-anjou-hqb.com* OR url=*xn--chemillenanjou-hkb.com* OR url=*xn--grzill-cvae.com* OR url=*zoodessables.com* OR url=*zoodessables.mobi* OR url=*alimentsgenouel.alimentsgenouel.fr* OR url=*anena.anena-attelage.com* OR url=*angers.angers-kits-miniatures.com* OR url=*anjou.anjou-sieges.fr* OR url=*arcane.arcane-research.com* OR url=*bertranlotth.bertranlotth.fr* OR url=*caoconcept.caoconcept.fr* OR url=*cheminsdelarose.cheminsdelarose.fr* OR url=*cinemasdafrique.cinemasdafrique.asso.fr* OR url=*cmi.cmi-france.com* OR url=*cvl.cvl-contract.fr* OR url=*editions.editions-crer.fr* OR url=*fondation.fondation-visio.org* OR url=*lecouteux.lecouteux-branly-lacaze.com* OR url=*leraysecurite.leraysecurite.fr* OR url=*mail.tapodhan.de* OR url=*mecaflor.mecaflor.com* OR url=*meublesneova.meublesneova.fr* OR url=*midual.midual.com* OR url=*net.unimedia.fr* OR url=*optik.optik-telecom.fr* OR url=*philippelepape.philippelepape.com* OR url=*php53-1.unimedia.fr* OR url=*php53-3.unimedia.fr* OR url=*rblrei.rblrei-france.com* OR url=*saintmichelauto.saintmichelauto.fr* OR url=*samson.samson-horticulture.com* OR url=*visitesvertes.visitesvertes.tv* OR url=*vita.vita-consult.com* OR url=*www.aeria-ci.com* OR url=*www.grezille.com* OR url=*www.partenaires.anjou-sieges.fr* OR url=*zoodoue.zoodoue.fr*) NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rex field=url "((?:http(?:s)?:\/\/)?(?<domain>[\w\-\.]+)(?:\:|\/)?(?: \d+)?[^$]*)" | table _time src_ip domain

[Petya Ransomware Detector - Connections to Petya Hosts]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Connection to Petya Hosts " Severity="6" src_ip="$result.src_ip$" dest_ip=$result.IPAddress$ dest_port=$result.dest_port$
action.logevent.param.index = petya_ransomware_detector
action.logevent.param.source = petya_ransomware_detector
action.logevent.param.sourcetype = petya_ransomware_detector
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimePetyaRansomwareDetector
request.ui_dispatch_view = search
search = index=* (tag::eventtype="web" OR tag::eventtype="proxy" OR tag::eventtype="communicate" OR tag::eventtype="network") NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | rex field=dest "(?<IP_add>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(?<dest_port>\d+)" | rename dest_ip as clientip  | lookup ipdomain clientip  OUTPUT class | search NOT class=*  | rename clientip as IPAddress | search (IPAddress=111.90.139.247 OR IPAddress=84.200.16.242 OR IPAddress=95.141.115.108) | table  _time ,src_ip, IPAddress, dest_port

[Petya Ransomware Detector -Activity on Windows Hosts by Process]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Activity on Windows Hosts by Process" Severity="8"\
src_ip="$result.ip$" CommandLine="$result.CommandLine$"
action.logevent.param.index = petya_ransomware_detector
action.logevent.param.source = petya_ransomware_detector
action.logevent.param.sourcetype = petya_ransomware_detector
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimePetyaRansomwareDetector
request.ui_dispatch_view = search
search = index=*  source="WinEventLog:Microsoft-Windows-Sysmon/Operational"  (EventDescription="Process Create" OR EventDescription="File Create" )\
    (*\\10807.exe) OR (*\\5295.exe) OR (*\\BCA9D6.exe) OR (*\\mshta.exe) OR (*\\myguy.exe) OR (*\\myguy.xls) OR (*\\Order-20062017.doc) OR (*\\Quote-PO26062017A.msg)  | rename Computer as host | lookup dnsLookup host  OUTPUT ip | table _time ip CommandLine

[Petya Ransomware Detector - Petya Network Scan]
action.email.useNSSubject = 1
action.logevent = 1
action.logevent.param.event = $result._time$ Name="Petya Network Scan" Severity="8" src_ip="$result.src_ip$" HostsScanned=$result.HostsScanned$
action.logevent.param.index = petya_ransomware_detector
action.logevent.param.source = petya_ransomware_detector
action.logevent.param.sourcetype = petya_ransomware_detector
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = SOCPrimePetyaRansomwareDetector
request.ui_dispatch_view = search
search = index=* ( tag::eventtype="communicate" OR tag::eventtype="network") (dest_port=445 OR dest_port=135 OR dest_port=1024 OR dest_port=1025 OR dest_port=1026 OR dest_port=1027 OR dest_port=1028 OR dest_port=1029 OR dest_port=1030 OR dest_port=1031 OR dest_port=1032 OR dest_port=1033 OR dest_port=1034 OR dest_port=1035)  NOT ([|inputlookup exclude.csv| rename ip as src_ip |  fields src_ip ] OR [|inputlookup exclude.csv| rename ip as dest_ip |  fields dest_ip ]) | bucket _time span=60 | eventstats dc(dest_ip) AS HostsScanned by src_ip, _time |  where HostsScanned >= 30 | dedup src_ip, HostsScanned | table src_ip, HostsScanned, _time
